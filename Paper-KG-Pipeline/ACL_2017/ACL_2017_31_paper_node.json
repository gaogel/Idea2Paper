{
  "paper_id": "ACL_2017_31",
  "title": "Event Factuality Identification via Deep Neural Networks",
  "conference": "ACL",
  "domain": {
    "research_object": "研究对象为事件事实性识别，即判断文本中事件是否真实发生。",
    "core_technique": "采用深度神经网络方法对事件事实性进行自动识别和分类。",
    "application": "可应用于信息抽取、舆情分析、自动问答等自然语言处理任务。",
    "domains": [
      "自然语言处理",
      "人工智能"
    ]
  },
  "ideal": {
    "core_idea": "利用深度神经网络自动识别事件的事实性属性",
    "tech_stack": [
      "深度神经网络",
      "事件表示学习",
      "语义分析"
    ],
    "input_type": "包含事件的文本数据",
    "output_type": "事件的事实性分类标签（如事实、可能、虚构）"
  },
  "skeleton": {
    "problem_framing": "论文引言部分通过定义event factuality，并结合具体应用场景（如观点检测、问答、谣言识别等）展示其重要性。通过举例说明事件事实性在实际文本中的表现，增强了问题的现实意义和研究价值。",
    "gap_pattern": "作者指出现有方法在处理某些事实性类别（如CT-、PR+、PS+）时覆盖率低，仅占总值的7.57%，识别难度大。通过对比，强调了现有模型在这些类别上的不足，明确提出研究空白。",
    "method_story": "方法部分采用对比实验策略，详细描述了不同模型（如规则、MaxEnt、注意力神经网络）在各类别上的表现，突出新模型在难分类别上的优势，并通过宏、微平均指标体现性能均衡性。",
    "experiments_story": "实验部分先介绍数据集、评价指标和实验设置，确保实验的可复现性和科学性。随后分步骤报告结果，结合数据分布和交叉验证，系统分析模型在各事实性类别上的表现和整体效果。"
  },
  "tricks": [
    {
      "name": "定义核心概念",
      "type": "writing-level",
      "purpose": "帮助读者理解研究主题与背景",
      "location": "论文开头对event factuality的定义",
      "description": "在论文开头明确阐述event factuality的定义及其在NLP中的重要性，为后续方法和实验提供理论基础。"
    },
    {
      "name": "举例说明理论",
      "type": "writing-level",
      "purpose": "通过具体例句帮助读者理解抽象概念",
      "location": "紧接定义后的例句S1和S2",
      "description": "用标注事件和信息源的例句说明event factuality的具体表现，展示谓词和线索如何影响事件的事实性。"
    },
    {
      "name": "对比传统方法与新方法",
      "type": "writing-level",
      "purpose": "突出新方法的创新性和优势",
      "location": "介绍传统方法后转向神经网络方法",
      "description": "先介绍传统的规则和特征工程方法，再说明神经网络模型的改进和优越性，为新方法的提出做铺垫。"
    },
    {
      "name": "类别分布分析",
      "type": "experiment-level",
      "purpose": "揭示任务难点与模型挑战",
      "location": "分析CT-, PR+和PS+类别的覆盖率",
      "description": "通过统计分析不同类别的分布，指出某些类别样本稀少，强调模型在这些类别上的识别难度。"
    },
    {
      "name": "宏平均和微平均评价指标",
      "type": "experiment-level",
      "purpose": "全面衡量模型性能，避免类别不均衡影响结果",
      "location": "模型结果比较部分",
      "description": "采用macro和micro-averaging指标评价模型，确保结果不仅仅受主流类别影响，体现模型在各类别的均衡表现。"
    },
    {
      "name": "模型结构对比实验",
      "type": "method-level",
      "purpose": "验证不同模型设计的效果",
      "location": "比较单输出与双输出模型的实验结果",
      "description": "通过对比单输出和双输出结构，证明双输出设计能更好地利用推测和否定线索，提高模型在难分类别上的表现。"
    },
    {
      "name": "上下文特征建模",
      "type": "method-level",
      "purpose": "提升模型对句法和语义信息的捕捉能力",
      "location": "BiLSTM与CNN模型对比部分",
      "description": "强调BiLSTM能够从前后语境中学习特征，优于只关注局部信息的CNN，提升事件事实性识别的准确性。"
    },
    {
      "name": "引入注意力机制",
      "type": "method-level",
      "purpose": "增强模型对关键线索的关注，提高性能",
      "location": "讨论BiLSTM+CNN(Att)和CNN+CNN(Att)模型",
      "description": "在神经网络中加入attention机制，提升模型对关键信息的捕捉能力，实验显示引入注意力后性能显著提升。"
    },
    {
      "name": "统计显著性检验",
      "type": "experiment-level",
      "purpose": "证明模型改进的有效性具有统计意义",
      "location": "模型实验结果的p值报告",
      "description": "通过统计检验（如p<0.05, p<0.001）验证模型改进后的性能提升具有统计显著性，增强实验结果的说服力。"
    },
    {
      "name": "用表格系统展示结果",
      "type": "writing-level",
      "purpose": "清晰、系统地呈现实验数据，方便对比",
      "location": "Table 4展示各模型性能",
      "description": "采用表格方式集中展示各模型在不同类别上的表现，便于读者快速比较和理解实验结果。"
    }
  ]
}