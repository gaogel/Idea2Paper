[
  {
    "review_id": "673930d9f7da80b1",
    "paper_id": "ACL_2017_335",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "This work describes a gated attention-based recurrent neural network method for reading comprehension and question answering. This method employs a self-matching attention technique to counterbalance the limited context knowledge of gated attention-based recurrent neural networks when processing passages. Finally, authors use pointer networks  with signals from the question attention-based vector to predict the beginning and ending of the answer. \nExperimental results with the SQuAD dataset offer state-of-the-art performance compared with several recent approaches.  The paper is well-written, structured and explained. As far as I know, the mathematics look also good. In my opinion, this is a very interesting work which may be useful for the question answering community.\nI was wondering if the authors have plans to release the code of this approach. \nFrom that perspective, I miss a bit of information about the technology used for the implementation (theano, CUDA, CuDNN...), which may be useful for readers.\nI would appreciate if authors could perform a test of statistical significance of the results. That would highlight even more the quality of your results.\nFinally, I know that the space may be a constraint, but an evaluation including some additional dataset would validate more your work.",
    "overall_score": "4",
    "confidence": "2"
  },
  {
    "review_id": "793815387121a6cf",
    "paper_id": "ACL_2017_335",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "The paper clearly breaks the network into three component for descriptive purposes, relates each of them to prior work and mentions its novelties with respect to them. It does a sound empirical analysis by describing the impact of each component by doing an ablation study. This is appreciated.\nThe results are impressive!",
    "weaknesses": "The paper describes the results on a single model and an ensemble model. I could not find any details of the ensemble and how was it created. I believe it might be the ensemble of the character based and word based model. Can the authors please describe this in the rebuttal and the paper.",
    "comments": "Along with the ablation study, it would be nice if we can have a qualitative analysis describing some example cases where the components of gating, character embedding, self embedding, etc. become crucial ... where a simple model doesn't get the question right but adding one or more of these components helps. This can go in some form of appendix or supplementary.",
    "overall_score": "4",
    "confidence": "4"
  }
]