[
  {
    "review_id": "3b5f6fd5e10d6d48",
    "paper_id": "ACL_2017_108",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "the paper is well-written, except for a few places as described below. The problem the paper tackles is useful. The proposed approach, multigraph-based model, is a variant of MH. The empirical result is solid.",
    "weaknesses": "Clarification is needed in several places.\n1. In section 3, in addition to the description of the previous model, MH, you need point out the issues of MH which motivate you to propose a new model.\n2. In section 4, I don't see the reason why separators are introduced. what additional info they convene beyond T/I/O?\n3. section 5.1 does not seem to provide useful info regarding why the new model is superior.\n4. the discussion in section 5.2 is so abstract that I don't get the insights why the new model is better than MH. can you provide examples of spurious structures?",
    "comments": "The paper presents a new model for detecting overlapping entities in text. The new model improves the previous state-of-the-art, MH, in the experiments on a few benchmark datasets. But it is not clear why and how the new model works better.",
    "overall_score": "3",
    "confidence": "3"
  },
  {
    "review_id": "009c94991db35f13",
    "paper_id": "ACL_2017_108",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "The problem itself could be rather interesting especially for crossing entities to decide which one might actually be mentioned in some text. The technique seems to work although the empirically results do not show some \"dramatic\" effect. I like that some words are spent on efficiency compared to a previous system. The paper in general is well-written but also needs some further polishing in some details (see minor remarks below).",
    "weaknesses": "The problem itself is not really well motivated. Why is it important to detect China as an entity within the entity Bank of China, to stay with the example in the introduction? I do see a point for crossing entities but what is the use case for nested entities? This could be much more motivated to make the reader interested. As for the approach itself, some important details are missing in my opinion: What is the decision criterion to include an edge or not? In lines 229--233 several different options for the I^k_t nodes are mentioned but it is never clarified which edges should be present!\nAs for the empirical evaluation, the achieved results are better than some previous approaches but not really by a large margin. I would not really call the slight improvements as \"outperformed\" as is done in the paper. What is the effect size? Does it really matter to some user that there is some improvement of two percentage points in F_1? What is the actual effect one can observe? How many \"important\" entities are discovered, that have not been discovered by previous methods? Furthermore, what performance would some simplistic dictionary-based method achieve that could also be used to find overlapping things? And in a similar direction: what would some commercial system like Google's NLP cloud that should also be able to detect and link entities would have achieved on the datasets. Just to put the results also into contrast of existing \"commercial\" systems.\nAs for the result discussion, I would have liked to see some more emphasis on actual crossing entities. How is the performance there? This in my opinion is the more interesting subset of overlapping entities than the nested ones. How many more crossing entities are detected than were possible before? Which ones were missed and maybe why? Is the performance improvement due to better nested detection only or also detecting crossing entities? Some",
    "comments": "",
    "overall_score": "2",
    "confidence": "3"
  }
]