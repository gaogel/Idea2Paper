[
  {
    "review_id": "df5a4b5403274a14",
    "paper_id": "ACL_2017_564",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "of the paper is that the experiments are somewhat limited. \nThe interactive MT simulation shows that the method basically works, but it is difficult to get a sense of how well - for instance, in how many cases the constraint was incorporated in an acceptable manner (the large BLEU score increases are only indirect evidence). Similarly, adaptation should have been  compared to the standard “fine-tuning” baseline, which would be relatively inexpensive to run on the 100K Autodesk corpus.\nDespite this weakness, I think this is a decent contribution that deserves to be published.\nFurther details: 422 Given its common usage in PBMT, “coverage vector” is a potentially misleading term. The appropriate data structure seems more likely to be a coverage set.\nTable 2 should also give some indication of the number of constraints per source sentence in the test corpora, to allow for calibration of the BLEU gains.",
    "comments": "",
    "overall_score": "4",
    "confidence": "4"
  }
]