[
  {
    "review_id": "4fb12403381dc32d",
    "paper_id": "ACL_2017_496",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "The authors have nice coverage of a different range of language settings to isolate the way that relatedness and amount of morphology interact (i.e., translating between closely related morphologically rich languages vs distant ones) in affecting what the system learns about morphology. They include an illuminating analysis of what parts of the architecture end up being responsible for learning morphology, particularly in examining how the attention mechanism leads to more impoverished target side representations. \nTheir findings are of high interest and practical usefulness for other users of NMT.",
    "weaknesses": "They gloss over the details of their character-based encoder. \nThere are many different ways to learn character-based representations, and omitting a discussion of how they do this leaves open questions about the generality of their findings. Also, their analysis could've been made more interesting had they chosen languages with richer and more challenging morphology such as Turkish or Finnish, accompanied by finer-grained morphology prediction and analysis.",
    "comments": "This paper brings insight into what NMT models learn about morphology by training NMT systems and using the encoder or decoder representations, respectively, as input feature representations to a POS- or morphology-tagging classification task. This paper is a straightforward extension of \"Does String-Based Neural MT Learn Source Syntax?,\" using the same methodology but this time applied to morphology. Their findings offer useful insights into what NMT systems learn.",
    "overall_score": "4",
    "confidence": "4"
  },
  {
    "review_id": "5a40b606e3191326",
    "paper_id": "ACL_2017_496",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "- This paper describes experiments that aim to address a crucial problem for NMT: understanding what does the model learn about morphology and syntax, etc.. - Very clear objectives and experiments effectively laid down.              Good state of the art review and comparison. In general, this paper is a pleasure to read.\n- Sound experimentation framework. Encoder/Decoder Recurrent layer outputs are used to train POS/morphological classifiers. They show the effect of certain changes in the framework on the classifier accuracy (e.g. use characters instead of words).\n- Experimentation is carried out on many language pairs.\n- Interesting conclusions derived from this work, and not all agree with intuition.",
    "weaknesses": "-  The contrast of character-based vs word-based representations  is slightly lacking: NMT with byte-pair encoding is showing v. strong performance in the literature. It would have been more relevant to have BPE in the mix, or replace word-based representations if three is too many. \n - Section 1: \"â€¦ while higher layers are more focused on word meaning\"; similar sentence in Section 7. I am ready to agree with this intuition, but I think the experiments in this paper do not support this particular sentence. \nTherefore it should not be included, or it should be clearly stressed that this is a reasonable hypothesis based on indirect evidence (translation performance improves but morphology on higher layers does not).\nDiscussion: This is a  fine paper that presents a thorough and systematic analysis of the NMT model, and derives several interesting conclusions based on many data points across several language pairs. I find particularly interesting that (a) the target language affects the quality of the encoding on the source side; in particular, when the target side is a morphologically-poor language (English) the pos tagger accuracy for the encoder improves. ( b) increasing the depth of the encoder does not improve pos accuracy (more experiments needed to determine what does it improve); (c) the attention layer hurts the quality of the decoder representations.  I wonder if (a) and (c) are actually related? The attention hurts the decoder representation, which is more difficult to learn for a morphologically rich language; in turn, the encoders learn based on the global objective, and this backpropagates through the decoder. Would this not be a strong indication that we need separate objectives to govern the encoder/decoder modules of the NMT model?",
    "comments": "",
    "overall_score": "4",
    "confidence": "4"
  }
]