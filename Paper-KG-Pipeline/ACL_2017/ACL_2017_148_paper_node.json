{
  "paper_id": "ACL_2017_148",
  "title": "Evaluation Metrics for Reading Comprehension: Prerequisite Skills and Readability",
  "conference": "ACL",
  "domain": {
    "research_object": "分析阅读理解评估指标，关注前置技能与可读性对评估效果的影响。",
    "core_technique": "结合前置技能分析与文本可读性评估方法，提升阅读理解测评的准确性。",
    "application": "用于教育测评、智能辅导系统和自动化阅读理解能力评估。",
    "domains": [
      "自然语言处理",
      "教育技术"
    ]
  },
  "ideal": {
    "core_idea": "分析阅读理解评估指标对前置技能和文本可读性的影响。",
    "tech_stack": [
      "自然语言处理",
      "阅读理解评估",
      "技能分析"
    ],
    "input_type": "开放域文档与相关问题",
    "output_type": "系统在阅读理解任务中的表现评估"
  },
  "skeleton": {
    "problem_framing": "论文引言通过强调自然语言处理（NLP）目标——让智能体理解自然语言——引入研究问题，并以阅读理解（RC）任务为测试手段，突出RC能力的复杂性和多步骤特性，凸显其研究价值和挑战性。",
    "gap_pattern": "作者批评当前RC数据集主要以表层类别（如问题类型）进行分类，忽视了对系统实际能力的细致刻画，指出仅用简单准确率衡量系统不足，强调需要更丰富的评测维度以推动RC系统发展。",
    "method_story": "方法部分采用逐一说明数据集选择与样本筛选过程，详细列举所用RC数据集（QA4MRE、MCTest、SQuAD）及其抽样策略，突出实验设计的代表性和覆盖性，为后续分析奠定基础。",
    "experiments_story": "实验部分以理论为依据，明确提出两大评价维度（前提技能与可读性），并结合前人工作细化技能分类，强调评价指标的科学性和系统性，展示实验设计的理论支撑和创新点。"
  },
  "tricks": [
    {
      "name": "多维度评估系统性能",
      "type": "writing-level",
      "purpose": "强调评估RC系统时应采用多种指标，而非仅依赖准确率，提升论文说服力",
      "location": "Clarifying what a system achieves is important... systems need to be measured according to various metrics, not just simple accuracy.",
      "description": "在论文中提出RC系统评估应采用多种指标（如多维度分析），不仅仅依赖于准确率，突出评估的全面性。"
    },
    {
      "name": "数据集样本选择的随机抽样法",
      "type": "method-level",
      "purpose": "保证样本具有代表性与随机性，减少选择偏差",
      "location": "We randomly selected 100 main and auxiliary questions... We randomly chose 25 tasks (100 questions)... We randomly chose 100 paragraphs...",
      "description": "对不同数据集中的问题或段落采用随机抽样，确保评价的公平性和代表性。"
    },
    {
      "name": "数据集多样性覆盖",
      "type": "experiment-level",
      "purpose": "确保实验结果具有普适性和广泛适用性",
      "location": "The goldstandard dataset consists of four different topics and four documents for each topic... includes some Wikipedia articles from various topics...",
      "description": "在实验设计中选择涵盖多主题、多类型的数据集，提升模型评估的全面性和结论的广泛适用性。"
    },
    {
      "name": "数据集质量控制",
      "type": "method-level",
      "purpose": "剔除低质量或可被简单方法解决的问题，保证测试的有效性",
      "location": "questions that can be solved by a simple baseline method are excluded from the dataset.",
      "description": "在数据集构建或挑选过程中，排除能够被简单基线方法解决的问题，提升测试集的区分度和挑战性。"
    },
    {
      "name": "对比分析具体案例",
      "type": "writing-level",
      "purpose": "通过具体例子展示问题难度差异，增强论述的直观性和说服力",
      "location": "For example, see the two RC questions in Figure 1...",
      "description": "在论文中通过展示和比较不同数据集的具体问题，说明系统面临的难度和挑战，增强论述的具体性和说服力。"
    },
    {
      "name": "引用前人研究发现数据集局限",
      "type": "writing-level",
      "purpose": "增强论点的权威性和论文的学术基础",
      "location": "Chen et al. (2016) revealed that some questions in datasets may not have the quality to test RC systems.",
      "description": "通过引用相关文献指出现有数据集存在的缺陷或局限，显示对领域前沿的掌握，并为后续研究提供理论支撑。"
    },
    {
      "name": "详细记录数据选择流程",
      "type": "method-level",
      "purpose": "保证实验可复现性和透明度",
      "location": "In this appendix, we explain the method of choosing questions for the annotation...",
      "description": "在方法部分详细说明数据选择和标注流程，便于他人复现实验结果，提升论文的可信度和学术价值。"
    },
    {
      "name": "覆盖多种数据集类型",
      "type": "experiment-level",
      "purpose": "测试模型在不同场景下的泛化能力",
      "location": "QA4MRE... MCTest... SQuAD... Who-did-What... MS MARCO... NewsQA...",
      "description": "实验设计时涵盖多种类型的数据集（如新闻、百科、考试题等），以检验模型在不同文本领域和任务类型下的表现。"
    },
    {
      "name": "区分主问题与辅助问题",
      "type": "method-level",
      "purpose": "细化分析不同类型问题对系统能力的考察",
      "location": "We randomly selected 100 main and auxiliary questions...",
      "description": "在数据选择过程中区分主问题和辅助问题，有助于更细致地分析系统对不同类型问题的解答能力。"
    }
  ]
}