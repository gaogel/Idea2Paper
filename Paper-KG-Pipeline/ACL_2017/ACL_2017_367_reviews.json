[
  {
    "review_id": "09f28a174d85d2d9",
    "paper_id": "ACL_2017_367",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "The paper addresses a long standing problem concerning automatic evaluation of the output of generation/translation systems.\nThe analysis of all the available metrics is thorough and comprehensive.\nThe authors demonstrate a new metric with a higher correlation with human judgements The bibliography will help new entrants into the field.",
    "weaknesses": "The paper is written as a numerical analysis paper, with very little insights to linguistic issues in generation, the method of generation, the differences in the output from a different systems and human generated reference.\nIt is unclear if the crowd source generated references serve well in the context of an application that needs language generation.",
    "comments": "Overall, the paper could use some linguistic examples (and a description of the different systems) at the risk of dropping a few tables to help the reader with intuitions.",
    "overall_score": "3",
    "confidence": "3"
  }
]