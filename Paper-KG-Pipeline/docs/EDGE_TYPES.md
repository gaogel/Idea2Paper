# çŸ¥è¯†å›¾è°±è¾¹ç±»å‹è¯´æ˜

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜äº† Idea2Pattern çŸ¥è¯†å›¾è°±ä¸­æ‰€æœ‰è¾¹çš„ç±»å‹ã€ç”¨é€”å’Œæƒé‡å®šä¹‰ã€‚

---

## ğŸ“‹ ç›®å½•

1. [åŸºç¡€è¿æ¥è¾¹](#åŸºç¡€è¿æ¥è¾¹)
2. [ä¸‰è·¯å¬å›ç­–ç•¥](#ä¸‰è·¯å¬å›ç­–ç•¥)
3. [æƒé‡è®¡ç®—å…¬å¼æ€»ç»“](#æƒé‡è®¡ç®—å…¬å¼æ€»ç»“)

---

## åŸºç¡€è¿æ¥è¾¹

è¿™äº›è¾¹ç”¨äºå»ºç«‹å®ä½“ä¹‹é—´çš„åŸºæœ¬å…³ç³»ï¼Œä¸ºå¬å›è·¯å¾„æä¾›åŸºç¡€ç»“æ„ã€‚

### 1. Paper -[implements]-> Idea

**ç”¨é€”**: è¡¨ç¤ºæŸç¯‡ Paper å®ç°äº†æŸä¸ªæ ¸å¿ƒ Ideaã€‚

**æƒé‡**: æ— æƒé‡ï¼ˆå¸ƒå°”å…³ç³»ï¼‰

**æ„å»ºé€»è¾‘**:
- é€šè¿‡ Paper çš„ `source_paper_ids` å­—æ®µä¸ Idea èŠ‚ç‚¹åŒ¹é…
- æ¯ä¸ª Paper åªé“¾æ¥åˆ°ä¸€ä¸ª Idea

**ç¤ºä¾‹**:
```json
{
  "source": "ACL_2017_104",
  "target": "idea_0",
  "relation": "implements"
}
```

---

### 2. Paper -[uses_pattern]-> Pattern

**ç”¨é€”**: è¡¨ç¤ºæŸç¯‡ Paper ä½¿ç”¨äº†æŸä¸ªå†™ä½œ Patternã€‚

**æƒé‡**:
- `quality`: Paper çš„ç»¼åˆè´¨é‡åˆ†æ•° (0-1)

**æ„å»ºé€»è¾‘**:
- ä» Paper çš„ `pattern_ids` å­—æ®µè·å–å…³è”çš„ Pattern
- è´¨é‡åˆ†æ•°åŸºäº Review è¯„åˆ†å½’ä¸€åŒ–

**è´¨é‡åˆ†æ•°è®¡ç®—**:
```python
quality = (avg_review_score - 1) / 9  # å½’ä¸€åŒ–åˆ° [0, 1]
```

**ç¤ºä¾‹**:
```json
{
  "source": "ACL_2017_104",
  "target": "pattern_5",
  "relation": "uses_pattern",
  "quality": 0.78
}
```

---

### 3. Paper -[in_domain]-> Domain

**ç”¨é€”**: è¡¨ç¤ºæŸç¯‡ Paper å±äºæŸä¸ªç ”ç©¶é¢†åŸŸã€‚

**æƒé‡**: æ— æƒé‡ï¼ˆå¸ƒå°”å…³ç³»ï¼‰

**æ„å»ºé€»è¾‘**:
- ä» Paper çš„ `domains` å­—æ®µè·å–æ‰€å±é¢†åŸŸ
- ä¸€ç¯‡ Paper å¯ä»¥å±äºå¤šä¸ª Domain

**ç¤ºä¾‹**:
```json
{
  "source": "ACL_2017_104",
  "target": "domain_12",
  "relation": "in_domain"
}
```

---

## ä¸‰è·¯å¬å›ç­–ç•¥

### è·¯å¾„1: Idea â†’ Idea â†’ Pattern (ç›¸ä¼¼Ideaå¬å›)

**å¬å›æµç¨‹**:
```
ç”¨æˆ·è¾“å…¥æ–°Idea â†’ å®æ—¶è®¡ç®—ä¸å›¾è°±ä¸­æ‰€æœ‰Ideaçš„ç›¸ä¼¼åº¦ â†’ Top-Kç›¸ä¼¼Idea â†’ è¿™äº›Ideaçš„pattern_ids
```

**ä¸éœ€è¦é¢„æ„å»ºè¾¹**:
- âŒ ä¸éœ€è¦ `Idea â†’ Idea` è¾¹
- âœ… Idea èŠ‚ç‚¹å·²æœ‰ `pattern_ids` å­—æ®µ

**å®æ—¶è®¡ç®—ç›¸ä¼¼åº¦**:
```python
def find_similar_ideas(user_idea_text, top_k=10):
    similarities = []
    for idea in graph_ideas:
        sim = compute_similarity(user_idea_text, idea['description'])
        similarities.append((idea['idea_id'], sim))

    # è¿”å›Top-Kç›¸ä¼¼Idea
    top_ideas = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]

    # æ”¶é›†è¿™äº›Ideaçš„Pattern
    patterns = set()
    for idea_id, sim in top_ideas:
        patterns.update(graph_ideas[idea_id]['pattern_ids'])

    return patterns
```

**æƒé‡å®šä¹‰**:
- `similarity`: å®æ—¶è®¡ç®—çš„è¯­ä¹‰ç›¸ä¼¼åº¦ (0-1)
- `pattern_relevance`: Ideaä½¿ç”¨è¯¥Patternçš„Paperçš„å¹³å‡è´¨é‡

---

### è·¯å¾„2: Idea â†’ Domain â†’ Pattern (é¢†åŸŸç›¸å…³æ€§å¬å›)

**å¬å›æµç¨‹**:
```
ç”¨æˆ·è¾“å…¥æ–°Idea â†’ æ‰¾åˆ°ç›¸å…³Domain â†’ è¯¥Domainä¸­è¡¨ç°å¥½çš„Pattern
```

#### 2.1 Idea -[belongs_to]-> Domain

**ç”¨é€”**: è¡¨ç¤ºæŸä¸ª Idea ä¸»è¦å±äºå“ªäº›ç ”ç©¶é¢†åŸŸã€‚

**æƒé‡**:
- `weight`: Idea ç›¸å…³ Paper åœ¨è¯¥ Domain ä¸­çš„å æ¯” (0-1)
- `paper_count`: è¯¥ Domain ä¸­çš„ Paper æ•°é‡
- `total_papers`: Idea çš„æ‰€æœ‰ Paper æ€»æ•°

**æ„å»ºé€»è¾‘**:
1. ç»Ÿè®¡ Idea çš„æ‰€æœ‰ `source_paper_ids`
2. ç»Ÿè®¡è¿™äº› Paper åœ¨å„ Domain ä¸­çš„åˆ†å¸ƒ
3. è®¡ç®—æ¯ä¸ª Domain çš„å æ¯”ä½œä¸ºæƒé‡

**æƒé‡è®¡ç®—**:
```python
weight = paper_count_in_domain / total_papers
```

**ç¤ºä¾‹**:
```json
{
  "source": "idea_42",
  "target": "domain_12",
  "relation": "belongs_to",
  "weight": 0.75,
  "paper_count": 3,
  "total_papers": 4
}
```

#### 2.2 Pattern -[works_well_in]-> Domain

**ç”¨é€”**: è¡¨ç¤ºæŸä¸ª Pattern åœ¨æŸä¸ªé¢†åŸŸä¸­çš„ä½¿ç”¨æ•ˆæœã€‚

**æƒé‡**:
- `frequency`: Pattern åœ¨è¯¥ Domain ä¸­çš„ä½¿ç”¨æ¬¡æ•°
- `effectiveness`: Pattern åœ¨è¯¥ Domain ä¸­çš„æ•ˆæœå¢ç›Šï¼ˆç›¸å¯¹åŸºçº¿ï¼‰
- `confidence`: ç½®ä¿¡åº¦ (0-1)ï¼ŒåŸºäºæ ·æœ¬æ•°
- `avg_quality`: Pattern åœ¨è¯¥ Domain ä¸­ Paper çš„å¹³å‡è´¨é‡
- `baseline`: è¯¥ Domain çš„è´¨é‡åŸºçº¿

**æ„å»ºé€»è¾‘**:
1. ç»Ÿè®¡ä½¿ç”¨è¯¥ Pattern ä¸”å±äºè¯¥ Domain çš„æ‰€æœ‰ Paper
2. è®¡ç®—è¿™äº› Paper çš„å¹³å‡è´¨é‡
3. è®¡ç®—è¯¥ Domain æ‰€æœ‰ Paper çš„å¹³å‡è´¨é‡ä½œä¸ºåŸºçº¿
4. æ•ˆæœå¢ç›Š = å¹³å‡è´¨é‡ - åŸºçº¿

**æƒé‡è®¡ç®—**:
```python
effectiveness = avg_quality - baseline
confidence = min(frequency / 20, 1.0)
```

**ç¤ºä¾‹**:
```json
{
  "source": "pattern_5",
  "target": "domain_12",
  "relation": "works_well_in",
  "frequency": 15,
  "effectiveness": 0.12,
  "confidence": 0.75,
  "avg_quality": 0.82,
  "baseline": 0.70
}
```

**å¬å›ä½¿ç”¨**:
```python
# 1. æ‰¾åˆ°ç”¨æˆ·Ideaæœ€ç›¸å…³çš„Domain
user_idea_domains = find_related_domains(user_idea)

# 2. åœ¨è¿™äº›Domainä¸­æ‰¾æ•ˆæœæœ€å¥½çš„Pattern
patterns = []
for domain in user_idea_domains:
    domain_patterns = G.predecessors(domain, relation='works_well_in')
    ranked = sorted(domain_patterns,
        key=lambda p: G[p][domain]['effectiveness'] * G[p][domain]['confidence'],
        reverse=True)
    patterns.extend(ranked[:10])
```

---

### è·¯å¾„3: Idea â†’ Paper â†’ Pattern (ç›¸ä¼¼Paperå¬å›)

**å¬å›æµç¨‹**:
```
ç”¨æˆ·è¾“å…¥æ–°Idea â†’ æ‰¾åˆ°å®ç°ç›¸ä¼¼Ideaçš„é«˜è´¨é‡Paper â†’ è¿™äº›Paperä½¿ç”¨çš„Pattern
```

#### 3.1 Idea -[similar_to_paper]-> Paper

**ç”¨é€”**: è¡¨ç¤ºæŸä¸ª Idea ä¸æŸç¯‡ Paper çš„æ ¸å¿ƒæ€æƒ³ç›¸ä¼¼ã€‚

**æƒé‡**:
- `similarity`: è¯­ä¹‰ç›¸ä¼¼åº¦ (0-1)
- `quality`: Paper çš„ç»¼åˆè´¨é‡åˆ†æ•° (0-1)
- `combined_weight`: ç»¼åˆæƒé‡ = similarity Ã— quality

**æ„å»ºé€»è¾‘**:
1. è®¡ç®— Idea æè¿°ä¸æ‰€æœ‰ Paper çš„ core_idea çš„ç›¸ä¼¼åº¦
2. è¿‡æ»¤ä½ç›¸ä¼¼åº¦çš„ Paper (é˜ˆå€¼ 0.1)
3. è®¡ç®—ç»¼åˆæƒé‡
4. æ¯ä¸ª Idea åªä¿ç•™ Top-50 ç›¸ä¼¼ Paper

**ç›¸ä¼¼åº¦è®¡ç®—**:
```python
# ä½¿ç”¨ Jaccard ç›¸ä¼¼åº¦ï¼ˆè¯è¢‹æ¨¡å‹ï¼‰
similarity = |tokens1 âˆ© tokens2| / |tokens1 âˆª tokens2|
combined_weight = similarity * quality
```

**ç¤ºä¾‹**:
```json
{
  "source": "idea_42",
  "target": "ACL_2017_150",
  "relation": "similar_to_paper",
  "similarity": 0.65,
  "quality": 0.82,
  "combined_weight": 0.533
}
```

**å¬å›ä½¿ç”¨**:
```python
# 1. æ‰¾åˆ°ä¸ç”¨æˆ·Ideaæœ€ç›¸ä¼¼çš„Paper
similar_papers = find_similar_papers(user_idea, top_k=20)

# 2. æ”¶é›†è¿™äº›Paperä½¿ç”¨çš„Pattern
patterns = set()
for paper_id, combined_weight in similar_papers:
    paper_patterns = G.successors(paper_id, relation='uses_pattern')
    for pattern_id in paper_patterns:
        # è€ƒè™‘Paperè´¨é‡ä½œä¸ºPatternçš„æƒé‡
        pattern_weight = combined_weight * G[paper_id][pattern_id]['quality']
        patterns.add((pattern_id, pattern_weight))

# 3. æŒ‰æƒé‡æ’åº
ranked_patterns = sorted(patterns, key=lambda x: x[1], reverse=True)
```

---

## æƒé‡è®¡ç®—å…¬å¼æ€»ç»“

| è¾¹ç±»å‹ | å…³é”®æƒé‡ | è®¡ç®—å…¬å¼ | å–å€¼èŒƒå›´ |
|--------|---------|---------|---------|
| `Paper â†’ Pattern` | `quality` | `(avg_review - 1) / 9` | [0, 1] |
| `Idea â†’ Domain` | `weight` | `paper_count / total_papers` | [0, 1] |
| `Pattern â†’ Domain` | `effectiveness` | `avg_quality - baseline` | [-1, 1] |
| `Pattern â†’ Domain` | `confidence` | `min(frequency / 20, 1.0)` | [0, 1] |
| `Idea â†’ Paper` | `similarity` | `Jaccard(tokens1, tokens2)` | [0, 1] |
| `Idea â†’ Paper` | `combined_weight` | `similarity Ã— quality` | [0, 1] |

---

## å®Œæ•´å¬å›ç¤ºæ„å›¾

```
ç”¨æˆ·è¾“å…¥: æ–° Idea
    |
    |-- è·¯å¾„1: Idea â†’ Idea â†’ Pattern (å®æ—¶è®¡ç®—)
    |      |
    |      |-- è®¡ç®—ç›¸ä¼¼åº¦ â†’ Top-Kç›¸ä¼¼Idea
    |      |-- è·å– Idea.pattern_ids â†’ Pattern
    |      |
    |      â””â”€â”€ å¾—åˆ†: similarity Ã— patternä½¿ç”¨é¢‘ç‡
    |
    |-- è·¯å¾„2: Idea â†’ Domain â†’ Pattern
    |      |
    |      |-- [belongs_to] â†’ Domain (weight)
    |      |-- [works_well_in] â†’ Pattern (effectiveness, confidence)
    |      |
    |      â””â”€â”€ å¾—åˆ†: weight Ã— effectiveness Ã— confidence
    |
    â””-- è·¯å¾„3: Idea â†’ Paper â†’ Pattern
           |
           |-- [similar_to_paper] â†’ Paper (similarity, quality)
           |-- [uses_pattern] â†’ Pattern (quality)
           |
           â””â”€â”€ å¾—åˆ†: similarity Ã— quality_paper Ã— quality_pattern
```

---

## ä½¿ç”¨ç¤ºä¾‹

### å®Œæ•´å¬å›æµç¨‹

```python
def recall_patterns(user_idea_text):
    """ä¸‰è·¯å¬å›Pattern"""

    all_patterns = {}

    # è·¯å¾„1: ç›¸ä¼¼Ideaå¬å›
    similar_ideas = find_similar_ideas(user_idea_text, top_k=10)
    for idea_id, similarity in similar_ideas:
        for pattern_id in graph.nodes[idea_id]['pattern_ids']:
            score = similarity * 0.4  # è·¯å¾„1æƒé‡
            all_patterns[pattern_id] = all_patterns.get(pattern_id, 0) + score

    # è·¯å¾„2: é¢†åŸŸç›¸å…³å¬å›
    related_domains = find_related_domains(user_idea_text, top_k=5)
    for domain_id, domain_weight in related_domains:
        patterns = G.predecessors(domain_id, relation='works_well_in')
        for pattern_id in patterns:
            edge = G[pattern_id][domain_id]
            score = domain_weight * edge['effectiveness'] * edge['confidence'] * 0.3
            all_patterns[pattern_id] = all_patterns.get(pattern_id, 0) + score

    # è·¯å¾„3: ç›¸ä¼¼Paperå¬å›
    similar_papers = find_similar_papers(user_idea_text, top_k=20)
    for paper_id, combined_weight in similar_papers:
        patterns = G.successors(paper_id, relation='uses_pattern')
        for pattern_id in patterns:
            pattern_quality = G[paper_id][pattern_id]['quality']
            score = combined_weight * pattern_quality * 0.3
            all_patterns[pattern_id] = all_patterns.get(pattern_id, 0) + score

    # æ’åºè¿”å›Top-K
    ranked = sorted(all_patterns.items(), key=lambda x: x[1], reverse=True)
    return ranked[:10]
```

---

## æ³¨æ„äº‹é¡¹

1. **è·¯å¾„1ä¸éœ€è¦é¢„æ„å»ºè¾¹**: Idea â†’ Idea çš„ç›¸ä¼¼åº¦æ˜¯å®æ—¶è®¡ç®—çš„ï¼Œå› ä¸ºç”¨æˆ·è¾“å…¥çš„æ˜¯æ–°Idea
2. **ç›¸ä¼¼åº¦è®¡ç®—**: å½“å‰ä½¿ç”¨ç®€å•çš„ Jaccard ç›¸ä¼¼åº¦ï¼Œåç»­å¯å‡çº§ä¸ºè¯­ä¹‰åµŒå…¥æ¨¡å‹ï¼ˆå¦‚ BERTï¼‰
3. **Top-K é™åˆ¶**: `Idea â†’ Paper` è¾¹åªä¿ç•™ Top-50ï¼Œé¿å…å›¾è¿‡äºç¨ å¯†
4. **è´¨é‡å½’ä¸€åŒ–**: Review è¯„åˆ†å‡è®¾èŒƒå›´ä¸º 1-10ï¼Œéœ€æ ¹æ®å®é™…æ•°æ®è°ƒæ•´
5. **ç½®ä¿¡åº¦é˜ˆå€¼**: Pattern åœ¨ Domain ä¸­è‡³å°‘ 20 ä¸ªæ ·æœ¬æ‰èƒ½è¾¾åˆ°æ»¡ç½®ä¿¡åº¦

---

## æ–‡ä»¶ç”Ÿæˆ

- **è„šæœ¬**: `scripts/build_edges.py`
- **è¾“å‡º**: `output/edges.json`, `output/knowledge_graph_v2.gpickle`
- **è¿è¡Œ**: `python scripts/build_edges.py`

