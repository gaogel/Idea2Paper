[
  {
    "review_id": "40df350b76559d86",
    "paper_id": "COLING_2020_43",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "In this paper, the authors argue that using the topmost encoder output alone is problematic or suboptimal to neural machine translation. They propose multi-view learning, where the topmost encoding layer is regarded as the primary view and one intermediate encoding layer is used as an auxiliary view. Both views, as encoder outputs, are transferred to corresponding decoder steams, with shared model parameters except for the encoder-decoder attention. Prediction consistency loss is used to constrains these two streams. The authors claim that this method can improve the robustness of the encoding representations. Experiments on five translation tasks show better performance compared to vanilla baselines, and generalization to other neural architectures.\nOn one hand, the experiments conducted in this paper are rich, including five translation tasks, two NMT architectures, shallow and deep models, and many ablations and analysis.  On the other hand, I have several concerns regarding motivation, claims and experiments: - The authors pointed out two problems for using the topmost encoder output alone: 1) overfitting; 2) “It cannot make full use of representations extracted from lower encoder layers,”. I’m not convinced by the second one especially. For example, in PreNorm-based Transformer, the final encoder output is actually a direct addition of all previous encoding layers. Although there is a layer normalization, I believe this output carries critical information from lower layers.\n- The authors claim that “circumventing the necessity to change the model structure.”, but the proposed method requires to change the decoder, and manipulate the parameter sharing pattern. In my opinion, the method still requires structure modification.\n- The major ablations and analysis are performed on IWSLT De-En task, which is actually a low-resource task, where regularization is the main bottleneck. From Table 1, it seems like the proposed approach yields much smaller gains on large-scale WMT En-De task compared to low-resource tasks. Thus, it’s still questionable whether the conclusion from experiments on low-resource task can generalize to high-resource tasks.\n- Which WMT En-De test set did you use? WMT14 or WMT16? It seems like the authors used WMT16 for test, but the baseline (33.06 tokenized BLEU) is below standard (~34 BLEU).\n- Besides, some experiment has mixed results and is hard to draw convincing conclusions. For example, in Table 5, MV-3-6 (shared) achieves the best performance on De->En while MV-3-6 is the best on Ro->En. It seems like different tasks have different preferences (share or separate). In the paper, the author only highlights the superiority of separate settings on Ro->En task.\nOverall, I'm not convinced by the motivation and the analysis on low-resource tasks (In particular, this paper doesn't target at low-resource translation. Note that the authors claim that \"our method has a good generalization for the scale of data size.\"). I think the score of this paper is around 3.5 with several unclear questions to be solved. Since we don't have this option, I prefer to give the score of 3.",
    "overall_score": "3",
    "confidence": "4"
  }
]