[
  {
    "review_id": "70cef37f3e3c8e50",
    "paper_id": "COLING_2020_37",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "This paper proposes a method of using treebanks that are comparable across languages (e.g. Universal Dependencies) to evaluate linguistic \"universals\". The idea is to express the universals as formulas of propositional logic, with logical atoms corresponding to things like \"has SVO word order\". Then, for any given language, the atoms are interpreted with reference to relative frequencies in treebanks, and fuzzy logic interpretations are used for the connectives, to arrive at a real-valued \"truth value\" representing that language's degree of conformity to the universal (i.e. each language acts as a model); these values are averaged across languages, in a way that prevents large groups of closely-related languages from having undue influence, to calculate a single value for the universal. The authors show that the Greenberg universals get generally high scores (i.e. high \"degrees of truth\"), that the scores are relatively stable across samples of languages, and that the method can be used to identify new candidate universals via brute-force \"search\" of arbitrary propositional formulas.\nI think this is an interesting and well-written paper. It provides a new confirmation of some well-known universals. The potential for uncovering new universals seems clear in principle, although care is needed in interpreting the scores, as the authors point out on p.8 with the confound raised by the majority of languages having subject-verb order. My main concerns are about exactly how clearly the calculations here actually correspond to the intended interpretations of the (fuzzy) logical formulas. It's possible that some small tweaks to the system aimed at shoring up its \"logical grounding\" could fix or reduce the interpretability problems like the one caused by the abundance of subject-verb order.\nFirst, the fact that expressing the universals in Table 1 as formulas required addition as well as disjunction (see footnote 5) is a clue that plain propositional logic is not quite what we want. There's no discussion of how the authors chose between addition and disjunction in \"translating\" Greenberg's statements of the universals, but the idea seems to be basically the addition is used between mutually-exclusive alternatives (hence same denominator) and disjunction is used otherwise. ( I think disjunction is only used once though, in #24?) I get the intuition here, that disjunction is for \"real disjunction\" whereas addition is just for tallying up things that we don't happen to have an atomic symbol for. That makes sense for #1, but I'm less sure about #6: why is the antecedent included in the sum? Why isn't this just \"verb-nsubj:noun-obj:noun => nsubj:noun-verb-obj:noun\"? I worry that these choices are a bit ad hoc. It might be useful to think about real-valued logics with distinct connectives interpreted as maximum and addition, and how they are usually used -- see e.g. the strong and weak disjunction in ≈Åukasiewicz logic.\nI think that oddity in the translation of Greenberg #6 points to another issue in thinking of this as logic: what exactly does the logical atom \"nsubj:noun-verb-obj:noun\" mean? Does it mean that SVO is the \"dominant\" order, or that it's an \"alternative\" order, or just that it's a possible option in the language? What actually gets calculated from the treebank is the relative frequency of that order, among the six possible orders. But suppose that this frequency turns out to be 0.2 in a certain language. Does this mean that it's \"20% true\" that SVO is the dominant word order in that language? Not entirely straightforward. ( A proportion around 20% might be taken as indicating that the language has this as an *alternative* order, with a very very high degree of truth ...) These sorts of complications, I think, mean that the authors had to add together VSO+SVO to try to get a measure of \"dominant VSO with SVO as an alternative\" -- but, among many other things one might worry about, this is presumably the same as what we'd get if we tried to translate \"dominant SVO with VSO as an alternative\".\nI suspect that in practice the concerns of the sort in the last paragraph just get \"washed out\" because most of the time the universals are talking about dominant worder, and it works well enough if we assume that, e.g., 70% relative frequency for SOV order indicates 70%-true for the proposition \"has SOV as dominant word order\". But that's a substantive assumption the system is relying on -- or, perhaps in different terms, the way this system interprets \"X is 70% true for language L\" is as meaning that \"X happens 70% of the time in language L\". That's fine, but it brings out the general issue of whether we're really dealing with fuzzy logic here rather than just calculations on relative frequencies. And it makes the success of the system seem slightly less principled than its description suggests.\nThe presentation of some of the formal details is slightly sloppy:  - In (4), applying the valuation function to \"1 \\wedge 1\" makes no sense; it applies for formulas.\n - The formula in (5) implies that there's a different weight for each language-formula pair (i.e. w(\\sigma,\\ell)), but this wouldn't make much sense, and doesn't seem to be what actually happens (i.e. it should be just w(\\ell); note that (13) doesn't use \\phi.)\n - The notation for logical atoms, with hyphens and colons, should be introduced explicitly. I figured it out using (6) and (7) as clues but the reader shouldn't have to.\nAnd some other minor comments:  - A natural alternative to consider, from a logical perspective, would be to move to a first-order logic where things like SVO correspond to one-place predicates, and then the individual languages could be entities in the model with each Greenberg-style universal being evaluated just once in that single logical model. ( As opposed to the current setup where each language is its own model for propositional formulas, and then the averaging has to happen \"outside the logic\".) I'm not sure how the weighting of the average to account for genealogical structure would work though.\n - I didn't understand the cryptic two sentence justifying the choice of fuzzy logic at the end of section 3.2.\n - Why constrain the invented candidate universals to have the same logical structure as existing ones? Why not just some formally-natural class such as, say, all well-formed formulas with at most two connectives?\n - Rather than #13 being an example of \"two conflicting universal tendencies\" (p.8), couldn't this just be described as discovering that #13 as written is not a good universal after all.\n - I'm not sure whether it makes sense to talk about the experiments in section 4.2 in terms of \"predicting\" scores on one subset from those on the other. Isn't the issue just about how stable/reliable these scores are across the dataset as a whole? ( Even if the reason we care about this might be so that we can assess the validity of inferences from incomplete data.)\n - I couldn't understand the first few sentences after Figure 3 and Table 2. Is there a typo -- should 80% be 50%?\n - I'm not sure about the reasoning around complementary antecedents at the bottom of page 8. Are those two implications uninformative? Don't they basically tell us that all languages have nsubj-head order? ( Notice that their two antecedents are not only complementary numerically, they have the form P and not-P, given the fuzzy logic interpretation of negation.)\n - (#13) on page 9 does not seem \"completely new\": this seems like a straightforward instance of head-finality.",
    "overall_score": "4",
    "confidence": "3"
  }
]