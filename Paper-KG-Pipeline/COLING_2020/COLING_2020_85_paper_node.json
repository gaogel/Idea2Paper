{
  "paper_id": "COLING_2020_85",
  "title": "ContraCAT: Contrastive Coreference Analytical Templates for Machine Translation",
  "conference": "COLING",
  "domain": {
    "research_object": "针对机器翻译中的指代消解问题，提出分析模板以提升翻译质量。",
    "core_technique": "采用对比学习方法与指代消解分析模板，增强模型对指代关系的理解。",
    "application": "用于提升机器翻译系统在处理指代关系时的准确性和一致性。",
    "domains": [
      "自然语言处理",
      "机器翻译"
    ]
  },
  "ideal": {
    "core_idea": "通过对比模板提升机器翻译中的指代消解准确性",
    "tech_stack": [
      "对比学习",
      "指代消解分析",
      "模板方法"
    ],
    "input_type": "包含需翻译文本及指代信息的语料",
    "output_type": "指代消解优化后的目标语言翻译文本"
  },
  "skeleton": {
    "problem_framing": "论文通过具体实例（英语it到德语的翻译）展示机器翻译任务的复杂性，强调需要多层次语言知识。引用前人工作，突出指代消解在上下文感知模型中的重要性，并提出核心问题：Transformer模型是否真正学会了该任务。",
    "gap_pattern": "作者指出虽然已有方法和模型在指代翻译上取得进展，但Transformer是否真正理解和解决了指代消解问题仍存疑。通过质疑现有模型的能力，明确研究空白，强调进一步分析的必要性。",
    "method_story": "方法部分采用对比和扩展策略，先以句级Transformer为基线，再通过拼接上下文句子增强模型能力。详细描述数据处理和实验设置，突出方法的创新点和与前人工作的联系，确保可复现性。",
    "experiments_story": "实验设计围绕对模型表现的系统性攻击，分析不同类型干扰对分数的影响。通过具体案例（如引入新实体、同义词替换等）揭示模型弱点，并用数据和图表支持分析，强调实验结果的解释性和洞察力。"
  },
  "tricks": [
    {
      "name": "引用前人工作以建立研究背景",
      "type": "writing-level",
      "purpose": "展示研究的背景和相关性，说明问题的重要性",
      "location": "引言段（如提及Hardmeier and Federico, 2010; Miculicich Werlen and Popescu-Belis, 2017; Müller et al., 2018）",
      "description": "通过引用前人的研究，说明pronoun translation在NMT中的挑战和已有的评测方法，为本研究提供理论基础。"
    },
    {
      "name": "提出研究问题并设立假设",
      "type": "writing-level",
      "purpose": "明确研究目标，引导读者关注核心问题",
      "location": "引言段（如：'the question remains: Are transformers...?'）",
      "description": "在介绍背景后，直接提出当前transformer模型是否真正学会了指代消解任务，还是仅仅利用了简单启发式规则，明确研究关注点。"
    },
    {
      "name": "对比实验（基线与改进模型）",
      "type": "experiment-level",
      "purpose": "评估上下文信息对模型性能的影响",
      "location": "方法部分（如：'We use Transformer for all experiments and train a sentence-level model as a baseline.'）",
      "description": "设置句子级Transformer作为基线模型，再通过添加上下文信息的模型与之比较，分析上下文对表现的提升。"
    },
    {
      "name": "引入对抗性攻击（adversarial attacks）",
      "type": "method-level",
      "purpose": "测试模型的鲁棒性，揭示模型潜在缺陷",
      "location": "方法部分（如：'making small adversarial changes in the contextual sentences.'）",
      "description": "通过对输入文本做细微但有针对性的修改，检验模型对pronoun coreference的处理是否依赖于脆弱的启发式规则。"
    },
    {
      "name": "使用对比数据集（ContraPro扩展）",
      "type": "experiment-level",
      "purpose": "系统化评测模型对指代消解的能力",
      "location": "方法部分（如：'we extend ContraPro...a contrastive challenge set'）",
      "description": "在已有的ContraPro数据集基础上，通过对抗性修改扩展测试集，便于自动化且细粒度地评估模型表现。"
    },
    {
      "name": "上下文拼接输入法（concatenation of sentences）",
      "type": "method-level",
      "purpose": "将上下文信息纳入模型输入，提升模型对跨句指代的处理能力",
      "location": "方法部分（如：'incorporate contextual information...by concatenating consecutive sentences.'）",
      "description": "通过在源端和目标端分别拼接前一句和当前句，并用特殊分隔符<SEP>区分，使模型能够获取更多上下文信息。"
    },
    {
      "name": "消融实验（移除重叠文档）",
      "type": "experiment-level",
      "purpose": "避免数据泄漏，确保评测的公正性",
      "location": "方法部分（如：'We remove documents overlapping with ContraPro.'）",
      "description": "训练集与测试集去重，防止模型在训练时见过测试数据，保证评测结果的有效性。"
    },
    {
      "name": "错误案例分析",
      "type": "experiment-level",
      "purpose": "深入理解模型错误原因，发现潜在问题",
      "location": "结果分析部分（如：'We analyze examples that are scored incorrectly.'）",
      "description": "对模型预测错误的样本进行详细分析，区分不同类型的对抗攻击对模型的影响，揭示模型脆弱点。"
    },
    {
      "name": "同义词替换实验",
      "type": "experiment-level",
      "purpose": "检验模型对词汇变化的敏感性",
      "location": "结果分析部分（如：'Our synonym replacement also leads to a 17% drop in scores.'）",
      "description": "通过替换输入中的同义词，测试模型对轻微语义变动的鲁棒性，发现其对同义表达的适应能力有限。"
    },
    {
      "name": "定量与直观分析结合",
      "type": "writing-level",
      "purpose": "增强论证的说服力，便于读者理解结果",
      "location": "结果分析部分（如：'These straightforward modifications drop the ContraPro scores by over 10%'）",
      "description": "通过量化分数变化（如10%、17%下降）和举具体实例（如it/that替换）相结合，说明模型对对抗性攻击的脆弱。"
    }
  ]
}