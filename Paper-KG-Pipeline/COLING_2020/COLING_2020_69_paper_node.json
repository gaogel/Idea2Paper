{
  "paper_id": "COLING_2020_69",
  "title": "Evaluating Unsupervised Representation Learning for Detecting Stances of Fake News",
  "conference": "COLING",
  "domain": {
    "research_object": "针对假新闻立场检测任务，研究无监督表示学习方法的有效性。",
    "core_technique": "采用无监督表示学习技术，对文本进行特征提取和建模以辅助立场识别。",
    "application": "用于社交媒体或新闻平台中自动识别和分析假新闻相关立场。",
    "domains": [
      "自然语言处理",
      "信息检索"
    ]
  },
  "ideal": {
    "core_idea": "利用无监督表征学习自动检测假新闻的立场倾向",
    "tech_stack": [
      "无监督学习",
      "表征学习",
      "假新闻检测"
    ],
    "input_type": "新闻文本或社交媒体内容",
    "output_type": "立场分类标签（如支持、反对、中立）"
  },
  "skeleton": {
    "problem_framing": "论文通过强调社交媒体兴起带来的信息传播速度加快，指出传统新闻审核机制被削弱，虚假新闻更易传播，突出了自动化检测虚假新闻的现实紧迫性。这种策略以社会现象为切入点，引发读者关注。",
    "gap_pattern": "作者批评了现有依赖人工识别虚假新闻的方式，指出其受限于人力资源且难以覆盖多样化内容和文体，明确提出自动化检测面临的挑战，从而为后续研究提供理论缺口。",
    "method_story": "方法部分采用技术演进叙述，先介绍表示学习对NLP模型的重要性，再具体说明BERT等模型在双向语境建模上的创新，强调其相较于以往方法的优势，为后续实验奠定理论基础。",
    "experiments_story": "实验部分以探索性实验为起点，明确实验目标为评估模型性能及超参数推荐的有效性。通过控制主要超参数，聚焦不同冻结技术的表现，逻辑清晰地为后续网格搜索和结论铺垫证据。"
  },
  "tricks": [
    {
      "name": "背景引入",
      "type": "writing-level",
      "purpose": "为研究主题设定背景和重要性",
      "location": "开头段落",
      "description": "通过描述社交媒体对新闻传播的影响，以及传统新闻与现代传播的对比，引出假新闻检测的重要性。"
    },
    {
      "name": "引用权威文献",
      "type": "writing-level",
      "purpose": "增强论述的可信度和学术性",
      "location": "文中多处（如Shu et al., 2017; Khan et al., 2019）",
      "description": "在论述现象和方法时，引用相关领域的权威论文，建立理论和方法的依据。"
    },
    {
      "name": "问题定义与任务转化",
      "type": "method-level",
      "purpose": "明确研究任务及其技术实现方式",
      "location": "第二段",
      "description": "将假新闻检测问题转化为stance detection任务（即判断新闻与标题的立场关系），便于采用现有NLP方法。"
    },
    {
      "name": "多模型对比实验设计",
      "type": "experiment-level",
      "purpose": "系统评估多种主流模型的表现",
      "location": "第三段",
      "description": "选择BERT, RoBERTa, DistilBERT, ALBERT, XLNet等近期主流预训练模型进行对比评估，展示方法的全面性。"
    },
    {
      "name": "模型原理简述",
      "type": "writing-level",
      "purpose": "帮助读者理解所用模型的核心机制",
      "location": "后续段落",
      "description": "简要介绍每个模型的创新点和训练方法，如BERT的双向编码、RoBERTa的更长预训练等。"
    },
    {
      "name": "技术演变脉络梳理",
      "type": "writing-level",
      "purpose": "展现领域技术发展的逻辑和进步",
      "location": "介绍各模型时",
      "description": "按照时间和技术发展顺序介绍BERT及其衍生模型，突出技术创新和改进点。"
    },
    {
      "name": "模型轻量化方法说明",
      "type": "method-level",
      "purpose": "解释模型参数精简的技术实现及意义",
      "location": "介绍DistilBERT与ALBERT时",
      "description": "阐述如何通过参数减少技术（如知识蒸馏、分解嵌入等）实现模型轻量化，适应资源受限场景。"
    },
    {
      "name": "预训练与微调策略说明",
      "type": "method-level",
      "purpose": "展示模型训练流程和应用方式",
      "location": "介绍BERT及相关模型时",
      "description": "说明模型先在大规模无标注语料上自监督预训练，再在特定任务上微调或特征抽取，突出迁移学习优势。"
    },
    {
      "name": "任务目标与方法关联",
      "type": "writing-level",
      "purpose": "将具体方法与研究目标紧密结合",
      "location": "各模型介绍与任务结合处",
      "description": "强调所选模型的特性如何服务于假新闻检测任务，如利用深度表征学习提升检测准确率。"
    },
    {
      "name": "对比分析训练目标",
      "type": "method-level",
      "purpose": "分析不同模型训练目标对性能的影响",
      "location": "介绍RoBERTa时",
      "description": "对比BERT的训练目标（如NSP任务）与RoBERTa的调整，讨论其对模型效果的影响和改进原因。"
    }
  ]
}