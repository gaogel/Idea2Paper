{
  "paper_id": "COLING_2020_21",
  "title": null,
  "conference": "COLING",
  "domain": {
    "research_object": "播客音频及其自动语音识别转录文本，包含多样风格和体裁。",
    "core_technique": "自动语音识别（ASR）、自然语言处理（NLP）、信息检索（IR）等方法。",
    "application": "用于语音处理、文本分析、语言学研究及信息检索等任务。",
    "domains": [
      "自然语言处理",
      "语音处理"
    ]
  },
  "ideal": {
    "core_idea": "构建播客语音数据集，促进语音与语言技术研究",
    "tech_stack": [
      "自动语音识别",
      "语料库构建",
      "语音处理"
    ],
    "input_type": "播客音频数据",
    "output_type": "转录文本及相关语料库"
  },
  "skeleton": {
    "problem_framing": "论文通过介绍播客的多样性和流行度，强调其在新闻、对话、虚构与非虚构等多种形式上的广泛应用，提出播客作为研究对象在语言技术、信息检索等领域具有丰富潜力，从而引出对播客研究的必要性。",
    "gap_pattern": "作者指出尽管播客日益流行，但相关学术研究却相对较少，现有转录语音数据集规模有限，缺乏对播客多样性和结构的系统性分析，明确提出当前研究领域存在的数据和方法上的空白。",
    "method_story": "方法部分采用标准化的信息检索主题设定，参考TREC的做法，明确区分不同类型的信息需求，并详细说明如何构建评价标准和检索流程，突出方法的规范性和可复现性。",
    "experiments_story": "实验设计以具体任务驱动，先定义检索主题，再通过BM25模型进行初步检索，并结合人工调整以提升覆盖率，最后通过人工判定相关性，展现实验流程的系统性和严谨性。"
  },
  "tricks": [
    {
      "name": "结构化贡献列表",
      "type": "writing-level",
      "purpose": "清晰展示论文贡献",
      "location": "Our contributions are four-fold: • The largest corpus... • A set of labeled data... • Benchmarking results... • An analysis of the data...",
      "description": "通过项目符号（bullet points）方式将主要贡献分条列出，便于读者快速把握论文核心成果。"
    },
    {
      "name": "对比数据集规模",
      "type": "writing-level",
      "purpose": "突出数据集的创新性和重要性",
      "location": "This is orders of magnitude larger than previous transcribed speech datasets...",
      "description": "通过与已有数据集的对比，强调所构建数据集在规模和多样性上的优势。"
    },
    {
      "name": "引用权威基准与先前工作",
      "type": "writing-level",
      "purpose": "增强方法的权威性和可复现性",
      "location": "following those used by the Text REtrieval Conference (TREC) (Voorhees et al., 2005)",
      "description": "在实验设计时，采用权威会议或文献中已有的标准流程或定义，提升研究的规范性和可对比性。"
    },
    {
      "name": "多类型任务定义",
      "type": "method-level",
      "purpose": "覆盖多样化的信息需求，提升任务适用性",
      "location": "Topics can be one of three types: topical, re-finding, and known item...",
      "description": "根据实际应用场景，将检索任务细分为不同类型，更全面地评估系统性能。"
    },
    {
      "name": "人工与众包结合标注",
      "type": "experiment-level",
      "purpose": "提高标注数据的质量与规模",
      "location": "We started with expert annotation... then added 1060 crowdsourced labels...",
      "description": "先由专家进行初步标注，确保质量，再通过众包扩展数据量，实现效率与质量的平衡。"
    },
    {
      "name": "多元辅助资源支持标注",
      "type": "method-level",
      "purpose": "提升标注准确性",
      "location": "They could use the metadata, the full transcript, the audio, and any other resources...",
      "description": "允许标注者参考多种信息源（元数据、文本、音频等），以便做出更准确的判断。"
    },
    {
      "name": "分级相关性评判标准",
      "type": "method-level",
      "purpose": "细致区分检索结果的相关程度",
      "location": "They used a standard graded scale of Excellent/Good/Fair/Bad, along with a Perfect grade...",
      "description": "采用分级标准对检索相关性进行细致标注，使评测结果更具区分度。"
    },
    {
      "name": "详细标注指南提供",
      "type": "writing-level",
      "purpose": "保证标注一致性和可复现性",
      "location": "Table A1 in Appendix C shows the guidelines we provided the human assessors.",
      "description": "在附录中公布标注指南，确保标注过程标准化，有助于后续复现和扩展。"
    },
    {
      "name": "标准基线模型对比",
      "type": "experiment-level",
      "purpose": "客观评估任务难度和数据集价值",
      "location": "Benchmarking results for retrieval and summarization tasks using standard baselines",
      "description": "采用标准基线模型进行任务基准测试，为后续研究提供参考点。"
    }
  ]
}