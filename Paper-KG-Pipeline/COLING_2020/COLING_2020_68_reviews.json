[
  {
    "review_id": "9bfeab97c9c80594",
    "paper_id": "COLING_2020_68",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "+ The idea of combining different distance metrics in metric learning is interesting. Illustrations of measures are welcome.   In figure 2, there is a mismatch between captions (b) and (c) and their corresponding matrices + Strategy to identify positive and negative examples + Experiments assess the effectiveness of the approach and some analysis are provided",
    "weaknesses": "The main weakness of the paper relies on very insufficient literature review. It does impact the positioning of the contribution (i.e., novelty) as well as its evaluation through suitable baselines. \nAll the literature about neural information retrieval is missing: 1. Metric learning has already been used in neural IR (DRMM by Guo et al 2016, DeepMatch Lu and LI 2013, ...). Il would be also interesting to mention other neural IR models (Yang et al 2019, Guo et al 2019, … and different tutorial nn4ir at sigir) Please compare your work with these references.\n2. I do not agree with the following statement : “It is remarkable that although the biomedical domain has  plenty of structured knowledge as biomedical terminology databases and ontologies, most of the approaches have not made use of these resources (Majdoubi et al., 2009). An exception is the work presented by (Bhogal et al., 2007), where ontologies are used to expand query terms. Structured resources offer information that is complementary to textual information and that can be used to alleviate problems as polysemy or synonymy disambiguation”   Check more recent references such as :  Tymoshenko, K., Moschitti, A., & Severyn, A. (2014, April). Encoding semantic resources in syntactic structures for passage reranking. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (pp. 664-672). \nXu, B., Lin, H., & Lin, Y. (2018). Learning to refine expansion terms for biomedical information retrieval using semantic resources. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 16(3), 954-966. \nL. Tamine, L. Soulier, G.‑H. Nguyen, N. Souf : “Offline versus Online Representation Learning of Documents Using External Knowledge”, ACM Transactions on Information Systems, vol. 37 (4), pp. 42:1-42:34, (Association for Computing Machinery) (2019) G.‑H. Nguyen, L. Soulier, L. Tamine, N. Bricon‑Souf : “DSRIM: A Deep Neural Information Retrieval Model Enhanced by a Knowledge Resource Driven Representation of Documents”, The 3rd ACM International Conference on the Theory of Information Retrieval, Amsterdam, Netherlands (2017) The authors should rework the positioning of their paper according to these references as well as the choice of baselines.\nIn addition, we can add the following remarks: All notation used in equations and figures should be clearly defined mainly in formula (1) and figure 1.  : alpha, w, N, disc(q,p+), etc by analyzing table 3 and table 4, the three representations have, individually, led to a MAPs < 0,150, however, the MAP is doubled when the three representations are combined. It is an interesting result, however I am curious to know what is the result of combining these representations by paires, for example : (w2vec -terms), (w2vec -concepts) or  (terms-concepts) having influenced the results or not.   Some edits  Section 1 comparing against →  comparing with It is important to highlighted →  to highlight Section 2  (Feng et al., 2015) were a metric learning approach… →  where the convolutional neural netowork learns to represent →  network  Section 3 The proposed architecture is describe →  is described The model implementation is publicity available → publicly  Section 5 The following results à the following study (experiment)",
    "comments": "",
    "overall_score": "1",
    "confidence": "4"
  }
]