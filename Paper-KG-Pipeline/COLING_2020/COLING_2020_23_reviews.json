[
  {
    "review_id": "7420b9259a5bb05d",
    "paper_id": "COLING_2020_23",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "This paper presents BioMedBERT a transformer-based model (derived from BERT large) trained on the domain specific large-scale corpus called BREATHE and tuned on the SQUAD2 corpus.  According to the authors, BioMedBERT achieves state-of-the-art results in QA, especially in the medical domain, as suggested from the results obtained in the BioASQ 5b, 6b and 7b datasets. \nMoreover, interesting results are obtained in the NER and RE tasks, always with respect to evaluations in the medical domain.  Although the core contribution of this work seems “only” the tuning of an existing BERT model on a brand-new corpus, the proposed models seems quite effective.  Unfortunately, it is very difficult to confirm the improvements with respect to the state-of-the-art. In fact, while only the standard BERT is evaluated with respect to the SQUAD dataset, all the more effective methods presented in the SQuAD v2.0 leaderboard are completely ignored. \nMoreover, I tried to figure out the state-of-the-art reported in this paper with respect to the results provided at http://participants-area.bioasq.org or  https://www.aclweb.org/anthology/W18-5301.pdf but it was really difficult.  Overall, the novelty of the contribution (especially from a linguistic perspective) is quite limited (the adopted method is quite used as is), even though a large and interesting (but not really clear) experimental evaluation is provided. More reference to previous work (especially the state-of-the-art) would be beneficial.",
    "overall_score": "3",
    "confidence": "4"
  },
  {
    "review_id": "b7daba2533c998c0",
    "paper_id": "COLING_2020_23",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "The paper introduces BioMedBert, a BERT-like model trained on BREATHE, a very large bio-medical dataset (10Bwords). The model is trained started from BERT_Large model and then fine-tuned on some of the original task datasets (Squad 1 and Squad 2) but also more interestingly on bio-medical task datasets (NER, Relation Extration, Question-Answering). Evaluations are provided for these tasks that show that BioMedBert outperforms BERT and also that BioMedBert is state-of-the-art on QA tasks over several BioASQ datasets. \nThe paper also shows the interest of BioMedBert (versus other generic embeddings) to improve information retrieval of medical papers by reranking the list of documents returned by Elastic Search. \nThe paper does not introduce new techniques or notions but is clear and well written. And BioMedBert should be an interesting resource for health applications which shows there are a room for domain-specific BERT-like models when there are enough data for training. However, the paper mentions that it is still better to start from the general domain BERT, and it could also be interesting to check how much specific domain data is really necessary to add in order to achieve good results. Also, in order to test the stability of BioMedBert (on general domain), as done for Squad, it would be nice to get the performance of BioMedBert on the other original BERT-tasks In table 5 about Relation Extraction, I was a bit surprised to observe that recall decreases strongly when using BioMedBert. Do you have some explanation ?",
    "overall_score": "4",
    "confidence": "4"
  }
]