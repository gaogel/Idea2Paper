[
  {
    "review_id": "44d30e06334cd663",
    "paper_id": "COLING_2020_78",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "The topic of the paper is grammatical error detection (GED) in speech. While GED in written texts has been subject of many studies, GED in speech has been less well studied and the results so far have been disappointing: due to relatively short duration of most spoken responses and multiple disfluencies typical for spontaneous speech, especially non-native, conventional methods of GED that worked well on written text generally tended to fail on speech.\nThis paper presents a new set of annotations of grammatical errors in English native and non-native speech obtained via crowdsourcing. The authors promise to publicly release these annotations. The first part of the paper is devoted to the detailed description of data processing including transcription QC and error annotation. The second part of the paper describes the training and evaluation of GED system based on GloVe and BERT. The authors also tried numerous other features including prosody but disappointingly these have not led to further improvement.  The paper is very well written and the methodology is sound. All evaluations are done with 10-fold CV and 10 random seeds with the evaluations reported based on means across these 100 runs. All analyses are done using open-source tools and could be reproduced. The authors promise to release the data partitioning to further aide reproducibility.  I believe it will be a great addition to COLING program.  I only have a few minor comments and suggestions for references: - The overall precision and recall remain relatively low, which is consistent with previous work. Anther metrics that you might consider in future is how well your system predicts the overall grammaticality score/total number of grammatical errors. While less useful for targeted feedback, this could still be a very useful measure in the context of language assessment.\n- Section 2: Privacy concerns is another reason speech corpora are less common. Since voice recordings are considered PII, releasing spoken corpora requires a different level of participant consent and additional legal considerations.\n- It would be helpful to have some information about English language proficiency level of the non-native crowdworkers.   - This reference might be useful for your transcription analysis: Evanini, K., Higgins, D., & Zechner, K. (2010). Using Amazon Mechanical Turk for transcription of non-native speech. In CSLDAMT ’10 Proceedings of the NAACL HLT 2010 Workshop on Creating Speech and Language Data with Amazon’s Mechanical Turk (pp. 53–56).   - 3.1 In addition to total number of recordings, it would be useful to also report total duration in hours or minutes.  - This volume: https://benjamins.com/catalog/scl.23 might be a useful resource for speech vs. text comparison in the context of ELL assessment.\n- 4.1 Should \"M^2\" be a number?",
    "overall_score": "5",
    "confidence": "4"
  }
]