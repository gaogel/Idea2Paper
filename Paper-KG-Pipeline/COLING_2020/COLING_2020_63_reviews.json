[
  {
    "review_id": "c39647a8dd484dd5",
    "paper_id": "COLING_2020_63",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "On the example of domain adaptation for machine translation using a transformer network, this paper analyzes and visualizes the impact of different model components and specific neurons w.r.t. both adaptation performance and catastrophic forgetting, i.e. general-domain performance. Each component is investigated by either freezing only the component or all other components. Individual parameters are evaluated with respect to their importance by approximating the impact on the loss function by their removal.\nI find that the authors tackle an important problem, the methodology is described in good detail, the experiments well conducted and the analyses insightful. Some of the methods could be more generally applied for interpreting networks. \nMy main concern is that the work seems incomplete without what the authors state as future work: \"Inspired by our findings, we can freeze part of those important parameters during continual training to avoid catastrophic forgetting. Besides, we can retrain those unimportant parameters to further improve the in-domain translation\". Without those experiments it is pretty much impossible to draw conclusions from the parameter-wise analysis, leaving the following questions open: - If we freeze the most important parameters, will the network find a way to replace them with other parameters when fine-tuning?  - Will that mitigate catastrophic forgetting?  - What does the importance matrix look like after fine tuning, if the previously most important parameters are frozen? \nIt seems to me that adding those results will easily fit into the scope of the paper.\nSo I am somewhat ambivalent about accepting the paper. I did gain some interesting insights, but at the same time I wish the authors would get a chance to complete their work before publishing.\nMinor comments: - Fig. 1: Please state the task, model and domain which the graph represents - 2) - notation: ground truth sequence and translation can have different lengths, so you should use different variables (e.g. I and I*) - 4.3.2 - it is unclear on which training examples t you are computing Eq. 7 before and after fine-tuning. I'm guessing it is the general domain training corpus before fine-tuning, and the in-domain training corpus after fine-tuning, but that should be explicitly stated.\n- Eq. 8 - it seems that you should be iterating over individual scalar parameters, rather than modules i. Otherwise the sum over matrices with different dimensions is undefined (assuming that the square and sqrt are computed element-wise) - Fig. 6 - does the x-axis denote importance before or after fine-tuning?\nMissing reference: - \"Compact Personalized Models for Neural Machine Translation\", EMNLP 2018, also investigates the impact of freezing subnetworks on adaptation performance.",
    "overall_score": "3",
    "confidence": "4"
  }
]