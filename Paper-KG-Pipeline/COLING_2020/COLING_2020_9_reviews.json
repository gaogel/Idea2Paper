[
  {
    "review_id": "21e82addf86f0429",
    "paper_id": "COLING_2020_9",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "Related to a recent notion of Visual Dialog tasks, the paper introduces and evaluates a sophisticated neural architecture to answer queries related to images through a dialog (a sequence of several queries and answers). \nThere are several components in the system but the paper focuses on two of them, namely VTA to map visual features to textual features found in the dialog history and current query; and VGAT to build graphs from these visual-textual pairs An evaluation is done on the VisDial dataset for 5 metrics and with comparison with several SOTA systems covering different approaches. The proposed system performs best for all metrics. Ablation seems to confirm the interest of both components (VTA and VGAT), even if the results are maybe not so significative. A few exemples are provided for illustration. \nThe task and the proposed architecture are interesting. However, it is difficult to follow the details of the model, also because of (maybe) some errors. There are also a lot a parameters and some hypothesis that may be discussed. For instance, it is unclear why a graph representation is really needed instead of some ranking of the visual-textual pairs and how exactly the graph is exploited, a priori (from Fig. 4) the top-5 strongest connections in the graph More specific remarks: - in 3.1, is the number k of visual features a fixed parameter (and then which value is used for the experiments) or a parameter depending on the image being processed ?\n- In eq. (1), (2), and maybe (3) and (4), I wonder if i should range from 1 to h rather than from 1 to k ?\n- in 3.3, I don't understand what you mean by \"homogenous information\" - in 3.3, what do you mean by two textual operations (with different colors) - the construction of the sequence of graphs in 3.3 is really unclear; in eq (10), do you mean G(i>0) rather than G(i) ? If I understand correctly, G(i=0) and G(i>0) are a kind of serialization of the graphs but it is unclear if e(i>0)=e(i) ? In eq (6), are you using new multiheads or are they related to those defined in 3.2 ? Why k iteration steps ? Is it to identify at each step (i) the most interesting neighbor nodes for node (i) ?\n- in 3.1: how if build the list of 100 answers for each query ? Are some false answers randomly added to the right answer, or a specific set of 100 answers is provided for each query ? It is a single set of 100 answers for each dialog ?",
    "overall_score": "4",
    "confidence": "3"
  }
]