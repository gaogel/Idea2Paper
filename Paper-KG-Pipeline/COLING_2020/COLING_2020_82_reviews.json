[
  {
    "review_id": "aad3d6f1569faa42",
    "paper_id": "COLING_2020_82",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "• Clear hypothesis and argumentation • Strong result which shows the contributions of the individual components",
    "weaknesses": "• Could use better motivation of specifically why the BiLSTM model with attention was chosen. Why not use BERT, since this has been shown to be very effective on this task? \n• Would be nice to see some followup analysis of what the model gets wrong. Where is the next improvement going to come from?",
    "comments": "",
    "overall_score": "4",
    "confidence": "3"
  }
]