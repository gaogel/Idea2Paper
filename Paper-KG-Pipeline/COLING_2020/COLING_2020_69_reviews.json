[
  {
    "review_id": "8fe34372cb461bc9",
    "paper_id": "COLING_2020_69",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "of the paper is the clarity: the paper is clearly presented and well-reasoned. It is easy to follow and possibly easy to replicate. To this end, the authors have set up a GitHub link, but since it is anonymised it cannot be browsed.  I would suggest the following, if the paper is accepted for publication:  1) Replace \"n't\" with full form: academic papers are still a quite formal genre. \n2) Replace the section title \"Summary\" with \"Conclusion\" and expand it. For example, say in which way the presented results can benefit the community, whether future experiments of the same kind are planned on another task or using other datasets or for another downstream task. Fine-tuning of pre-trained models is a pervasive problem: is there a way to generalize on the results presented on the paper? Or are these task- and dataset-specific? etc.   3) Update the preliminary results in Table 3. \n4) Add a table or an appendix where the hardware characteristics (computer resources) are shown (eg. CPU, GPU, Clock Speed, Ram etc). \n5) Add a table or an appendix where the the processing time of the performance (first row in Table 4) is reported for each model.",
    "weaknesses": "",
    "comments": "",
    "overall_score": "4",
    "confidence": "4"
  }
]