[
  {
    "pattern_id": 1,
    "pattern_name": "语言分布特性训练策略",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决词义消歧和语义表示问题，采用基于语言分布特性的训练策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过数据分布分析指出问题，引入理论依据并明确创新点，多采用对比实验和消融分析验证方法效果。\n第3段（60字）：适用场景与预期效果 - 适用于词义消歧、语义表示和多词表达建模任务，预期提升模型在稀有和零样本词义上的性能，增强泛化能力。",
    "writing_guide": "写作模板：语言分布特性训练策略\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决词义消歧和语义表示问题，采用基于语言分布特性的训练策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过数据分布分析指出问题，引入理论依据并明确创新点，多采用对比实验和消融分析验证方法效果。\n第3段（60字）：适用场景与预期效果 - 适用于词义消歧、语义表示和多词表达建模任务，预期提升模型在稀有和零样本词义上的性能，增强泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting》\n  • 问题定位：论文首先从自然语言处理领域的长期难题——词义消歧（WSD）任务切入，强调其对机器翻译、信息检索等下游应用的重要性（从应用需求出发）。通过举例说明词义消歧的实际困难，进一步指出常见语义与罕见语义在数据分布上的极度不平衡，进而引出稀有和零样本词义的挑战（结合实际痛点和数据分布问题）。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法局限于...’的逻辑。\n  • 核心方法：方法部分采用‘先整体后对比’的叙述策略。首先说明方法的核心思想（Z-reweighting策略），随后对比不同主干模型（Bert-base与Bert-large）在该策略下的表现。\n  • 实验设计：实验部分采用‘主实验+细粒度分析+消融与参数影响’的叙述策略。首先介绍数据集和评测指标，然后展示不同训练策略下的整体性能对比（主实验）。接着，细致分析了方法在最常见语义（MCS）、最少见语义（LCS）和零样本语义上的提升效果（细粒度分组分析）。\n\n示例 2：《Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments》\n  • 问题定位：论文通过定义type-level word embeddings及其在下游任务中的泛化能力，引入了词类型与词实例的区分，结合具体例子（如‘pool’）说明现有模型的局限，为后续研究设定了明确的背景和动机。\n  • 现有研究缺口：作者指出大多数词向量模型仅为每个词类型定义单一向量，忽视了同一词在不同上下文中的多样语义，暗示现有方法在处理词义歧义和上下文相关性方面存在不足，明确了研究的创新空间。\n  • 核心方法：方法部分采用‘先总后分’策略，先整体描述模型结构（bi-LSTM编码序列），再细致阐述候选头词的打分流程、损失函数和预测方式，逻辑清晰，便于读者理解模型设计与实现细节。\n  • 实验设计：实验部分先介绍数据集来源、规模及分割，强调数据集的现实性和挑战性，并通过与经典数据集的对比突出所选数据集的优势，随后详细说明输入结构和任务设置，确保实验设计的合理性与可复现性。\n\n示例 3：《How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks》\n  • 问题定位：论文通过回顾词向量在NLP中的核心地位和广泛应用，引出其在实际任务迁移中的重要性。作者以引用权威文献的方式，强调词表示学习对领域进步的推动作用，设定了研究的现实背景和理论基础。\n  • 现有研究缺口：作者指出当前领域的主要不足在于缺乏系统、原则性的评估方法，这阻碍了词向量研究的进一步发展。同时，训练和调优词向量面临多重挑战，现有评测手段难以有效指导模型选择，明确提出了研究的gap。\n  • 核心方法：方法部分采用分类叙述策略，系统地将评测数据集分为四类，详细说明每类数据的构成和来源。通过枚举具体数据集，展示方法的全面性和实验设计的严谨性，为后续实验奠定基础。\n  • 实验设计：实验部分以问题驱动的方式展开，围绕三个核心科学问题组织实验设计。每个问题都对应具体的评测指标和分析目标，强调实验对方法有效性的实证验证，逻辑清晰地串联起研究假设与实验结果。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 实际应用场景举例（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：通过举例说明WSD在机器翻译和信息检索等下游任务中的作用，强调该问题的广泛影响\n\n2. 数据分布分析（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：分析SemCor语料的常见/稀有/零样本词义分布，强调训练样本不均衡的问题\n\n3. 现有方法归纳与不足（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：总结前人方法（数据集设计、外部知识引入）并指出其局限，为新方法做铺垫\n\n4. 理论依据引入（使用频率 1 次，占比 5.3%）\n   类型：method-level\n   应用：引用Zipf定律及相关语言学理论，解释词频与词义多样性的关系，为方法设计提供理论支撑\n\n5. 创新点明确声明（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：明确指出首次利用语言分布规律解决WSD训练偏差，强调方法的独特性\n\n6. 方法原理分步解释（使用频率 1 次，占比 5.3%）\n   类型：method-level\n   应用：分步介绍从语料统计、数学拟合到训练权重分配的过程，层层递进解释方法设计\n\n7. 参数设置透明化（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：详细说明模型初始化、参数选择和训练设置，便于他人复现\n\n8. 多策略对比实验（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：同时对比B-reweighting、Z-reweighting、B-resampling等多种训练策略，展示各自效果\n\n9. 主干模型消融分析（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：比较Bert-base与Bert-large作为主干模型的表现，结合效率选择最终模型\n\n10. 分组细粒度结果分析（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：分别分析常见词义（MCS）、稀有词义（LCS）和零样本词义的性能提升\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_246",
        "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
        "problem_framing": "论文首先从自然语言处理领域的长期难题——词义消歧（WSD）任务切入，强调其对机器翻译、信息检索等下游应用的重要性（从应用需求出发）。通过举例说明词义消歧的实际困难，进一步指出常见语义与罕见语义在数据分布上的极度不平衡，进而引出稀有和零样本词义的挑战（结合实际痛点和数据分布问题）。随后，作者从语言学现象（Zipf定律）和统计规律的角度，提出利用语言分布特性来缓解训练偏差，巧妙地将学术理论与实际问题结合，形成问题引出的完整链条。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法局限于...’的逻辑。具体指出：1）很多深度神经网络方法受限于训练语料的不平衡；2）以往方法主要通过设计专门数据集或引入外部知识来解决稀有和零样本词义问题，未从训练过程本身调整角度出发；3）强调本工作是首个利用语言分布规律（Zipf定律）来缓解WSD训练偏差的方法。整体上，批评策略为‘现有方法忽视了训练过程中的语言分布特性’和‘现有方法在训练偏差问题上存在局限’。",
        "method_story": "方法部分采用‘先整体后对比’的叙述策略。首先说明方法的核心思想（Z-reweighting策略），随后对比不同主干模型（Bert-base与Bert-large）在该策略下的表现。进一步，方法部分还对比了多种平衡训练策略（如B-reweighting、B-resampling、LDAM等），并通过实验结果展示各自的优劣。整体上，方法部分先介绍主要创新点，再通过与现有策略的对比，突出方法的有效性和选择理由。",
        "experiments_story": "实验部分采用‘主实验+细粒度分析+消融与参数影响’的叙述策略。首先介绍数据集和评测指标，然后展示不同训练策略下的整体性能对比（主实验）。接着，细致分析了方法在最常见语义（MCS）、最少见语义（LCS）和零样本语义上的提升效果（细粒度分组分析）。最后，考察了Z-reweighting中超参数和主干模型选择对结果的影响（消融与参数敏感性分析）。实验设计涵盖了主实验、分组细节分析和消融实验，验证了方法的有效性和鲁棒性。"
      },
      {
        "paper_id": "ACL_2017_691",
        "title": "Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments",
        "problem_framing": "论文通过定义type-level word embeddings及其在下游任务中的泛化能力，引入了词类型与词实例的区分，结合具体例子（如‘pool’）说明现有模型的局限，为后续研究设定了明确的背景和动机。",
        "gap_pattern": "作者指出大多数词向量模型仅为每个词类型定义单一向量，忽视了同一词在不同上下文中的多样语义，暗示现有方法在处理词义歧义和上下文相关性方面存在不足，明确了研究的创新空间。",
        "method_story": "方法部分采用‘先总后分’策略，先整体描述模型结构（bi-LSTM编码序列），再细致阐述候选头词的打分流程、损失函数和预测方式，逻辑清晰，便于读者理解模型设计与实现细节。",
        "experiments_story": "实验部分先介绍数据集来源、规模及分割，强调数据集的现实性和挑战性，并通过与经典数据集的对比突出所选数据集的优势，随后详细说明输入结构和任务设置，确保实验设计的合理性与可复现性。"
      },
      {
        "paper_id": "ACL_2017_239",
        "title": "How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks",
        "problem_framing": "论文通过回顾词向量在NLP中的核心地位和广泛应用，引出其在实际任务迁移中的重要性。作者以引用权威文献的方式，强调词表示学习对领域进步的推动作用，设定了研究的现实背景和理论基础。",
        "gap_pattern": "作者指出当前领域的主要不足在于缺乏系统、原则性的评估方法，这阻碍了词向量研究的进一步发展。同时，训练和调优词向量面临多重挑战，现有评测手段难以有效指导模型选择，明确提出了研究的gap。",
        "method_story": "方法部分采用分类叙述策略，系统地将评测数据集分为四类，详细说明每类数据的构成和来源。通过枚举具体数据集，展示方法的全面性和实验设计的严谨性，为后续实验奠定基础。",
        "experiments_story": "实验部分以问题驱动的方式展开，围绕三个核心科学问题组织实验设计。每个问题都对应具体的评测指标和分析目标，强调实验对方法有效性的实证验证，逻辑清晰地串联起研究假设与实验结果。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "实际应用场景举例",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "通过举例说明WSD在机器翻译和信息检索等下游任务中的作用，强调该问题的广泛影响",
            "type": "writing-level",
            "purpose": "增强说服力，让读者感受到问题的重要性和实际价值"
          }
        ]
      },
      {
        "trick_name": "数据分布分析",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "分析SemCor语料的常见/稀有/零样本词义分布，强调训练样本不均衡的问题",
            "type": "writing-level",
            "purpose": "突出问题难点，说明现有数据分布对模型训练的影响"
          }
        ]
      },
      {
        "trick_name": "现有方法归纳与不足",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "总结前人方法（数据集设计、外部知识引入）并指出其局限，为新方法做铺垫",
            "type": "writing-level",
            "purpose": "突出新方法的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "理论依据引入",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "引用Zipf定律及相关语言学理论，解释词频与词义多样性的关系，为方法设计提供理论支撑",
            "type": "method-level",
            "purpose": "增强方法的可解释性和科学性"
          }
        ]
      },
      {
        "trick_name": "创新点明确声明",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "明确指出首次利用语言分布规律解决WSD训练偏差，强调方法的独特性",
            "type": "writing-level",
            "purpose": "突出工作的新颖性和首创性"
          }
        ]
      },
      {
        "trick_name": "方法原理分步解释",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "分步介绍从语料统计、数学拟合到训练权重分配的过程，层层递进解释方法设计",
            "type": "method-level",
            "purpose": "提升可解释性，帮助读者理解方法逻辑"
          }
        ]
      },
      {
        "trick_name": "参数设置透明化",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "详细说明模型初始化、参数选择和训练设置，便于他人复现",
            "type": "experiment-level",
            "purpose": "提升实验的可复现性和完备性"
          }
        ]
      },
      {
        "trick_name": "多策略对比实验",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "同时对比B-reweighting、Z-reweighting、B-resampling等多种训练策略，展示各自效果",
            "type": "experiment-level",
            "purpose": "增强对比性，突出新方法的优势或特点"
          }
        ]
      },
      {
        "trick_name": "主干模型消融分析",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "比较Bert-base与Bert-large作为主干模型的表现，结合效率选择最终模型",
            "type": "experiment-level",
            "purpose": "验证方法的稳健性和效率选择"
          }
        ]
      },
      {
        "trick_name": "分组细粒度结果分析",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "分别分析常见词义（MCS）、稀有词义（LCS）和零样本词义的性能提升",
            "type": "experiment-level",
            "purpose": "提升实验完备性，展示方法在不同词义分布上的效果"
          }
        ]
      },
      {
        "trick_name": "超参数影响分析",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "分析Z-reweighting中超参数对模型性能的影响，展示方法的调优空间",
            "type": "experiment-level",
            "purpose": "增强方法的可解释性和完备性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_246",
            "title": "Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting",
            "description": "从问题引入、现状分析、方法提出到实验验证，层层递进，呼应结论",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "类型与词元区分",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_691",
            "title": "Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments",
            "description": "明确区分word type（词的表面形式）与word token（词在具体上下文中的实例），通过举例说明同一个type在不同句子中的不同token及其语义差异。",
            "type": "writing-level",
            "purpose": "澄清概念，避免混淆"
          }
        ]
      },
      {
        "trick_name": "揭示现有方法的局限性",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_691",
            "title": "Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments",
            "description": "指出主流type-level词嵌入无法区分多义词或抽象概念的不足，通过具体例子（如‘pool’）说明该问题。",
            "type": "writing-level",
            "purpose": "突出研究意义，激发读者兴趣"
          }
        ]
      },
      {
        "trick_name": "利用预训练词嵌入初始化模型参数",
        "frequency": 1,
        "percentage": "5.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_691",
            "title": "Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments",
            "description": "采用在大规模无标注语料上预训练的词嵌入作为模型参数的初始化值，并在下游任务训练阶段进行微调。",
            "type": "method-level",
            "purpose": "提升模型泛化能力与训练效果"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 19,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_246",
        "ACL_2017_691",
        "ACL_2017_239",
        "ACL_2017_768",
        "ACL_2017_553",
        "ACL_2017_477",
        "ACL_2017_178",
        "ACL_2017_145",
        "ACL_2017_563",
        "ACL_2017_395",
        "ACL_2017_56",
        "ACL_2017_318",
        "ACL_2017_201",
        "ACL_2017_494",
        "ACL_2017_251",
        "ACL_2017_173",
        "COLING_2020_45",
        "COLING_2020_60",
        "COLING_2020_71"
      ]
    }
  },
  {
    "pattern_id": 2,
    "pattern_name": "跨领域泛化模块化方法",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨领域泛化和复杂结构理解问题，采用新数据集设计和模块化方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过现有方法不足对比引出问题，方法部分采用模块化设计和多数据集验证。\n第3段（60字）：适用场景与预期效果 - 适用于表格解析、数学题理解等复杂结构任务，预期提升泛化能力和模型鲁棒性。",
    "writing_guide": "写作模板：跨领域泛化模块化方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨领域泛化和复杂结构理解问题，采用新数据集设计和模块化方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过现有方法不足对比引出问题，方法部分采用模块化设计和多数据集验证。\n第3段（60字）：适用场景与预期效果 - 适用于表格解析、数学题理解等复杂结构任务，预期提升泛化能力和模型鲁棒性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion》\n  • 问题定位：论文从实际应用需求出发引出问题，指出在真实场景中用户需要对大表格进行查询以提升生产力，但现有的 text-to-SQL 解析器在遇到未见过的新领域表格时泛化能力很差。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，具体指出虽然最新的神经语义解析器在大规模数据集上表现良好，但在 out-of-domain（跨领域）泛化方面远未成功。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先明确提出要构建具备跨领域泛化能力的评测基准（包括合成数据集和 SQUALL 数据集的新划分），然后提出一种简单但有效的基线方法，作为未来工作的参考点。\n  • 实验设计：实验部分采用‘多数据集验证+多配置对比’的叙述策略。首先在两个新提出的基准（合成数据集和 SQUALL 新划分）以及原有 SQUALL 基准上进行实验，覆盖不同领域。每个实验均采用交叉领域（train/test 不同领域）和 i.i.d.（同分布）两种划分。\n\n示例 2：《Text-to-Table: A New Way of Information Extraction》\n  • 问题定位：论文首先从信息抽取（IE）这一广泛应用的任务切入，强调其在结构化数据提取和下游应用（如文本挖掘）中的重要性。随后，作者提出了一个新的设置——text-to-table，指出其与传统IE的不同之处，特别是在能够从长文本中提取复杂结构化数据、无需显式定义schema等方面。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先，系统梳理了NER、RE、EE等主流IE方法，指出它们均依赖预定义schema且多针对短文本，难以直接应用于text-to-table任务。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述顺序。首先，简要介绍整体思路——基于seq2seq模型实现text-to-table，并支持多表输出。\n  • 实验设计：实验部分采用‘主实验+多数据集验证+对比分析’的策略。首先，在Rotowire数据集上与doc-level RE、sent-level RE等基线方法进行主实验对比，突出自身方法的优势。其次，在E2E、WikiTableText、WikiBio等多个数据集上进一步验证方法的通用性和有效性。\n\n示例 3：《Turning Tables: Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills》\n  • 问题定位：论文从学术gap出发引出问题，首先指出大规模预训练语言模型已成为自然语言处理的核心，但在符号推理（如事实组合、数值运算、量化等）方面表现不足，且需要大量额外数据才能提升相关能力。通过引用前人工作，强调当前模型在推理任务上的局限性，明确提出需要新的数据生成和训练方法以提升模型的推理能力。\n  • 现有研究缺口：论文批评现有方法时采用了对比和归类的逻辑，指出过去的工作主要有两类：一类是为特定推理技能添加专用组件，另一类是大规模合成数据生成。作者强调这些方法要么针对性强、扩展性有限，要么数据生成方式受限，未能充分利用结构化资源。\n  • 核心方法：方法部分采用先整体后局部的叙述策略，首先介绍整体思路：利用半结构化表格自动生成多种推理类型的阅读理解训练数据。随后详细说明数据生成流程，包括表格爬取、16种推理技能的模板化生成器、自动填充变量和答案计算、上下文构造等。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略，首先在下游阅读理解数据集上进行主实验，验证方法的有效性。随后在合成数据上进行补充实验，分析模型在生成数据上的表现。实验设计突出对比不同采样策略和模型规模，并说明数据集去重处理，保证实验公正性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 指标多样化（使用频率 2 次，占比 25.0%）\n   类型：experiment-level\n   应用：采用Execution Accuracy、Spurious Program Rate等多种指标，全面衡量模型性能和鲁棒性。\n\n2. 现有方法局限性批判（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者指出现有预训练目标忽视数值关系，合成SQL/问题仅适用于数据库表，难以保证真实性\n\n3. 现实场景动机引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过描述真实用户在处理大型表格时遇到的挑战，引出研究问题并强调其实际意义。\n\n4. 现有方法不足对比（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：引用最新文献指出当前SOTA方法在跨领域泛化上的不足，为提出新方法做铺垫。\n\n5. 问题分解与细化（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：将泛化难题细分为列匹配和列操作两大类，分别举例说明具体挑战。\n\n6. 新基准数据集设计（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：提出两个新的评测基准（合成数据集和SQUALL重划分），专门用于量化列操作的跨域泛化能力。\n\n7. 方法简化与模块化（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：将方法拆分为schema expansion和schema pruning两个独立模块，可与任意现有parser结合。\n\n8. 直观类比与实例说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过具体例子（如“Income”映射到不同表的不同列组合）和图示，帮助读者把握抽象操作的实际含义。\n\n9. 现实约束假设说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：说明schema expansion基于列类型假设，强调方法对新领域的适用性和可扩展性。\n\n10. 实验对比分组设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：设计四种配置（Base, Base+P, Base+E, Base+P+E）系统性对比，清晰展示各模块贡献。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_52",
        "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
        "problem_framing": "论文从实际应用需求出发引出问题，指出在真实场景中用户需要对大表格进行查询以提升生产力，但现有的 text-to-SQL 解析器在遇到未见过的新领域表格时泛化能力很差。通过举例说明用户在操作 Excel 等表格时会遇到新领域数据，强调模型需要理解和映射领域特定短语到表格元素的挑战，突出实际痛点和应用需求。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，具体指出虽然最新的神经语义解析器在大规模数据集上表现良好，但在 out-of-domain（跨领域）泛化方面远未成功。进一步指出，现有方法主要依赖预训练语言模型解决列匹配问题，但对列操作（如复合表达式）的泛化能力不足，且缺乏相关评测基准。常用句式包括‘recent work has suggested that... are far from successful in terms of...’和‘remain relatively unexplored due to the lack of evaluation benchmarks’。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先明确提出要构建具备跨领域泛化能力的评测基准（包括合成数据集和 SQUALL 数据集的新划分），然后提出一种简单但有效的基线方法，作为未来工作的参考点。具体方法由两个可插拔组件组成：schema expansion 和 schema pruning，先整体介绍两者的目标和作用，再分别详细说明每个组件的设计思路和实现方式，强调其通用性和可扩展性。",
        "experiments_story": "实验部分采用‘多数据集验证+多配置对比’的叙述策略。首先在两个新提出的基准（合成数据集和 SQUALL 新划分）以及原有 SQUALL 基准上进行实验，覆盖不同领域。每个实验均采用交叉领域（train/test 不同领域）和 i.i.d.（同分布）两种划分。对比四种配置（基线、基线+pruning、基线+expansion、基线+pruning+expansion），并多次重复实验报告均值和标准误。实验指标以 exact match accuracy 为主，分析不同配置和划分下的性能提升，突出方法在跨领域泛化上的优势。"
      },
      {
        "paper_id": "ARR_2022_138",
        "title": "Text-to-Table: A New Way of Information Extraction",
        "problem_framing": "论文首先从信息抽取（IE）这一广泛应用的任务切入，强调其在结构化数据提取和下游应用（如文本挖掘）中的重要性。随后，作者提出了一个新的设置——text-to-table，指出其与传统IE的不同之处，特别是在能够从长文本中提取复杂结构化数据、无需显式定义schema等方面。整体采用了从实际应用需求和学术gap结合的开篇策略：一方面强调IE结构化结果的实际价值，另一方面指出现有方法在新场景下的不足，顺势引出自身研究的问题。",
        "gap_pattern": "论文批评现有方法时，采用了对比和局限性分析的逻辑。首先，系统梳理了NER、RE、EE等主流IE方法，指出它们均依赖预定义schema且多针对短文本，难以直接应用于text-to-table任务。其次，针对OpenIE和doc-level IE等相关工作，指出它们要么只能处理简单结构，要么不能适应复杂表格结构的抽取需求。常用句式包括‘cannot be directly applied to...’、‘most methods are designed for...’等，突出当前方法在新任务下的失效和不足。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述顺序。首先，简要介绍整体思路——基于seq2seq模型实现text-to-table，并支持多表输出。随后，以Rotowire数据集为例，具体说明如何将表格结构序列化（如用caption分隔不同表格），再分别介绍表格约束（table constraint）和表格关系嵌入（table relation embeddings）两个关键技术点。整体结构清晰，先给出框架，再细化到关键模块和实现细节。",
        "experiments_story": "实验部分采用‘主实验+多数据集验证+对比分析’的策略。首先，在Rotowire数据集上与doc-level RE、sent-level RE等基线方法进行主实验对比，突出自身方法的优势。其次，在E2E、WikiTableText、WikiBio等多个数据集上进一步验证方法的通用性和有效性。实验评价指标为精确率、召回率和F1分数，采用严格的exact match标准。实验还分析了不同方法在不同数据集上的表现差异，体现了全面性和严谨性。"
      },
      {
        "paper_id": "ARR_2022_87",
        "title": "Turning Tables: Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills",
        "problem_framing": "论文从学术gap出发引出问题，首先指出大规模预训练语言模型已成为自然语言处理的核心，但在符号推理（如事实组合、数值运算、量化等）方面表现不足，且需要大量额外数据才能提升相关能力。通过引用前人工作，强调当前模型在推理任务上的局限性，明确提出需要新的数据生成和训练方法以提升模型的推理能力。",
        "gap_pattern": "论文批评现有方法时采用了对比和归类的逻辑，指出过去的工作主要有两类：一类是为特定推理技能添加专用组件，另一类是大规模合成数据生成。作者强调这些方法要么针对性强、扩展性有限，要么数据生成方式受限，未能充分利用结构化资源。通过举例和引用，说明现有方法在提升推理能力和数据覆盖面方面存在不足，尤其是在利用半结构化表格自动生成多样化推理训练数据方面的缺失。",
        "method_story": "方法部分采用先整体后局部的叙述策略，首先介绍整体思路：利用半结构化表格自动生成多种推理类型的阅读理解训练数据。随后详细说明数据生成流程，包括表格爬取、16种推理技能的模板化生成器、自动填充变量和答案计算、上下文构造等。最后介绍模型预训练流程和三种采样策略（均匀采样、错误驱动采样、动量采样），并与主流基线模型进行对比。",
        "experiments_story": "实验部分采用主实验+多数据集验证的策略，首先在下游阅读理解数据集上进行主实验，验证方法的有效性。随后在合成数据上进行补充实验，分析模型在生成数据上的表现。实验设计突出对比不同采样策略和模型规模，并说明数据集去重处理，保证实验公正性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "指标多样化",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_221",
            "title": "HiTab: A Hierarchical Table Dataset for Question Answering and Natural Language Generation",
            "description": "采用Execution Accuracy、Spurious Program Rate等多种指标，全面衡量模型性能和鲁棒性。",
            "type": "experiment-level",
            "purpose": "从多个角度评估方法，增强实验的完备性和结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_119",
            "title": "Leveraging Explicit Lexico-logical Alignments in Text-to-SQL Parsing",
            "description": "采用ACCLF和ACCEXE两种指标，分别衡量逻辑形式和执行结果的准确性，确保评价全面。",
            "type": "experiment-level",
            "purpose": "从不同维度验证方法有效性"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性批判",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_62",
            "title": "FORTAP: Using Formulas for Numerical-Reasoning-Aware Table Pretraining",
            "description": "作者指出现有预训练目标忽视数值关系，合成SQL/问题仅适用于数据库表，难以保证真实性",
            "type": "writing-level",
            "purpose": "通过批判已有工作的不足，突出自身工作的创新性和必要性"
          },
          {
            "paper_id": "ARR_2022_292",
            "title": "Seeking Patterns, Not just Memorizing Procedures: Contrastive Learning for Solving Math Word Problems",
            "description": "指出现有深度学习方法依赖浅层启发式和记忆程序，缺乏对模式的理解，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "通过批判现有方法的不足，突出自身工作的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "现实场景动机引入",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "通过描述真实用户在处理大型表格时遇到的挑战，引出研究问题并强调其实际意义。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者意识到问题的重要性和实际价值"
          }
        ]
      },
      {
        "trick_name": "现有方法不足对比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "引用最新文献指出当前SOTA方法在跨领域泛化上的不足，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "突出新方法的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "问题分解与细化",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "将泛化难题细分为列匹配和列操作两大类，分别举例说明具体挑战。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者理解任务难点"
          }
        ]
      },
      {
        "trick_name": "新基准数据集设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "提出两个新的评测基准（合成数据集和SQUALL重划分），专门用于量化列操作的跨域泛化能力。",
            "type": "method-level",
            "purpose": "展示新颖性，证明方法可评估且问题真实存在"
          }
        ]
      },
      {
        "trick_name": "方法简化与模块化",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "将方法拆分为schema expansion和schema pruning两个独立模块，可与任意现有parser结合。",
            "type": "method-level",
            "purpose": "提升可解释性和可复用性，降低理解和应用门槛"
          }
        ]
      },
      {
        "trick_name": "直观类比与实例说明",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "通过具体例子（如“Income”映射到不同表的不同列组合）和图示，帮助读者把握抽象操作的实际含义。",
            "type": "writing-level",
            "purpose": "增强可解释性，使技术细节易于理解"
          }
        ]
      },
      {
        "trick_name": "现实约束假设说明",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "说明schema expansion基于列类型假设，强调方法对新领域的适用性和可扩展性。",
            "type": "writing-level",
            "purpose": "增强说服力，回应潜在质疑"
          }
        ]
      },
      {
        "trick_name": "实验对比分组设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "设计四种配置（Base, Base+P, Base+E, Base+P+E）系统性对比，清晰展示各模块贡献。",
            "type": "experiment-level",
            "purpose": "突出方法有效性和对比性"
          }
        ]
      },
      {
        "trick_name": "多数据集多分割验证",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "在多个数据集和多种分割（i.i.d.与跨域）下重复实验，确保结果稳健。",
            "type": "experiment-level",
            "purpose": "提升完备性，证明结论具有广泛适用性"
          }
        ]
      },
      {
        "trick_name": "细粒度类别分析",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "对不同数据类别（如“Date Expressions”）的表现进行详细分析，解释性能提升原因。",
            "type": "experiment-level",
            "purpose": "增强可解释性，揭示方法提升来源"
          }
        ]
      },
      {
        "trick_name": "负面结果与局限讨论",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "坦率指出某些类别（如Accessor）未见提升，表明方法局限并为后续研究留空间。",
            "type": "writing-level",
            "purpose": "提升说服力和学术诚信"
          }
        ]
      },
      {
        "trick_name": "逐步递进的叙事结构",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_52",
            "title": "Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion",
            "description": "先提出问题和挑战，再介绍创新方法，最后通过系统实验和分析呼应前文，形成闭环。",
            "type": "writing-level",
            "purpose": "优化逻辑流，增强整体可读性"
          }
        ]
      },
      {
        "trick_name": "任务反转类比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_138",
            "title": "Text-to-Table: A New Way of Information Extraction",
            "description": "将text-to-table任务与已有的table-to-text任务进行类比，指出二者是互为逆问题，并强调应用和难点的不同，突出研究的创新点",
            "type": "writing-level",
            "purpose": "突出新颖性，通过与已知任务（table-to-text）的对比，强调提出任务的创新性和独特性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 8,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_52",
        "ARR_2022_138",
        "ARR_2022_87",
        "ARR_2022_221",
        "ARR_2022_293",
        "ARR_2022_62",
        "ARR_2022_119",
        "ARR_2022_292"
      ]
    }
  },
  {
    "pattern_id": 3,
    "pattern_name": "多语言验证+统计显著性检验",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨语言模型在特定语言学理论上的表现，通过对比实验和多语言验证展示模型能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，采用'多语言验证+统计显著性检验'，常用tricks包括理论对比、心理语言学证据铺垫和消除表层词汇偏差。\n第3段（60字）：适用场景与预期效果 - 适用于评估语言模型在复杂语言现象上的表现，预期提升模型的跨语言泛化能力和理论解释力。",
    "writing_guide": "写作模板：多语言验证+统计显著性检验\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨语言模型在特定语言学理论上的表现，通过对比实验和多语言验证展示模型能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，采用'多语言验证+统计显著性检验'，常用tricks包括理论对比、心理语言学证据铺垫和消除表层词汇偏差。\n第3段（60字）：适用场景与预期效果 - 适用于评估语言模型在复杂语言现象上的表现，预期提升模型的跨语言泛化能力和理论解释力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Neural reality of argument structure constructions》\n  • 问题定位：论文通过回顾预训练Transformer语言模型（如BERT和RoBERTa）在自然语言任务上的成功，引出了一个新的跨学科研究领域：将语言模型与语言学理论对齐，并探究其语言能力。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法忽视了X'的逻辑。具体指出：大多数探究工作假设生成语法框架，关注句子的语言可接受性，较少从建构语法出发，关注多词构式及其交互。此外，现有方法未充分探究语言模型对论元结构构式（ASC）的神经表征，忽略了建构语法在心理语言学中的实证基础。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍了所用模型（MiniBERTa、RoBERTa、mBERT及各语言单语模型），并说明不同模型用于模拟不同语言能力水平。随后详细描述了刺激句子的生成流程，包括模板设计、随机填充以及多轮采样，确保实验样本充足。\n  • 实验设计：实验部分采用主实验+多语言验证的策略。首先在英语数据上进行主实验，分析不同预训练数据量下模型对构式与动词排序的偏好，并与人类实验结果对比。随后在德语、意大利语和西班牙语进行多语言实验，验证结论的跨语言适用性。\n\n示例 2：《Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese》\n  • 问题定位：论文通过介绍东亚和东南亚语言中广泛存在的无显性连接词的并列结构（coordinate compounds, CCs 和 elaborate expressions, EEs），以丰富的实例说明该现象的普遍性和重要性，进而引出对其构成顺序预测的科学问题。\n  • 现有研究缺口：论文批评现有方法时，首先指出早期研究多基于音系特征（如元音质量、声调）提出顺序预测规则，但这些规则难以用语音学原理合理解释，且与主流语言学理论（如形态句法优先于音系，音系应以语音学为基础）相悖。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略，首先提出研究目标——探究（计算）学习者需要什么数据才能习得这些顺序规律，随后介绍使用的机器学习模型（如决策树），并说明仅用音系特征即可高准确率预测顺序。方法介绍简明，突出核心变量和模型，未分模块细化，强调实验设计的简洁性和针对性。\n  • 实验设计：实验部分采用了‘多数据集验证’的策略，分别在Hmong和Lahu两种语言上进行主实验，报告了模型在不同语言上的预测准确率（96%和79%）。实验叙述聚焦于主实验结果，突出模型的有效性，未涉及消融或可视化等辅助实验，强调跨语言的泛化能力和方法的实用性。\n\n示例 3：《Discontinuous Constituency and BERT: A Case Study of Dutch》\n  • 问题定位：论文从学术gap出发引出问题。开篇先回顾了BERT及其变体在语言学理论自动获取方面的突出表现，并指出主流做法是通过浅层探针模型检测BERT内部编码的语言学信息。接着，作者指出当前探针研究主要集中在英语，这种语言本身语法结构较简单，接近上下文无关语言，因此不能代表其他语言的复杂性。\n  • 现有研究缺口：论文批评现有方法的逻辑为：现有探针研究过度依赖英语，忽视了英语语法的简单性和上下文无关性，导致对BERT语法能力的结论不能泛化到其他更复杂的语言。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了探针模型的输入输出流程，即如何从BERT的上下文表示中聚合动词和名词短语，再通过交叉注意力机制建立动词-名词映射。随后详细分步介绍了每个模块：短语聚合、注意力分数计算、低维映射、点积注意力、最终的主语选择机制。\n  • 实验设计：实验部分采用‘多阶段+多数据集验证’的策略。首先描述了如何自动筛选和标注真实语料，构建自然数据集用于训练探针。然后详细介绍了如何基于形式语法生成人工数据，测试模型在不同复杂度和生成参数下的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 创新点突出（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者明确指出以往的音系排序难以用语音学解释，并提出要用计算学习方法探究这些模式的可习得性，突出研究创新。\n\n2. 理论对比引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过对比生成语法和构式语法在动词论元结构分析上的分歧，引出构式语法视角下探测语言模型的研究空白。\n\n3. 心理语言学证据铺垫（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：引用大量心理语言学实验（如句子分类、启动、虚构动词实验）证明构式语法理论的心理现实性，为后续神经网络探针实验提供理论支撑。\n\n4. 跨语言实验设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：在多种语言（英语、德语、意大利语、西班牙语）上复现实验，展示方法的普适性和稳健性。\n\n5. 模型规模与人类能力类比（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：通过不同规模的语言模型和不同熟练度的非母语者对比，类比人类语言习得过程，说明模型能力与数据量的关系。\n\n6. 消除表层词汇偏差（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：采用模板填充和随机词生成（Jabberwocky句子），避免模型依赖表层词汇，确保测试的是结构性知识而非词汇记忆。\n\n7. 与经典实验对齐（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：将神经网络实验设计与Bencini and Goldberg (2000)等经典心理语言学实验对齐，便于读者理解实验逻辑和创新点。\n\n8. 聚类与距离度量（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：采用聚类和欧氏距离等直观的量化指标，明确展示模型内部嵌入对构式与动词的区分能力。\n\n9. 统计显著性检验（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：对主要实验结果进行统计显著性检验（如p < .001），确保观察到的效果非偶然。\n\n10. 实验局限性讨论（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：主动讨论实验设计和数据来源的局限性，警示读者对结论的适用范围，避免过度解读。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_161",
        "title": "Neural reality of argument structure constructions",
        "problem_framing": "论文通过回顾预训练Transformer语言模型（如BERT和RoBERTa）在自然语言任务上的成功，引出了一个新的跨学科研究领域：将语言模型与语言学理论对齐，并探究其语言能力。开篇策略主要从学术gap出发，指出当前探究工作大多基于生成语法理论，鲜有关注建构语法视角，特别是在动词论元结构分析方面存在理论分歧。通过对比生成语法和建构语法在论元结构上的不同假设，论文自然引出对语言模型能否体现建构语法论元结构的关注。",
        "gap_pattern": "论文批评现有方法时，采用了'现有方法忽视了X'的逻辑。具体指出：大多数探究工作假设生成语法框架，关注句子的语言可接受性，较少从建构语法出发，关注多词构式及其交互。此外，现有方法未充分探究语言模型对论元结构构式（ASC）的神经表征，忽略了建构语法在心理语言学中的实证基础。句式如'relatively little work has been done on probing LMs from construction grammar'和'One area where construction grammar disagrees with many generative theories...'。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先介绍了所用模型（MiniBERTa、RoBERTa、mBERT及各语言单语模型），并说明不同模型用于模拟不同语言能力水平。随后详细描述了刺激句子的生成流程，包括模板设计、随机填充以及多轮采样，确保实验样本充足。最后介绍了评估方法：通过聚类和匈牙利算法计算句子排序的偏差，衡量模型对构式信息的敏感度。整体流程由模型选择、数据生成、评估方法三大模块组成，层层递进。",
        "experiments_story": "实验部分采用主实验+多语言验证的策略。首先在英语数据上进行主实验，分析不同预训练数据量下模型对构式与动词排序的偏好，并与人类实验结果对比。随后在德语、意大利语和西班牙语进行多语言实验，验证结论的跨语言适用性。实验结果通过统计显著性分析、趋势对比和可视化（图表）呈现，同时讨论实验局限性和跨语言结果的解释边界。实验类型包括主排序实验、多模型对比和多语言泛化验证。"
      },
      {
        "paper_id": "ARR_2022_224",
        "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
        "problem_framing": "论文通过介绍东亚和东南亚语言中广泛存在的无显性连接词的并列结构（coordinate compounds, CCs 和 elaborate expressions, EEs），以丰富的实例说明该现象的普遍性和重要性，进而引出对其构成顺序预测的科学问题。开篇策略结合了学术gap（现有理论难以解释顺序规律）、实际语言现象的复杂性，以及对语言学习机制的探索需求，属于从学术gap和理论争议出发，辅以实际语言现象痛点。",
        "gap_pattern": "论文批评现有方法时，首先指出早期研究多基于音系特征（如元音质量、声调）提出顺序预测规则，但这些规则难以用语音学原理合理解释，且与主流语言学理论（如形态句法优先于音系，音系应以语音学为基础）相悖。批评逻辑采用了‘现有方法难以解释/不易合理化’、‘与主流理论不符’、‘可学习性存疑’等句式，强调了理论和实证上的不足。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述策略，首先提出研究目标——探究（计算）学习者需要什么数据才能习得这些顺序规律，随后介绍使用的机器学习模型（如决策树），并说明仅用音系特征即可高准确率预测顺序。方法介绍简明，突出核心变量和模型，未分模块细化，强调实验设计的简洁性和针对性。",
        "experiments_story": "实验部分采用了‘多数据集验证’的策略，分别在Hmong和Lahu两种语言上进行主实验，报告了模型在不同语言上的预测准确率（96%和79%）。实验叙述聚焦于主实验结果，突出模型的有效性，未涉及消融或可视化等辅助实验，强调跨语言的泛化能力和方法的实用性。"
      },
      {
        "paper_id": "ARR_2022_164",
        "title": "Discontinuous Constituency and BERT: A Case Study of Dutch",
        "problem_framing": "论文从学术gap出发引出问题。开篇先回顾了BERT及其变体在语言学理论自动获取方面的突出表现，并指出主流做法是通过浅层探针模型检测BERT内部编码的语言学信息。接着，作者指出当前探针研究主要集中在英语，这种语言本身语法结构较简单，接近上下文无关语言，因此不能代表其他语言的复杂性。由此引出本文关注的核心问题：BERT在处理超越上下文无关语法的复杂语言现象（如荷兰语的交叉串行依赖）时的能力评估。",
        "gap_pattern": "论文批评现有方法的逻辑为：现有探针研究过度依赖英语，忽视了英语语法的简单性和上下文无关性，导致对BERT语法能力的结论不能泛化到其他更复杂的语言。具体句式包括‘a latent bias persists in the insights provided by the probing literature, due to its focus being, by default, on English’和‘claims about the syntactic skills of language models should not be assumed to freely transfer between languages’等，强调了方法的局限性和外推风险。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了探针模型的输入输出流程，即如何从BERT的上下文表示中聚合动词和名词短语，再通过交叉注意力机制建立动词-名词映射。随后详细分步介绍了每个模块：短语聚合、注意力分数计算、低维映射、点积注意力、最终的主语选择机制。每一步都交代了技术细节和实现动机，层层递进。",
        "experiments_story": "实验部分采用‘多阶段+多数据集验证’的策略。首先描述了如何自动筛选和标注真实语料，构建自然数据集用于训练探针。然后详细介绍了如何基于形式语法生成人工数据，测试模型在不同复杂度和生成参数下的表现。实验内容包括：真实语料训练、人工数据测试、不同语言模型（BERTje和RobBERT）对比、不同初始化种子下的稳健性检验。整体上，实验设计兼顾了真实性和可控性，强调泛化能力和方法有效性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "创新点突出",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_224",
            "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
            "description": "作者明确指出以往的音系排序难以用语音学解释，并提出要用计算学习方法探究这些模式的可习得性，突出研究创新。",
            "type": "writing-level",
            "purpose": "展示新颖性，强调本研究与前人工作的不同及突破"
          },
          {
            "paper_id": "ARR_2022_164",
            "title": "Discontinuous Constituency and BERT: A Case Study of Dutch",
            "description": "明确提出本研究关注超越上下文无关语法的复杂句法现象，并选用荷兰语作为实验对象。",
            "type": "writing-level",
            "purpose": "强调研究的新颖性和突破"
          }
        ]
      },
      {
        "trick_name": "理论对比引入",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "通过对比生成语法和构式语法在动词论元结构分析上的分歧，引出构式语法视角下探测语言模型的研究空白。",
            "type": "writing-level",
            "purpose": "突出研究问题的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "心理语言学证据铺垫",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "引用大量心理语言学实验（如句子分类、启动、虚构动词实验）证明构式语法理论的心理现实性，为后续神经网络探针实验提供理论支撑。",
            "type": "writing-level",
            "purpose": "增强方法的说服力和理论基础"
          }
        ]
      },
      {
        "trick_name": "跨语言实验设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "在多种语言（英语、德语、意大利语、西班牙语）上复现实验，展示方法的普适性和稳健性。",
            "type": "experiment-level",
            "purpose": "提升实验的完备性和结论的广泛适用性"
          }
        ]
      },
      {
        "trick_name": "模型规模与人类能力类比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "通过不同规模的语言模型和不同熟练度的非母语者对比，类比人类语言习得过程，说明模型能力与数据量的关系。",
            "type": "experiment-level",
            "purpose": "提升说服力并增强可解释性"
          }
        ]
      },
      {
        "trick_name": "消除表层词汇偏差",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "采用模板填充和随机词生成（Jabberwocky句子），避免模型依赖表层词汇，确保测试的是结构性知识而非词汇记忆。",
            "type": "method-level",
            "purpose": "增强实验的科学性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "与经典实验对齐",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "将神经网络实验设计与Bencini and Goldberg (2000)等经典心理语言学实验对齐，便于读者理解实验逻辑和创新点。",
            "type": "writing-level",
            "purpose": "增强方法的可解释性和权威性"
          }
        ]
      },
      {
        "trick_name": "聚类与距离度量",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "采用聚类和欧氏距离等直观的量化指标，明确展示模型内部嵌入对构式与动词的区分能力。",
            "type": "method-level",
            "purpose": "提升方法的可解释性和结果的量化可比性"
          }
        ]
      },
      {
        "trick_name": "统计显著性检验",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "对主要实验结果进行统计显著性检验（如p < .001），确保观察到的效果非偶然。",
            "type": "experiment-level",
            "purpose": "增强实验结论的说服力和科学性"
          }
        ]
      },
      {
        "trick_name": "实验局限性讨论",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "主动讨论实验设计和数据来源的局限性，警示读者对结论的适用范围，避免过度解读。",
            "type": "writing-level",
            "purpose": "提升论文的科学严谨性和可信度"
          }
        ]
      },
      {
        "trick_name": "递进式叙事结构",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_161",
            "title": "Neural reality of argument structure constructions",
            "description": "先提出理论分歧和研究空白，后介绍方法设计，再展示实验结果，最后回扣理论假设，形成完整的逻辑闭环。",
            "type": "writing-level",
            "purpose": "提升论文的逻辑性和可读性"
          }
        ]
      },
      {
        "trick_name": "文献综述与权威引用",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_224",
            "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
            "description": "作者在引言部分密集引用了多篇相关领域的经典文献，展示了无标记协调结构在东南亚语言中的普遍存在，并强调了前人研究的理论基础和争议点。",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用大量权威文献证明问题的广泛性和重要性"
          }
        ]
      },
      {
        "trick_name": "典型实例举例",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_224",
            "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
            "description": "作者用中文和拉祜语的协调复合词与精致表达的具体例子，直观展示了研究对象的语言现象。",
            "type": "writing-level",
            "purpose": "提升可解释性，通过具体例子帮助读者理解抽象概念"
          }
        ]
      },
      {
        "trick_name": "问题引入与争议铺垫",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_224",
            "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
            "description": "作者在介绍现象后，指出现有理论的分歧和难以解释之处，为后续方法和实验的提出埋下伏笔。",
            "type": "writing-level",
            "purpose": "增强叙事结构，通过提出未解之谜和理论争议吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "方法简要预告",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_224",
            "title": "Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese",
            "description": "作者在引言结尾处简要说明将采用决策树等简单分类器进行预测实验，为后文方法和实验做铺垫。",
            "type": "method-level",
            "purpose": "提升可解释性和叙事流畅性，让读者提前了解研究方法框架"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 8,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_161",
        "ARR_2022_224",
        "ARR_2022_164",
        "ACL_2017_524",
        "ACL_2017_193",
        "COLING_2020_66",
        "COLING_2020_37",
        "COLING_2020_29"
      ]
    }
  },
  {
    "pattern_id": 4,
    "pattern_name": "多基线对比与多数据集验证",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决NLP领域数据集和基准不足的问题，采用多基线对比和多数据集验证的技术路线。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从现状梳理开篇，通过贡献清单式总结突出创新点，方法部分采用任务三元组框架化和数据集质量标准化，实验设计强调分步逻辑结构安排和数据集公开复现性。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要构建高质量数据集和基准的NLP任务，预期提升模型的公平性、泛化能力和实验结果的可信度。",
    "writing_guide": "写作模板：多基线对比与多数据集验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决NLP领域数据集和基准不足的问题，采用多基线对比和多数据集验证的技术路线。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从现状梳理开篇，通过贡献清单式总结突出创新点，方法部分采用任务三元组框架化和数据集质量标准化，实验设计强调分步逻辑结构安排和数据集公开复现性。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要构建高质量数据集和基准的NLP任务，预期提升模型的公平性、泛化能力和实验结果的可信度。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《MUKAYESE: Turkish NLP Strikes Back》\n  • 问题定位：论文从学术gap出发引出问题，指出虽然土耳其语并非资源稀缺语言，但由于研究社区规模小，缺乏有组织的基准和基线，导致其在NLP领域落后。\n  • 现有研究缺口：论文通过对现有工作的批评，强调了缺乏有组织的基准和基线是土耳其语NLP发展缓慢的主要原因。采用了‘缺失/不足’的批评逻辑，如‘我们观察到缺乏有组织的基准和研究’、‘缺乏基准会导致研究落后于NLP领域的最前沿’等句式，突出当前方法的局限和不足。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略。首先，整体定义了基准的三要素（数据集、评测、基线），并逐一详细解释每个要素的构建标准和注意事项。随后，针对具体任务（如语言建模），分模块介绍了数据集的构建、评价指标的选择和基线模型的设置。\n  • 实验设计：实验部分（根据方法和引言的描述）采用了多数据集验证和多基线对比的策略。每个任务至少包含两个基线模型，并在新构建和现有的多个数据集上进行评测，确保结果的全面性和可复现性。实验内容涵盖了数据集统计、评测细节、基线方法效果等，强调了系统性和公平性，突出新基准和方法在土耳其语NLP任务上的有效性。\n\n示例 2：《Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective》\n  • 问题定位：论文从学术gap出发引出问题。首先指出NLP领域近年来的进步主要得益于无标注数据的利用，强调了这种方法在训练阶段带来的优势和趋势。随后，作者对比了训练和测试阶段，指出当前NLP模型的测试极度依赖于有标注的groundtruth数据，这种依赖限制了测试用例的数量和质量。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法过度关注单一行为类型’的逻辑。具体来说，作者指出大多数已提出的元变关系都集中在鲁棒性（robustness）上，即模型输出在输入微小扰动下应保持稳定。\n  • 核心方法：由于未提供方法部分内容，无法详细分析其具体叙述策略。但从引言推断，方法部分可能会先整体介绍元变测试的基本思想和适用范围，然后针对鲁棒性以外的语言属性提出新的元变关系，可能采用分模块介绍或从简单到复杂的顺序，逐步展开对不同类型元变关系的定义与实现。\n  • 实验设计：由于未提供实验部分内容，无法具体分析实验叙述策略。从引言内容推测，实验部分可能包括对不同类型元变关系的实证验证，涵盖主实验（验证新提出的元变关系对模型测试的有效性），并可能涉及多任务或多数据集的对比实验，以展示新方法的广泛适用性和优越性。\n\n示例 3：《Dataset Geography: Mapping Language Data to Language Users》\n  • 问题定位：论文首先从学术领域的痛点和现实需求出发，指出NLP研究在语言、类型和地理多样性上的缺失已被广泛认可和记录。接着，作者强调多语言模型的出现为服务弱势语言用户带来了希望，但要实现覆盖全球近7000种语言的目标极具挑战。\n  • 现有研究缺口：论文批评现有工作的逻辑主要有两方面：一是现有研究虽然关注了数据可用性、模型公平性和系统效用等，但‘缺乏评估数据集代表性的方法’，即现有方法未能判断数据是否真实反映目标语言用户；二是相关工作中，现有多语言模型和数据集在跨语言一致性、数据偏见等方面存在明显不足，且资源分布极不均衡。\n  • 核心方法：方法部分采用‘先定义核心概念，再提出具体方法，最后报告实验细节’的顺序。首先界定了‘跨语言一致性’的具体含义，针对实体相关任务提出了适用的定义。随后介绍了如何利用平行语料、自动标注和词级对齐工具，计算跨语言一致性指标。整体上，方法叙述由概念定义到具体实现，层层递进，兼顾理论和实践。\n  • 实验设计：实验部分采用‘模型对比+多语言验证+定量分析+人工分析’的策略。先介绍了对比的两类模型（SpaCy单语模型和mBERT多语模型），再说明训练和评测流程，覆盖多种语言（希腊语、意大利语、中文、英语）。实验内容包括主实验（跨语言一致性评测）、不同模型对比、标签类型分析，并补充了人工误差分析。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题设定与现状梳理（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过引用权威文献和指出土耳其语NLP领域缺乏组织化基准和研究，强调研究空白和实际需求。\n\n2. 贡献清单式总结（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：用条目式列出工作贡献，包括数据集、基准、分割方式、基线和方法等，突出创新和系统性。\n\n3. 任务三元组框架化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将每个基准任务分为数据集、评估、基线三要素，系统阐述方法构建流程。\n\n4. 数据集质量与规模标准化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：详细说明数据集的规模、质量、可访问性等标准，强调手工标注一致性和领域泛化能力。\n\n5. 评价指标合理性分析（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：针对每个任务讨论评价指标的合理性、与人类判断的相关性及潜在问题，提升评估科学性。\n\n6. 多样化基线设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：为每个任务设置至少两个不同类型的基线，包括预训练与非预训练、规则与训练、监督与非监督等多种方法。\n\n7. 与现有数据集和方法对齐（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：新数据集设计参考英文主流数据集（如WikiText），并与已有方法结果进行对比。\n\n8. 分步逻辑结构安排（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：明确说明论文结构安排，逐步引入背景、方法、数据、实验和结论，形成环环相扣的逻辑流。\n\n9. 数据集公开与复现性强调（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：公开数据集原始和处理版本，强调可复现性和公平性（如数据集分割），增加研究透明度。\n\n10. 案例分析与领域泛化说明（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：通过具体案例（如句子分割在社交媒体与编辑文本的差异）说明方法泛化能力和局限性。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_329",
        "title": "MUKAYESE: Turkish NLP Strikes Back",
        "problem_framing": "论文从学术gap出发引出问题，指出虽然土耳其语并非资源稀缺语言，但由于研究社区规模小，缺乏有组织的基准和基线，导致其在NLP领域落后。开篇通过引用权威文献（Joshi et al., 2020）和对现状的描述，强调了资源充足不等于研究充分，突出“under-researched”这一痛点，明确了研究的现实意义和紧迫性。",
        "gap_pattern": "论文通过对现有工作的批评，强调了缺乏有组织的基准和基线是土耳其语NLP发展缓慢的主要原因。采用了‘缺失/不足’的批评逻辑，如‘我们观察到缺乏有组织的基准和研究’、‘缺乏基准会导致研究落后于NLP领域的最前沿’等句式，突出当前方法的局限和不足。此外，通过对比资源充足与研究充分的区别，进一步强化了现有工作的不足。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述策略。首先，整体定义了基准的三要素（数据集、评测、基线），并逐一详细解释每个要素的构建标准和注意事项。随后，针对具体任务（如语言建模），分模块介绍了数据集的构建、评价指标的选择和基线模型的设置。整体逻辑由抽象到具体，层层递进，便于读者理解各部分如何协同构成完整的基准体系。",
        "experiments_story": "实验部分（根据方法和引言的描述）采用了多数据集验证和多基线对比的策略。每个任务至少包含两个基线模型，并在新构建和现有的多个数据集上进行评测，确保结果的全面性和可复现性。实验内容涵盖了数据集统计、评测细节、基线方法效果等，强调了系统性和公平性，突出新基准和方法在土耳其语NLP任务上的有效性。"
      },
      {
        "paper_id": "ARR_2022_103",
        "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
        "problem_framing": "论文从学术gap出发引出问题。首先指出NLP领域近年来的进步主要得益于无标注数据的利用，强调了这种方法在训练阶段带来的优势和趋势。随后，作者对比了训练和测试阶段，指出当前NLP模型的测试极度依赖于有标注的groundtruth数据，这种依赖限制了测试用例的数量和质量。通过引用软件测试领域的相关问题，进一步引出元变测试（metamorphic testing）作为潜在解决方案，强调了现有测试方法的局限性和改进的必要性。",
        "gap_pattern": "论文批评现有方法主要采用‘现有方法过度关注单一行为类型’的逻辑。具体来说，作者指出大多数已提出的元变关系都集中在鲁棒性（robustness）上，即模型输出在输入微小扰动下应保持稳定。通过举例说明这些扰动类型（如拼写错误、同义词替换、无关信息添加），并指出这些方法已广泛应用于多种NLP任务和公平性测试。接着，作者指出仅关注鲁棒性不足以覆盖NLP模型应具备的更广泛语言属性，强调系统性泛化等更高阶需求，批评了现有方法的单一性和局限性。",
        "method_story": "由于未提供方法部分内容，无法详细分析其具体叙述策略。但从引言推断，方法部分可能会先整体介绍元变测试的基本思想和适用范围，然后针对鲁棒性以外的语言属性提出新的元变关系，可能采用分模块介绍或从简单到复杂的顺序，逐步展开对不同类型元变关系的定义与实现。",
        "experiments_story": "由于未提供实验部分内容，无法具体分析实验叙述策略。从引言内容推测，实验部分可能包括对不同类型元变关系的实证验证，涵盖主实验（验证新提出的元变关系对模型测试的有效性），并可能涉及多任务或多数据集的对比实验，以展示新方法的广泛适用性和优越性。"
      },
      {
        "paper_id": "ARR_2022_259",
        "title": "Dataset Geography: Mapping Language Data to Language Users",
        "problem_framing": "论文首先从学术领域的痛点和现实需求出发，指出NLP研究在语言、类型和地理多样性上的缺失已被广泛认可和记录。接着，作者强调多语言模型的出现为服务弱势语言用户带来了希望，但要实现覆盖全球近7000种语言的目标极具挑战。作者引用已有工作总结当前数据可用性和评估框架，进而提出尚缺乏评估数据集代表性的方法，明确点出‘数据代表性’是进一步进展的关键缺口。整体采用了‘现状-已有努力-关键缺失’的递进式开篇策略。",
        "gap_pattern": "论文批评现有工作的逻辑主要有两方面：一是现有研究虽然关注了数据可用性、模型公平性和系统效用等，但‘缺乏评估数据集代表性的方法’，即现有方法未能判断数据是否真实反映目标语言用户；二是相关工作中，现有多语言模型和数据集在跨语言一致性、数据偏见等方面存在明显不足，且资源分布极不均衡。常用句式包括‘However, there is one missing building block...’‘current state-of-the-art language applications are far from achieving this goal’等，突出现有方法的不足和失效场景。",
        "method_story": "方法部分采用‘先定义核心概念，再提出具体方法，最后报告实验细节’的顺序。首先界定了‘跨语言一致性’的具体含义，针对实体相关任务提出了适用的定义。随后介绍了如何利用平行语料、自动标注和词级对齐工具，计算跨语言一致性指标。整体上，方法叙述由概念定义到具体实现，层层递进，兼顾理论和实践。",
        "experiments_story": "实验部分采用‘模型对比+多语言验证+定量分析+人工分析’的策略。先介绍了对比的两类模型（SpaCy单语模型和mBERT多语模型），再说明训练和评测流程，覆盖多种语言（希腊语、意大利语、中文、英语）。实验内容包括主实验（跨语言一致性评测）、不同模型对比、标签类型分析，并补充了人工误差分析。整体结构为‘主实验+多模型多语言对比+定性分析’，突出方法有效性和局限性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "问题设定与现状梳理",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "通过引用权威文献和指出土耳其语NLP领域缺乏组织化基准和研究，强调研究空白和实际需求。",
            "type": "writing-level",
            "purpose": "突出研究的必要性和紧迫性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "贡献清单式总结",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "用条目式列出工作贡献，包括数据集、基准、分割方式、基线和方法等，突出创新和系统性。",
            "type": "writing-level",
            "purpose": "明确展示工作新颖性和全面性，便于读者快速抓住创新点"
          }
        ]
      },
      {
        "trick_name": "任务三元组框架化",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "将每个基准任务分为数据集、评估、基线三要素，系统阐述方法构建流程。",
            "type": "method-level",
            "purpose": "提升方法可解释性和结构化，帮助读者理解整体设计思路"
          }
        ]
      },
      {
        "trick_name": "数据集质量与规模标准化",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "详细说明数据集的规模、质量、可访问性等标准，强调手工标注一致性和领域泛化能力。",
            "type": "method-level",
            "purpose": "证明方法的科学性和实验的可靠性，增强完备性"
          }
        ]
      },
      {
        "trick_name": "评价指标合理性分析",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "针对每个任务讨论评价指标的合理性、与人类判断的相关性及潜在问题，提升评估科学性。",
            "type": "method-level",
            "purpose": "增强方法的可解释性和实验结果的说服力"
          }
        ]
      },
      {
        "trick_name": "多样化基线设计",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "为每个任务设置至少两个不同类型的基线，包括预训练与非预训练、规则与训练、监督与非监督等多种方法。",
            "type": "experiment-level",
            "purpose": "突出对比性和实验的充分性，确保结论可靠"
          }
        ]
      },
      {
        "trick_name": "与现有数据集和方法对齐",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "新数据集设计参考英文主流数据集（如WikiText），并与已有方法结果进行对比。",
            "type": "experiment-level",
            "purpose": "增强对比性和国际通用性，便于同行评估"
          }
        ]
      },
      {
        "trick_name": "分步逻辑结构安排",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "明确说明论文结构安排，逐步引入背景、方法、数据、实验和结论，形成环环相扣的逻辑流。",
            "type": "writing-level",
            "purpose": "提升叙事结构的清晰度和逻辑性，便于读者理解和跟进"
          }
        ]
      },
      {
        "trick_name": "数据集公开与复现性强调",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "公开数据集原始和处理版本，强调可复现性和公平性（如数据集分割），增加研究透明度。",
            "type": "experiment-level",
            "purpose": "提升研究的完备性和可信度，促进社区复现和后续研究"
          }
        ]
      },
      {
        "trick_name": "案例分析与领域泛化说明",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_329",
            "title": "MUKAYESE: Turkish NLP Strikes Back",
            "description": "通过具体案例（如句子分割在社交媒体与编辑文本的差异）说明方法泛化能力和局限性。",
            "type": "experiment-level",
            "purpose": "增强方法的可解释性和实际应用价值"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_103",
            "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "description": "作者在引言开头引用了多篇重要文献（如Devlin et al., 2019; Brown et al., 2020），说明无监督学习推动了NLP进步，为后续论述奠定权威基础。",
            "type": "writing-level",
            "purpose": "通过引用领域内权威工作，增强论述的可信度和说服力"
          }
        ]
      },
      {
        "trick_name": "对比现有测试方法的局限性",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_103",
            "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "description": "作者指出现有NLP测试极度依赖标注数据，限制了测试用例的数量和质量，强调了该问题的普遍性和迫切性。",
            "type": "writing-level",
            "purpose": "突出当前方法的不足，引出自身工作的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "引入新范式（变形测试）",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_103",
            "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "description": "作者提出变形测试作为解决现有测试局限的有前景方法，并简要解释其原理，突出创新性。",
            "type": "writing-level",
            "purpose": "通过介绍新颖测试范式，展示研究工作的创新点"
          }
        ]
      },
      {
        "trick_name": "分类总结现有方法",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_103",
            "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "description": "作者指出大多数变形关系集中于鲁棒性，并举例说明，展示对领域现状的全面把握。",
            "type": "writing-level",
            "purpose": "通过对比和归纳，展示本工作的系统性和对现有工作的理解"
          }
        ]
      },
      {
        "trick_name": "提出更高层次的需求",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_103",
            "title": "Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective",
            "description": "作者强调NLP模型应具备系统性泛化等更复杂的语言能力，而不仅仅是鲁棒性，呼应后续方法创新。",
            "type": "writing-level",
            "purpose": "通过提出更高的模型能力要求，提升自身工作的理论高度和实际意义"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 6,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_329",
        "ARR_2022_103",
        "ARR_2022_259",
        "ARR_2022_46",
        "ACL_2017_382",
        "COLING_2020_64"
      ]
    }
  },
  {
    "pattern_id": 5,
    "pattern_name": "分层多任务迁移学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决大规模预训练语言模型在数据稀缺和迁移学习中的不足，采用分层结构和多任务迁移方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点和学术gap开篇，通过引用主流模型和竞赛结果建立背景，多采用分层结构和多数据集验证，结合自动和人工评测增强说服力。\n第3段（60字）：适用场景与预期效果 - 适用于文本生成、迁移学习和零样本任务，预期提升模型在低资源条件下的性能和泛化能力。",
    "writing_guide": "写作模板：分层多任务迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决大规模预训练语言模型在数据稀缺和迁移学习中的不足，采用分层结构和多任务迁移方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点和学术gap开篇，通过引用主流模型和竞赛结果建立背景，多采用分层结构和多数据集验证，结合自动和人工评测增强说服力。\n第3段（60字）：适用场景与预期效果 - 适用于文本生成、迁移学习和零样本任务，预期提升模型在低资源条件下的性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Hierarchical Recurrent Aggregative Generation for Few-Shot NLG》\n  • 问题定位：论文通过介绍大规模预训练语言模型（PLMs）在自然语言生成（NLG）领域带来的研究兴趣转变，引出当前在概念到文本生成任务中的挑战。开篇首先强调了PLMs在领域适应和迁移学习中的重要性，并指出在数据稀缺（few-shot/zero-shot）场景下，迁移学习成为主流且有效的方案。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在低资源/小样本场景下研究不足’和‘现有方法依赖人工模板或领域特定资源，成本高且泛化性差’的逻辑。具体通过引用相关工作，指出前人方法要么依赖合成数据、人工模板，或是未能充分利用迁移学习在不同子任务上的潜力，尤其是在词汇化和聚合阶段的迁移能力差异未被深入探讨。\n  • 核心方法：方法部分采用分模块介绍的策略，先整体描述提出的分层模型HRAG的架构与设计理念，再细致分解为三个模块：词汇化、聚合和后编辑。每个模块对应传统NLG流程中的关键阶段，并结合其在迁移学习中的潜力进行阐述。通过图示和具体例子，展示各模块的输出及其协同工作方式，体现从局部到整体、由简单到复杂的递进叙述顺序。\n  • 实验设计：实验部分采用多数据集、多训练规模验证的策略，系统性比较HRAG与主流端到端T5模型在不同数据量和领域上的表现。包含主实验（自动评测指标如BLEU、BLEURT、MER）、极低资源条件下的性能分析、跨域/零样本泛化能力测试，以及人类评测。\n\n示例 2：《ELLE: Efficient Lifelong Pre-training for Emerging Data》\n  • 问题定位：论文从实际痛点和应用需求出发引出问题。开篇指出预训练语言模型（PLM）在NLP任务中的突破性进展，但现有PLM通常基于静态快照训练，忽略了现实世界中数据是持续流入且分布变化的场景。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法忽视了X”与“现有方法在Y场景下失效”的逻辑。具体地，指出大多数现有PLM只在静态数据上训练，忽略了流式、多源、分布变化的数据场景。此外，现有终身学习方法主要关注记忆回放、参数巩固或动态结构，但很少考虑多源流数据的顺序集成和训练效率问题。\n  • 核心方法：方法部分采用“先整体后局部、分模块介绍”的叙述策略。首先整体介绍为提升知识增长效率，提出在每次新数据到来时对模型宽度和深度进行扩展。随后分别详细介绍宽度扩展和深度扩展的具体实现，包括函数保持初始化（FPI）和分层插入等技术细节，并对比现有方法，指出创新点和改进之处。\n  • 实验设计：实验部分采用“主实验+多数据集验证+消融分析”的叙述策略。首先模拟多领域流式数据场景，涵盖5个不同领域的数据集，验证方法在真实终身学习场景下的有效性。其次，详细描述模型架构、训练细节和评测指标，确保实验可复现和公平。\n\n示例 3：《Compression of Generative Pre-trained Language Models via Quantization》\n  • 问题定位：论文开篇先强调了Transformer类生成式预训练语言模型（PLMs）在多任务和小样本学习上的强大能力及其在各类任务中的卓越表现，随后指出其计算和存储开销巨大是实际应用中的主要痛点。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性揭示的策略。\n  • 核心方法：方法部分先指出直接用传统量化方法训练低比特生成式PLM存在挑战，随后简要回顾量化背景。接着，基于前文观察，分两大模块提出创新方法：1）token-level对比蒸馏提升词嵌入可区分性，2）module-wise动态缩放提升量化器适应性。\n  • 实验设计：实验部分采用了多数据集、多任务验证的策略。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 5 次，占比 45.5%）\n   类型：writing-level\n   应用：从领域背景、问题分析、方法提出到实验验证，层层递进，前后呼应，逻辑清晰地展开全文。\n\n2. 现实场景动机引入（使用频率 2 次，占比 18.2%）\n   类型：writing-level\n   应用：通过举例说明现实中数据持续增长（如新闻、论文等），强调现有PLM静态训练的局限性，凸显研究问题的现实意义。\n\n3. 引用主流模型和竞赛结果建立背景（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过引用BERT、GPT-3、T5等主流PLM模型及WebNLG+ Shared Task竞赛结果，强调当前研究热点和主流方法，说明本工作顺应趋势。\n\n4. 细分子任务揭示转移学习潜力差异（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：分析NLG传统子任务（如lexicalisation和aggregation）在迁移学习中的表现差异，论证现有端到端方法的不足，为提出分层结构做铺垫。\n\n5. 提出分层结构以提升可解释性（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：明确将模型分为lexicalisation、aggregation、postedit三模块，对应传统NLG流程，帮助读者理解每一模块的功能和分工。\n\n6. 图示模型结构和流程（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过图1、图2展示模型整体结构和各阶段输出，直观帮助读者理解方法流程。\n\n7. 多数据集、多设置全面实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：在FewShotSGD、FewShotWeb、MultiWoZ等多个数据集上，分别在few-shot、zero-shot等多种设置下进行实验，覆盖广泛应用场景。\n\n8. 多指标量化评估（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：采用BLEU、BLEURT、MER等多种自动评测指标，结合人工评测，全面评价模型性能。\n\n9. 与主流强基线系统对比（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：与端到端T5系统在各数据集和设置下进行直接对比，展示HRAG的性能提升和优势。\n\n10. 分析异常现象并解释原因（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：对E2E T5在某些设置下MER异常高但流畅性差的现象进行剖析，解释模型行为，避免误导性结论。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_97",
        "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
        "problem_framing": "论文通过介绍大规模预训练语言模型（PLMs）在自然语言生成（NLG）领域带来的研究兴趣转变，引出当前在概念到文本生成任务中的挑战。开篇首先强调了PLMs在领域适应和迁移学习中的重要性，并指出在数据稀缺（few-shot/zero-shot）场景下，迁移学习成为主流且有效的方案。作者结合实际应用需求和学术发展趋势，提出在端到端NLG模型中，部分子任务（如词汇化和聚合）对迁移学习的利用潜力不同，由此引出本文关注的核心问题。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在低资源/小样本场景下研究不足’和‘现有方法依赖人工模板或领域特定资源，成本高且泛化性差’的逻辑。具体通过引用相关工作，指出前人方法要么依赖合成数据、人工模板，或是未能充分利用迁移学习在不同子任务上的潜力，尤其是在词汇化和聚合阶段的迁移能力差异未被深入探讨。句式上强调‘未被广泛研究’、‘不一定能获得人工模板’、‘在低资源条件下难以泛化’等批评点。",
        "method_story": "方法部分采用分模块介绍的策略，先整体描述提出的分层模型HRAG的架构与设计理念，再细致分解为三个模块：词汇化、聚合和后编辑。每个模块对应传统NLG流程中的关键阶段，并结合其在迁移学习中的潜力进行阐述。通过图示和具体例子，展示各模块的输出及其协同工作方式，体现从局部到整体、由简单到复杂的递进叙述顺序。",
        "experiments_story": "实验部分采用多数据集、多训练规模验证的策略，系统性比较HRAG与主流端到端T5模型在不同数据量和领域上的表现。包含主实验（自动评测指标如BLEU、BLEURT、MER）、极低资源条件下的性能分析、跨域/零样本泛化能力测试，以及人类评测。实验叙述强调不同数据集、不同训练规模下的对比，并通过定量和定性分析（如输出示例、附录补充）全面展示方法优势和局限。"
      },
      {
        "paper_id": "ARR_2022_27",
        "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
        "problem_framing": "论文从实际痛点和应用需求出发引出问题。开篇指出预训练语言模型（PLM）在NLP任务中的突破性进展，但现有PLM通常基于静态快照训练，忽略了现实世界中数据是持续流入且分布变化的场景。通过举例（文学作品、新闻、科学论文等数据不断增长），强调需要PLM具备持续集成新知识的能力，并提出在计算资源有限的情况下，如何高效地实现PLM的终身适应是一个重要问题。最终将问题正式定义为高效终身预训练（efficient lifelong pre-training）。",
        "gap_pattern": "论文批评现有方法时，采用了“现有方法忽视了X”与“现有方法在Y场景下失效”的逻辑。具体地，指出大多数现有PLM只在静态数据上训练，忽略了流式、多源、分布变化的数据场景。此外，现有终身学习方法主要关注记忆回放、参数巩固或动态结构，但很少考虑多源流数据的顺序集成和训练效率问题。通过对比相关工作，强调已有方法未能兼顾知识增长效率和任务相关知识激活，且未关注PLM在持续扩展数据下的训练效率。",
        "method_story": "方法部分采用“先整体后局部、分模块介绍”的叙述策略。首先整体介绍为提升知识增长效率，提出在每次新数据到来时对模型宽度和深度进行扩展。随后分别详细介绍宽度扩展和深度扩展的具体实现，包括函数保持初始化（FPI）和分层插入等技术细节，并对比现有方法，指出创新点和改进之处。每个模块都结合理论和实现细节，层层递进，逻辑清晰。",
        "experiments_story": "实验部分采用“主实验+多数据集验证+消融分析”的叙述策略。首先模拟多领域流式数据场景，涵盖5个不同领域的数据集，验证方法在真实终身学习场景下的有效性。其次，详细描述模型架构、训练细节和评测指标，确保实验可复现和公平。还通过不同模型规模、计算和存储预算等设置，分析方法在不同资源约束下的表现，并在附录中补充更多消融实验和细节分析，增强实验说服力。"
      },
      {
        "paper_id": "ARR_2022_352",
        "title": "Compression of Generative Pre-trained Language Models via Quantization",
        "problem_framing": "论文开篇先强调了Transformer类生成式预训练语言模型（PLMs）在多任务和小样本学习上的强大能力及其在各类任务中的卓越表现，随后指出其计算和存储开销巨大是实际应用中的主要痛点。接着，作者回顾了已有的压缩方法多聚焦于理解类任务（如BERT），而生成式PLMs的压缩仍存在难题，且压缩率远低于BERT，具体困难尚不明确。整体策略为：先从实际应用痛点（高资源消耗）出发，再引出学术gap（生成式PLMs压缩难且原因未明），形成问题导向。",
        "gap_pattern": "论文批评现有方法时，采用了对比和局限性揭示的策略。具体逻辑为：1）指出已有压缩方法主要针对BERT等理解任务，忽视了生成式PLMs；2）即便有少量针对GPT-2的压缩工作（如张量分解、知识蒸馏），其压缩率显著低于BERT，且未能解决根本难题；3）直接套用BERT或CV领域的量化方法在生成式PLMs上效果很差，性能急剧下降。常用句式包括“但大多聚焦于X”、“但压缩率远低于Y”、“直接应用Z方法导致性能大幅下降”等。",
        "method_story": "方法部分先指出直接用传统量化方法训练低比特生成式PLM存在挑战，随后简要回顾量化背景。接着，基于前文观察，分两大模块提出创新方法：1）token-level对比蒸馏提升词嵌入可区分性，2）module-wise动态缩放提升量化器适应性。叙述顺序为：先整体问题描述与背景，再分模块详细介绍创新点，属于‘先整体后局部，分模块介绍’的策略。",
        "experiments_story": "实验部分采用了多数据集、多任务验证的策略。具体包括：1）在WikiText2、PTB、WikiText103等数据集上进行语言建模主实验，2）对比不同bit-width下的方法性能，3）与主流量化方法（如PACT、LSQ、LAQ）和最新GPT-2压缩方法（如KnGPT2、DistilGPT2、LightPAFF）做系统对比，4）分析量化误差累积等机制。整体叙述为‘主实验+多方法对比+多数据集验证’，突出方法的普适性和优越性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 5,
        "percentage": "45.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "从领域背景、问题分析、方法提出到实验验证，层层递进，前后呼应，逻辑清晰地展开全文。",
            "type": "writing-level",
            "purpose": "提升文章整体可读性和逻辑性，帮助读者顺畅理解创新点和贡献"
          },
          {
            "paper_id": "ARR_2022_289",
            "title": "Learning to Transfer Prompts for Text Generation",
            "description": "从问题引入、技术背景、挑战点、方法设计到实验验证，层层递进，呼应前后，结构清晰。",
            "type": "writing-level",
            "purpose": "提升整体可读性和说服力，使读者顺畅理解研究脉络"
          },
          {
            "paper_id": "ARR_2022_171",
            "title": "AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks",
            "description": "作者从问题引入、现有方法梳理、创新点提出、方法细节说明到实验验证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，使读者易于跟随论证过程"
          }
        ]
      },
      {
        "trick_name": "现实场景动机引入",
        "frequency": 2,
        "percentage": "18.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_27",
            "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
            "description": "通过举例说明现实中数据持续增长（如新闻、论文等），强调现有PLM静态训练的局限性，凸显研究问题的现实意义。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者感受到问题的实际紧迫性和广泛性"
          },
          {
            "paper_id": "ARR_2022_289",
            "title": "Learning to Transfer Prompts for Text Generation",
            "description": "通过强调现实中数据稀缺的情况（如新领域任务标注数据有限），说明现有方法的局限性并引出研究动机。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者理解方法解决的是实际存在的问题"
          }
        ]
      },
      {
        "trick_name": "引用主流模型和竞赛结果建立背景",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "通过引用BERT、GPT-3、T5等主流PLM模型及WebNLG+ Shared Task竞赛结果，强调当前研究热点和主流方法，说明本工作顺应趋势。",
            "type": "writing-level",
            "purpose": "增强说服力和权威性，让读者相信该领域的主流趋势和挑战"
          }
        ]
      },
      {
        "trick_name": "细分子任务揭示转移学习潜力差异",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "分析NLG传统子任务（如lexicalisation和aggregation）在迁移学习中的表现差异，论证现有端到端方法的不足，为提出分层结构做铺垫。",
            "type": "method-level",
            "purpose": "突出新颖性，通过分析子任务差异引出新方法的必要性"
          }
        ]
      },
      {
        "trick_name": "提出分层结构以提升可解释性",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "明确将模型分为lexicalisation、aggregation、postedit三模块，对应传统NLG流程，帮助读者理解每一模块的功能和分工。",
            "type": "method-level",
            "purpose": "提升可解释性，让读者更好理解模型设计动机和结构"
          }
        ]
      },
      {
        "trick_name": "图示模型结构和流程",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "通过图1、图2展示模型整体结构和各阶段输出，直观帮助读者理解方法流程。",
            "type": "writing-level",
            "purpose": "提升可解释性，降低理解难度"
          }
        ]
      },
      {
        "trick_name": "多数据集、多设置全面实验",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "在FewShotSGD、FewShotWeb、MultiWoZ等多个数据集上，分别在few-shot、zero-shot等多种设置下进行实验，覆盖广泛应用场景。",
            "type": "experiment-level",
            "purpose": "增强完备性，证明方法在不同场景下的有效性和泛化能力"
          }
        ]
      },
      {
        "trick_name": "多指标量化评估",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "采用BLEU、BLEURT、MER等多种自动评测指标，结合人工评测，全面评价模型性能。",
            "type": "experiment-level",
            "purpose": "增强说服力和完备性，防止单一指标偏见"
          }
        ]
      },
      {
        "trick_name": "与主流强基线系统对比",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "与端到端T5系统在各数据集和设置下进行直接对比，展示HRAG的性能提升和优势。",
            "type": "experiment-level",
            "purpose": "突出方法优势，增强对比性和说服力"
          }
        ]
      },
      {
        "trick_name": "分析异常现象并解释原因",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "对E2E T5在某些设置下MER异常高但流畅性差的现象进行剖析，解释模型行为，避免误导性结论。",
            "type": "experiment-level",
            "purpose": "提升可信度和科学性，展示作者对实验现象的深入理解"
          }
        ]
      },
      {
        "trick_name": "案例分析和输出示例补充定量结果",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_97",
            "title": "Hierarchical Recurrent Aggregative Generation for Few-Shot NLG",
            "description": "通过具体输出示例和人工评测，展示模型在实际生成中的表现，验证定量结果的合理性。",
            "type": "experiment-level",
            "purpose": "提升可解释性和说服力，弥补自动评测的不足"
          }
        ]
      },
      {
        "trick_name": "挑战点明确分解",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_27",
            "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
            "description": "将efficient lifelong pre-training分解为两个新挑战（知识增长效率和知识激活），为提出新方法埋下伏笔。",
            "type": "writing-level",
            "purpose": "突出新颖性和问题复杂性，为后续方法创新做铺垫"
          }
        ]
      },
      {
        "trick_name": "文献对比与引用",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_27",
            "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
            "description": "多次引用主流PLM、终身学习和模型扩展等相关工作，指出现有方法的不足并与自身方法形成对比。",
            "type": "writing-level",
            "purpose": "增强对比性和说服力，表明作者熟悉领域并有针对性地改进现有方法"
          }
        ]
      },
      {
        "trick_name": "方法命名与缩写",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_27",
            "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
            "description": "为提出的方法命名ELLE，并在后文持续使用，增强方法的品牌感。",
            "type": "writing-level",
            "purpose": "提升可识别性和传播性，便于后文反复引用和讨论"
          }
        ]
      },
      {
        "trick_name": "逐步拆解方法流程",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_27",
            "title": "ELLE: Efficient Lifelong Pre-training for Emerging Data",
            "description": "将模型扩展分为宽度扩展、深度扩展、功能恢复预热等步骤，分别详细解释每一步的原理和实现。",
            "type": "method-level",
            "purpose": "提升可解释性，帮助读者逐步理解复杂方法的每一步"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 11,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_97",
        "ARR_2022_27",
        "ARR_2022_352",
        "ARR_2022_289",
        "ARR_2022_171",
        "ARR_2022_223",
        "ARR_2022_347",
        "ARR_2022_116",
        "ARR_2022_274",
        "ARR_2022_194",
        "ARR_2022_225"
      ]
    }
  },
  {
    "pattern_id": 6,
    "pattern_name": "多模态虚假信息检测方法",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多模态虚假信息检测问题，采用跨文档或多模态融合方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以社会痛点开篇，通过现有方法局限对比铺垫，方法部分采用模块化和技术细节分步阐述，实验设计注重多层次对比与消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于多模态虚假信息检测任务，数据集包含文本、图片、视频等，预期提升检测准确性和泛化能力。",
    "writing_guide": "写作模板：多模态虚假信息检测方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多模态虚假信息检测问题，采用跨文档或多模态融合方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以社会痛点开篇，通过现有方法局限对比铺垫，方法部分采用模块化和技术细节分步阐述，实验设计注重多层次对比与消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于多模态虚假信息检测任务，数据集包含文本、图片、视频等，预期提升检测准确性和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Cross-document Misinformation Detection based on Event Graph Reasoning》\n  • 问题定位：论文从实际社会痛点出发，强调虚假新闻传播已成为重要社会问题，并指出在复杂突发事件中，读者通常会接触到多个来源的新闻文档，其中有真有假。通过具体案例（如美国国会袭击事件中关于死亡事件的报道），展示了单独判断新闻难以识别虚假信息，但跨文档的信息冲突和互补可以帮助检测虚假信息。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法局限于单文档判断’、‘未利用跨文档信息’、‘相关工作仅关注知识三元组或事实验证，无法处理复杂结构’等逻辑。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先整体介绍方法流程（如图2所示），即先对每个文档构建知识图谱，再通过事件共指将各文档知识图谱连接为跨文档知识图谱。随后介绍具体技术细节，如使用异构GNN进行检测，并说明如何将事件级检测结果用于文档级检测，体现模块化和层次化的结构。\n  • 实验设计：实验部分采用多数据集验证、主实验+消融分析的策略。首先介绍主实验设计，包括与现有主流方法的对比（文档级）、以及针对新任务的启发式基线（事件级）。随后通过消融实验分析各组件（如事件共指、事件级检测）的作用，并在不同数据集和集群规模下验证方法有效性。\n\n示例 2：《Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal Misinformation》\n  • 问题定位：论文首先从实际痛点出发，强调了‘out-of-context images’作为一种廉价却极具危害性的虚假信息形式，尤其在社会和国家安全相关领域影响巨大。通过举例说明该问题在COVID-19、气候变化和军事领域的现实影响，明确了研究的应用需求和社会价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。具体指出：已有数据集要么规模小，要么仅关注文本虚假声明，未覆盖多模态不一致性；部分方法依赖外部知识库，限制了通用性和可扩展性。通过对比，强调了本工作在多模态、规模和自动化标注方面的创新。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了基于CLIP模型的多模态嵌入与分类框架，然后细化到具体的融合方式（如Concat、Concat+Dot、Multiply），并通过实验对比三种融合策略，说明最终选择Multiply。\n  • 实验设计：实验部分采用‘多数据集验证+消融分析+任务难点分析’的策略。首先在合成数据（Dev）和两个人工构造的真实场景数据集（hNews、hTwitter）上验证主方法性能，并与基线方法对比。随后进行消融实验，分析不同融合方式和模型设计对性能的影响。\n\n示例 3：《MM-Claims: A Dataset for Multimodal Claim Detection in Social Media》\n  • 问题定位：论文首先从实际社会痛点出发，强调新冠疫情期间错误信息（misinformation）对社会的危害，提出‘信息疫情’（infodemic）的概念，并引用联合国的呼吁，凸显问题的紧迫性和现实影响。\n  • 现有研究缺口：论文通过梳理现有文献，指出当前研究主要集中在单一模态（尤其是文本）上的claim检测，虽然有部分多模态相关的数据集和模型，但大多关注于真假（veracity）判定或仅限于单一主题（如COVID-19），缺乏对多主题、多模态claim检测的系统研究。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先回顾claim检测领域的发展脉络，从早期基于结构和特征的方法到当前主流的transformer模型，涵盖了不同场景（如跨领域、跨语言等）和数据集。随后，介绍多模态相关工作，指出已有数据集和方法的不足，最后聚焦到自身提出的数据集和模型设计。\n  • 实验设计：实验部分采用‘主实验+多角度分析’的策略。首先介绍实验设置，包括特征、基线模型和评价指标。主实验围绕新提出的数据集，测试多种特征和最新的多模态模型，报告二分类和三分类的准确率和Macro-F1。其次，分析模型在视觉相关与非视觉相关claim上的表现，探讨模型对不同模态的偏好。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 37.5%）\n   类型：writing-level\n   应用：作者采用问题提出-方法介绍-实验验证的经典结构，层层递进，呼应研究目标与结论。\n\n2. 现实问题引入（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：通过COVID-19疫情期间的信息误导问题引入，强调打击虚假信息的重要性，激发读者关注\n\n3. 场景化问题引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：以假新闻传播为社会问题切入，强调现实影响，增强问题的紧迫性和相关性。\n\n4. 案例驱动说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过Rosanne Boyland事件的多文档知识图谱，展示跨文档信息冲突与互补，直观体现方法价值。\n\n5. 现有方法局限对比（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：指出现有方法仅能单文档判断，无法利用跨文档信息，铺垫新任务的必要性。\n\n6. 任务分层细化（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：将检测任务分为文档级和事件级，明确各自目标和意义。\n\n7. 数据集创新与构建说明（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：首次构建包含话题相关文档簇的假新闻检测数据集，并详细说明生成过程。\n\n8. 方法流程图展示（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：用图示（Figure 2）展示整体流程，包括KG构建、跨文档连接和检测步骤。\n\n9. 技术细节分步阐述（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：分步骤介绍KG构建、跨文档事件共指、异构GNN检测及事件级结果融合。\n\n10. 多层次对比实验设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：分别在文档级与事件级任务上与多种基线方法对比，包括现有模型和启发式方法。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_355",
        "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
        "problem_framing": "论文从实际社会痛点出发，强调虚假新闻传播已成为重要社会问题，并指出在复杂突发事件中，读者通常会接触到多个来源的新闻文档，其中有真有假。通过具体案例（如美国国会袭击事件中关于死亡事件的报道），展示了单独判断新闻难以识别虚假信息，但跨文档的信息冲突和互补可以帮助检测虚假信息。由此引出现有方法的不足，并提出跨文档虚假信息检测的新任务。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法局限于单文档判断’、‘未利用跨文档信息’、‘相关工作仅关注知识三元组或事实验证，无法处理复杂结构’等逻辑。具体句式包括‘Most existing work... is limited to judging each document in isolation’和‘to the best of our knowledge, no published work has considered using cross-document inference for misinformation detection’，突出学术gap和未被关注的需求。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先整体介绍方法流程（如图2所示），即先对每个文档构建知识图谱，再通过事件共指将各文档知识图谱连接为跨文档知识图谱。随后介绍具体技术细节，如使用异构GNN进行检测，并说明如何将事件级检测结果用于文档级检测，体现模块化和层次化的结构。",
        "experiments_story": "实验部分采用多数据集验证、主实验+消融分析的策略。首先介绍主实验设计，包括与现有主流方法的对比（文档级）、以及针对新任务的启发式基线（事件级）。随后通过消融实验分析各组件（如事件共指、事件级检测）的作用，并在不同数据集和集群规模下验证方法有效性。实验评价指标包括F1和AUC，针对不同任务设计，体现全面性和细致性。"
      },
      {
        "paper_id": "ARR_2022_236",
        "title": "Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal Misinformation",
        "problem_framing": "论文首先从实际痛点出发，强调了‘out-of-context images’作为一种廉价却极具危害性的虚假信息形式，尤其在社会和国家安全相关领域影响巨大。通过举例说明该问题在COVID-19、气候变化和军事领域的现实影响，明确了研究的应用需求和社会价值。随后，作者提出目标：通过检测图文语义不一致性，自动判别推文的真实性。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。具体指出：已有数据集要么规模小，要么仅关注文本虚假声明，未覆盖多模态不一致性；部分方法依赖外部知识库，限制了通用性和可扩展性。通过对比，强调了本工作在多模态、规模和自动化标注方面的创新。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了基于CLIP模型的多模态嵌入与分类框架，然后细化到具体的融合方式（如Concat、Concat+Dot、Multiply），并通过实验对比三种融合策略，说明最终选择Multiply。参数设置、训练细节和基线方法也逐步展开，形成由宏观到微观的递进结构。",
        "experiments_story": "实验部分采用‘多数据集验证+消融分析+任务难点分析’的策略。首先在合成数据（Dev）和两个人工构造的真实场景数据集（hNews、hTwitter）上验证主方法性能，并与基线方法对比。随后进行消融实验，分析不同融合方式和模型设计对性能的影响。进一步，针对OCR覆盖率和推文文本聚类等特征，深入分析模型在不同场景和子任务下的表现，揭示任务挑战和模型优势。"
      },
      {
        "paper_id": "ARR_2022_155",
        "title": "MM-Claims: A Dataset for Multimodal Claim Detection in Social Media",
        "problem_framing": "论文首先从实际社会痛点出发，强调新冠疫情期间错误信息（misinformation）对社会的危害，提出‘信息疫情’（infodemic）的概念，并引用联合国的呼吁，凸显问题的紧迫性和现实影响。随后，论文指出在社交媒体上打击错误信息的挑战，特别是多模态（文本、图片、视频）信息的复杂性，进一步引出学术界在该领域的研究现状，逐步聚焦到多模态claim检测这一具体问题。整体采用‘从社会痛点—学术挑战—具体问题’的递进式开篇策略。",
        "gap_pattern": "论文通过梳理现有文献，指出当前研究主要集中在单一模态（尤其是文本）上的claim检测，虽然有部分多模态相关的数据集和模型，但大多关注于真假（veracity）判定或仅限于单一主题（如COVID-19），缺乏对多主题、多模态claim检测的系统研究。常用句式包括‘hardly any research has focused on...’、‘Although previous work has provided... they are either... or...’等，逻辑上强调现有方法的局限性和覆盖盲区，突出自身工作的创新点和必要性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先回顾claim检测领域的发展脉络，从早期基于结构和特征的方法到当前主流的transformer模型，涵盖了不同场景（如跨领域、跨语言等）和数据集。随后，介绍多模态相关工作，指出已有数据集和方法的不足，最后聚焦到自身提出的数据集和模型设计。整体上，先铺垫领域背景和技术演进，再突出自身方法的创新点和具体实现。",
        "experiments_story": "实验部分采用‘主实验+多角度分析’的策略。首先介绍实验设置，包括特征、基线模型和评价指标。主实验围绕新提出的数据集，测试多种特征和最新的多模态模型，报告二分类和三分类的准确率和Macro-F1。其次，分析模型在视觉相关与非视觉相关claim上的表现，探讨模型对不同模态的偏好。补充了超参数设置和训练细节，保证实验的可复现性和严谨性。整体结构为‘主实验+细粒度分析+实验细节’。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "37.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_236",
            "title": "Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal Misinformation",
            "description": "作者采用问题提出-方法介绍-实验验证的经典结构，层层递进，呼应研究目标与结论。",
            "type": "writing-level",
            "purpose": "提升论文可读性和逻辑性，帮助读者理解研究流程"
          },
          {
            "paper_id": "ARR_2022_155",
            "title": "MM-Claims: A Dataset for Multimodal Claim Detection in Social Media",
            "description": "从问题引入、相关工作综述、方法提出到实验验证，层层递进，逻辑清晰",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究动机、方法和实验结果"
          },
          {
            "paper_id": "ARR_2022_2",
            "title": "WatClaimCheck: A new Dataset for Claim Entailment and Inference",
            "description": "从问题引入、现有方法分析、提出新任务、方法分解、实验验证到现实意义呼应，环环相扣。",
            "type": "writing-level",
            "purpose": "提升文章的可读性和逻辑性，帮助读者顺畅理解研究流程"
          }
        ]
      },
      {
        "trick_name": "现实问题引入",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_155",
            "title": "MM-Claims: A Dataset for Multimodal Claim Detection in Social Media",
            "description": "通过COVID-19疫情期间的信息误导问题引入，强调打击虚假信息的重要性，激发读者关注",
            "type": "writing-level",
            "purpose": "凸显研究的现实意义和紧迫性，增强说服力"
          },
          {
            "paper_id": "ARR_2022_2",
            "title": "WatClaimCheck: A new Dataset for Claim Entailment and Inference",
            "description": "通过描述社交媒体假新闻泛滥和事实核查组织的实际工作，强调自动化事实核查的现实需求和挑战。",
            "type": "writing-level",
            "purpose": "增强说服力和现实意义，让读者意识到问题的重要性和紧迫性"
          }
        ]
      },
      {
        "trick_name": "场景化问题引入",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "以假新闻传播为社会问题切入，强调现实影响，增强问题的紧迫性和相关性。",
            "type": "writing-level",
            "purpose": "通过具体社会问题吸引读者关注并凸显研究意义"
          }
        ]
      },
      {
        "trick_name": "案例驱动说明",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "通过Rosanne Boyland事件的多文档知识图谱，展示跨文档信息冲突与互补，直观体现方法价值。",
            "type": "writing-level",
            "purpose": "用具体例子帮助读者理解问题复杂性及方法优势"
          }
        ]
      },
      {
        "trick_name": "现有方法局限对比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "指出现有方法仅能单文档判断，无法利用跨文档信息，铺垫新任务的必要性。",
            "type": "writing-level",
            "purpose": "突出本工作与前人工作的区别，强化创新性"
          }
        ]
      },
      {
        "trick_name": "任务分层细化",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "将检测任务分为文档级和事件级，明确各自目标和意义。",
            "type": "method-level",
            "purpose": "增强方法可解释性和科学性，便于读者理解不同粒度的检测目标"
          }
        ]
      },
      {
        "trick_name": "数据集创新与构建说明",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "首次构建包含话题相关文档簇的假新闻检测数据集，并详细说明生成过程。",
            "type": "experiment-level",
            "purpose": "展示工作新颖性并解决领域数据缺乏问题"
          }
        ]
      },
      {
        "trick_name": "方法流程图展示",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "用图示（Figure 2）展示整体流程，包括KG构建、跨文档连接和检测步骤。",
            "type": "writing-level",
            "purpose": "提升方法可解释性和直观性，降低理解门槛"
          }
        ]
      },
      {
        "trick_name": "技术细节分步阐述",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "分步骤介绍KG构建、跨文档事件共指、异构GNN检测及事件级结果融合。",
            "type": "method-level",
            "purpose": "帮助读者系统理解方法原理和创新点"
          }
        ]
      },
      {
        "trick_name": "多层次对比实验设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "分别在文档级与事件级任务上与多种基线方法对比，包括现有模型和启发式方法。",
            "type": "experiment-level",
            "purpose": "增强说服力，通过多维度对比展示方法优越性"
          }
        ]
      },
      {
        "trick_name": "消融实验分析",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "通过去除关键模块（如事件共指边）分析性能变化，证明跨文档信息的重要性。",
            "type": "experiment-level",
            "purpose": "验证方法各组成部分的贡献，提升结论可靠性"
          }
        ]
      },
      {
        "trick_name": "参数与设置透明披露",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "详细说明模型结构、参数量、超参数搜索范围与训练细节。",
            "type": "experiment-level",
            "purpose": "提升实验复现性和结果可信度"
          }
        ]
      },
      {
        "trick_name": "性能指标多样化",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "针对标签不均衡等问题，采用F1和AUC等多种指标进行评估。",
            "type": "experiment-level",
            "purpose": "确保评估全面，适应不同任务特点"
          }
        ]
      },
      {
        "trick_name": "理论与实验呼应",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "实验结果直接验证引言中提出的跨文档信息利用和事件级检测的优势。",
            "type": "writing-level",
            "purpose": "强化方法有效性，形成闭环论证"
          }
        ]
      },
      {
        "trick_name": "数据生成过程追踪",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_355",
            "title": "Cross-document Misinformation Detection based on Event Graph Reasoning",
            "description": "通过追踪知识图谱操作，获得事件级假信息标签，确保监督信号准确。",
            "type": "experiment-level",
            "purpose": "增强事件级检测的监督信度和科学性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 8,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_355",
        "ARR_2022_236",
        "ARR_2022_155",
        "ARR_2022_150",
        "ARR_2022_2",
        "ACL_2017_729",
        "COLING_2020_69",
        "COLING_2020_75"
      ]
    }
  },
  {
    "pattern_id": 7,
    "pattern_name": "多模态融合多任务学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决命名实体识别中的复杂场景问题，采用多模态融合和多任务学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过引用权威工作铺垫背景，常用tricks包括多数据集验证、与主流方法对比和强基线设定。\n第3段（60字）：适用场景与预期效果 - 适用于复杂场景的命名实体识别任务，如嵌套实体、金融XBRL标签和口语NER，预期提升模型性能和泛化能力。",
    "writing_guide": "写作模板：多模态融合多任务学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决命名实体识别中的复杂场景问题，采用多模态融合和多任务学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过引用权威工作铺垫背景，常用tricks包括多数据集验证、与主流方法对比和强基线设定。\n第3段（60字）：适用场景与预期效果 - 适用于复杂场景的命名实体识别任务，如嵌套实体、金融XBRL标签和口语NER，预期提升模型性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition》\n  • 问题定位：论文首先从实际应用出发，指出命名实体识别（NER）作为基础的自然语言处理任务已被广泛研究，尤其是平坦实体识别。随后，论文强调在真实场景中嵌套实体广泛存在，且具有多粒度语义，现有序列标注框架难以处理嵌套实体。\n  • 现有研究缺口：论文批评现有方法主要采用两种逻辑：一是指出现有的span-based方法虽然借助预训练语言模型取得了不错效果，但结构过于简单，未能显式建模关键特征（如边界、标签感知、相关span间的交互）；二是具体分析这些特征对嵌套实体识别的重要性，并举例说明仅依赖边界或单一特征无法充分区分不同类型的嵌套实体...\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先通过图示给出方法的整体框架，明确核心创新点为triaffine变换用于融合多种异质特征。随后，分步骤详细介绍triaffine变换的原理和作用，再具体讲解基于该变换的模型结构和实现细节。整体逻辑清晰，由总到分，突出创新点。\n  • 实验设计：实验部分采用‘多数据集主实验+与主流方法对比’的策略。通过在ACE2004、ACE2005、GENIA和KBP2017等多个公开数据集上与多种主流方法（包括不同范式和不同编码器）进行全面对比，突出方法的优越性。此外，实验结果细致呈现不同编码器下的性能，强调模型在各场景下的领先表现。\n\n示例 2：《FiNER: Financial Numeric Entity Recognition for XBRL Tagging》\n  • 问题定位：论文从应用需求和实际痛点出发引出问题。首先强调金融领域自然语言处理（NLP）的重要性和现有应用场景，如股市预测、情感分析、事件检测等，指出金融数据不仅存在于结构化表格，还大量分布于非结构化文本（如公司报告、分析师评论、新闻）。\n  • 现有研究缺口：论文通过对比现有实体抽取方法（如NER和合同元素抽取），批评其在金融XBRL标签任务上的局限。主要逻辑是：现有方法通常只处理少量通用实体类型（如人名、机构名），而XBRL标签类型数量巨大（6k），且绝大多数标签对象为数字型token，正确标签高度依赖上下文。\n  • 核心方法：方法部分采用从整体到局部、从简单到复杂的叙述策略。首先介绍主流NLP工具spaCy作为基线，随后依次介绍更复杂的模型：bilstm（双向LSTM）、bert（预训练Transformer），并分别说明其输入嵌入和训练数据。\n  • 实验设计：实验部分采用主实验为主、分析模型表现差异的策略。首先统一采用微平均F1和宏平均F1作为评价指标，确保不同模型可直接比较。主实验涵盖spaCy、bilstm、bert及其与CRF结合的多种模型，重点分析各模型在实体级别的表现及其原因。\n\n示例 3：《MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective》\n  • 问题定位：论文首先从实际应用场景出发，强调命名实体识别（NER）在信息检索、问答系统、对话系统等领域的重要性，进而指出传统方法和深度学习方法在公开基准上取得了较好表现，但在处理未见实体（OOV）时存在显著性能下降的问题。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在OOV场景下失效’的逻辑。具体地，作者指出当前NER模型主要依赖于已见实体的记忆，导致在未见实体预测时表现不佳。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先，作者介绍了NER任务从序列标注向Span预测的范式转变，并阐述选择SpanNER作为基础架构的原因。随后，详细说明SpanNER的三大模块，并突出本方法在架构中插入信息瓶颈层以优化信息。\n  • 实验设计：实验部分采用‘主实验+多数据集验证+对比分析’的叙述策略。作者在五个OOV数据集上验证了所提方法的性能，并与多种现有方法进行了系统对比。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 多数据集验证（使用频率 3 次，占比 25.0%）\n   类型：experiment-level\n   应用：在多个公开数据集（ACE2004, ACE2005, GENIA, KBP2017）上进行实验，覆盖不同领域，证明方法的普适性和稳定性。\n\n2. 具体案例引入（使用频率 2 次，占比 16.7%）\n   类型：writing-level\n   应用：通过具体的例子（如“NF - chi B site”）说明嵌套实体识别中标签和边界的复杂性，帮助读者理解方法设计动机。\n\n3. 消融实验设计（使用频率 2 次，占比 16.7%）\n   类型：experiment-level\n   应用：通过对比有无CRF层、不同tokenization（word/subword）等设置，细致分析模型表现差异，支持机制解释。\n\n4. 多维度问题分解（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：作者将嵌套实体识别任务分解为多个关键因素（tokens、边界、标签、相关span），逐一阐述每个因素的必要性和挑战性，为后续方法设计铺垫理论基础。\n\n5. 引用权威工作（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：通过大量引用领域内代表性工作，说明现有方法的局限和发展趋势，为新方法的提出做铺垫。\n\n6. 方法核心突出（使用频率 1 次，占比 8.3%）\n   类型：method-level\n   应用：在方法部分开头直接强调“triaffine transformations”为模型核心，突出该技术在融合多种异质特征上的创新性。\n\n7. 分步式方法介绍（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：先介绍核心技术，再分步骤描述整体模型结构，帮助读者逐步建立对方法原理的认知。\n\n8. 与主流方法全面对比（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：与多种主流方法（如BENSC, Pyramid, TreeCRF, Biaffine, Locate and Label, Sequence to Set）进行详细对比，并量化性能提升。\n\n9. 强基线设定（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：采用BERT和ALBERT等强大的预训练模型作为编码器，确保对比结果具有代表性和说服力。\n\n10. 量化性能提升（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：通过具体的F1分数和提升幅度（如“+0.70”、“+2.49”），清晰呈现新方法的性能优势。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_320",
        "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
        "problem_framing": "论文首先从实际应用出发，指出命名实体识别（NER）作为基础的自然语言处理任务已被广泛研究，尤其是平坦实体识别。随后，论文强调在真实场景中嵌套实体广泛存在，且具有多粒度语义，现有序列标注框架难以处理嵌套实体。通过引用相关文献，进一步说明嵌套实体识别的必要性和挑战，明确提出当前方法的局限性，为后续研究铺垫背景。",
        "gap_pattern": "论文批评现有方法主要采用两种逻辑：一是指出现有的span-based方法虽然借助预训练语言模型取得了不错效果，但结构过于简单，未能显式建模关键特征（如边界、标签感知、相关span间的交互）；二是具体分析这些特征对嵌套实体识别的重要性，并举例说明仅依赖边界或单一特征无法充分区分不同类型的嵌套实体。整体采用‘现有方法忽视了X’和‘在复杂嵌套场景下失效’的批评句式。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先通过图示给出方法的整体框架，明确核心创新点为triaffine变换用于融合多种异质特征。随后，分步骤详细介绍triaffine变换的原理和作用，再具体讲解基于该变换的模型结构和实现细节。整体逻辑清晰，由总到分，突出创新点。",
        "experiments_story": "实验部分采用‘多数据集主实验+与主流方法对比’的策略。通过在ACE2004、ACE2005、GENIA和KBP2017等多个公开数据集上与多种主流方法（包括不同范式和不同编码器）进行全面对比，突出方法的优越性。此外，实验结果细致呈现不同编码器下的性能，强调模型在各场景下的领先表现。"
      },
      {
        "paper_id": "ARR_2022_36",
        "title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
        "problem_framing": "论文从应用需求和实际痛点出发引出问题。首先强调金融领域自然语言处理（NLP）的重要性和现有应用场景，如股市预测、情感分析、事件检测等，指出金融数据不仅存在于结构化表格，还大量分布于非结构化文本（如公司报告、分析师评论、新闻）。接着聚焦于金融报告文本部分的XBRL标签自动化注释任务，指出该任务繁琐且成本高昂，且目前尚未被充分研究，强调其对提升信息透明度和合规性的重要性。通过介绍公开数据集 finer-139，进一步突显任务的实际价值和学术意义。",
        "gap_pattern": "论文通过对比现有实体抽取方法（如NER和合同元素抽取），批评其在金融XBRL标签任务上的局限。主要逻辑是：现有方法通常只处理少量通用实体类型（如人名、机构名），而XBRL标签类型数量巨大（6k），且绝大多数标签对象为数字型token，正确标签高度依赖上下文。论文指出现有NER方法往往通过正则表达式即可识别数字实体，但无法满足XBRL标签的精细化需求。此外，合同元素抽取虽然也需考虑上下文，但标签规模远小于XBRL。通过这些对比，强调现有方法在大规模、多样化、上下文敏感的金融标签任务下失效。",
        "method_story": "方法部分采用从整体到局部、从简单到复杂的叙述策略。首先介绍主流NLP工具spaCy作为基线，随后依次介绍更复杂的模型：bilstm（双向LSTM）、bert（预训练Transformer），并分别说明其输入嵌入和训练数据。最后，进一步引入CRF层，分别与bilstm和bert结合，强调CRF在序列标注任务中的优势。每种方法都简要说明技术细节和实现方式，整体呈现由基础到高级、逐步递进的结构。",
        "experiments_story": "实验部分采用主实验为主、分析模型表现差异的策略。首先统一采用微平均F1和宏平均F1作为评价指标，确保不同模型可直接比较。主实验涵盖spaCy、bilstm、bert及其与CRF结合的多种模型，重点分析各模型在实体级别的表现及其原因。实验过程中穿插消融分析，如对bilstm使用不同嵌入（词级 vs 子词级）及是否加CRF层，探讨模型结构对性能的影响，并提出假设解释现象。整体实验设计突出模型对任务特殊性的适应性和不足，没有多数据集或可视化实验，主要聚焦于方法本身的对比和机制解释。"
      },
      {
        "paper_id": "ARR_2022_37",
        "title": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective",
        "problem_framing": "论文首先从实际应用场景出发，强调命名实体识别（NER）在信息检索、问答系统、对话系统等领域的重要性，进而指出传统方法和深度学习方法在公开基准上取得了较好表现，但在处理未见实体（OOV）时存在显著性能下降的问题。通过引用相关文献，作者进一步强调OOV问题的普遍性和挑战性，最后提出如何让模型关注上下文信息以解决OOV问题，自然引出本文的研究动机和方法。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在OOV场景下失效’的逻辑。具体地，作者指出当前NER模型主要依赖于已见实体的记忆，导致在未见实体预测时表现不佳。此外，作者系统性地分析了三类经典缓解OOV问题的策略（外部知识、OOV词嵌入、上下文嵌入），并指出它们各自的局限性，如外部知识难以获取、OOV嵌入未充分利用上下文、预训练模型提升可能仅因更好地学习了子词结构。对于信息瓶颈原理，作者指出其在NER任务中难以权衡压缩与预测能力，且无法区分泛化性强与弱的特征，导致模型可能采用捷径学习而非真正泛化。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先，作者介绍了NER任务从序列标注向Span预测的范式转变，并阐述选择SpanNER作为基础架构的原因。随后，详细说明SpanNER的三大模块，并突出本方法在架构中插入信息瓶颈层以优化信息。接着，作者对比了本方法与多种基线方法，包括原始SpanNER、经典信息瓶颈、数据增强、其他同类方法等，逐一说明各方法的原理和与MINER的区别，最后强调对不同预训练模型的适用性验证。",
        "experiments_story": "实验部分采用‘主实验+多数据集验证+对比分析’的叙述策略。作者在五个OOV数据集上验证了所提方法的性能，并与多种现有方法进行了系统对比。实验内容包括：1）主实验，展示MINER在OOV实体预测上的效果；2）对比实验，分析与SpanNER及其他SOTA方法的性能差异；3）不同OOV扰动类型（如typos、实体替换）下的鲁棒性分析；4）信息瓶颈方法的消融效果；5）在不同预训练模型（BERT、RoBERTa、ALBERT）上的通用性实验。整体上，实验部分通过多维度、多场景验证方法有效性和泛化能力。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "多数据集验证",
        "frequency": 3,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "在多个公开数据集（ACE2004, ACE2005, GENIA, KBP2017）上进行实验，覆盖不同领域，证明方法的普适性和稳定性。",
            "type": "experiment-level",
            "purpose": "增强实验结果的完备性和结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_37",
            "title": "MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective",
            "description": "在五个OOV数据集上进行实验，确保结果具有普适性和代表性。",
            "type": "experiment-level",
            "purpose": "提升实验的完备性和结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_127",
            "title": "Delving Deep into Regularity: A Simple but Effective Method for Chinese Named Entity Recognition",
            "description": "在OntoNotes V4.0、V5.0、MSRA和CBLUE-CMeEE等多个公开数据集上进行实验",
            "type": "experiment-level",
            "purpose": "证明方法的通用性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "具体案例引入",
        "frequency": 2,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "通过具体的例子（如“NF - chi B site”）说明嵌套实体识别中标签和边界的复杂性，帮助读者理解方法设计动机。",
            "type": "writing-level",
            "purpose": "提升可解释性和易理解性，让读者直观感受问题复杂性"
          },
          {
            "paper_id": "ARR_2022_333",
            "title": "Thai Nested Named Entity Recognition Corpus",
            "description": "用“Chiang Mai University”实体举例，展示传统NER忽略嵌套结构的问题，引出N-NER的需求。",
            "type": "writing-level",
            "purpose": "帮助读者直观理解问题本质，提高可解释性"
          }
        ]
      },
      {
        "trick_name": "消融实验设计",
        "frequency": 2,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_36",
            "title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
            "description": "通过对比有无CRF层、不同tokenization（word/subword）等设置，细致分析模型表现差异，支持机制解释。",
            "type": "experiment-level",
            "purpose": "分析各组件（如CRF层、tokenization方式）对性能的具体影响，提升结论的解释力和可靠性"
          },
          {
            "paper_id": "ARR_2022_181",
            "title": "Boundary Smoothing for Named Entity Recognition",
            "description": "通过‘Baseline’与‘Baseline+BS’的对比，突出boundary smoothing的独立贡献。",
            "type": "experiment-level",
            "purpose": "验证方法中关键组件的作用，提升结论的可信度"
          }
        ]
      },
      {
        "trick_name": "多维度问题分解",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "作者将嵌套实体识别任务分解为多个关键因素（tokens、边界、标签、相关span），逐一阐述每个因素的必要性和挑战性，为后续方法设计铺垫理论基础。",
            "type": "writing-level",
            "purpose": "突出任务复杂性和挑战性，增加方法创新的说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "通过大量引用领域内代表性工作，说明现有方法的局限和发展趋势，为新方法的提出做铺垫。",
            "type": "writing-level",
            "purpose": "增强论述的学术可信度，展示对领域现状的充分了解"
          }
        ]
      },
      {
        "trick_name": "方法核心突出",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "在方法部分开头直接强调“triaffine transformations”为模型核心，突出该技术在融合多种异质特征上的创新性。",
            "type": "method-level",
            "purpose": "强调方法创新点，突出与现有工作的区别"
          }
        ]
      },
      {
        "trick_name": "分步式方法介绍",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "先介绍核心技术，再分步骤描述整体模型结构，帮助读者逐步建立对方法原理的认知。",
            "type": "writing-level",
            "purpose": "提升方法描述的条理性和可理解性"
          }
        ]
      },
      {
        "trick_name": "与主流方法全面对比",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "与多种主流方法（如BENSC, Pyramid, TreeCRF, Biaffine, Locate and Label, Sequence to Set）进行详细对比，并量化性能提升。",
            "type": "experiment-level",
            "purpose": "突出方法的优越性和进步性"
          }
        ]
      },
      {
        "trick_name": "强基线设定",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "采用BERT和ALBERT等强大的预训练模型作为编码器，确保对比结果具有代表性和说服力。",
            "type": "experiment-level",
            "purpose": "增强实验说服力，避免“弱基线”质疑"
          }
        ]
      },
      {
        "trick_name": "量化性能提升",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "通过具体的F1分数和提升幅度（如“+0.70”、“+2.49”），清晰呈现新方法的性能优势。",
            "type": "experiment-level",
            "purpose": "直观展示方法的实际效果，增强说服力"
          }
        ]
      },
      {
        "trick_name": "结构化叙事流",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "按照“问题-挑战-方法-实验-结论”的顺序组织内容，层层递进，逻辑清晰，便于读者理解和跟进。",
            "type": "writing-level",
            "purpose": "提升论文整体逻辑性和易读性"
          }
        ]
      },
      {
        "trick_name": "呼应理论与实验",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_320",
            "title": "Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition",
            "description": "在引言中提出的关键因素（如标签、边界、相关span）在实验部分得到验证，理论与实践相互呼应。",
            "type": "writing-level",
            "purpose": "增强方法与实验之间的内在联系，提高结论的可信度"
          }
        ]
      },
      {
        "trick_name": "问题动机强化",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_36",
            "title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
            "description": "通过强调金融文本XBRL标注的繁琐与高成本，以及立法强制要求，突出自动化标注的现实意义和紧迫性。",
            "type": "writing-level",
            "purpose": "突出任务的重要性和现实需求，吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "数据集贡献强调",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_36",
            "title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
            "description": "通过发布新的大规模数据集 finer-139，强调为领域提供了前所未有的资源，提升工作的独特性。",
            "type": "writing-level",
            "purpose": "突出工作的创新性和社区价值"
          }
        ]
      },
      {
        "trick_name": "任务难度对比",
        "frequency": 1,
        "percentage": "8.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_36",
            "title": "FiNER: Financial Numeric Entity Recognition for XBRL Tagging",
            "description": "将XBRL实体识别与传统NER等任务进行对比，指出标签数量巨大、数字占比高、依赖上下文等独特难点。",
            "type": "writing-level",
            "purpose": "凸显所研究任务的挑战性和区别于传统任务"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 12,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_320",
        "ARR_2022_36",
        "ARR_2022_37",
        "ARR_2022_127",
        "ARR_2022_181",
        "ARR_2022_256",
        "ARR_2022_248",
        "ARR_2022_83",
        "ARR_2022_333",
        "ACL_2017_107",
        "ACL_2017_108",
        "COLING_2020_33"
      ]
    }
  },
  {
    "pattern_id": 8,
    "pattern_name": "基于预训练模型的多标签分类",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多标签分类中的不平衡和复杂性问题，采用基于预训练模型的方法并结合新颖的注意力机制和评价指标。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用痛点出发，通过问题-方法-实验三段式结构展开，常用tricks包括引用前沿文献、多指标评估和复现与开源承诺。\n第3段（60字）：适用场景与预期效果 - 适用于大规模、多标签、不平衡和复杂语义的文本分类任务，预期提升模型性能和实际应用效果，增强研究的透明度和可验证性。",
    "writing_guide": "写作模板：基于预训练模型的多标签分类\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多标签分类中的不平衡和复杂性问题，采用基于预训练模型的方法并结合新颖的注意力机制和评价指标。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用痛点出发，通过问题-方法-实验三段式结构展开，常用tricks包括引用前沿文献、多指标评估和复现与开源承诺。\n第3段（60字）：适用场景与预期效果 - 适用于大规模、多标签、不平衡和复杂语义的文本分类任务，预期提升模型性能和实际应用效果，增强研究的透明度和可验证性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting》\n  • 问题定位：论文通过从实际应用需求出发引入问题，强调多标签文档分类在科学出版物、医疗记录、法律法规和产品描述等领域的广泛应用。作者指出该任务面临大规模标签空间和标签分布极度不均衡的挑战，并进一步提出时间概念漂移问题，强调现实世界中标签分布随时间变化，凸显了任务的复杂性和实际痛点。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体来说，作者指出现有关于时间漂移的工作主要是诊断性分析，缺乏针对类不平衡和时间概念漂移的技术解决方案。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先介绍了基线模型的整体架构，包括使用预训练BERT模型进行文档表示，然后详细描述了Label-Wise Attention Network（LWAN）与BERT结合的具体实现，逐步解释每个模块的作用和技术细节。\n  • 实验设计：实验部分采用‘多数据集验证’和‘主实验+多指标评估’的策略。作者在多个法律和生物医学数据集上进行实验，比较不同模型（如LEGAL-BERT、BERT-LWAN）的表现，详细说明训练和评估细节。\n\n示例 2：《Evaluating Extreme Hierarchical Multi-label Classification》\n  • 问题定位：论文从实际应用痛点出发引出问题，强调自然语言处理中的分类任务广泛存在于情感分析、实体链接等场景，但评价指标的充分性仍是未解决的问题。通过具体举例（如准确率与宏平均准确率在多类别分布下的表现差异），逐步引出多标签、多层级、极端不均衡分类等复杂场景下评价难题，明确提出当前评价标准难以适应实际复杂需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，指出不同评价指标（如Accuracy、F-measure、MAAC）在多标签、层级结构、类别极度不均衡等情形下表现不一致，无法全面反映系统优劣。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序，首先介绍了Information Contrast Model (ICM)的整体思想和理论基础，明确其统一了特征集和信息论的相似性度量。随后具体给出ICM的数学定义和计算方式，解释各参数的含义和直觉，并指出ICM如何推广现有的相似性度量方法。\n  • 实验设计：实验部分采用‘多维度测试+对比验证’的策略。首先通过构造大规模、极度不均衡的层级多标签合成数据集，系统性地考察不同评价指标在各类评价属性（如错误率敏感性、类别特异性、层级结构等）下的表现。实验类型包括：1）合成数据上的敏感性和属性测试，2）多指标横向对比，3）真实案例（医学文档）应用验证。\n\n示例 3：《KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling》\n  • 问题定位：论文从实际应用需求和痛点出发引出问题。首先介绍了PubMed/MEDLINE数据库的规模和MeSH索引在生物医学文本挖掘中的重要性，强调了人工标注的高成本和效率低下，结合文献引用和统计数据展示了人工索引的不可持续性，进而提出自动化MeSH索引的迫切需求。\n  • 现有研究缺口：论文通过描述现有人工方法的高成本和低效率，批评了当前依赖人工标注的局限性，并指出随着数据规模的增长，现有做法难以为继。此外，通过具体数据（如标签数量、标签分布不均、每篇文章标签数差异大等）强调了现有方法难以应对大规模和复杂语义的挑战。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先将MeSH索引形式化为多标签分类问题，给出整体建模框架。随后，分模块介绍模型的各个组成部分，包括多通道文档表示、标签特征学习、动态语义掩码注意力模块和分类器，层层递进，突出每个模块在整体架构中的作用。\n  • 实验设计：实验部分聚焦于主实验，采用多种主流评价指标（Microaverage、example-based、ranking-based）对模型进行系统评估。通过与五种主流方法（包括只用摘要/标题和用全文训练的系统）进行对比，突出自身方法的优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 应用场景举例（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过列举科学出版物、医疗记录、法律文本和商品描述等多种实际应用场景，强调多标签文档分类的广泛用途和现实意义。\n\n2. 问题难点细化（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：详细分析了类别不平衡和时序概念漂移等实际难点，说明现有方法的局限性和研究空白。\n\n3. 引用前沿文献（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：广泛引用近年来的重要文献，说明所关注问题和采用方法均有坚实的学术基础。\n\n4. 对比分割策略（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：对比随机分割和时间顺序分割，证明后者能更真实地反映模型在实际应用中的表现。\n\n5. 多指标评估（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：同时报告m-RP、micro-F1和macro-F1等多种评价指标，全面衡量模型性能和类别间差异。\n\n6. 复现与开源承诺（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：承诺开源全部代码，并为审稿人提供内部代码包，方便复现和后续研究。\n\n7. 方法细节可解释化（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：详细描述BERT-LWAN模型每一步的计算流程和直观解释，如每个标签独立注意力头如何关注不同文本片段。\n\n8. 与SOTA方法对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：引用并复现BERT-LWAN等当前最优方法，展示本方法在公开数据集上的性能对比。\n\n9. 实验设置细致说明（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：详细说明模型配置、训练参数、分组采样策略等实验细节，确保实验过程透明。\n\n10. 问题-方法-实验三段式结构（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：采用先引入问题，再提出方法，最后通过实验验证的经典三段式结构，逻辑清晰、层层递进。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_255",
        "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
        "problem_framing": "论文通过从实际应用需求出发引入问题，强调多标签文档分类在科学出版物、医疗记录、法律法规和产品描述等领域的广泛应用。作者指出该任务面临大规模标签空间和标签分布极度不均衡的挑战，并进一步提出时间概念漂移问题，强调现实世界中标签分布随时间变化，凸显了任务的复杂性和实际痛点。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体来说，作者指出现有关于时间漂移的工作主要是诊断性分析，缺乏针对类不平衡和时间概念漂移的技术解决方案。同时，现有多标签不平衡处理方法依赖于启发式假设，在复杂任务中表现不稳定、适用性差、计算成本高，且未能动态学习最优数据利用与类别平衡的权衡。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先介绍了基线模型的整体架构，包括使用预训练BERT模型进行文档表示，然后详细描述了Label-Wise Attention Network（LWAN）与BERT结合的具体实现，逐步解释每个模块的作用和技术细节。方法描述由通用到专用，逐层展开，便于读者理解整体流程及关键创新点。",
        "experiments_story": "实验部分采用‘多数据集验证’和‘主实验+多指标评估’的策略。作者在多个法律和生物医学数据集上进行实验，比较不同模型（如LEGAL-BERT、BERT-LWAN）的表现，详细说明训练和评估细节。实验报告包括主指标（如m-RP、micro-F1、macro-F1），以全面衡量模型性能及类别间表现差异，突出方法在实际应用中的有效性和公平性。"
      },
      {
        "paper_id": "ARR_2022_264",
        "title": "Evaluating Extreme Hierarchical Multi-label Classification",
        "problem_framing": "论文从实际应用痛点出发引出问题，强调自然语言处理中的分类任务广泛存在于情感分析、实体链接等场景，但评价指标的充分性仍是未解决的问题。通过具体举例（如准确率与宏平均准确率在多类别分布下的表现差异），逐步引出多标签、多层级、极端不均衡分类等复杂场景下评价难题，明确提出当前评价标准难以适应实际复杂需求。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，指出不同评价指标（如Accuracy、F-measure、MAAC）在多标签、层级结构、类别极度不均衡等情形下表现不一致，无法全面反映系统优劣。具体句式包括‘不同指标可能差异很大，严重影响系统优化过程’、‘在多标签和层级分类下，现有指标难以兼顾类别特异性、标签分布、层级距离等多种因素’，并通过实际案例（如医学文档不良事件标注）进一步突出现有方法的不足。",
        "method_story": "方法部分采用‘先整体后局部’的叙述顺序，首先介绍了Information Contrast Model (ICM)的整体思想和理论基础，明确其统一了特征集和信息论的相似性度量。随后具体给出ICM的数学定义和计算方式，解释各参数的含义和直觉，并指出ICM如何推广现有的相似性度量方法。最后强调ICM在理论上满足多种相似性公理，为后续实验验证做铺垫。",
        "experiments_story": "实验部分采用‘多维度测试+对比验证’的策略。首先通过构造大规模、极度不均衡的层级多标签合成数据集，系统性地考察不同评价指标在各类评价属性（如错误率敏感性、类别特异性、层级结构等）下的表现。实验类型包括：1）合成数据上的敏感性和属性测试，2）多指标横向对比，3）真实案例（医学文档）应用验证。每项实验都围绕特定评价属性设计，并通过定量指标（如优劣输出的得分排序）进行效果对比，突出ICM的优势。"
      },
      {
        "paper_id": "ARR_2022_33",
        "title": "KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling",
        "problem_framing": "论文从实际应用需求和痛点出发引出问题。首先介绍了PubMed/MEDLINE数据库的规模和MeSH索引在生物医学文本挖掘中的重要性，强调了人工标注的高成本和效率低下，结合文献引用和统计数据展示了人工索引的不可持续性，进而提出自动化MeSH索引的迫切需求。随后将自动MeSH索引问题形式化为极端多标签文本分类（XMC）问题，进一步突出任务的挑战性，如标签数量巨大、标签分布极不均衡、语义复杂等。",
        "gap_pattern": "论文通过描述现有人工方法的高成本和低效率，批评了当前依赖人工标注的局限性，并指出随着数据规模的增长，现有做法难以为继。此外，通过具体数据（如标签数量、标签分布不均、每篇文章标签数差异大等）强调了现有方法难以应对大规模和复杂语义的挑战。虽然没有详细罗列所有相关工作的缺陷，但通过对任务难点的系统性描述，隐含批评了现有自动化方法在标签规模和语义复杂性上的不足。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先将MeSH索引形式化为多标签分类问题，给出整体建模框架。随后，分模块介绍模型的各个组成部分，包括多通道文档表示、标签特征学习、动态语义掩码注意力模块和分类器，层层递进，突出每个模块在整体架构中的作用。",
        "experiments_story": "实验部分聚焦于主实验，采用多种主流评价指标（Microaverage、example-based、ranking-based）对模型进行系统评估。通过与五种主流方法（包括只用摘要/标题和用全文训练的系统）进行对比，突出自身方法的优势。实验主要包括主实验和不同训练数据（摘要/标题 vs 全文）条件下的对比，强调在主评价指标MiF上的提升。未涉及消融实验或可视化等补充实验，核心在于与现有系统的全面对比验证。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "应用场景举例",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "通过列举科学出版物、医疗记录、法律文本和商品描述等多种实际应用场景，强调多标签文档分类的广泛用途和现实意义。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者直观理解任务的重要性和应用价值"
          }
        ]
      },
      {
        "trick_name": "问题难点细化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "详细分析了类别不平衡和时序概念漂移等实际难点，说明现有方法的局限性和研究空白。",
            "type": "writing-level",
            "purpose": "突出任务挑战性，为后续方法创新铺垫合理性"
          }
        ]
      },
      {
        "trick_name": "引用前沿文献",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "广泛引用近年来的重要文献，说明所关注问题和采用方法均有坚实的学术基础。",
            "type": "writing-level",
            "purpose": "增强说服力，显示对领域前沿的把握和方法的理论基础"
          }
        ]
      },
      {
        "trick_name": "对比分割策略",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "对比随机分割和时间顺序分割，证明后者能更真实地反映模型在实际应用中的表现。",
            "type": "experiment-level",
            "purpose": "突出实验设计的科学性和现实性，强调新分割方式的重要性"
          }
        ]
      },
      {
        "trick_name": "多指标评估",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "同时报告m-RP、micro-F1和macro-F1等多种评价指标，全面衡量模型性能和类别间差异。",
            "type": "experiment-level",
            "purpose": "提升实验完备性和结果可信度，揭示模型在不同维度的表现"
          }
        ]
      },
      {
        "trick_name": "复现与开源承诺",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "承诺开源全部代码，并为审稿人提供内部代码包，方便复现和后续研究。",
            "type": "experiment-level",
            "purpose": "增强实验的可验证性和透明度，提升论文可信度"
          }
        ]
      },
      {
        "trick_name": "方法细节可解释化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "详细描述BERT-LWAN模型每一步的计算流程和直观解释，如每个标签独立注意力头如何关注不同文本片段。",
            "type": "method-level",
            "purpose": "提升可解释性，帮助读者理解模型内部机制"
          }
        ]
      },
      {
        "trick_name": "与SOTA方法对比",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "引用并复现BERT-LWAN等当前最优方法，展示本方法在公开数据集上的性能对比。",
            "type": "experiment-level",
            "purpose": "突出方法有效性和创新性，展示相较于已有方法的优势"
          }
        ]
      },
      {
        "trick_name": "实验设置细致说明",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "详细说明模型配置、训练参数、分组采样策略等实验细节，确保实验过程透明。",
            "type": "experiment-level",
            "purpose": "增强实验的可复现性和科学性"
          }
        ]
      },
      {
        "trick_name": "问题-方法-实验三段式结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_255",
            "title": "Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting",
            "description": "采用先引入问题，再提出方法，最后通过实验验证的经典三段式结构，逻辑清晰、层层递进。",
            "type": "writing-level",
            "purpose": "提升叙事流畅性和逻辑性，帮助读者顺畅理解研究动机、方法与结论"
          }
        ]
      },
      {
        "trick_name": "问题复杂化与场景扩展",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_264",
            "title": "Evaluating Extreme Hierarchical Multi-label Classification",
            "description": "通过逐步引入多标签、层次结构、极端分类等复杂场景，展示评价指标面临的多重挑战，增强问题的说服力和紧迫感",
            "type": "writing-level",
            "purpose": "突出现有评价指标的不足，强调研究问题的重要性和挑战性"
          }
        ]
      },
      {
        "trick_name": "案例驱动引入",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_264",
            "title": "Evaluating Extreme Hierarchical Multi-label Classification",
            "description": "以医疗文档不良事件标注为案例，说明方法的实际应用价值和适用范围",
            "type": "writing-level",
            "purpose": "让方法与实际应用场景紧密关联，提高研究的现实意义"
          }
        ]
      },
      {
        "trick_name": "形式化属性分析",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_264",
            "title": "Evaluating Extreme Hierarchical Multi-label Classification",
            "description": "通过定义一组形式化属性对现有指标进行系统性分析，为后续方法设计和比较奠定理论基础",
            "type": "method-level",
            "purpose": "提升方法的理论深度和可解释性，帮助读者理解评价指标的本质"
          }
        ]
      },
      {
        "trick_name": "信息论与认知理论支撑",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_264",
            "title": "Evaluating Extreme Hierarchical Multi-label Classification",
            "description": "将ICM与信息论和认知科学中的相似性公理关联，突出方法的理论创新和科学依据",
            "type": "method-level",
            "purpose": "增强方法的理论说服力和新颖性"
          }
        ]
      },
      {
        "trick_name": "方法泛化能力强调",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_264",
            "title": "Evaluating Extreme Hierarchical Multi-label Classification",
            "description": "说明ICM可特化到更简单场景（如单标签、平坦结构），且保持形式化属性，突出方法的普适性",
            "type": "method-level",
            "purpose": "展示方法的灵活性和广泛适用性，提升创新性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_255",
        "ARR_2022_264",
        "ARR_2022_33",
        "ACL_2017_384",
        "COLING_2020_16"
      ]
    }
  },
  {
    "pattern_id": 9,
    "pattern_name": "低资源语音自监督学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低资源语音处理问题，采用自监督学习和多模态融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点开篇，通过理论定义引入核心概念，常用tricks包括优势对比论证、创新问题设定和详细基线对比。\n第3段（60字）：适用场景与预期效果 - 适用于低资源语言和多模态语音任务，预期提升模型在小数据集上的性能和泛化能力。",
    "writing_guide": "写作模板：低资源语音自监督学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低资源语音处理问题，采用自监督学习和多模态融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点开篇，通过理论定义引入核心概念，常用tricks包括优势对比论证、创新问题设定和详细基线对比。\n第3段（60字）：适用场景与预期效果 - 适用于低资源语言和多模态语音任务，预期提升模型在小数据集上的性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition》\n  • 问题定位：论文从实际痛点和应用需求出发引入问题。首先指出传统的有监督语音处理系统（如自动语音识别）高度依赖大量文本标注，这在低资源语言中难以实现。接着强调自监督语音表示学习的最新进展为无需完整文本转录的语音处理系统带来了新希望，尤其适用于标注稀缺或不可用的语言。\n  • 现有研究缺口：论文批评现有方法时，主要采用“现有方法忽视了X”以及“现有方法在Y方面存在不足”的逻辑。具体而言，早期无监督语音表示学习方法只关注声学相似性（phones），未考虑语义信息。神经网络方法虽然能学习离散表示，但其生成的码本远大于实际音素数量，导致在标准音素发现指标上表现不佳。\n  • 核心方法：方法部分采用分模块介绍和先整体后局部的叙述策略。首先简要说明整体流程（如预分割阶段、编码器和判别器结构），然后分别详细介绍各模块的实现，包括预分割模型、编码器（CPC模型）、判别器结构、损失函数的具体设计与优化细节。\n  • 实验设计：实验部分采用多数据集验证和主实验+基准对比的策略。首先详细介绍了用于训练和测试的多种数据集，包括英语和低资源语言（Mboshi），并说明数据集构建方式及标注量远低于以往工作。实验类型涵盖主任务（音素发现）、标准基准测试（TIMIT和Mboshi）、以及与四种主流基线方法的系统性对比。\n\n示例 2：《Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features》\n  • 问题定位：论文从学术gap出发引出问题。开篇先回顾了深度学习推动下TTS的巨大进步，列举了多个主流模型和声码器，强调了这些方法在数据充足时表现优异。随后，作者指出跨语言数据利用仍是TTS领域的关键挑战，尤其是大多数语言属于低资源，现有方法难以适用。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在X场景下失效’和‘现有方法需要复杂改动’的逻辑。具体包括：1) 现有跨语言迁移方法需要复杂的结构调整，难以与主流TTS架构结合；2) 直接混合多语言训练虽然可行，但训练过程复杂；3) 以往尝试用发音特征或音系特征，但依赖额外工具或数据，且方法局限。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述策略。首先介绍MAML的总体目标和基本流程（外循环、内循环、参数更新），再补充说明计算复杂度问题及其变体（如一阶MAML）。方法描述逻辑清晰，先给出核心思想，再逐步展开细节和相关改进，便于读者理解整体框架及其适用性。\n  • 实验设计：实验部分采用‘主实验+多数据集+对比验证’的策略。首先在单语言场景下评估发音特征输入的效果，随后在跨语言场景下结合LAML和发音特征进行自动和人工评测。\n\n示例 3：《Cross-modal Contrastive Learning for Speech Translation》\n  • 问题定位：论文首先从实际应用需求出发，强调端到端语音到文本翻译（E2E ST）在产品和真实应用中的重要性。接着对比传统级联模型和E2E模型的性能，指出虽然E2E模型表现接近甚至优于传统方法，但受限于平行数据较少。\n  • 现有研究缺口：论文批评现有方法主要采用以下逻辑：首先，指出现有ST方法大多关注于利用MT和ASR的额外数据，如预训练、多任务训练等，但这些方法主要解决数据稀缺问题。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了端到端语音翻译的输入输出和数据结构，然后介绍模型的四个子模块（语音编码器、词嵌入层、Transformer编码器和解码器），并说明其统一框架可支持ST、MT、ASR多任务。\n  • 实验设计：实验部分采用‘多数据集验证+主实验对比’的策略。首先介绍使用的ST和MT数据集及其规模，确保实验具有代表性。然后详细说明模型配置和实验细节，保证可复现性。主实验包括与现有端到端ST模型的对比，分为不使用和使用外部MT数据两种设置，突出方法的普适性和优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 消融实验（使用频率 2 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过逐步移除或替换系统组件，展示不同部分对整体性能的影响，证明各模块的有效性。\n\n2. 问题驱动开篇（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者首先强调了自监督语音表示学习的最新进展，并指出传统方法依赖大量标注，强调在低资源语言中的困难，明确提出亟需无需文本转录的语音处理系统。\n\n3. 理论定义引入（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者引用标准语言学定义（Swadesh, 1934）对音素进行解释，阐明音素与词语的关系，为后续方法选择音素作为离散表示做理论铺垫。\n\n4. 优势对比论证（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：通过与词语表示的对比，论证音素在样本复杂度、分布均衡性和泛化能力上的优势，层层递进地说服读者。\n\n5. 创新问题设定（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：将音素库学习问题重新表述为自监督学习问题，并引入少量语义监督，区别于完全无监督或全监督的传统方法。\n\n6. 多数据集覆盖（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：实验覆盖多个英语和低资源语言数据集，包括标准基准和自建词语数据集，确保方法在不同场景下的有效性。\n\n7. 详细基线对比（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：与多种连续和离散表示的基线方法进行系统对比，包括CPC+k-means、Gumbel VIB、DIB等，且所有模型共享同一编码器，确保公平性。\n\n8. 低资源场景强调（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：多次强调方法在低资源语言和极低标注条件下的表现，说明所需标注远低于前人工作，突出应用潜力。\n\n9. 方法细节透明化（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：详细说明模型架构、训练参数、优化策略和离散化细节，引用相关文献并给出具体数值，便于读者理解和复现。\n\n10. 标准评价指标使用（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：采用标准评价指标（如NMI）对模型进行评估，确保实验结果具有权威性和可比性。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_8",
        "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
        "problem_framing": "论文从实际痛点和应用需求出发引入问题。首先指出传统的有监督语音处理系统（如自动语音识别）高度依赖大量文本标注，这在低资源语言中难以实现。接着强调自监督语音表示学习的最新进展为无需完整文本转录的语音处理系统带来了新希望，尤其适用于标注稀缺或不可用的语言。作者进一步提出，理想的离散语音表示应能桥接连续声学信号与更高层次的语言结构（如句法和语义），以便将书面语言的算法迁移到口头语言任务，如语音翻译和口语理解。最后，通过对比词和音素的学习难度，强调音素作为离散语音表示的优势，并据此提出带有少量语义监督的自监督音素库学习问题。",
        "gap_pattern": "论文批评现有方法时，主要采用“现有方法忽视了X”以及“现有方法在Y方面存在不足”的逻辑。具体而言，早期无监督语音表示学习方法只关注声学相似性（phones），未考虑语义信息。神经网络方法虽然能学习离散表示，但其生成的码本远大于实际音素数量，导致在标准音素发现指标上表现不佳。此外，部分方法依赖弱监督（如多语言ASR预测的嘈杂标签），但未能充分解决语义驱动的音素学习问题。整体批评策略是指出现有方法在离散语义驱动表示和码本紧凑性上的不足。",
        "method_story": "方法部分采用分模块介绍和先整体后局部的叙述策略。首先简要说明整体流程（如预分割阶段、编码器和判别器结构），然后分别详细介绍各模块的实现，包括预分割模型、编码器（CPC模型）、判别器结构、损失函数的具体设计与优化细节。方法描述中还穿插对相关模型的微调和参数设置，最后说明与其他方法的离散单元提取方式保持一致以便公平对比。",
        "experiments_story": "实验部分采用多数据集验证和主实验+基准对比的策略。首先详细介绍了用于训练和测试的多种数据集，包括英语和低资源语言（Mboshi），并说明数据集构建方式及标注量远低于以往工作。实验类型涵盖主任务（音素发现）、标准基准测试（TIMIT和Mboshi）、以及与四种主流基线方法的系统性对比。实验描述突出数据集多样性、低标注需求和与现有方法的直接对比，体现方法的广泛适用性和有效性。"
      },
      {
        "paper_id": "ARR_2022_238",
        "title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features",
        "problem_framing": "论文从学术gap出发引出问题。开篇先回顾了深度学习推动下TTS的巨大进步，列举了多个主流模型和声码器，强调了这些方法在数据充足时表现优异。随后，作者指出跨语言数据利用仍是TTS领域的关键挑战，尤其是大多数语言属于低资源，现有方法难以适用。通过对比高资源与低资源语言的现状，明确提出了低资源TTS的现实痛点和研究空白。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在X场景下失效’和‘现有方法需要复杂改动’的逻辑。具体包括：1) 现有跨语言迁移方法需要复杂的结构调整，难以与主流TTS架构结合；2) 直接混合多语言训练虽然可行，但训练过程复杂；3) 以往尝试用发音特征或音系特征，但依赖额外工具或数据，且方法局限。通过逐条分析，突出当前方法在低资源、跨语言场景下的不足和局限性。",
        "method_story": "方法部分采用‘先整体后细节’的叙述策略。首先介绍MAML的总体目标和基本流程（外循环、内循环、参数更新），再补充说明计算复杂度问题及其变体（如一阶MAML）。方法描述逻辑清晰，先给出核心思想，再逐步展开细节和相关改进，便于读者理解整体框架及其适用性。",
        "experiments_story": "实验部分采用‘主实验+多数据集+对比验证’的策略。首先在单语言场景下评估发音特征输入的效果，随后在跨语言场景下结合LAML和发音特征进行自动和人工评测。实验涉及多语言多数据集，设置了强基线（大数据训练）、迁移学习基线（多语言预训练+小数据微调）、消融实验（embedding lookup-table vs. articulatory features），以及进一步的微调实验。通过多角度、多对比，系统验证了所提方法的有效性和必要性。"
      },
      {
        "paper_id": "ARR_2022_168",
        "title": "Cross-modal Contrastive Learning for Speech Translation",
        "problem_framing": "论文首先从实际应用需求出发，强调端到端语音到文本翻译（E2E ST）在产品和真实应用中的重要性。接着对比传统级联模型和E2E模型的性能，指出虽然E2E模型表现接近甚至优于传统方法，但受限于平行数据较少。随后，论文进一步从学术gap出发，指出现有研究主要关注数据层面的改进，而忽视了神经表示层面的瓶颈，提出研究音频输入的合适表示对于有效语音翻译至关重要，并借用神经科学研究引出“统一表示”的假设，最终自然过渡到本文的研究主题。",
        "gap_pattern": "论文批评现有方法主要采用以下逻辑：首先，指出现有ST方法大多关注于利用MT和ASR的额外数据，如预训练、多任务训练等，但这些方法主要解决数据稀缺问题。其次，强调现有方法忽视了‘模态间表示差异’（modality gap）这一核心问题，且即使有相关工作（如引入语义记忆模块），仍未从根本上解决表示对齐问题。批评常用句式包括‘现有方法主要关注于...’，‘然而，我们发现...’，‘现有方法未能...’等，突出本文关注的神经表示视角的独特性。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了端到端语音翻译的输入输出和数据结构，然后介绍模型的四个子模块（语音编码器、词嵌入层、Transformer编码器和解码器），并说明其统一框架可支持ST、MT、ASR多任务。随后详细介绍各模块功能和结构，最后说明训练损失的组成，包括主任务损失和创新的跨模态对比损失，逐步引出方法创新点。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验对比’的策略。首先介绍使用的ST和MT数据集及其规模，确保实验具有代表性。然后详细说明模型配置和实验细节，保证可复现性。主实验包括与现有端到端ST模型的对比，分为不使用和使用外部MT数据两种设置，突出方法的普适性和优势。此外，还报告了多种评测指标（BLEU, ChrF++, TER），并在附录中补充消融实验和超参数选择等分析，增强实验的全面性和说服力。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "消融实验",
        "frequency": 2,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_278",
            "title": "Cross-Utterance Conditioned VAE for Non-Autoregressive Text-to-Speech",
            "description": "通过逐步移除或替换系统组件，展示不同部分对整体性能的影响，证明各模块的有效性。",
            "type": "experiment-level",
            "purpose": "验证各模块贡献，提升方法可解释性和说服力"
          },
          {
            "paper_id": "ARR_2022_348",
            "title": "Leveraging Uni-Modal Self-Supervised Learning for Multimodal Audio-visual Speech Recognition",
            "description": "通过ablation study分解各模块的作用，定量展示每一部分对整体性能的影响",
            "type": "experiment-level",
            "purpose": "分析各组成部分的贡献，增强结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "问题驱动开篇",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "作者首先强调了自监督语音表示学习的最新进展，并指出传统方法依赖大量标注，强调在低资源语言中的困难，明确提出亟需无需文本转录的语音处理系统。",
            "type": "writing-level",
            "purpose": "引导读者关注领域内的核心挑战，突出研究意义"
          }
        ]
      },
      {
        "trick_name": "理论定义引入",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "作者引用标准语言学定义（Swadesh, 1934）对音素进行解释，阐明音素与词语的关系，为后续方法选择音素作为离散表示做理论铺垫。",
            "type": "writing-level",
            "purpose": "增强方法的可解释性和理论基础，帮助读者理解核心概念"
          }
        ]
      },
      {
        "trick_name": "优势对比论证",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "通过与词语表示的对比，论证音素在样本复杂度、分布均衡性和泛化能力上的优势，层层递进地说服读者。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者相信音素作为表示的合理性和优越性"
          }
        ]
      },
      {
        "trick_name": "创新问题设定",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "将音素库学习问题重新表述为自监督学习问题，并引入少量语义监督，区别于完全无监督或全监督的传统方法。",
            "type": "method-level",
            "purpose": "突出工作的新颖性，展示与传统方法的区别"
          }
        ]
      },
      {
        "trick_name": "多数据集覆盖",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "实验覆盖多个英语和低资源语言数据集，包括标准基准和自建词语数据集，确保方法在不同场景下的有效性。",
            "type": "experiment-level",
            "purpose": "证明方法的完备性和广泛适用性，增强结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "详细基线对比",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "与多种连续和离散表示的基线方法进行系统对比，包括CPC+k-means、Gumbel VIB、DIB等，且所有模型共享同一编码器，确保公平性。",
            "type": "experiment-level",
            "purpose": "突出方法的有效性和创新性，通过与多种现有方法对比增强说服力"
          }
        ]
      },
      {
        "trick_name": "低资源场景强调",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "多次强调方法在低资源语言和极低标注条件下的表现，说明所需标注远低于前人工作，突出应用潜力。",
            "type": "writing-level",
            "purpose": "突出方法的实际价值和应用前景，提升说服力"
          }
        ]
      },
      {
        "trick_name": "方法细节透明化",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "详细说明模型架构、训练参数、优化策略和离散化细节，引用相关文献并给出具体数值，便于读者理解和复现。",
            "type": "method-level",
            "purpose": "提升可解释性和复现性，让读者清楚方法实现细节"
          }
        ]
      },
      {
        "trick_name": "标准评价指标使用",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "采用标准评价指标（如NMI）对模型进行评估，确保实验结果具有权威性和可比性。",
            "type": "experiment-level",
            "purpose": "提升实验的科学性和结果的可比性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进结构",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "从问题提出、理论基础、方法设计到实验验证，层层递进，逻辑清晰，便于读者跟随作者思路。",
            "type": "writing-level",
            "purpose": "提升叙事流畅性，引导读者逐步理解问题、方法和实验设计"
          }
        ]
      },
      {
        "trick_name": "文献引用支撑",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_8",
            "title": "Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition",
            "description": "大量引用领域内权威文献，支撑方法选择、理论依据和实验基线，增强可信度。",
            "type": "writing-level",
            "purpose": "增强论述的权威性和学术背景，提升说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_238",
            "title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features",
            "description": "在引言部分大量引用经典和最新的TTS及相关方法文献，展示对领域现状的全面了解，增强说服力。",
            "type": "writing-level",
            "purpose": "通过引用领域内权威文献，增强研究背景的权威性和可信度"
          }
        ]
      },
      {
        "trick_name": "突出未解决的关键挑战",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_238",
            "title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features",
            "description": "强调跨语言TTS数据利用仍是关键挑战，现有方法在低资源语言上受限，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "明确指出现有方法的不足，引出本文工作的必要性和创新点"
          }
        ]
      },
      {
        "trick_name": "创新点前置与明确列举",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_238",
            "title": "Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features",
            "description": "在引言末尾明确列出两大创新点：1) 语言学驱动的输入表示，2) 首次将MAML应用于低资源TTS。",
            "type": "writing-level",
            "purpose": "让读者一开始就清楚本工作的创新点，突出新颖性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 10,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_8",
        "ARR_2022_238",
        "ARR_2022_168",
        "ARR_2022_189",
        "ARR_2022_278",
        "ARR_2022_348",
        "ARR_2022_359",
        "ARR_2022_17",
        "ACL_2017_484",
        "COLING_2020_80"
      ]
    }
  },
  {
    "pattern_id": 10,
    "pattern_name": "无监督预训练对比学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决稠密检索和句子表示学习中的数据依赖和泛化问题，采用无监督预训练和对比学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过权威基准对比指出现有方法不足，方法部分采用整体框架+模块细节，实验设计多数据集验证+消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于低资源和跨领域场景的检索和表示学习任务，预期提升模型泛化能力和效率。",
    "writing_guide": "写作模板：无监督预训练对比学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决稠密检索和句子表示学习中的数据依赖和泛化问题，采用无监督预训练和对比学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过权威基准对比指出现有方法不足，方法部分采用整体框架+模块细节，实验设计多数据集验证+消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于低资源和跨领域场景的检索和表示学习任务，预期提升模型泛化能力和效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval》\n  • 问题定位：论文开篇从实际痛点和应用需求出发，首先介绍了 dense retrieval 在效率上的优势（可毫秒级运行），但随即指出其对大规模有标注数据的依赖以及在跨领域（out-of-domain, OOD）场景下性能下降的问题。\n  • 现有研究缺口：论文批评现有方法时，采用了多层逻辑：首先指出现有 dense retrieval 方法（如 cross-encoder、late-interaction、DPR、RocketQA 等）虽然在部分数据集上有效，但在 BEIR 基准测试中暴露出主要缺点——无法很好地泛化到域外数据（out-of-d...\n  • 核心方法：方法部分采用先整体后局部的叙述顺序。首先整体介绍 LaPraDoR 的设计理念——无监督预训练、兼顾语义与词法匹配。随后，聚焦于训练效率的关键挑战，详细阐述提出的 Iterative Contrastive Learning (ICoL) 机制，包括缓存机制、权重共享、模型结构选择等细节。\n  • 实验设计：实验部分采用多数据集、多设置验证的策略。首先在 BEIR 基准上进行主实验，覆盖18个异构数据集，强调模型的跨领域泛化能力。实验指标采用标准的 NDCG@10。其次，详细介绍模型设置与训练细节，包括预训练和微调流程。再次，进行消融实验（如模型层数、权重共享等），分析设计选择的影响。\n\n示例 2：《MCSE: Multimodal Contrastive Learning of Sentence Embeddings》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先强调句子表征学习在NLP中的基础地位，随后指出尽管预训练语言模型（如BERT）取得了巨大成功，但其未经微调的句子表征在语义相似度任务上甚至不如简单的Glove词向量平均。\n  • 现有研究缺口：论文批评现有方法的逻辑为：1）指出PLM未微调时效果不佳，甚至不如简单方法（如Glove平均）；2）现有无监督方法虽有进展，但纯文本模型难以捕捉超越文本分布的深层语义（即缺乏现实世界语义锚定）；3）引用相关文献，强调文本模型在语义理解上的局限性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先简要介绍采用SimCSE作为文本基线，然后说明其扩展为多模态对比学习目标。具体地，先描述整体框架如何结合视觉和文本信息，再分别介绍文本对比目标和多模态对比目标，突出方法的创新点和与现有工作的区别。\n  • 实验设计：实验部分采用‘多数据集验证+消融分析+机制解释’的叙述策略。首先在标准STS基准上进行主实验，比较不同模型（如BERT、RoBERTa、SimCSE、MCSE）的表现。其次，通过消融实验（如仅用多模态数据、打乱图像配对、替换图像编码器）分析各模块和设计的有效性。\n\n示例 3：《Efficient Cluster-based k-Nearest-Neighbor Machine Translation》\n  • 问题定位：论文通过结合实际应用痛点和学术研究空白来引出问题。开篇先介绍了非参数方法在神经机器翻译领域的成功应用，强调其在领域自适应中的优势，随后指出尽管这些方法在翻译质量上有显著提升，但对其核心组件——datastore的行为分析尚未充分展开，特别是在检索延迟和语义分布两个方面存在不足。\n  • 现有研究缺口：论文对现有方法的批评采用了‘现有方法在实际场景下存在不足’和‘现有方法忽视了关键行为分析’的逻辑。具体通过实验数据和可视化分析指出传统datastore构建方式在检索延迟和语义分布上不理想，导致实际应用中效率低下和语义噪声，影响检索效果。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了方法的核心思想——通过聚类信号进行特征压缩和规模剪枝以重构datastore。随后细致分模块介绍了四种具体剪枝策略（距离剪枝、低概率剪枝、高概率剪枝、随机剪枝），并对每种策略的设计动机和实际效果进行阐述。\n  • 实验设计：实验部分采用‘多数据集验证+剪枝率消融+大规模实验’的策略。首先在多个领域（如IT、Koran等）进行主实验，比较不同剪枝策略的性能。其次在大规模数据集（Subtitles）上测试剪枝方法的极限表现，分析剪枝率变化对性能的影响，属于消融实验。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 8 次，占比 40.0%）\n   类型：writing-level\n   应用：先提出问题和挑战，再介绍方法创新，最后通过实验验证，层层递进，呼应开篇问题。\n\n2. 逻辑递进的叙事结构（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：先引入问题和动机，再提出方法，最后通过系统实验和分析呼应前述假设和创新点，形成闭环。\n\n3. 现有方法不足对比（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：详细分析了稠密检索和查询增强等现有方法的局限，如标注数据稀缺、生成成本高、无法处理未标注文档等。\n\n4. 引用权威工作（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：作者在引言中广泛引用了领域内的权威工作，展示该领域已有的成果和不足，强化自身工作的合理性和必要性\n\n5. 图示辅助理解（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：作者在引言和方法部分分别用图1和图2展示事件关系和方法整体框架，降低理解门槛\n\n6. 引用权威文献建立背景（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：通过大量引用相关领域的权威文献，展示该问题的研究基础和前人工作。\n\n7. 对比实验设计（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：实验部分通过与多种主流方法在实体聚类和主题建模任务上的对比，展示了新方法的性能提升。\n\n8. 消融实验（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：通过SR w/o QU、SR w/o PE等消融实验，分析各组件对整体性能的影响。\n\n9. 多数据集验证（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：在WebQSP和CWQ两个主流数据集上进行实验，证明方法的通用性和稳健性。\n\n10. 问题驱动开篇（使用频率 1 次，占比 5.0%）\n   类型：writing-level\n   应用：作者首先指出现有Dense Retrieval方法在跨域泛化和低资源场景下的局限性，突出实际应用难题，吸引读者关注。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_7",
        "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
        "problem_framing": "论文开篇从实际痛点和应用需求出发，首先介绍了 dense retrieval 在效率上的优势（可毫秒级运行），但随即指出其对大规模有标注数据的依赖以及在跨领域（out-of-domain, OOD）场景下性能下降的问题。这些问题不仅限制了 dense retrieval 的实际应用，尤其是在低资源语言和领域，还导致构建高质量训练数据变得昂贵且困难。通过引用 BEIR 基准测试，进一步强调了检索系统的泛化能力需求，最终引出本文提出的无监督预训练检索器 LaPraDoR，旨在解决上述痛点。",
        "gap_pattern": "论文批评现有方法时，采用了多层逻辑：首先指出现有 dense retrieval 方法（如 cross-encoder、late-interaction、DPR、RocketQA 等）虽然在部分数据集上有效，但在 BEIR 基准测试中暴露出主要缺点——无法很好地泛化到域外数据（out-of-domain）。其次，强调这些方法高度依赖大规模有监督数据，且在低资源场景下难以应用。批评逻辑常用“现有方法在X场景下失效”、“现有方法忽视了Y需求”、“现有方法需要昂贵的数据”等句式，并通过引用相关工作和基准测试结果加以论证。",
        "method_story": "方法部分采用先整体后局部的叙述顺序。首先整体介绍 LaPraDoR 的设计理念——无监督预训练、兼顾语义与词法匹配。随后，聚焦于训练效率的关键挑战，详细阐述提出的 Iterative Contrastive Learning (ICoL) 机制，包括缓存机制、权重共享、模型结构选择等细节。方法描述中穿插与现有方案（如 MoCo、xMoCo）的对比，突出自身创新点。整体结构为：总体框架 → 关键技术难点 → 具体模块与实现细节。",
        "experiments_story": "实验部分采用多数据集、多设置验证的策略。首先在 BEIR 基准上进行主实验，覆盖18个异构数据集，强调模型的跨领域泛化能力。实验指标采用标准的 NDCG@10。其次，详细介绍模型设置与训练细节，包括预训练和微调流程。再次，进行消融实验（如模型层数、权重共享等），分析设计选择的影响。最后，设置多种对比基线（dense retrieval、BM25等），并在不同训练数据（C4、Wikipedia）下测试，确保实验结果的全面性和说服力。"
      },
      {
        "paper_id": "ARR_2022_154",
        "title": "MCSE: Multimodal Contrastive Learning of Sentence Embeddings",
        "problem_framing": "论文从学术gap出发引出问题。开篇首先强调句子表征学习在NLP中的基础地位，随后指出尽管预训练语言模型（如BERT）取得了巨大成功，但其未经微调的句子表征在语义相似度任务上甚至不如简单的Glove词向量平均。接着，作者进一步指出，现有方法主要关注于无监督地调整PLM的句子表征，但纯文本模型在捕捉深层语义上仍有不足，特别是缺乏对现实世界的语义锚定。最后，作者提出视觉信息作为补充语义来源的假设，顺势引出自己的多模态对比学习方法。",
        "gap_pattern": "论文批评现有方法的逻辑为：1）指出PLM未微调时效果不佳，甚至不如简单方法（如Glove平均）；2）现有无监督方法虽有进展，但纯文本模型难以捕捉超越文本分布的深层语义（即缺乏现实世界语义锚定）；3）引用相关文献，强调文本模型在语义理解上的局限性。句式上多用‘尽管...但...’‘然而...仍然...’‘现有方法主要关注...但...’等对比和转折结构。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先简要介绍采用SimCSE作为文本基线，然后说明其扩展为多模态对比学习目标。具体地，先描述整体框架如何结合视觉和文本信息，再分别介绍文本对比目标和多模态对比目标，突出方法的创新点和与现有工作的区别。",
        "experiments_story": "实验部分采用‘多数据集验证+消融分析+机制解释’的叙述策略。首先在标准STS基准上进行主实验，比较不同模型（如BERT、RoBERTa、SimCSE、MCSE）的表现。其次，通过消融实验（如仅用多模态数据、打乱图像配对、替换图像编码器）分析各模块和设计的有效性。最后，通过alignment和uniformity等可解释性指标分析模型表征空间的性质，进一步支持方法有效性。"
      },
      {
        "paper_id": "ARR_2022_143",
        "title": "Efficient Cluster-based k-Nearest-Neighbor Machine Translation",
        "problem_framing": "论文通过结合实际应用痛点和学术研究空白来引出问题。开篇先介绍了非参数方法在神经机器翻译领域的成功应用，强调其在领域自适应中的优势，随后指出尽管这些方法在翻译质量上有显著提升，但对其核心组件——datastore的行为分析尚未充分展开，特别是在检索延迟和语义分布两个方面存在不足。这种策略既体现了实际需求（如实时性和检索效率），也突出了学术研究的未覆盖点，形成问题驱动的叙事开端。",
        "gap_pattern": "论文对现有方法的批评采用了‘现有方法在实际场景下存在不足’和‘现有方法忽视了关键行为分析’的逻辑。具体通过实验数据和可视化分析指出传统datastore构建方式在检索延迟和语义分布上不理想，导致实际应用中效率低下和语义噪声，影响检索效果。同时引用相关文献，强调特征维度与速度的关系，进一步说明现有方法未能优化这些关键点。整体采用‘现有方法虽有效但未解决X/Y问题’的批评句式。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了方法的核心思想——通过聚类信号进行特征压缩和规模剪枝以重构datastore。随后细致分模块介绍了四种具体剪枝策略（距离剪枝、低概率剪枝、高概率剪枝、随机剪枝），并对每种策略的设计动机和实际效果进行阐述。最后通过实验结果对比，突出聚类剪枝方法的稳定性和有效性，形成由方法设计到效果验证的完整链条。",
        "experiments_story": "实验部分采用‘多数据集验证+剪枝率消融+大规模实验’的策略。首先在多个领域（如IT、Koran等）进行主实验，比较不同剪枝策略的性能。其次在大规模数据集（Subtitles）上测试剪枝方法的极限表现，分析剪枝率变化对性能的影响，属于消融实验。实验还包括速度评估，验证方法在保持BLEU分数的同时能显著降低计算延迟。整体叙述顺序为：主实验比较、消融实验、极限场景测试、效率评估，形成多角度、系统性的实验验证框架。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 8,
        "percentage": "40.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "先提出问题和挑战，再介绍方法创新，最后通过实验验证，层层递进，呼应开篇问题。",
            "type": "writing-level",
            "purpose": "提升论文可读性和逻辑性，帮助读者跟随研究思路"
          },
          {
            "paper_id": "ARR_2022_291",
            "title": "Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation",
            "description": "从问题引入、现有方法不足、创新方法提出、原理解释到实验验证，层层递进，呼应前后。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题、方法和结论，提升论文整体可读性"
          },
          {
            "paper_id": "ARR_2022_202",
            "title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering",
            "description": "作者先介绍问题和挑战，再提出方法，最后用实验验证，形成完整的论证闭环",
            "type": "writing-level",
            "purpose": "提升整体可读性和说服力，通过清晰的逻辑流引导读者理解问题和方法"
          }
        ]
      },
      {
        "trick_name": "逻辑递进的叙事结构",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_154",
            "title": "MCSE: Multimodal Contrastive Learning of Sentence Embeddings",
            "description": "先引入问题和动机，再提出方法，最后通过系统实验和分析呼应前述假设和创新点，形成闭环。",
            "type": "writing-level",
            "purpose": "提升整体可读性和说服力，帮助读者顺畅理解研究流程"
          },
          {
            "paper_id": "ARR_2022_219",
            "title": "A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings",
            "description": "先介绍背景和挑战，再提出方法，最后通过充分实验验证，形成完整闭环。",
            "type": "writing-level",
            "purpose": "通过清晰的逻辑结构引导读者理解问题、方法和结论"
          }
        ]
      },
      {
        "trick_name": "现有方法不足对比",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_291",
            "title": "Augmenting Document Representations for Dense Retrieval with Interpolation and Perturbation",
            "description": "详细分析了稠密检索和查询增强等现有方法的局限，如标注数据稀缺、生成成本高、无法处理未标注文档等。",
            "type": "writing-level",
            "purpose": "突出当前主流方法的缺陷，为新方法的提出制造需求"
          },
          {
            "paper_id": "ARR_2022_84",
            "title": "Debiased Contrastive Learning of Unsupervised Sentence Representations",
            "description": "详细分析了PLM句子表示的各向异性和随机负采样带来的采样偏差，指出这些问题限制了表示学习的效果。",
            "type": "writing-level",
            "purpose": "凸显现有方法的局限性，为新方法的提出做铺垫"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_202",
            "title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering",
            "description": "作者在引言中广泛引用了领域内的权威工作，展示该领域已有的成果和不足，强化自身工作的合理性和必要性",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用大量相关文献证明问题的重要性和方法的有效性"
          },
          {
            "paper_id": "ARR_2022_163",
            "title": "Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval",
            "description": "通过大量引用领域内权威论文（如BERT、BM25、DPR等），展示方法建立在已有研究基础上，增强说服力。",
            "type": "writing-level",
            "purpose": "增强方法的可信度和学术背景"
          }
        ]
      },
      {
        "trick_name": "图示辅助理解",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_202",
            "title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering",
            "description": "作者在引言和方法部分分别用图1和图2展示事件关系和方法整体框架，降低理解门槛",
            "type": "writing-level",
            "purpose": "提升可解释性，通过图示帮助读者直观理解事件关系和方法框架"
          },
          {
            "paper_id": "ARR_2022_163",
            "title": "Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval",
            "description": "通过引用图示（如Figure 1）帮助读者直观理解问题本质和方法原理。",
            "type": "writing-level",
            "purpose": "提升方法的可解释性和易读性"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_141",
            "title": "Multi-Vector Models with Textual Guidance for Fine-Grained Scientific Document Similarity",
            "description": "通过大量引用相关领域的权威文献，展示该问题的研究基础和前人工作。",
            "type": "writing-level",
            "purpose": "提升说服力和可信度，证明问题受到广泛关注"
          },
          {
            "paper_id": "ARR_2022_219",
            "title": "A Sentence is Worth 128 Pseudo Tokens: A Semantic-Aware Contrastive Learning Framework for Sentence Embeddings",
            "description": "在引言中引用多个经典和最新工作，展示句子表示和对比学习的研究基础，增强说服力。",
            "type": "writing-level",
            "purpose": "通过引用大量权威文献增强方法的可信度和领域相关性"
          }
        ]
      },
      {
        "trick_name": "对比实验设计",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_56",
            "title": "UCTopic: Unsupervised Contrastive Learning for Phrase Representations and Topic Mining",
            "description": "实验部分通过与多种主流方法在实体聚类和主题建模任务上的对比，展示了新方法的性能提升。",
            "type": "experiment-level",
            "purpose": "证明方法的有效性和优越性"
          },
          {
            "paper_id": "ARR_2022_163",
            "title": "Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval",
            "description": "通过与主流方法DPR在多个数据集上的对比实验，展示新方法的显著性能提升。",
            "type": "experiment-level",
            "purpose": "证明新方法优于现有方法，增强说服力"
          }
        ]
      },
      {
        "trick_name": "消融实验",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_251",
            "title": "Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering",
            "description": "通过SR w/o QU、SR w/o PE等消融实验，分析各组件对整体性能的影响。",
            "type": "experiment-level",
            "purpose": "提升可解释性和完备性，分析各模块贡献"
          },
          {
            "paper_id": "ARR_2022_294",
            "title": "PROMPT WAYWARDNESS: The Curious Case of Discretized Interpretation of Continuous Prompts",
            "description": "通过调整γ参数和分析不同投射目标，展示方法在不同设置下的表现和结论的稳健性。",
            "type": "experiment-level",
            "purpose": "验证方法的鲁棒性和参数影响"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 2,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_251",
            "title": "Subgraph Retrieval Enhanced Model for Multi-hop Knowledge Base Question Answering",
            "description": "在WebQSP和CWQ两个主流数据集上进行实验，证明方法的通用性和稳健性。",
            "type": "experiment-level",
            "purpose": "增强完备性和结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_163",
            "title": "Sentence-aware Contrastive Learning for Open-Domain Passage Retrieval",
            "description": "在受影响严重和不严重的数据集上均进行实验，展示方法在不同场景下的有效性。",
            "type": "experiment-level",
            "purpose": "证明方法的通用性和鲁棒性"
          }
        ]
      },
      {
        "trick_name": "问题驱动开篇",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "作者首先指出现有Dense Retrieval方法在跨域泛化和低资源场景下的局限性，突出实际应用难题，吸引读者关注。",
            "type": "writing-level",
            "purpose": "引导读者关注领域痛点，强调研究意义"
          }
        ]
      },
      {
        "trick_name": "引用权威基准与数据集",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "多次引用BEIR、MS-MARCO等权威数据集和基准，强调方法在这些标准上的有效性和竞争力。",
            "type": "writing-level",
            "purpose": "增强说服力和可信度，展示方法在主流标准下的表现"
          }
        ]
      },
      {
        "trick_name": "突出零样本能力",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "强调LaPraDoR在完全无监督（zero-shot）条件下超越现有有监督方法，突出创新点。",
            "type": "method-level",
            "purpose": "展示新颖性和实际价值，强调无需监督数据即可取得优异效果"
          }
        ]
      },
      {
        "trick_name": "与主流方法对比",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "系统性地与BM25、DPR、ANCE、TASB、ColBERT等主流方法进行性能和效率对比，展示自身优势。",
            "type": "experiment-level",
            "purpose": "证明方法优越性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "速度与效率强调",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "不仅展示准确率，还强调LaPraDoR在GPU和CPU上的推理速度远超重排序方法，突出实用性。",
            "type": "experiment-level",
            "purpose": "提升方法实际应用吸引力，补充性能优势"
          }
        ]
      },
      {
        "trick_name": "方法原理简化与可解释性设计",
        "frequency": 1,
        "percentage": "5.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_7",
            "title": "LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval",
            "description": "通过权重共享、缓存机制等设计，简化模型结构并解释其带来的参数减少和多任务适应能力。",
            "type": "method-level",
            "purpose": "降低理解门槛，提升可解释性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 20,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_7",
        "ARR_2022_154",
        "ARR_2022_143",
        "ARR_2022_345",
        "ARR_2022_291",
        "ARR_2022_202",
        "ARR_2022_285",
        "ARR_2022_240",
        "ARR_2022_141",
        "ARR_2022_56",
        "ARR_2022_251",
        "ARR_2022_294",
        "ARR_2022_101",
        "ARR_2022_219",
        "ARR_2022_151",
        "ARR_2022_163",
        "ARR_2022_185",
        "ARR_2022_22",
        "ARR_2022_84",
        "COLING_2020_68"
      ]
    }
  },
  {
    "pattern_id": 11,
    "pattern_name": "模型压缩与知识蒸馏",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型压缩与知识蒸馏中的问题，采用元学习和双层优化框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以现实类比和引用权威文献增强说服力，方法命名突出创新性，实验设计全面对比多种基线。\n第3段（60字）：适用场景与预期效果 - 适用于NLP和CV领域，需要模型压缩和知识蒸馏的场景，预期提升模型效率和性能。",
    "writing_guide": "写作模板：模型压缩与知识蒸馏\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型压缩与知识蒸馏中的问题，采用元学习和双层优化框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以现实类比和引用权威文献增强说服力，方法命名突出创新性，实验设计全面对比多种基线。\n第3段（60字）：适用场景与预期效果 - 适用于NLP和CV领域，需要模型压缩和知识蒸馏的场景，预期提升模型效率和性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《BERT Learns to Teach: Knowledge Distillation with Meta Learning》\n  • 问题定位：论文通过实际应用需求和学术痛点双重策略引出问题。首先指出随着大规模神经网络的普及，模型压缩对于高效、环保的机器学习部署变得重要，强调了知识蒸馏作为主流压缩技术的有效性。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y方面存在不足’的逻辑。具体地，指出传统知识蒸馏中教师模型对学生模型的能力和学习进度不敏感，且教师模型仅优化自身表现而非知识迁移能力。通过类比现实教育场景（如博士生与教授的区别），进一步强调教师模型缺乏“教学技能”。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了MetaDistil框架的核心思想，即利用元学习动态调整教师模型以适应学生模型的学习进度。随后，进一步细化，提出了基于双层优化的元学习机制，并创新性地引入了‘pilot update’机制以协同教师和学生的学习过程。\n  • 实验设计：实验部分采用‘多数据集验证+主流对比+公平性控制’的策略。首先在自然语言处理和计算机视觉两个主流领域的多个分类基准数据集上进行验证，涵盖GLUE等多个细分任务。\n\n示例 2：《Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation》\n  • 问题定位：论文首先从自然语言处理领域Transformer模型的成功应用切入，强调预训练-微调范式已成为主流，并以BERT等模型为例，指出其广泛应用。接着，作者指出这些模型在需要领域知识的任务（如生物医学、金融）中存在局限，因为它们主要基于通用语料进行预训练。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和举例的策略。首先指出现有主流做法（领域额外预训练）虽能提升领域任务表现，但存在明显缺陷：需要大量训练数据和算力资源、训练时间长、每有新模型出现需重新执行等。具体通过BioBERT需23天8卡训练的例子，突出成本高昂。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序。首先简要回顾了Transformer及主流PLM（BERT、ALBERT、RoBERTa）的架构和发展，铺垫领域背景。随后，聚焦介绍DoKTra框架，作为主方法。方法介绍强调其与传统领域适应方法的不同，突出其高效性和创新性。\n  • 实验设计：实验部分采用‘主实验+多模型/多任务验证’的策略。首先说明实验设置，包括教师模型（BioBERT）和两种学生模型（ALBERT-xlarge、RoBERTa-large），并详细描述了参数设置和调优过程。实验在五个生物医学和临床分类任务上进行，采用F1分数作为指标。\n\n示例 3：《RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation》\n  • 问题定位：论文首先从应用需求出发，指出虽然预训练语言模型（如BERT、RoBERTa、XLNet）在自然语言理解任务上表现优异，但其在实际应用（如边缘设备）中部署存在模型体积大、推理时间长等挑战。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下存在不足’的句式。例如，指出已有的中间层蒸馏方法多采用固定的层映射，忽视了层选择对性能的影响，导致难以找到最优的层匹配方案（即layer skip and search问题）。\n  • 核心方法：方法部分未给出详细内容，但从相关工作和实验部分可推测，方法叙述策略为‘先整体后局部’，即先介绍知识蒸馏及中间层蒸馏的基本框架和常见做法，然后聚焦于层选择问题，逐步引出并细化本文提出的新方法（如RAIL-KD），并与现有方法进行对比。可能还会分模块介绍方法的不同组成部分或创新点。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+对比实验’的策略。首先在GLUE基准的8个任务上进行主实验，涵盖分类和回归任务，验证方法的普适性。其次，为检验方法的泛化能力，还在跨领域（OOD）数据集上进行测试。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 2 次，占比 40.0%）\n   类型：writing-level\n   应用：从现有方法局限入手，逐步引出自身方法，再通过系统实验验证，最后回扣前述问题，形成闭环。\n\n2. 现实类比增强说服力（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过将教师模型与博士生、教授的教学过程类比，形象说明教师模型需要专门训练以提升知识传递能力，增强问题设定的现实感和说服力。\n\n3. 引用大量权威文献（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：在介绍知识蒸馏和学生中心学习时，密集引用相关领域的经典和最新文献，显示方法建立在坚实的学术基础上。\n\n4. 明确指出现有方法的不足（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：系统总结并批判现有知识蒸馏方法的两大缺陷（教师不关心学生、教师未针对蒸馏优化），为新方法的提出做铺垫。\n\n5. 引入教育学理论支持（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：引用教育学中“以学生为中心”的学习理论，论证让教师关注学生能力的合理性和有效性。\n\n6. 方法命名和框架包装（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：为方法命名为MetaDistil，并用“知识蒸馏+元学习”框架包装，强调其创新性和理论深度。\n\n7. 机制创新点突出（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：提出“pilot update”机制，强调其在双层优化（bi-level optimization）中的独特作用，突出方法细节创新。\n\n8. 流程图辅助理解（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过Figure 1展示MetaDistil的整体流程，使复杂的训练过程一目了然。\n\n9. 细致的任务和数据集覆盖（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：在NLP和CV两个领域、多个主流任务和数据集（如GLUE、BERT压缩）上进行评测，覆盖多种任务类型。\n\n10. 与多种强基线全面对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：系统对比vanilla KD、PKD、Theseus、TinyBERT、MiniLM等多种主流和最新压缩方法，展示自身优势。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_231",
        "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
        "problem_framing": "论文通过实际应用需求和学术痛点双重策略引出问题。首先指出随着大规模神经网络的普及，模型压缩对于高效、环保的机器学习部署变得重要，强调了知识蒸馏作为主流压缩技术的有效性。随后，作者从教育学理论（学生中心学习）引入学术gap，指出传统知识蒸馏忽视了学生模型的学习能力和个性化需求，强调了现有方法的局限性与改进空间。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y方面存在不足’的逻辑。具体地，指出传统知识蒸馏中教师模型对学生模型的能力和学习进度不敏感，且教师模型仅优化自身表现而非知识迁移能力。通过类比现实教育场景（如博士生与教授的区别），进一步强调教师模型缺乏“教学技能”。同时，批评了相关工作中教师模型进化方式的离散性和独立性，强调MetaDistil的连续性和适应性优势。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了MetaDistil框架的核心思想，即利用元学习动态调整教师模型以适应学生模型的学习进度。随后，进一步细化，提出了基于双层优化的元学习机制，并创新性地引入了‘pilot update’机制以协同教师和学生的学习过程。方法描述由高层理念逐步深入到具体实现细节，强调新机制与现有方法的区别。",
        "experiments_story": "实验部分采用‘多数据集验证+主流对比+公平性控制’的策略。首先在自然语言处理和计算机视觉两个主流领域的多个分类基准数据集上进行验证，涵盖GLUE等多个细分任务。实验设计包括与多种主流和最新知识蒸馏方法的对比（如vanilla KD、patient KD、progressive module replacing、DML、TAKD、RCO、ProKT、SFTN等），并特别强调了学生模型初始化公平性以确保结果可比。实验报告涵盖主任务性能、不同指标（如准确率、F1、相关系数等），并对预训练蒸馏模型进行参考对比，展现方法的全面有效性。"
      },
      {
        "paper_id": "ARR_2022_180",
        "title": "Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation",
        "problem_framing": "论文首先从自然语言处理领域Transformer模型的成功应用切入，强调预训练-微调范式已成为主流，并以BERT等模型为例，指出其广泛应用。接着，作者指出这些模型在需要领域知识的任务（如生物医学、金融）中存在局限，因为它们主要基于通用语料进行预训练。随后，作者引出领域适应的主流做法——在领域语料上额外预训练，并以生物医学领域的BioBERT等为例，说明该方法虽有效但存在成本高、需大量数据和资源、每有新模型需重复训练等实际痛点。最后，作者提出无需额外预训练的高效领域知识迁移框架作为解决方案。整体采用了“从应用需求和实际痛点出发，结合学术gap”的引入策略。",
        "gap_pattern": "论文批评现有方法时，采用了对比和举例的策略。首先指出现有主流做法（领域额外预训练）虽能提升领域任务表现，但存在明显缺陷：需要大量训练数据和算力资源、训练时间长、每有新模型出现需重新执行等。具体通过BioBERT需23天8卡训练的例子，突出成本高昂。句式上多用‘然而’‘但’‘需要’‘必须’等逻辑转折词，强调现有方法的局限性和不便。最后引出自身方法可在单卡几小时内完成，突出优势。",
        "method_story": "方法部分采用‘先整体后局部’的叙述顺序。首先简要回顾了Transformer及主流PLM（BERT、ALBERT、RoBERTa）的架构和发展，铺垫领域背景。随后，聚焦介绍DoKTra框架，作为主方法。方法介绍强调其与传统领域适应方法的不同，突出其高效性和创新性。整体上，先从相关技术背景入手，再逐步聚焦到自身方法，逻辑清晰递进。",
        "experiments_story": "实验部分采用‘主实验+多模型/多任务验证’的策略。首先说明实验设置，包括教师模型（BioBERT）和两种学生模型（ALBERT-xlarge、RoBERTa-large），并详细描述了参数设置和调优过程。实验在五个生物医学和临床分类任务上进行，采用F1分数作为指标。通过对比初始学生模型和应用DoKTra后的表现，展示方法有效性，并报告多次实验的均值和标准差，保证结果可靠性。实验重点在于主任务验证和多模型适用性，突出方法的通用性和高效性。"
      },
      {
        "paper_id": "ARR_2022_214",
        "title": "RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation",
        "problem_framing": "论文首先从应用需求出发，指出虽然预训练语言模型（如BERT、RoBERTa、XLNet）在自然语言理解任务上表现优异，但其在实际应用（如边缘设备）中部署存在模型体积大、推理时间长等挑战。接着，论文引出模型压缩技术，尤其聚焦于知识蒸馏（KD），并进一步指出在BERT压缩中，如何选择和匹配中间层（ILD）是一个关键但未被充分解决的问题。整体上，论文采用了从实际痛点到学术挑战的递进式开篇策略。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下存在不足’的句式。例如，指出已有的中间层蒸馏方法多采用固定的层映射，忽视了层选择对性能的影响，导致难以找到最优的层匹配方案（即layer skip and search问题）。同时，批评部分方法虽然提出了解决方案，但缺乏对这些技术在效率和性能上的全面评估。整体逻辑是：先总结已有方法的做法，再指出其局限或未覆盖的方面，最后引出本文关注的具体gap。",
        "method_story": "方法部分未给出详细内容，但从相关工作和实验部分可推测，方法叙述策略为‘先整体后局部’，即先介绍知识蒸馏及中间层蒸馏的基本框架和常见做法，然后聚焦于层选择问题，逐步引出并细化本文提出的新方法（如RAIL-KD），并与现有方法进行对比。可能还会分模块介绍方法的不同组成部分或创新点。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验+对比实验’的策略。首先在GLUE基准的8个任务上进行主实验，涵盖分类和回归任务，验证方法的普适性。其次，为检验方法的泛化能力，还在跨领域（OOD）数据集上进行测试。实验中与多种主流和最新的中间层蒸馏方法（如PKD、ALP-KD、CoDIR）进行直接对比，评估性能提升。实验结果通过多种模型结构（如BERT12到DistilBERT6、RoBERTa24到DistilRoberta6）和不同压缩比例进行验证，突出方法的有效性和适用范围。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "40.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_214",
            "title": "RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation",
            "description": "从现有方法局限入手，逐步引出自身方法，再通过系统实验验证，最后回扣前述问题，形成闭环。",
            "type": "writing-level",
            "purpose": "让读者顺畅理解问题提出、方法创新、实验验证和结论呼应的全过程。"
          },
          {
            "paper_id": "ARR_2022_300",
            "title": "Towards Computationally Feasible Deep Active Learning",
            "description": "从问题引入、方法铺垫到实验验证，层层递进，逻辑清晰，便于读者把握全文主线。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究脉络，增强论文整体说服力"
          }
        ]
      },
      {
        "trick_name": "现实类比增强说服力",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "通过将教师模型与博士生、教授的教学过程类比，形象说明教师模型需要专门训练以提升知识传递能力，增强问题设定的现实感和说服力。",
            "type": "writing-level",
            "purpose": "帮助读者理解并认同问题的合理性和方法的必要性"
          }
        ]
      },
      {
        "trick_name": "引用大量权威文献",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "在介绍知识蒸馏和学生中心学习时，密集引用相关领域的经典和最新文献，显示方法建立在坚实的学术基础上。",
            "type": "writing-level",
            "purpose": "证明所述问题和方法在学术界的重要性和广泛关注度，提升论证的权威性"
          }
        ]
      },
      {
        "trick_name": "明确指出现有方法的不足",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "系统总结并批判现有知识蒸馏方法的两大缺陷（教师不关心学生、教师未针对蒸馏优化），为新方法的提出做铺垫。",
            "type": "writing-level",
            "purpose": "突出自身工作的创新空间和必要性"
          }
        ]
      },
      {
        "trick_name": "引入教育学理论支持",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "引用教育学中“以学生为中心”的学习理论，论证让教师关注学生能力的合理性和有效性。",
            "type": "writing-level",
            "purpose": "借助跨领域理论增强方法的科学性和新颖性"
          }
        ]
      },
      {
        "trick_name": "方法命名和框架包装",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "为方法命名为MetaDistil，并用“知识蒸馏+元学习”框架包装，强调其创新性和理论深度。",
            "type": "method-level",
            "purpose": "突出方法的新颖性和系统性，便于记忆和传播"
          }
        ]
      },
      {
        "trick_name": "机制创新点突出",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "提出“pilot update”机制，强调其在双层优化（bi-level optimization）中的独特作用，突出方法细节创新。",
            "type": "method-level",
            "purpose": "清晰展示技术创新，便于同行辨识贡献"
          }
        ]
      },
      {
        "trick_name": "流程图辅助理解",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "通过Figure 1展示MetaDistil的整体流程，使复杂的训练过程一目了然。",
            "type": "writing-level",
            "purpose": "提升方法可解释性，帮助读者快速把握整体流程"
          }
        ]
      },
      {
        "trick_name": "细致的任务和数据集覆盖",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "在NLP和CV两个领域、多个主流任务和数据集（如GLUE、BERT压缩）上进行评测，覆盖多种任务类型。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和实验结果的代表性"
          }
        ]
      },
      {
        "trick_name": "与多种强基线全面对比",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "系统对比vanilla KD、PKD、Theseus、TinyBERT、MiniLM等多种主流和最新压缩方法，展示自身优势。",
            "type": "experiment-level",
            "purpose": "突出方法的优越性和进步幅度"
          }
        ]
      },
      {
        "trick_name": "公平性控制",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "为保证公平，将所有基线的学生模型初始化方式统一，并重跑实验，排除初始化差异对结果的影响。",
            "type": "experiment-level",
            "purpose": "消除实验偏差，确保对比结果公正可信"
          }
        ]
      },
      {
        "trick_name": "详细的超参数搜索说明",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "详细列出所有超参数的搜索空间和设置，便于他人复现和验证实验结果。",
            "type": "experiment-level",
            "purpose": "提升实验的可复现性和科学性"
          }
        ]
      },
      {
        "trick_name": "任务分解与指标多样化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "针对不同任务采用多种评测指标（如F1、accuracy、Pearson/Spearman相关、Matthew’s correlation），细致展示方法效果。",
            "type": "experiment-level",
            "purpose": "全面反映方法在不同任务和评价指标下的表现"
          }
        ]
      },
      {
        "trick_name": "逻辑递进的叙事结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_231",
            "title": "BERT Learns to Teach: Knowledge Distillation with Meta Learning",
            "description": "先提出问题和现有方法不足，后介绍创新方法，最后用充分实验验证，形成“问题-方法-验证”闭环。",
            "type": "writing-level",
            "purpose": "增强论文整体的可读性和逻辑说服力"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性强调",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_180",
            "title": "Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation",
            "description": "作者详细阐述了现有领域预训练方法的高成本和低效率，强调了每次新模型出现都需重新预训练的弊端，从而为提出新框架铺垫合理性。",
            "type": "writing-level",
            "purpose": "突出研究动机，增强新方法的必要性和说服力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_231",
        "ARR_2022_180",
        "ARR_2022_214",
        "ARR_2022_300",
        "ARR_2022_159"
      ]
    }
  },
  {
    "pattern_id": 12,
    "pattern_name": "多任务学习扩展分类体系",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦于自动扩展分类体系（如WordNet），采用多任务学习框架实现attach和merge操作的统一建模。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际应用需求和学术gap开篇，通过多版本方法设计和多指标实验评估增强说服力，常用tricks包括问题重要性强调、现有方法不足归纳等。\n第3段（60字）：适用场景与预期效果 - 适用于词汇资源扩展和多语言语义层级构建等任务，预期提升模型在多数据集上的泛化能力和性能表现。",
    "writing_guide": "写作模板：多任务学习扩展分类体系\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦于自动扩展分类体系（如WordNet），采用多任务学习框架实现attach和merge操作的统一建模。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际应用需求和学术gap开篇，通过多版本方法设计和多指标实验评估增强说服力，常用tricks包括问题重要性强调、现有方法不足归纳等。\n第3段（60字）：适用场景与预期效果 - 适用于词汇资源扩展和多语言语义层级构建等任务，预期提升模型在多数据集上的泛化能力和性能表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge》\n  • 问题定位：论文首先强调了分类体系（如 WordNet）在自然语言处理中的重要性，指出其在信息检索、信息抽取、文本分类和摘要等任务中的核心作用。接着指出现有 WordNet 主要依赖人工构建，导致覆盖面有限，由此引出自动化扩展分类体系的必要性。\n  • 现有研究缺口：论文批评现有方法时，首先将其分为两大类（多分类体系对齐和基于机器学习的子图评分），并进一步细分为只做 merge 或只做 attach 的子类。通过归纳总结指出：‘所有现有方法要么只做 merge，要么只做 attach’，而 WordNet 扩展本质上是两者的结合任务。\n  • 核心方法：方法部分先明确目标，即在单一模型中集成 attach 和 merge 两种操作，并提出采用多任务学习框架（TEAM）。接着说明该框架如何实现任务间信息流动和相互促进。\n  • 实验设计：实验部分首先介绍了数据集和评价指标，强调多语言多数据集（Assamese、Bengali、Hindi WordNet）验证的广泛性。随后明确对比基线（TaxoExpan、TMN）及自身方法的不同变体（TEAM-RG、TEAM-CL 及任务特定版本）。\n\n示例 2：《Constructing Semantic Hierarchies via Fusion Learning Architecture》\n  • 问题定位：论文在引言部分通过强调本体和语义词库在自然语言处理中的重要性，聚焦于其核心组成——语义层级结构，并以WordNet为例具体说明“is-a”关系，快速让读者了解研究对象及其关键关系，建立研究背景。\n  • 现有研究缺口：作者指出现有如WordNet、YAGO等语义层级多依赖人工构建，面临覆盖范围与人工成本的权衡难题，进而引出自动化构建语义层级的必要性，明确当前方法的不足与改进空间。\n  • 核心方法：方法部分以具体任务为切入点，明确目标是根据词的hypernyms列表自动构建语义层级，随后区分并介绍判别式和生成式两种主流架构，突出自身方法的定位与创新点，并辅以流程图辅助理解。\n  • 实验设计：实验部分按逻辑顺序展开，先介绍实验准备与数据集，接着报告融合架构及其组件的性能表现，再与已有方法多维度对比，并通过具体示例展示语义层级构建效果，突出方法有效性与实用性。\n\n示例 3：《None》\n  • 问题定位：引言部分通过定义paraphrase及其在自然语言处理中的重要性，强调大规模同义资源对应用的促进作用。作者以实际应用需求为切入点，逐步引出自动获取同义词资源的研究背景，建立了问题的现实意义和研究基础。\n  • 现有研究缺口：作者指出现有同义词资源（如PPDB）虽然规模庞大，但未能充分区分多义词的不同语义，导致同义词集合混杂。通过举例说明词语多义性带来的挑战，明确当前资源在语义细粒度划分上的不足，形成研究切入点。\n  • 核心方法：方法部分采用先介绍整体流程，再细化模型选择的策略。作者先说明需要高质量词语替换排名作为基础，随后分别介绍两种模型的原理、特征和上下文处理方式，突出模型选择的合理性和创新性。\n  • 实验设计：实验部分以具体任务为导向，详细说明数据选取、参数设置和阈值选择的依据，强调实验设计的科学性。通过描述聚类算法的参数选择和评估方法，展现实验流程的系统性和对结果可靠性的重视。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题重要性强调（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过列举WordNet在NLP各类任务中的核心作用，并指出人工构建的局限性，强调自动扩展taxonomy的必要性。\n\n2. 现有方法不足归纳（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：系统梳理现有工作仅关注attach或merge操作，未有统一模型，强调自身工作的独特切入点。\n\n3. 任务创新点明确（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：首次提出可同时执行attach和merge操作的多任务学习框架，并将taxonomy扩展任务转化为分类与回归两类问题。\n\n4. 多版本方法设计（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：提出TEAM-RG和TEAM-CL两种版本，分别对应回归和分类目标，满足不同任务需求。\n\n5. 原理可视化举例（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过具体例子（如Mango和Nutrient）及图示，直观展示attach与merge操作的区别和应用场景。\n\n6. 多任务学习框架阐释（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：详细说明如何通过多任务学习实现信息流动和任务互助，解释模型设计的合理性。\n\n7. 多指标实验评估（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：采用多种评价指标（MR, Hit@k, MRR, Accuracy, F1等）从不同角度衡量模型性能。\n\n8. 多数据集验证（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：在Assamese、Bengali和Hindi三种WordNet taxonomy上进行实验，验证方法的适用性。\n\n9. 与主流方法对比（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：与Taxo-Expan和TMN等SOTA方法进行系统对比，展示TEAM在各项指标上的优越表现。\n\n10. 方法变体消融分析（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：对TEAM的attach、merge、merge+attach等变体进行对比，探讨不同任务组合的效果。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_358",
        "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
        "problem_framing": "论文首先强调了分类体系（如 WordNet）在自然语言处理中的重要性，指出其在信息检索、信息抽取、文本分类和摘要等任务中的核心作用。接着指出现有 WordNet 主要依赖人工构建，导致覆盖面有限，由此引出自动化扩展分类体系的必要性。通过举例说明 WordNet 扩展时需要两种操作（attach 和 merge），并指出现有研究仅关注其中之一，未能同时处理两种操作，进一步强化了研究问题的实际痛点和学术空白。整体采用了“从实际应用需求和学术gap双重出发”的开篇策略。",
        "gap_pattern": "论文批评现有方法时，首先将其分为两大类（多分类体系对齐和基于机器学习的子图评分），并进一步细分为只做 merge 或只做 attach 的子类。通过归纳总结指出：‘所有现有方法要么只做 merge，要么只做 attach’，而 WordNet 扩展本质上是两者的结合任务。使用了‘然而，现有方法……’、‘我们是首个……’等句式，突出当前方法的局限性和自身工作的创新性。此外，引用 SemEval 2016 任务的需求，强调业界对两类操作集成的呼声，进一步论证 gap 的存在和价值。",
        "method_story": "方法部分先明确目标，即在单一模型中集成 attach 和 merge 两种操作，并提出采用多任务学习框架（TEAM）。接着说明该框架如何实现任务间信息流动和相互促进。然后介绍具体任务设定（操作分类和候选锚点排序），并提出两种实现方式（TEAM-RG: 回归，TEAM-CL: 分类），分别对应不同的学习目标。最后详细描述每种方法的决策流程和优化目标。整体采用‘先整体框架，后细分两大实现版本，再到具体流程’的叙述顺序，兼顾了宏观设计和微观实现。",
        "experiments_story": "实验部分首先介绍了数据集和评价指标，强调多语言多数据集（Assamese、Bengali、Hindi WordNet）验证的广泛性。随后明确对比基线（TaxoExpan、TMN）及自身方法的不同变体（TEAM-RG、TEAM-CL 及任务特定版本）。实验内容涵盖主实验（与 SOTA 方法对比）、不同任务（attach、merge、merge+attach）的性能对比，以及不同模型变体的消融分析。评价指标既有排序类（MR、Hit@k、MRR），也有分类类（Accuracy、F1、Precision、Recall），体现了多维度、多角度的实验验证策略。整体采用‘多数据集+多基线+多任务+多指标’的系统性实验设计。"
      },
      {
        "paper_id": "ACL_2017_67",
        "title": "Constructing Semantic Hierarchies via Fusion Learning Architecture",
        "problem_framing": "论文在引言部分通过强调本体和语义词库在自然语言处理中的重要性，聚焦于其核心组成——语义层级结构，并以WordNet为例具体说明“is-a”关系，快速让读者了解研究对象及其关键关系，建立研究背景。",
        "gap_pattern": "作者指出现有如WordNet、YAGO等语义层级多依赖人工构建，面临覆盖范围与人工成本的权衡难题，进而引出自动化构建语义层级的必要性，明确当前方法的不足与改进空间。",
        "method_story": "方法部分以具体任务为切入点，明确目标是根据词的hypernyms列表自动构建语义层级，随后区分并介绍判别式和生成式两种主流架构，突出自身方法的定位与创新点，并辅以流程图辅助理解。",
        "experiments_story": "实验部分按逻辑顺序展开，先介绍实验准备与数据集，接着报告融合架构及其组件的性能表现，再与已有方法多维度对比，并通过具体示例展示语义层级构建效果，突出方法有效性与实用性。"
      },
      {
        "paper_id": "ACL_2017_614",
        "title": null,
        "problem_framing": "引言部分通过定义paraphrase及其在自然语言处理中的重要性，强调大规模同义资源对应用的促进作用。作者以实际应用需求为切入点，逐步引出自动获取同义词资源的研究背景，建立了问题的现实意义和研究基础。",
        "gap_pattern": "作者指出现有同义词资源（如PPDB）虽然规模庞大，但未能充分区分多义词的不同语义，导致同义词集合混杂。通过举例说明词语多义性带来的挑战，明确当前资源在语义细粒度划分上的不足，形成研究切入点。",
        "method_story": "方法部分采用先介绍整体流程，再细化模型选择的策略。作者先说明需要高质量词语替换排名作为基础，随后分别介绍两种模型的原理、特征和上下文处理方式，突出模型选择的合理性和创新性。",
        "experiments_story": "实验部分以具体任务为导向，详细说明数据选取、参数设置和阈值选择的依据，强调实验设计的科学性。通过描述聚类算法的参数选择和评估方法，展现实验流程的系统性和对结果可靠性的重视。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "问题重要性强调",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "通过列举WordNet在NLP各类任务中的核心作用，并指出人工构建的局限性，强调自动扩展taxonomy的必要性。",
            "type": "writing-level",
            "purpose": "凸显研究问题的实际价值和紧迫性，吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "现有方法不足归纳",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "系统梳理现有工作仅关注attach或merge操作，未有统一模型，强调自身工作的独特切入点。",
            "type": "writing-level",
            "purpose": "突出当前研究领域的空白，为新方法的提出做铺垫"
          }
        ]
      },
      {
        "trick_name": "任务创新点明确",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "首次提出可同时执行attach和merge操作的多任务学习框架，并将taxonomy扩展任务转化为分类与回归两类问题。",
            "type": "method-level",
            "purpose": "突出方法的创新性和独特贡献，提升论文新颖性"
          }
        ]
      },
      {
        "trick_name": "多版本方法设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "提出TEAM-RG和TEAM-CL两种版本，分别对应回归和分类目标，满足不同任务需求。",
            "type": "method-level",
            "purpose": "展示方法的灵活性和广泛适用性，增加说服力"
          }
        ]
      },
      {
        "trick_name": "原理可视化举例",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "通过具体例子（如Mango和Nutrient）及图示，直观展示attach与merge操作的区别和应用场景。",
            "type": "writing-level",
            "purpose": "提升方法可解释性，帮助读者理解操作流程"
          }
        ]
      },
      {
        "trick_name": "多任务学习框架阐释",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "详细说明如何通过多任务学习实现信息流动和任务互助，解释模型设计的合理性。",
            "type": "method-level",
            "purpose": "增强方法的理论说服力，体现技术深度"
          }
        ]
      },
      {
        "trick_name": "多指标实验评估",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "采用多种评价指标（MR, Hit@k, MRR, Accuracy, F1等）从不同角度衡量模型性能。",
            "type": "experiment-level",
            "purpose": "证明实验的全面性和结果的可靠性"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "在Assamese、Bengali和Hindi三种WordNet taxonomy上进行实验，验证方法的适用性。",
            "type": "experiment-level",
            "purpose": "提升实验结果的泛化性和说服力"
          }
        ]
      },
      {
        "trick_name": "与主流方法对比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "与Taxo-Expan和TMN等SOTA方法进行系统对比，展示TEAM在各项指标上的优越表现。",
            "type": "experiment-level",
            "purpose": "突出自身方法的优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "方法变体消融分析",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "对TEAM的attach、merge、merge+attach等变体进行对比，探讨不同任务组合的效果。",
            "type": "experiment-level",
            "purpose": "分析各模块贡献，增强结果的解释性和完备性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "从问题提出、现状分析、方法设计到实验验证，层层递进，环环相扣，最后呼应前文结论。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，便于读者跟随思路"
          }
        ]
      },
      {
        "trick_name": "实验细节补充说明",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_358",
            "title": "TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge",
            "description": "在正文中简要说明实验设置，并在附录中提供详细复现信息，便于同行验证。",
            "type": "writing-level",
            "purpose": "增强实验可复现性和透明度，提升论文可信度"
          }
        ]
      },
      {
        "trick_name": "引用经典与现有工作",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ACL_2017_67",
            "title": "Constructing Semantic Hierarchies via Fusion Learning Architecture",
            "description": "通过引用WordNet、YAGO等经典语义层次结构和相关方法的文献，展示当前研究的背景和已有成果，为后续工作奠定理论基础。",
            "type": "writing-level",
            "purpose": "建立研究背景和权威性"
          }
        ]
      },
      {
        "trick_name": "明确问题与挑战",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ACL_2017_67",
            "title": "Constructing Semantic Hierarchies via Fusion Learning Architecture",
            "description": "直接指出语义层次结构自动构建的主要挑战，如人工成本与覆盖范围的权衡，以及上下文使用的瓶颈，强调研究的意义和难点。",
            "type": "writing-level",
            "purpose": "突出研究的核心难点"
          }
        ]
      },
      {
        "trick_name": "方法归类与对比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ACL_2017_67",
            "title": "Constructing Semantic Hierarchies via Fusion Learning Architecture",
            "description": "将现有方法分为判别式和生成式两大类，分别阐述其原理和优缺点，为后续提出融合模型做铺垫。",
            "type": "method-level",
            "purpose": "系统化现有技术方案，便于创新方法提出"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 8,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_358",
        "ACL_2017_67",
        "ACL_2017_614",
        "ACL_2017_21",
        "ACL_2017_741",
        "COLING_2020_26",
        "COLING_2020_74",
        "COLING_2020_5"
      ]
    }
  },
  {
    "pattern_id": 13,
    "pattern_name": "多尺度表征自动评价技术",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决自动评价和生成任务中的评估难题，采用多尺度表征和创新指标设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过多数据集验证和对比实验突出方法优势，常用tricks包括领域背景铺垫、方法分类梳理、引用权威数据集。\n第3段（60字）：适用场景与预期效果 - 适用于自动作文评分、对话生成、视觉故事评估等任务，预期提升模型的准确性和解释性，增强评估的可靠性和公平性。",
    "writing_guide": "写作模板：多尺度表征自动评价技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决自动评价和生成任务中的评估难题，采用多尺度表征和创新指标设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过多数据集验证和对比实验突出方法优势，常用tricks包括领域背景铺垫、方法分类梳理、引用权威数据集。\n第3段（60字）：适用场景与预期效果 - 适用于自动作文评分、对话生成、视觉故事评估等任务，预期提升模型的准确性和解释性，增强评估的可靠性和公平性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation》\n  • 问题定位：论文通过强调自动作文评分（AES）在减轻教师评分负担和推动自动化评测发展中的实际价值来引出问题，采用了从实际痛点和应用需求出发的开篇策略。作者指出，随着在线教育的兴起，AES 领域受到越来越多关注，进一步凸显了该问题的现实紧迫性和研究意义。\n  • 现有研究缺口：论文对现有方法的批评采用了分层对比和局限性剖析的逻辑。\n  • 核心方法：方法部分采用了先整体后局部、分模块介绍的叙述策略。\n  • 实验设计：实验部分采用了多数据集验证和主实验+对比分析的叙述策略。首先介绍了ASAP和CRP两个公开数据集及其评价指标（QWK和RMSE），并描述了数据集划分和实验设置。随后，通过表格展示基线模型与所提多尺度模型的性能对比，并在长文本场景下与最新方法进行详细对比，突出模型优势。\n\n示例 2：《Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand》\n  • 问题定位：论文从学术gap和实际痛点双重角度引出问题。首先指出自然语言生成领域（如机器翻译、摘要）近年来取得了显著进展，但主流评测方式依赖于自动分数（如BLEU、ROUGE），这些分数与人类评判的相关性在模型能力提升或模型类型变化时会显著下降。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序。首先介绍了BILLBOARDs的总体框架和设计理念，即将生成模型和评测指标作为两类独立的提交对象，动态关联模型排名与最优评测指标。\n  • 实验设计：实验部分采用‘对比分析+多数据集验证+主实验为主’的策略。首先强调实验初始化依赖于人工评测（专家与众包），并通过元评测（meta-evaluation）对比专家评测和众包评测的一致性，揭示众包评测的局限性。\n\n示例 3：《Many Hands Make Light Work: Using Essay Traits to Automatically Score Essays》\n  • 问题定位：论文首先从实际痛点出发，指出人工对作文进行定性评价耗时且资源消耗大，进而引出自动作文评分（AEG）领域的产生。随后，作者进一步从学术gap出发，强调现有研究主要关注整体分数的预测，而较少关注作文各个特征（traits）在整体分数中的作用。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑，明确指出大部分AEG领域的研究只关注整体评分，忽视了作文特征（traits）对整体分数的解释和贡献。此外，论文还指出现有的主流方法（如BERT）虽然效果较好，但存在参数量大、输入长度受限等实际应用中的缺陷，进一步强调了自身方法的轻量性和适用性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了多任务学习（MTL）框架在作文评分中的应用，说明模型结构和任务分配（主任务与辅助任务）。随后，详细描述了模型的各个组成部分，如共享词嵌入层、特征学习模块、损失函数设计等。最后结合实验设置，说明了模型选择、参数设置和与主流方法的对比方式。\n  • 实验设计：实验部分采用‘多配置对比+主实验+扩展实验’的策略。首先明确评价指标的选择及其合理性，然后在不同模型配置（STL-LSTM, STL-BiLSTM, MTL-LSTM, MTL-BiLSTM）下进行主实验，比较整体评分效果。其次，与已有的字符串核方法和BERT基线进行对比，验证方法有效性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 4 次，占比 36.4%）\n   类型：writing-level\n   应用：作者依次引入问题、分析现状、提出方法、描述实现、展示实验和总结优势，形成完整的逻辑闭环。\n\n2. 创新点突出（使用频率 2 次，占比 18.2%）\n   类型：method-level\n   应用：作者强调提出了多尺度（document、token、segment）联合表征和评分机制，区别于以往单一尺度或特征方式。\n\n3. 多指标评测（使用频率 2 次，占比 18.2%）\n   类型：experiment-level\n   应用：作者在多个数据集（ASAP、CRP）和多种评价指标（QWK、RMSE）下验证模型性能，采用5折交叉验证保证结果稳健。\n\n4. 领域背景铺垫（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者首先介绍AES任务的价值和应用场景，强调其在自动化评估和减轻教师负担中的作用，并结合在线教育趋势，突出研究的必要性。\n\n5. 方法分类梳理（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者将AES方法分为传统、深度神经网络和预训练三类，并分别介绍优缺点和发展历程，形成清晰的技术脉络。\n\n6. 引用权威与数据集（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者多次引用领域内权威论文和公开数据集（如ASAP、CRP），说明研究基础扎实。\n\n7. 现有方法局限性分析（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者详细分析传统方法、深度神经网络和预训练方法的局限，如特征设计复杂、迁移性差、预训练效果有限等。\n\n8. 结构化方法描述（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：作者用分步描述和公式推导，明确各个模块（BERT、LSTM、Attention、回归层）如何协同工作，配合图示（Figure 1）增强直观性。\n\n9. 与主流方法对比实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：作者将新方法与领域内主流模型（如BERT、LSTM、传统方法）进行直接性能对比，详细列出指标提升幅度。\n\n10. 实验结果总结与分析（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者对实验结果进行归纳总结，指出模型在长文本和多尺度表征上的优势，并分析与其他方法的性能差异。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_121",
        "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
        "problem_framing": "论文通过强调自动作文评分（AES）在减轻教师评分负担和推动自动化评测发展中的实际价值来引出问题，采用了从实际痛点和应用需求出发的开篇策略。作者指出，随着在线教育的兴起，AES 领域受到越来越多关注，进一步凸显了该问题的现实紧迫性和研究意义。",
        "gap_pattern": "论文对现有方法的批评采用了分层对比和局限性剖析的逻辑。首先，指出传统方法依赖复杂的人工特征，虽然在小数据集上表现好，但移植性差且设计成本高；其次，深度神经网络虽能自动提取特征，但在某些任务上与传统方法表现相当，且集成方法依然依赖人工特征，增加了研究者负担；最后，预训练模型虽在NLP任务中表现优异，但在AES任务中未能明显超越其他深度学习方法，仅有少数工作通过优化训练方式取得提升。批评句式包括“though... fail to show an advantage...”, “still needs handcrafted features which cost numerous energy of researchers”, “their improvement mainly comes from...”。",
        "method_story": "方法部分采用了先整体后局部、分模块介绍的叙述策略。先整体描述了模型架构（如图1所示），明确模型由多尺度（document-scale, token-scale, segment-scale）表示模块组成，随后详细介绍各个模块的实现方式，包括BERT提取不同尺度特征、LSTM与注意力机制处理分段特征、回归层输出分数，并给出公式说明各部分如何组合得到最终评分。",
        "experiments_story": "实验部分采用了多数据集验证和主实验+对比分析的叙述策略。首先介绍了ASAP和CRP两个公开数据集及其评价指标（QWK和RMSE），并描述了数据集划分和实验设置。随后，通过表格展示基线模型与所提多尺度模型的性能对比，并在长文本场景下与最新方法进行详细对比，突出模型优势。实验结论部分总结了主要发现，强调所提方法在长文本和多尺度编码上的有效性。"
      },
      {
        "paper_id": "ARR_2022_321",
        "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
        "problem_framing": "论文从学术gap和实际痛点双重角度引出问题。首先指出自然语言生成领域（如机器翻译、摘要）近年来取得了显著进展，但主流评测方式依赖于自动分数（如BLEU、ROUGE），这些分数与人类评判的相关性在模型能力提升或模型类型变化时会显著下降。作者通过引用大量文献和统计数据（如68%的论文仅用BLEU评测）强调当前评测方式与模型发展之间存在脱节，进而提出这是一个被忽视且亟需解决的问题。开篇策略为：先陈述领域进展，再指出评测与实际需求之间的错位，最后引出需要创新评测机制的现实需求。",
        "gap_pattern": "论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：1）指出自动评测指标（如BLEU、ROUGE）最初被采用是因为与人工评测有相关性，但在模型类型多样化和能力提升后，这种相关性会崩溃；2）尽管有许多新指标被提出并能更好地拟合人工评测，但主流研究者并未采纳这些新指标，导致评测与模型发展脱节；3）现有评测机制要求模型开发者自行实现新指标，增加了采用门槛。整体句式以‘然而/但是/不幸的是/被忽视的是...’为主，强调现有方法的局限和社区实践的滞后。",
        "method_story": "方法部分采用‘先整体后局部’的叙述顺序。首先介绍了BILLBOARDs的总体框架和设计理念，即将生成模型和评测指标作为两类独立的提交对象，动态关联模型排名与最优评测指标。随后详细分解各个模块：1）定义生成器和评测指标的输入输出关系；2）介绍如何对生成器和指标分别进行排名（如用与人工分数的相关性对指标排序，再用最优指标对生成器排序）；3）补充说明了可扩展性和可替代设计方案。整体逻辑是从高层设计到具体实现细节，逐步细化。",
        "experiments_story": "实验部分采用‘对比分析+多数据集验证+主实验为主’的策略。首先强调实验初始化依赖于人工评测（专家与众包），并通过元评测（meta-evaluation）对比专家评测和众包评测的一致性，揭示众包评测的局限性。实验类型包括：1）主实验——用专家评测初始化BILLBOARDs，分析不同评测指标与人工分数的相关性；2）对比实验——专家与众包评测结果的分歧分析；3）多数据集验证——在不同任务（如WMT20 EN-DE、WMT20 ZH-EN、CNNDM、MSCOCO）上进行实验，确保方法的通用性和稳健性。整体策略注重实验设计的科学性和结果的可解释性。"
      },
      {
        "paper_id": "ARR_2022_80",
        "title": "Many Hands Make Light Work: Using Essay Traits to Automatically Score Essays",
        "problem_framing": "论文首先从实际痛点出发，指出人工对作文进行定性评价耗时且资源消耗大，进而引出自动作文评分（AEG）领域的产生。随后，作者进一步从学术gap出发，强调现有研究主要关注整体分数的预测，而较少关注作文各个特征（traits）在整体分数中的作用。通过提出“能否利用作文特征评分来提升整体评分”的问题，明确了研究的切入点和创新点。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑，明确指出大部分AEG领域的研究只关注整体评分，忽视了作文特征（traits）对整体分数的解释和贡献。此外，论文还指出现有的主流方法（如BERT）虽然效果较好，但存在参数量大、输入长度受限等实际应用中的缺陷，进一步强调了自身方法的轻量性和适用性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了多任务学习（MTL）框架在作文评分中的应用，说明模型结构和任务分配（主任务与辅助任务）。随后，详细描述了模型的各个组成部分，如共享词嵌入层、特征学习模块、损失函数设计等。最后结合实验设置，说明了模型选择、参数设置和与主流方法的对比方式。",
        "experiments_story": "实验部分采用‘多配置对比+主实验+扩展实验’的策略。首先明确评价指标的选择及其合理性，然后在不同模型配置（STL-LSTM, STL-BiLSTM, MTL-LSTM, MTL-BiLSTM）下进行主实验，比较整体评分效果。其次，与已有的字符串核方法和BERT基线进行对比，验证方法有效性。此外，还设计了以作文特征为主任务的多任务变体（MTL*），分析模型在不同任务分配下的表现，体现了实验的全面性和深入性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 4,
        "percentage": "36.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者依次引入问题、分析现状、提出方法、描述实现、展示实验和总结优势，形成完整的逻辑闭环。",
            "type": "writing-level",
            "purpose": "保证全文结构清晰，便于读者跟随思路"
          },
          {
            "paper_id": "ARR_2022_93",
            "title": "Achieving Reliable Human Assessment of Open-Domain Dialogue Systems",
            "description": "从问题引入、现有方法批判、方法创新、实验验证到结论呼应，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题提出、方法创新和实验验证的全过程"
          },
          {
            "paper_id": "ARR_2022_216",
            "title": "Rethinking and Refining the Distinct Metric",
            "description": "作者先引入问题和现有方法不足，接着提出新方法，再通过实验验证，最后呼应前文结论，结构清晰递进。",
            "type": "writing-level",
            "purpose": "提升可读性和逻辑性，让读者顺畅理解问题、方法和结论"
          }
        ]
      },
      {
        "trick_name": "创新点突出",
        "frequency": 2,
        "percentage": "18.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者强调提出了多尺度（document、token、segment）联合表征和评分机制，区别于以往单一尺度或特征方式。",
            "type": "method-level",
            "purpose": "让读者明确本工作的独特贡献和创新性"
          },
          {
            "paper_id": "ARR_2022_174",
            "title": "Learning to Rank Visual Stories From Human Ranking Data",
            "description": "明确提出本工作首次将人类评测数据（VHED）系统化，并基于此训练无参考的评价指标Vrank。",
            "type": "writing-level",
            "purpose": "清晰展示工作的创新性，吸引读者注意"
          }
        ]
      },
      {
        "trick_name": "多指标评测",
        "frequency": 2,
        "percentage": "18.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者在多个数据集（ASAP、CRP）和多种评价指标（QWK、RMSE）下验证模型性能，采用5折交叉验证保证结果稳健。",
            "type": "experiment-level",
            "purpose": "证明方法的完备性和适用性，增强结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_25",
            "title": "Your Answer is Incorrect... Would you like to know why? Introducing a Bilingual Short Answer Feedback Dataset",
            "description": "采用多种自动化评价指标（BLEU、ROUGE、METEOR、BERTScore等）对生成反馈进行综合评估。",
            "type": "experiment-level",
            "purpose": "提升完备性和结果的可靠性，避免单一指标偏见"
          }
        ]
      },
      {
        "trick_name": "领域背景铺垫",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者首先介绍AES任务的价值和应用场景，强调其在自动化评估和减轻教师负担中的作用，并结合在线教育趋势，突出研究的必要性。",
            "type": "writing-level",
            "purpose": "让读者理解AES的重要性和研究现状，增强问题的现实意义和紧迫感"
          }
        ]
      },
      {
        "trick_name": "方法分类梳理",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者将AES方法分为传统、深度神经网络和预训练三类，并分别介绍优缺点和发展历程，形成清晰的技术脉络。",
            "type": "writing-level",
            "purpose": "帮助读者快速了解领域内主流方法，为后续创新点做铺垫"
          }
        ]
      },
      {
        "trick_name": "引用权威与数据集",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者多次引用领域内权威论文和公开数据集（如ASAP、CRP），说明研究基础扎实。",
            "type": "writing-level",
            "purpose": "增强说服力和可信度，表明方法和实验基于公认的数据和前人工作"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性分析",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者详细分析传统方法、深度神经网络和预训练方法的局限，如特征设计复杂、迁移性差、预训练效果有限等。",
            "type": "writing-level",
            "purpose": "突出当前方法的不足，为提出新方法做铺垫，突出创新动机"
          }
        ]
      },
      {
        "trick_name": "结构化方法描述",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者用分步描述和公式推导，明确各个模块（BERT、LSTM、Attention、回归层）如何协同工作，配合图示（Figure 1）增强直观性。",
            "type": "method-level",
            "purpose": "提升可解释性，让读者易于理解模型架构和流程"
          }
        ]
      },
      {
        "trick_name": "与主流方法对比实验",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者将新方法与领域内主流模型（如BERT、LSTM、传统方法）进行直接性能对比，详细列出指标提升幅度。",
            "type": "experiment-level",
            "purpose": "突出方法优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "实验结果总结与分析",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_121",
            "title": "On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation",
            "description": "作者对实验结果进行归纳总结，指出模型在长文本和多尺度表征上的优势，并分析与其他方法的性能差异。",
            "type": "writing-level",
            "purpose": "帮助读者理解结果背后的原因，强化结论的合理性"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立现有问题",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_321",
            "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "description": "作者通过引用Ng et al., 2019; Raffel et al., 2020; Brown et al., 2020等文献，说明当前主流自动指标（如BLEU、ROUGE）与人类评价脱节，强调现有方法的不足。",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用大量权威文献证明现有自动评价指标的局限性和社区现状"
          }
        ]
      },
      {
        "trick_name": "数据统计强化论点",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_321",
            "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "description": "作者统计了NAACL和ACL 2020会议论文中指标使用情况，用具体百分比说明社区对新指标的采纳率极低。",
            "type": "writing-level",
            "purpose": "用具体数据（如68%和5%等比例）展示社区对新评价指标的忽视，增强问题的紧迫感和说服力"
          }
        ]
      },
      {
        "trick_name": "提出抽象化新范式",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_321",
            "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "description": "作者提出了bidimensional leaderboards（BILLBOARDs），将模型和评价指标同时作为可提交对象，打破传统单一评价体系。",
            "type": "method-level",
            "purpose": "突出新颖性，通过提出BILLBOARDs这一新范式，显示方法的创新点和对现有leaderboard的突破"
          }
        ]
      },
      {
        "trick_name": "动态评价机制设计",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_321",
            "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "description": "BILLBOARDs根据与人类评价的相关性动态选择最优指标进行模型排名，而非预设固定指标。",
            "type": "method-level",
            "purpose": "增强可解释性和科学性，通过动态选择与人类评价最相关的指标进行模型排名，避免单一指标带来的偏差"
          }
        ]
      },
      {
        "trick_name": "引入可复现性和开放性",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_321",
            "title": "Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand",
            "description": "所有BILLBOARD分数均可复现，所有指标以可执行程序形式存储，便于后续模型和指标的持续评测。",
            "type": "method-level",
            "purpose": "增强完备性和社区影响力，强调所有分数可复现，促进后续研究和公平比较"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 11,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_121",
        "ARR_2022_321",
        "ARR_2022_80",
        "ARR_2022_93",
        "ARR_2022_216",
        "ARR_2022_174",
        "ARR_2022_25",
        "ACL_2017_367",
        "COLING_2020_38",
        "COLING_2020_40",
        "COLING_2020_11"
      ]
    }
  },
  {
    "pattern_id": 14,
    "pattern_name": "量化生成式事件抽取",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦事件检测与抽取中的类型差异与低资源问题，采用量化方法和生成式框架提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引出问题，常用tricks包括典型案例对比、数据反常现象强调、新概念命名与定义、量化指标设计等。\n第3段（60字）：适用场景与预期效果 - 适用于事件检测、低资源事件抽取等任务，预期显著提升模型在不同类型和数据集上的鲁棒性和性能。",
    "writing_guide": "写作模板：量化生成式事件抽取\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦事件检测与抽取中的类型差异与低资源问题，采用量化方法和生成式框架提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引出问题，常用tricks包括典型案例对比、数据反常现象强调、新概念命名与定义、量化指标设计等。\n第3段（60字）：适用场景与预期效果 - 适用于事件检测、低资源事件抽取等任务，预期显著提升模型在不同类型和数据集上的鲁棒性和性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Saliency as Evidence: Event Detection with Trigger Saliency Attribution》\n  • 问题定位：论文从实际痛点和学术gap双重角度引出问题。首先指出事件检测（ED）作为事件抽取的关键步骤，在不同事件类型上的表现极度不均衡，并以ACE基准数据为例，展示了最先进模型在不同类型上的巨大性能差异。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了事件类型差异’和‘现有方法在某些场景下失效’的逻辑。具体地，指出大多数方法将所有事件类型一视同仁，训练单一模型，导致对不同类型的事件表现不均衡。引用相关工作表明，尽管有研究关注上下文依赖型事件，但这些工作主要是提升性能而非探究根本原因。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先提出核心概念——触发词显著性归因（trigger saliency attribution），并解释其如何量化事件对触发词或上下文的依赖。\n  • 实验设计：实验部分采用‘多数据集验证+多指标分析’的策略。首先在ACE 2005和MAVEN两个数据集上进行主实验，确保结果具有广泛适用性。实验内容包括：数据集统计、评价指标（相关性、精确率、召回率、F1、Macro F1）、实现细节和超参数设置。\n\n示例 2：《DEGREE: A Data-Efficient Generation-Based Event Extraction Model》\n  • 问题定位：论文首先从实际痛点出发，指出事件抽取任务需要大量高质量标注数据，而这些数据的获取成本极高，限制了模型在新领域和新事件类型上的扩展能力。通过举例说明如ACE 2005数据集的高标注成本，强调了低资源事件抽取的现实需求和研究价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在低资源场景下失效’的逻辑。具体做法包括：一方面，指出主流方法依赖大量标注数据，难以扩展到新领域；另一方面，分析了分类式和生成式方法的局限，如TANL和BART-Gen等生成式方法采用管道式结构，无法充分共享知识，且输出格式不便于利用标签语义。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍DEGREE的生成式框架及其优势，随后细致拆解为DEGREE、DEGREE(ED)、DEGREE(EAE)三个子模块，分别对应事件检测和事件参数抽取，并详细说明各自的prompt设计与输出格式。\n  • 实验设计：实验部分采用‘多数据集验证+主实验’的策略。首先说明所用数据集和低资源划分方式，确保实验覆盖广泛场景。随后介绍评价指标和对比基线，包括分类式和生成式方法。主实验聚焦于不同训练数据比例下的性能对比，突出低资源场景下DEGREE的优势。实验结果以表格和可视化图展示，强调在极低数据量下的显著性能提升。\n\n示例 3：《Event Detection for Suicide Understanding》\n  • 问题定位：论文从实际社会痛点出发，指出自杀是一个严重且日益增长的问题，强调现有临床访谈方法在高自杀风险人群中难以获得参与。同时，结合应用需求，提出社交媒体数据作为新的诊断信息来源，并指出自动化分析工具的重要性。\n  • 现有研究缺口：论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体而言，指出以往自杀检测工作主要关注用户自杀倾向的整体文本分类，未能细粒度分析和识别自杀相关事件；同时，现有事件检测数据集和方法多针对一般事件类型和正式文本，缺乏针对社交媒体自杀相关事件的专用数据和方法。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先介绍了为理解自杀相关话题而进行的主题建模分析（LDA），说明数据处理和分析的总体流程。随后，展示主题分析结果，并将其归纳为学校、工作和家庭三大类，体现了方法的应用和分析深度。整体上，方法部分以数据分析为切入点，突出数据特征和事件来源。\n  • 实验设计：实验部分采用‘主实验+对比+领域适应’的策略。首先对多种主流事件检测模型进行性能评估，包括CNN、DMBERT、BERTED、BERTGCN、GatedGCN和EEGCN，涵盖了非图模型和图模型。其次，设计了领域自适应实验，通过在Reddit数据上微调BERT，分析领域定制对模型性能的影响。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 50.0%）\n   类型：writing-level\n   应用：先引入问题和现象，再提出新方法，最后通过实验验证，形成闭环。\n\n2. 典型案例对比引入（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者用DIVORCE和START-POSITION两个事件类型的极端性能差异作为切入点，直观展示现有模型的局限性。\n\n3. 数据反常现象强调（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：指出DIVORCE类型训练数据远少于START-POSITION但性能却远高，说明现有方法存在未被关注的问题。\n\n4. 提出关键科学问题（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者提出两个关键问题：如何量化事件模式、如何利用该模式提升模型鲁棒性。\n\n5. 新概念命名与定义（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：首次提出trigger saliency attribution概念，并详细解释其含义和作用。\n\n6. 类比与可解释方法借鉴（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：借鉴特征归因方法，将每个词视为特征，计算其对事件语义的贡献，帮助读者理解方法原理。\n\n7. 量化指标设计（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将trigger对事件的贡献量化为saliency value，便于后续分析和模型设计。\n\n8. 分组检测思想（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：提出按事件模式分组检测而非一刀切，展示方法的差异化优势。\n\n9. 多指标综合评估（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：采用多种指标评估方法，兼顾相关性、整体性能和类别均衡性。\n\n10. 与现有解释性指标对比（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：将trigger saliency attribution与其他解释性指标进行相关性对比，显示其相关性最高。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_190",
        "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
        "problem_framing": "论文从实际痛点和学术gap双重角度引出问题。首先指出事件检测（ED）作为事件抽取的关键步骤，在不同事件类型上的表现极度不均衡，并以ACE基准数据为例，展示了最先进模型在不同类型上的巨大性能差异。接着，作者强调这种现象背后的原因尚未被深入研究，提出对事件上下文模式的关注，并引出两个核心科学问题：如何定量估计事件模式，以及如何通过刻画这些模式提升模型鲁棒性。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了事件类型差异’和‘现有方法在某些场景下失效’的逻辑。具体地，指出大多数方法将所有事件类型一视同仁，训练单一模型，导致对不同类型的事件表现不均衡。引用相关工作表明，尽管有研究关注上下文依赖型事件，但这些工作主要是提升性能而非探究根本原因。论文强调自身方法是首次系统性定义和量化事件模式，为学习提供依据。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先提出核心概念——触发词显著性归因（trigger saliency attribution），并解释其如何量化事件对触发词或上下文的依赖。随后详细介绍具体实现流程，包括句子级事件标签分配、特征归因方法的应用、显著性值计算及事件类型分组。最后，介绍如何基于显著性归因设计新的训练机制，提升模型表现。",
        "experiments_story": "实验部分采用‘多数据集验证+多指标分析’的策略。首先在ACE 2005和MAVEN两个数据集上进行主实验，确保结果具有广泛适用性。实验内容包括：数据集统计、评价指标（相关性、精确率、召回率、F1、Macro F1）、实现细节和超参数设置。随后通过相关性分析（如斯皮尔曼相关系数）对方法有效性进行定量验证，并与多种标准（训练实例数、触发词多样性、注意力值等）对比，突出新方法的优势。"
      },
      {
        "paper_id": "ARR_2022_296",
        "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
        "problem_framing": "论文首先从实际痛点出发，指出事件抽取任务需要大量高质量标注数据，而这些数据的获取成本极高，限制了模型在新领域和新事件类型上的扩展能力。通过举例说明如ACE 2005数据集的高标注成本，强调了低资源事件抽取的现实需求和研究价值。随后，作者明确提出关注低资源场景下的事件抽取问题，并介绍了其提出的生成式方法DEGREE，作为对现有痛点的回应。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在低资源场景下失效’的逻辑。具体做法包括：一方面，指出主流方法依赖大量标注数据，难以扩展到新领域；另一方面，分析了分类式和生成式方法的局限，如TANL和BART-Gen等生成式方法采用管道式结构，无法充分共享知识，且输出格式不便于利用标签语义。句式上多用‘然而’、‘这些方法不能…’、‘他们的设计并不针对低资源场景’等表达，突出现有方法的不足和本工作填补的空白。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍DEGREE的生成式框架及其优势，随后细致拆解为DEGREE、DEGREE(ED)、DEGREE(EAE)三个子模块，分别对应事件检测和事件参数抽取，并详细说明各自的prompt设计与输出格式。最后补充训练细节和超参数设置，为后续实验做铺垫。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验’的策略。首先说明所用数据集和低资源划分方式，确保实验覆盖广泛场景。随后介绍评价指标和对比基线，包括分类式和生成式方法。主实验聚焦于不同训练数据比例下的性能对比，突出低资源场景下DEGREE的优势。实验结果以表格和可视化图展示，强调在极低数据量下的显著性能提升。"
      },
      {
        "paper_id": "ARR_2022_26",
        "title": "Event Detection for Suicide Understanding",
        "problem_framing": "论文从实际社会痛点出发，指出自杀是一个严重且日益增长的问题，强调现有临床访谈方法在高自杀风险人群中难以获得参与。同时，结合应用需求，提出社交媒体数据作为新的诊断信息来源，并指出自动化分析工具的重要性。通过引入自杀相关事件识别的必要性，逐步聚焦到自然语言处理（NLP）在自杀理解和预防中的作用，最终明确提出事件检测（ED）在该领域的研究价值。",
        "gap_pattern": "论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体而言，指出以往自杀检测工作主要关注用户自杀倾向的整体文本分类，未能细粒度分析和识别自杀相关事件；同时，现有事件检测数据集和方法多针对一般事件类型和正式文本，缺乏针对社交媒体自杀相关事件的专用数据和方法。通过举例和引用，强调了现有方法在特定领域（如社交媒体自杀事件）下的局限性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先介绍了为理解自杀相关话题而进行的主题建模分析（LDA），说明数据处理和分析的总体流程。随后，展示主题分析结果，并将其归纳为学校、工作和家庭三大类，体现了方法的应用和分析深度。整体上，方法部分以数据分析为切入点，突出数据特征和事件来源。",
        "experiments_story": "实验部分采用‘主实验+对比+领域适应’的策略。首先对多种主流事件检测模型进行性能评估，包括CNN、DMBERT、BERTED、BERTGCN、GatedGCN和EEGCN，涵盖了非图模型和图模型。其次，设计了领域自适应实验，通过在Reddit数据上微调BERT，分析领域定制对模型性能的影响。最后，比较不同模型在SuicideED与标准数据集上的表现，突出SuicideED的挑战性，并强调进一步研究的必要性。实验叙述逻辑清晰，层层递进，涵盖模型对比、领域适应和挑战分析。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "50.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "先引入问题和现象，再提出新方法，最后通过实验验证，形成闭环。",
            "type": "writing-level",
            "purpose": "通过问题引入—现象分析—方法提出—实验验证的结构，增强文章逻辑性和阅读流畅性"
          },
          {
            "paper_id": "ARR_2022_296",
            "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
            "description": "从问题引入、方法设计到实验验证，层层递进，前后呼应，确保读者易于跟随论文主线。",
            "type": "writing-level",
            "purpose": "增强论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_26",
            "title": "Event Detection for Suicide Understanding",
            "description": "从问题引入、方法铺垫、实验验证到结论呼应，层层递进，结构清晰。",
            "type": "writing-level",
            "purpose": "提升整体可读性和逻辑性，帮助读者顺畅理解研究流程"
          }
        ]
      },
      {
        "trick_name": "典型案例对比引入",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "作者用DIVORCE和START-POSITION两个事件类型的极端性能差异作为切入点，直观展示现有模型的局限性。",
            "type": "writing-level",
            "purpose": "通过具体例子直观展示现有方法的不足，增强问题的现实感和紧迫性"
          }
        ]
      },
      {
        "trick_name": "数据反常现象强调",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "指出DIVORCE类型训练数据远少于START-POSITION但性能却远高，说明现有方法存在未被关注的问题。",
            "type": "writing-level",
            "purpose": "通过强调数据中不合理现象（如训练集大小与性能不符），突出问题的重要性和研究的必要性"
          }
        ]
      },
      {
        "trick_name": "提出关键科学问题",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "作者提出两个关键问题：如何量化事件模式、如何利用该模式提升模型鲁棒性。",
            "type": "writing-level",
            "purpose": "明确提出核心科学问题，引导读者关注研究主线"
          }
        ]
      },
      {
        "trick_name": "新概念命名与定义",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "首次提出trigger saliency attribution概念，并详细解释其含义和作用。",
            "type": "method-level",
            "purpose": "通过提出新术语（trigger saliency attribution）彰显创新性并方便后续讨论"
          }
        ]
      },
      {
        "trick_name": "类比与可解释方法借鉴",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "借鉴特征归因方法，将每个词视为特征，计算其对事件语义的贡献，帮助读者理解方法原理。",
            "type": "method-level",
            "purpose": "通过借鉴已知的特征归因方法（如Simonyan等），增强方法的可解释性和科学性"
          }
        ]
      },
      {
        "trick_name": "量化指标设计",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "将trigger对事件的贡献量化为saliency value，便于后续分析和模型设计。",
            "type": "method-level",
            "purpose": "通过设计可量化的指标（saliency value），增强方法的科学性和可复现性"
          }
        ]
      },
      {
        "trick_name": "分组检测思想",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "提出按事件模式分组检测而非一刀切，展示方法的差异化优势。",
            "type": "method-level",
            "purpose": "通过将事件类型按模式分组，突出方法的创新性和针对性"
          }
        ]
      },
      {
        "trick_name": "多指标综合评估",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "采用多种指标评估方法，兼顾相关性、整体性能和类别均衡性。",
            "type": "experiment-level",
            "purpose": "通过多种评测指标（Spearman相关、P/R/F1、Macro F1），证明方法评价的全面性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "与现有解释性指标对比",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "将trigger saliency attribution与其他解释性指标进行相关性对比，显示其相关性最高。",
            "type": "experiment-level",
            "purpose": "通过与训练样本数、trigger variance、trigger attention等指标对比，突出自身方法的解释力和优越性"
          }
        ]
      },
      {
        "trick_name": "消融与反直觉现象分析",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "指出训练样本数与性能相关性极低，挑战常规认知，突出新方法的必要性。",
            "type": "experiment-level",
            "purpose": "通过分析训练样本数等常规因素的低相关性，强调现有认知的局限性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "数据集多样性与公开性",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_190",
            "title": "Saliency as Evidence: Event Detection with Trigger Saliency Attribution",
            "description": "在两个主流数据集上进行实验，并公开代码，保证结果的可复现性和广泛适用性。",
            "type": "experiment-level",
            "purpose": "通过在多个数据集（ACE 2005, MAVEN）上实验，增强结论的普适性和说服力"
          }
        ]
      },
      {
        "trick_name": "问题驱动开篇",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_296",
            "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
            "description": "作者首先介绍事件抽取的任务和实际应用，强调高质量标注数据的昂贵成本，提出低资源场景下的挑战，明确研究动机。",
            "type": "writing-level",
            "purpose": "突出实际需求和现有方法的不足，引发读者兴趣"
          }
        ]
      },
      {
        "trick_name": "具体案例引入",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_296",
            "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
            "description": "通过具体的Justice:Execute事件案例，详细说明事件触发词和参与者角色，降低理解门槛。",
            "type": "writing-level",
            "purpose": "帮助读者快速理解任务定义和难点"
          }
        ]
      },
      {
        "trick_name": "方法优势三点式总结",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_296",
            "title": "DEGREE: A Data-Efficient Generation-Based Event Extraction Model",
            "description": "在介绍DEGREE方法时，作者用三点式总结其优势，包括标签语义利用、弱监督信息扩展和端到端能力。",
            "type": "method-level",
            "purpose": "突出方法创新性和实际效果，增强说服力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 6,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_190",
        "ARR_2022_296",
        "ARR_2022_26",
        "ACL_2017_350",
        "ACL_2017_16",
        "COLING_2020_42"
      ]
    }
  },
  {
    "pattern_id": 15,
    "pattern_name": "高质量问题生成技术",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦教育场景下的高质量问题生成，采用QAG系统分步骤设计与SOTA方法对比验证。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引入，通过现有工作局限对比铺垫，专家标注数据集背书增强权威性，分步法流程清晰化提升可解释性，多维度评价体系确保科学性。\n\n第3段（60字）：适用场景与预期效果 - 适用于教育、对话系统等需要高质量问题生成的任务，预期提升模型生成问题的相关性和教育意义。",
    "writing_guide": "写作模板：高质量问题生成技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦教育场景下的高质量问题生成，采用QAG系统分步骤设计与SOTA方法对比验证。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引入，通过现有工作局限对比铺垫，专家标注数据集背书增强权威性，分步法流程清晰化提升可解释性，多维度评价体系确保科学性。\n\n第3段（60字）：适用场景与预期效果 - 适用于教育、对话系统等需要高质量问题生成的任务，预期提升模型生成问题的相关性和教育意义。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset》\n  • 问题定位：论文通过结合学术gap与应用需求来引出问题。首先强调了高质量、大规模阅读理解（RC）数据集对训练先进问答（QA）模型的重要性，指出现有数据集在教育领域应用时存在质量和有效性风险，尤其是在自动化生成QA对用于教育目的时表现不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视关键需求’的逻辑。具体指出现有数据集多为众包或自动检索生成，导致标注QA对的质量和有效性不足，尤其在教育场景下不适用。此外，现有QA模型虽能生成事实正确的QA对，但难以满足教育用途的有效性需求。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了QAG系统的三步流程：答案抽取、问题生成、QA对排序。随后分别详细描述每个步骤的实现方式，包括基于教育学框架的答案抽取、利用SOTA语言模型的问题生成，以及基于阈值的QA对筛选。\n  • 实验设计：实验部分采用‘主实验+多指标验证’的策略。首先明确自动化评估和人工评估两种实验类型，针对QAG任务的特殊性设计了MAP@N指标，详细说明了评估流程和理由。实验在自建数据集FairytaleQA的验证集和测试集上进行，比较了不同QAG系统在不同候选数量阈值下的表现。\n\n示例 2：《A Feasibility Study of Answer-Unaware Question Generation for Education》\n  • 问题定位：论文从实际应用需求出发引出问题，强调编写高质量、针对性强的问题（如测验题）既困难又耗时，自动化问题生成（QG）可以显著减少人工负担。通过描述教育场景下教师和学生的具体痛点（如教师出题慢、学生复习效率低），自然引出对自动化、无需人工标注答案的QG系统的需求。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法依赖于人工选择答案片段'、'在缺乏明确关键术语列表时不适用'等逻辑，指出主流的answer-aware QG模型需要人工高亮答案span，增加了使用门槛和负担，并在某些实际教育场景下不适用。\n  • 核心方法：方法部分采用了'先整体后细节'的叙述顺序。首先介绍了整体思路：借鉴多任务微调（QA+QG+答案抽取）提升模型能力，选择T5模型并说明其任务分离优势。\n  • 实验设计：实验部分采用了'多场景对比验证'的策略，设计了三类输入（原始教材文本、人写摘要、自动摘要）下的主实验，分别评估模型在不同输入条件下的表现。每类实验都详细描述了数据来源、处理方式和生成的QA对数量。\n\n示例 3：《Fantastic Questions and Where to Find Them: FairytaleQA— An Authentic Dataset for Narrative Comprehension》\n  • 问题定位：论文首先从阅读理解作为复杂认知过程的实际教育需求出发，强调高质量问题对于评估和提升学生阅读理解能力的重要性，指出现有问题生成资源和工具难以满足教育场景的精细化需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有数据集不适合/不具备/忽视了’等句式，逻辑上先指出主流数据集未围绕阅读理解子技能结构化设计，缺乏对测试子技能的信息，导致模型只能输出粗粒度分数，无法细致评估；进一步指出现有数据集多由众包工人生成，缺乏教育领域知识，难以保证问题有效性和一致性。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先简要说明FairytaleQA数据集可用于QA和QG任务，随后分别介绍QA任务的评测方法和QG任务的生成流程。QG部分进一步细分为三步：规则生成候选答案、BART生成问题、排序器验证，体现从简单到复杂、逐步细化的叙述顺序。\n  • 实验设计：实验部分采用‘主实验+多模型对比+分任务验证+细粒度分析’的叙述策略。首先对比多种主流预训练模型（BERT, BART, DistilBERT）在QA任务上的表现，确定最佳主干模型。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 现实需求铺垫（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过指出现有QA数据集在教育领域的不足和RC技能对儿童成长的重要性，强调高质量RC数据集的迫切需求。\n\n2. 现有工作局限对比（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：详细列举现有数据集和自动生成方法的缺陷，说明它们在教育领域应用时的不足，为提出新方法做铺垫。\n\n3. 专家标注数据集背书（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：强调FairytaleQA数据集由教育专家标注，并基于教育研究中的理论框架，增强数据集的科学性和适用性。\n\n4. 分步法流程清晰化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将QAG系统流程分为三个步骤（答案抽取、问题生成、QA对排序），用清晰的分步描述帮助读者把握整体架构。\n\n5. 与SOTA方法直接对比（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：明确提出与两种现有SOTA QAG系统进行对比，并在实验部分详细报告对比结果。\n\n6. 定制化评价指标设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：针对QAG任务的特殊性设计MAP@N指标，合理解决不同系统生成QA对数量不一的问题。\n\n7. 多维度评价体系（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：采用自动评价和人工评价相结合，全面考察系统性能。\n\n8. 缺陷自省与改进动机（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：指出Rouge-L指标的局限性，并说明将进一步进行人工评价，体现对实验结论的负责态度。\n\n9. 逻辑递进式叙事（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：从问题引入、现有方法不足、提出新方法、实验验证到结果分析，层层递进，逻辑清晰。\n\n10. 实际应用场景模拟（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：在评价指标选择上考虑实际应用中每段故事平均QA对数量，强调方法与真实教育场景的契合。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_129",
        "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
        "problem_framing": "论文通过结合学术gap与应用需求来引出问题。首先强调了高质量、大规模阅读理解（RC）数据集对训练先进问答（QA）模型的重要性，指出现有数据集在教育领域应用时存在质量和有效性风险，尤其是在自动化生成QA对用于教育目的时表现不足。进一步强调RC技能对儿童成长的关键作用，突出教育领域迫切需要高质量RC数据集的实际痛点，并以此为切入点提出自己的研究目标。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视关键需求’的逻辑。具体指出现有数据集多为众包或自动检索生成，导致标注QA对的质量和有效性不足，尤其在教育场景下不适用。此外，现有QA模型虽能生成事实正确的QA对，但难以满足教育用途的有效性需求。通过引用相关文献和举例，系统性地阐述了现有方法的局限性和未覆盖的需求。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了QAG系统的三步流程：答案抽取、问题生成、QA对排序。随后分别详细描述每个步骤的实现方式，包括基于教育学框架的答案抽取、利用SOTA语言模型的问题生成，以及基于阈值的QA对筛选。方法介绍逻辑清晰，由宏观流程逐步细化到各个模块的具体实现。",
        "experiments_story": "实验部分采用‘主实验+多指标验证’的策略。首先明确自动化评估和人工评估两种实验类型，针对QAG任务的特殊性设计了MAP@N指标，详细说明了评估流程和理由。实验在自建数据集FairytaleQA的验证集和测试集上进行，比较了不同QAG系统在不同候选数量阈值下的表现。整体叙述以主实验为核心，强调指标设计的合理性和实际应用场景的贴合性。"
      },
      {
        "paper_id": "ARR_2022_11",
        "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
        "problem_framing": "论文从实际应用需求出发引出问题，强调编写高质量、针对性强的问题（如测验题）既困难又耗时，自动化问题生成（QG）可以显著减少人工负担。通过描述教育场景下教师和学生的具体痛点（如教师出题慢、学生复习效率低），自然引出对自动化、无需人工标注答案的QG系统的需求。",
        "gap_pattern": "论文批评现有方法时，采用了'现有方法依赖于人工选择答案片段'、'在缺乏明确关键术语列表时不适用'等逻辑，指出主流的answer-aware QG模型需要人工高亮答案span，增加了使用门槛和负担，并在某些实际教育场景下不适用。句式上多用'Previous work has focused primarily on...'、'This adds significant overhead...'等表达，突出方法局限和实际应用中的不足。",
        "method_story": "方法部分采用了'先整体后细节'的叙述顺序。首先介绍了整体思路：借鉴多任务微调（QA+QG+答案抽取）提升模型能力，选择T5模型并说明其任务分离优势。随后分步骤详细描述了三种微调任务的具体实现方式、输入输出格式、数据处理细节（如文本分块、句子边界处理、答案抽取策略等），最后说明了如何利用该模型在answer-unaware场景下生成问题。",
        "experiments_story": "实验部分采用了'多场景对比验证'的策略，设计了三类输入（原始教材文本、人写摘要、自动摘要）下的主实验，分别评估模型在不同输入条件下的表现。每类实验都详细描述了数据来源、处理方式和生成的QA对数量。评测采用人工标注，设置了多维度评价标准（可用性、语法、可解释性、相关性、答案正确性），并对比分析了不同输入下的表现差异，突出方法有效性和适用性。"
      },
      {
        "paper_id": "ARR_2022_95",
        "title": "Fantastic Questions and Where to Find Them: FairytaleQA— An Authentic Dataset for Narrative Comprehension",
        "problem_framing": "论文首先从阅读理解作为复杂认知过程的实际教育需求出发，强调高质量问题对于评估和提升学生阅读理解能力的重要性，指出现有问题生成资源和工具难以满足教育场景的精细化需求。开篇策略结合了实际痛点（题目设计难、耗时、需高质量）、学术gap（缺乏针对阅读理解子技能的数据集）、以及应用需求（教师需细致诊断学生能力、机器阅读理解需高质量数据）三者，层层递进，最终引出构建FairytaleQA数据集的必要性。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有数据集不适合/不具备/忽视了’等句式，逻辑上先指出主流数据集未围绕阅读理解子技能结构化设计，缺乏对测试子技能的信息，导致模型只能输出粗粒度分数，无法细致评估；进一步指出现有数据集多由众包工人生成，缺乏教育领域知识，难以保证问题有效性和一致性。这种批评策略以需求—现状—不足为主线，逐步加深问题严重性。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先简要说明FairytaleQA数据集可用于QA和QG任务，随后分别介绍QA任务的评测方法和QG任务的生成流程。QG部分进一步细分为三步：规则生成候选答案、BART生成问题、排序器验证，体现从简单到复杂、逐步细化的叙述顺序。最后通过对比不同训练集（NarrativeQA vs FairytaleQA）下模型表现，突出新数据集的优势。",
        "experiments_story": "实验部分采用‘主实验+多模型对比+分任务验证+细粒度分析’的叙述策略。首先对比多种主流预训练模型（BERT, BART, DistilBERT）在QA任务上的表现，确定最佳主干模型。随后分别在QA和QG任务上，比较不同训练集（NarrativeQA、FairytaleQA、两者结合）下的模型效果，突出FairytaleQA的提升。进一步分析模型在不同问题类型（如wh-词分布）和七类阅读理解元素上的表现，提供定量和定性分析，展现数据集对模型能力细致提升的作用。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "现实需求铺垫",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "通过指出现有QA数据集在教育领域的不足和RC技能对儿童成长的重要性，强调高质量RC数据集的迫切需求。",
            "type": "writing-level",
            "purpose": "强调研究的实际意义和紧迫性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "现有工作局限对比",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "详细列举现有数据集和自动生成方法的缺陷，说明它们在教育领域应用时的不足，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "突出自身工作的创新性和必要性"
          }
        ]
      },
      {
        "trick_name": "专家标注数据集背书",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "强调FairytaleQA数据集由教育专家标注，并基于教育研究中的理论框架，增强数据集的科学性和适用性。",
            "type": "method-level",
            "purpose": "提升方法和数据集的权威性和说服力"
          }
        ]
      },
      {
        "trick_name": "分步法流程清晰化",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "将QAG系统流程分为三个步骤（答案抽取、问题生成、QA对排序），用清晰的分步描述帮助读者把握整体架构。",
            "type": "method-level",
            "purpose": "提升可解释性，让读者易于理解方法原理"
          }
        ]
      },
      {
        "trick_name": "与SOTA方法直接对比",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "明确提出与两种现有SOTA QAG系统进行对比，并在实验部分详细报告对比结果。",
            "type": "experiment-level",
            "purpose": "证明自身方法的有效性和先进性"
          }
        ]
      },
      {
        "trick_name": "定制化评价指标设计",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "针对QAG任务的特殊性设计MAP@N指标，合理解决不同系统生成QA对数量不一的问题。",
            "type": "experiment-level",
            "purpose": "确保实验评价的科学性和公正性，增强结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "多维度评价体系",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "采用自动评价和人工评价相结合，全面考察系统性能。",
            "type": "experiment-level",
            "purpose": "提升实验的完备性和结论的可信度"
          }
        ]
      },
      {
        "trick_name": "缺陷自省与改进动机",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "指出Rouge-L指标的局限性，并说明将进一步进行人工评价，体现对实验结论的负责态度。",
            "type": "writing-level",
            "purpose": "展现科学严谨态度，增强说服力"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "从问题引入、现有方法不足、提出新方法、实验验证到结果分析，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文的可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "实际应用场景模拟",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_129",
            "title": "It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset",
            "description": "在评价指标选择上考虑实际应用中每段故事平均QA对数量，强调方法与真实教育场景的契合。",
            "type": "experiment-level",
            "purpose": "增强方法的实际价值和适用性"
          }
        ]
      },
      {
        "trick_name": "问题动机引入",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_11",
            "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
            "description": "通过强调手工编写高质量问题的困难和自动生成问题对师生的潜在巨大帮助，突出研究的实际意义。",
            "type": "writing-level",
            "purpose": "引发读者兴趣，强调研究问题的重要性和实际价值"
          }
        ]
      },
      {
        "trick_name": "现有方法局限对比",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_11",
            "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
            "description": "指出以往QG方法依赖于人工选择答案片段，带来额外负担，强调本工作无需此步骤的优势。",
            "type": "writing-level",
            "purpose": "突出自身工作的创新点和必要性"
          }
        ]
      },
      {
        "trick_name": "贡献点列举",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_11",
            "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
            "description": "以条目化方式清晰列出三大贡献，便于读者快速把握创新点。",
            "type": "writing-level",
            "purpose": "明确展示工作的创新性和主要成果"
          }
        ]
      },
      {
        "trick_name": "失败分析",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_11",
            "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
            "description": "明确指出answer-unaware QG模型主要失败在于生成无关或难以理解的问题，显示对方法局限的自省。",
            "type": "experiment-level",
            "purpose": "增强说服力，通过展示模型失败的主要原因，体现分析的深度和科学性"
          }
        ]
      },
      {
        "trick_name": "多条件对比实验设计",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_11",
            "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
            "description": "分别在原始文本、人写摘要和自动摘要三种条件下进行实验，系统比较方法效果。",
            "type": "experiment-level",
            "purpose": "增强实验完备性和对比性，验证方法在不同输入条件下的表现"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 6,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_129",
        "ARR_2022_11",
        "ARR_2022_95",
        "ARR_2022_41",
        "ARR_2022_265",
        "COLING_2020_25"
      ]
    }
  },
  {
    "pattern_id": 16,
    "pattern_name": "Siamese Network与Label Tuning",
    "pattern_summary": "第1段（60字）：针对文本分类任务中的数据稀缺问题，采用Siamese Network和Label Tuning等方法提升效率和鲁棒性。\n第2段（60字）：skeleton以实际痛点开篇，通过对比现有方法指出不足，采用‘先整体后局部’和‘分模块介绍’策略，结合实验多样性与消融分析增强说服力。\n第3段（60字）：适用于低资源文本分类任务，尤其在多语言和细粒度场景下，预期提升模型性能和部署效率。",
    "writing_guide": "写作模板：Siamese Network与Label Tuning\n\n【模板聚焦】\n第1段（60字）：针对文本分类任务中的数据稀缺问题，采用Siamese Network和Label Tuning等方法提升效率和鲁棒性。\n第2段（60字）：skeleton以实际痛点开篇，通过对比现有方法指出不足，采用‘先整体后局部’和‘分模块介绍’策略，结合实验多样性与消融分析增强说服力。\n第3段（60字）：适用于低资源文本分类任务，尤其在多语言和细粒度场景下，预期提升模型性能和部署效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Few-Shot Learning with Siamese Networks and Label Tuning》\n  • 问题定位：论文通过介绍 few-shot 和 zero-shot 学习的实际挑战引出问题，强调在文本分类任务中标注数据稀缺的痛点，并指出近年来相关方法的兴起。开篇策略结合了实际应用需求（数据稀缺带来的挑战）和学术发展趋势（zero-shot/few-shot 方法的兴起），同时用任务定义和方法现状为后文铺垫。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出主流的 Cross Attention（CA）模型虽然理论上分类准确率高，但推理效率低（每个输入需与所有标签组合），部署难度大。其次，强调常规的模型微调方式导致参数无法共享，难以大规模部署。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述顺序。先整体介绍 Siamese Network 的架构和基本原理，再细分为零样本分类的直接应用、few-shot 分类的微调方式（包括常规微调和创新的 Label Tuning），并详细给出优化目标和正则化策略。\n  • 实验设计：实验部分采用‘多基线+多数据集+对比分析’的策略。先介绍多种基线方法（随机、词向量、SVM、CA、SN等），再说明模型训练和数据集设置，涵盖英语及多语言场景。\n\n示例 2：《Incremental Intent Detection for Medical Domain with Contrast Replay Networks》\n  • 问题定位：论文首先从医疗场景的实际应用需求出发，强调医疗意图识别对于医疗问答系统的重要性。随后指出现有方法依赖预定义的固定类别集合，无法应对新意图类别的不断出现，进一步强调存储和计算成本的实际痛点。最后引入增量学习作为解决方案，形成从应用需求到方法创新的自然过渡。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在实际应用中失效’的逻辑。具体指出传统方法无法处理新类别（out-of-set问题），且重新训练不可行。对于主流的记忆回放方法，进一步指出在医疗领域面临‘训练数据不均衡’和‘医疗领域稀有词’两大新挑战，使用‘然而’、‘但是’等转折句式突出不足。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍提出的CRN方法及其三大组成部分，然后分别详细阐述每个模块的功能和作用。描述过程中，先给出整体流程，再逐步细化到模型结构、数据处理、损失函数等细节，逻辑清晰递进。\n  • 实验设计：实验部分采用‘主实验+消融实验+多数据集验证’的策略。首先在两个基准数据集上进行主实验，报告整体准确率和最后一步的表现。随后通过消融实验分别验证方法各组成部分的有效性，分析不同模块对性能的影响。实验指标包括宏平均和微平均，参数设置详细，此外还在附录中补充了额外实验，保证结果的全面性和可靠性。\n\n示例 3：《Ranking-Constrained Learning with Rationales for Text Classification》\n  • 问题定位：论文通过实际应用需求引出问题，强调文本分类在多个现实场景（如法律文档、新闻、社交媒体分析等）中的重要性，并指出在这些场景下标注数据稀缺，人工标注成本高且难以大规模获取。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先回顾了早期和近期的 rationale 利用方法，指出这些方法要么依赖于大量标注数据（如深度学习模型需要大规模数据），要么在特征表达上有限（如仅用 bag-of-words 表示），或者在模型结构上对数据规模有较高要求（如句子级别训练）。\n  • 核心方法：方法部分的具体内容未给出，但从相关工作和实验部分推断，论文采用了先整体后局部的叙述策略。先介绍整体框架（如基于 BERT 的模型及 ranking-constrained loss），再细化到输入处理（如句子级别嵌入、截断策略）、模型结构（如隐藏层设置、激活函数选择）、参数规模和训练细节。\n  • 实验设计：实验部分采用多数据集验证的策略，涵盖了三个不同的数据集。实验流程包括主实验（对比多个 baseline 方法）、参数调优（网格搜索超参数）、学习曲线分析（不同标注预算下的表现）、结果可视化（平均曲线和误差条）、扩展实验（更大标注预算下的趋势验证）。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 与主流方法系统对比（使用频率 2 次，占比 28.6%）\n   类型：experiment-level\n   应用：与Cross Attention、Word Embedding、Char-SVM等主流和经典方法进行系统对比，展示性能。\n\n2. 创新点明确提出（使用频率 2 次，占比 28.6%）\n   类型：method-level\n   应用：明确提出Prompt-based Data Augmentation (PromDA)的核心思想，并强调仅微调soft prompts而非整个模型以避免过拟合。\n\n3. 逻辑递进式叙事结构（使用频率 2 次，占比 28.6%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新方法提出、再到实验验证，层层递进呼应结论。\n\n4. 问题极端化引入（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过介绍few-shot和zero-shot学习的极端情况，强调无标注数据下文本分类的难度和研究价值。\n\n5. 现有方法梳理与定位（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：系统梳理了当前主流的entailment/NLI方法，明确指出其优缺点，为后续提出Siamese Network方法做对比和铺垫。\n\n6. 理论与实践对比预设悬念（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：指出理论上Cross Attention模型应优于Siamese Network，但实际差距很小，激发读者好奇心。\n\n7. 方法优势突出（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：强调Siamese Network支持label embedding预计算，推理时只需一次模型调用，便于大规模部署。\n\n8. 创新点命名与概念化（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：将只微调label embedding的方法命名为Label Tuning (LT)，并系统化描述其流程和优缺点。\n\n9. 实验多样性与完备性（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：选用多种任务、多语言、多数据集进行实验，覆盖topic、情感、主观性等多种文本分类场景。\n\n10. 消融与细粒度分析（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：对比不同label verbalization、不同微调策略（如label tuning与全模型微调），分析性能变化。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_298",
        "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
        "problem_framing": "论文通过介绍 few-shot 和 zero-shot 学习的实际挑战引出问题，强调在文本分类任务中标注数据稀缺的痛点，并指出近年来相关方法的兴起。开篇策略结合了实际应用需求（数据稀缺带来的挑战）和学术发展趋势（zero-shot/few-shot 方法的兴起），同时用任务定义和方法现状为后文铺垫。",
        "gap_pattern": "论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出主流的 Cross Attention（CA）模型虽然理论上分类准确率高，但推理效率低（每个输入需与所有标签组合），部署难度大。其次，强调常规的模型微调方式导致参数无法共享，难以大规模部署。句式上多用“然而”、“但在实际中”、“有某些缺陷”等表达，突出现有方法在效率、可扩展性和部署方面的不足。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述顺序。先整体介绍 Siamese Network 的架构和基本原理，再细分为零样本分类的直接应用、few-shot 分类的微调方式（包括常规微调和创新的 Label Tuning），并详细给出优化目标和正则化策略。每个模块都先给出动机，再介绍具体实现，最后补充技术细节。",
        "experiments_story": "实验部分采用‘多基线+多数据集+对比分析’的策略。先介绍多种基线方法（随机、词向量、SVM、CA、SN等），再说明模型训练和数据集设置，涵盖英语及多语言场景。实验类型包括主实验（不同方法性能对比）、多数据集验证（英语、德语、西班牙语等）、与相关工作对比（如 NatCat），并补充了实现细节和数据来源，突出方法的广泛适用性和鲁棒性。"
      },
      {
        "paper_id": "ARR_2022_43",
        "title": "Incremental Intent Detection for Medical Domain with Contrast Replay Networks",
        "problem_framing": "论文首先从医疗场景的实际应用需求出发，强调医疗意图识别对于医疗问答系统的重要性。随后指出现有方法依赖预定义的固定类别集合，无法应对新意图类别的不断出现，进一步强调存储和计算成本的实际痛点。最后引入增量学习作为解决方案，形成从应用需求到方法创新的自然过渡。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在实际应用中失效’的逻辑。具体指出传统方法无法处理新类别（out-of-set问题），且重新训练不可行。对于主流的记忆回放方法，进一步指出在医疗领域面临‘训练数据不均衡’和‘医疗领域稀有词’两大新挑战，使用‘然而’、‘但是’等转折句式突出不足。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍提出的CRN方法及其三大组成部分，然后分别详细阐述每个模块的功能和作用。描述过程中，先给出整体流程，再逐步细化到模型结构、数据处理、损失函数等细节，逻辑清晰递进。",
        "experiments_story": "实验部分采用‘主实验+消融实验+多数据集验证’的策略。首先在两个基准数据集上进行主实验，报告整体准确率和最后一步的表现。随后通过消融实验分别验证方法各组成部分的有效性，分析不同模块对性能的影响。实验指标包括宏平均和微平均，参数设置详细，此外还在附录中补充了额外实验，保证结果的全面性和可靠性。"
      },
      {
        "paper_id": "ARR_2022_176",
        "title": "Ranking-Constrained Learning with Rationales for Text Classification",
        "problem_framing": "论文通过实际应用需求引出问题，强调文本分类在多个现实场景（如法律文档、新闻、社交媒体分析等）中的重要性，并指出在这些场景下标注数据稀缺，人工标注成本高且难以大规模获取。作者进一步通过具体案例（如法律案件的相关性标注、突发事件的快速响应分析）说明小规模高质量标注的重要性，强调需要更高效的标注利用方式，最终引入利用人类标注时附加的 rationale 信息作为提升模型性能的策略。",
        "gap_pattern": "论文批评现有方法时，采用了对比和局限性分析的逻辑。首先回顾了早期和近期的 rationale 利用方法，指出这些方法要么依赖于大量标注数据（如深度学习模型需要大规模数据），要么在特征表达上有限（如仅用 bag-of-words 表示），或者在模型结构上对数据规模有较高要求（如句子级别训练）。常用句式包括“然而，这些方法仍然需要大量标注数据”、“他们的方法依赖于...”、“现有方法在...方面存在局限”等，突出当前方法在小数据场景下的不足和对数据规模的依赖。",
        "method_story": "方法部分的具体内容未给出，但从相关工作和实验部分推断，论文采用了先整体后局部的叙述策略。先介绍整体框架（如基于 BERT 的模型及 ranking-constrained loss），再细化到输入处理（如句子级别嵌入、截断策略）、模型结构（如隐藏层设置、激活函数选择）、参数规模和训练细节。方法描述中穿插了与现有方法的对比，突出创新点和差异化设计。",
        "experiments_story": "实验部分采用多数据集验证的策略，涵盖了三个不同的数据集。实验流程包括主实验（对比多个 baseline 方法）、参数调优（网格搜索超参数）、学习曲线分析（不同标注预算下的表现）、结果可视化（平均曲线和误差条）、扩展实验（更大标注预算下的趋势验证）。此外，实验细节充分说明了数据处理、模型训练、硬件环境等，确保结果的可复现性和公平性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "与主流方法系统对比",
        "frequency": 2,
        "percentage": "28.6%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "与Cross Attention、Word Embedding、Char-SVM等主流和经典方法进行系统对比，展示性能。",
            "type": "experiment-level",
            "purpose": "突出自身方法的有效性和优势"
          },
          {
            "paper_id": "ARR_2022_47",
            "title": "Label Anchored Contrastive Learning for Language Understanding",
            "description": "与BERT、CE+SCL、LEAM、LSAN等主流方法进行系统性能对比，量化提升幅度。",
            "type": "experiment-level",
            "purpose": "突出方法的性能优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "创新点明确提出",
        "frequency": 2,
        "percentage": "28.6%",
        "examples": [
          {
            "paper_id": "ARR_2022_313",
            "title": "Prompt-based Data Augmentation for Low-Resource NLU Tasks",
            "description": "明确提出Prompt-based Data Augmentation (PromDA)的核心思想，并强调仅微调soft prompts而非整个模型以避免过拟合。",
            "type": "method-level",
            "purpose": "突出方法的新颖性和独特贡献"
          },
          {
            "paper_id": "ARR_2022_47",
            "title": "Label Anchored Contrastive Learning for Language Understanding",
            "description": "明确提出“标签锚定监督对比学习（LaCon）”方法，结合对比学习和标签嵌入优势。",
            "type": "method-level",
            "purpose": "突出工作的新颖性，吸引审稿人关注创新贡献"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "28.6%",
        "examples": [
          {
            "paper_id": "ARR_2022_47",
            "title": "Label Anchored Contrastive Learning for Language Understanding",
            "description": "从问题引入、现有方法分析、创新方法提出、再到实验验证，层层递进呼应结论。",
            "type": "writing-level",
            "purpose": "增强论文整体逻辑性和易读性"
          },
          {
            "paper_id": "ARR_2022_311",
            "title": "Text Smoothing: Enhance Various Data Augmentation Methods on Text Classification Tasks",
            "description": "先引入背景和问题，再介绍方法，最后通过实验验证和对比，形成完整闭环。",
            "type": "writing-level",
            "purpose": "提升整体可读性和逻辑性，帮助读者顺畅理解论文内容"
          }
        ]
      },
      {
        "trick_name": "问题极端化引入",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "通过介绍few-shot和zero-shot学习的极端情况，强调无标注数据下文本分类的难度和研究价值。",
            "type": "writing-level",
            "purpose": "突出研究背景和动机，强调任务的重要性和挑战性"
          }
        ]
      },
      {
        "trick_name": "现有方法梳理与定位",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "系统梳理了当前主流的entailment/NLI方法，明确指出其优缺点，为后续提出Siamese Network方法做对比和铺垫。",
            "type": "writing-level",
            "purpose": "展示对领域现状的掌握，为提出新方法做铺垫"
          }
        ]
      },
      {
        "trick_name": "理论与实践对比预设悬念",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "指出理论上Cross Attention模型应优于Siamese Network，但实际差距很小，激发读者好奇心。",
            "type": "writing-level",
            "purpose": "引发读者兴趣，预设理论与实际效果的反差，吸引继续阅读"
          }
        ]
      },
      {
        "trick_name": "方法优势突出",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "强调Siamese Network支持label embedding预计算，推理时只需一次模型调用，便于大规模部署。",
            "type": "method-level",
            "purpose": "凸显所提方法在效率和部署上的实际优势"
          }
        ]
      },
      {
        "trick_name": "创新点命名与概念化",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "将只微调label embedding的方法命名为Label Tuning (LT)，并系统化描述其流程和优缺点。",
            "type": "method-level",
            "purpose": "强化创新贡献，便于读者记忆和引用"
          }
        ]
      },
      {
        "trick_name": "实验多样性与完备性",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "选用多种任务、多语言、多数据集进行实验，覆盖topic、情感、主观性等多种文本分类场景。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "消融与细粒度分析",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "对比不同label verbalization、不同微调策略（如label tuning与全模型微调），分析性能变化。",
            "type": "experiment-level",
            "purpose": "增强实验说服力，分析方法各部分贡献"
          }
        ]
      },
      {
        "trick_name": "细致方法流程图示",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "通过Figure 1等图示，直观展示Siamese Network整体结构和训练/推理流程。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者快速理解方法流程"
          }
        ]
      },
      {
        "trick_name": "公式化目标函数",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "详细给出batch softmax和label tuning的目标函数公式，便于读者理解和实现。",
            "type": "method-level",
            "purpose": "增强方法的严谨性和可复现性"
          }
        ]
      },
      {
        "trick_name": "正则化与dropout细节补充",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "针对label tuning，补充正则项和dropout实现细节，说明超参数选择和防止过拟合的措施。",
            "type": "method-level",
            "purpose": "展示方法的细致设计，提升可复现性和实用性"
          }
        ]
      },
      {
        "trick_name": "知识蒸馏补偿策略",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "提出用知识蒸馏弥补label tuning性能下降，进一步提升模型实用性。",
            "type": "method-level",
            "purpose": "展现对方法缺陷的应对和提升最终性能的能力"
          }
        ]
      },
      {
        "trick_name": "统一假设模板设计",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_298",
            "title": "Few-Shot Learning with Siamese Networks and Label Tuning",
            "description": "所有模型统一使用同一套label假设模板，部分数据集自定义但保持风格一致，确保对比公平。",
            "type": "experiment-level",
            "purpose": "保证实验公平性和可比性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 7,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_298",
        "ARR_2022_43",
        "ARR_2022_176",
        "ARR_2022_313",
        "ARR_2022_47",
        "ARR_2022_311",
        "COLING_2020_3"
      ]
    }
  },
  {
    "pattern_id": 17,
    "pattern_name": "结构图谱预测方法",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义分析任务中的结构建模难题，采用直接预测结构图谱的方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以学术gap开篇，通过多数据集验证和多指标评估增强实验说服力，常用tricks包括直接对比强基线、多随机种子实验和明确声明创新点。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确结构建模的语义分析任务，如情感分析、依存句法分析和语义角色标注，预期提升结构表示和预测准确性。",
    "writing_guide": "写作模板：结构图谱预测方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义分析任务中的结构建模难题，采用直接预测结构图谱的方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以学术gap开篇，通过多数据集验证和多指标评估增强实验说服力，常用tricks包括直接对比强基线、多随机种子实验和明确声明创新点。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确结构建模的语义分析任务，如情感分析、依存句法分析和语义角色标注，预期提升结构表示和预测准确性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Direct parsing to sentiment graphs》\n  • 问题定位：论文通过介绍结构化情感分析（SSA）任务的定义和复杂性引出问题，强调该任务需要识别句子中的完整情感元组（包括极性表达、持有者、目标和极性），并指出虽然相关语料库已有多年，但现有研究多聚焦于子任务而非整体结构，突出学术上的gap。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法只能处理部分结构或需要信息损失的转换’的逻辑。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述策略。首先简要介绍所采用的PERIN模型及其适应SSA任务的修改，随后说明与现有依存句法分析方法的对比实验设计。方法介绍较为简明，强调模型的整体架构和创新点，细节部分则建议参考原始文献，突出本工作的改进和实验对比的公正性。\n  • 实验设计：实验部分采用‘多数据集验证+多指标评估’的策略。首先说明在四种语言的五个数据集上进行实验，覆盖多领域和多语言，增强结果的普适性。评估指标包括实体抽取的token-level F1和结构级别的图F1（NSF1和SF1），并对比不同编码方式和现有强基线。\n\n示例 2：《Improve Discourse Dependency Parsing with Contextualized Representations》\n  • 问题定位：论文通过强调话语依存分析（DDP）在自然语言理解中的基础性作用及其对下游应用的益处来引出问题，结合实际痛点（如EDU的表示困难、依存关系预测需要全局上下文）和学术gap（现有方法在表示EDU和捕捉上下文信息方面存在挑战），并通过具体实例（如科学摘要中的EDU长度变化和跨句依存）说明现有方法难以...\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在X方面存在不足’的逻辑，如指出传统方法和神经模型在EDU表示和上下文捕捉上不够充分，且未能有效区分句内和句间信息。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略，首先介绍任务分解为依存树构建和关系识别两个子任务，接着以Sent-First框架为主线，说明先句内建树再句间组装的流程。\n  • 实验设计：实验部分采用‘多数据集验证+主实验’的策略，分别在英文和中文两个话语树库上进行实验，涵盖不同语言和文本类型。实验设计围绕主任务（依存预测和关系识别）展开，详细说明数据集统计、评价指标（UAS/LAS）、模型训练细节，并通过对比传统特征工程、LSTM、BERT等多种基线方法，突出新方法的优势。\n\n示例 3：《Auxiliary tasks to boost Biaffine Semantic Dependency Parsing》\n  • 问题定位：论文从任务本身的结构复杂性和决策间高度相关性出发引出问题，强调语义依存分析（SDP）与传统依存句法分析（DP）在结构约束上的不同，指出SDP缺乏树结构约束导致决策间依赖更难处理。这种开篇策略结合了学术gap（结构约束缺失带来的挑战）和实际任务复杂性，聚焦于现有方法在处理依存关系决策相关性上的不足。\n  • 现有研究缺口：论文通过梳理现有方法（如高阶图模型、序列决策模型、biaffine模型等），批评现有方法要么计算复杂度高（如二阶图模型O(n^3)），要么存在错误传播（如序列决策模型），或者决策完全独立（如biaffine模型），未能充分捕捉依存关系间的相互影响。\n  • 核心方法：方法部分采用‘先整体后细节’的策略，首先明确采用简单高效的biaffine架构作为基础（O(n^2)复杂度），然后在此基础上引入辅助任务（auxiliary tasks）以增强模型能力。\n  • 实验设计：实验部分采用‘主实验+消融+多数据集验证’的综合策略。首先在高基线（预训练模型+Biaffine）上测试辅助任务的增益，报告多次重复的宏平均F分数，进行不同辅助任务组合的消融实验。其次，实验覆盖法语和英语两个数据集，检验方法的跨语言适用性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 27.3%）\n   类型：writing-level\n   应用：从问题定义、现有方法不足、提出新方法、详细实验对比到结果分析，层层递进，逻辑清晰。\n\n2. 问题现状对比引入（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过回顾已有方法的不足（如仅关注子任务、依赖中间转换等），引出自身方法直接预测情感图谱的优势和研究动机。\n\n3. 权威数据集覆盖（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：选用多个权威公开数据集（五个数据集、四种语言）进行实验，展示方法的广泛适用性和稳健性。\n\n4. 多指标综合评估（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：采用多种评测指标（token-level F1、NSF1、SF1）全面评估模型性能，突出方法在结构层面和局部抽取上的表现。\n\n5. 与最新强基线直接对比（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：将方法与当前最优的依存句法图模型和注意力模型进行直接对比，并量化性能提升（如SF1提升6.2pp）。\n\n6. 创新点明确声明（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：明确指出本方法为首个直接从文本预测情感图谱、无需启发式中间转换的模型，并借鉴了语义表示领域的最新进展。\n\n7. 方法原理简明转述（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：简要介绍PERIN模型的核心思想和与原始版本的区别，鼓励读者查阅原文获取细节。\n\n8. 多随机种子多次实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：所有模型均采用5个不同随机种子重复实验，报告均值和标准差，减少偶然性影响。\n\n9. 细致的结构性结果分析（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：分别分析不同编码方式在结构级和局部抽取任务上的表现，指出方法主要优势在结构层面。\n\n10. 补充材料指引（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：在正文中指明附录中包含开发集结果和训练细节，方便有需要的读者深入查阅。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_279",
        "title": "Direct parsing to sentiment graphs",
        "problem_framing": "论文通过介绍结构化情感分析（SSA）任务的定义和复杂性引出问题，强调该任务需要识别句子中的完整情感元组（包括极性表达、持有者、目标和极性），并指出虽然相关语料库已有多年，但现有研究多聚焦于子任务而非整体结构，突出学术上的gap。开篇策略以学术gap为主，强调当前方法未能完整建模情感结构，存在信息损失，暗示对更优方法的需求。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法只能处理部分结构或需要信息损失的转换’的逻辑。具体句式如‘so far been few attempts at modeling the full representation, rather focusing on various subcomponents’、‘have to rely on a lossy conversion to bi-lexical dependencies’等，指出依赖转换导致信息丢失，且现有方法在处理嵌套结构和完整图表示时存在局限，强调了方法适用性的不足和结构表达的缺陷。",
        "method_story": "方法部分采用‘先整体后细节’的叙述策略。首先简要介绍所采用的PERIN模型及其适应SSA任务的修改，随后说明与现有依存句法分析方法的对比实验设计。方法介绍较为简明，强调模型的整体架构和创新点，细节部分则建议参考原始文献，突出本工作的改进和实验对比的公正性。",
        "experiments_story": "实验部分采用‘多数据集验证+多指标评估’的策略。首先说明在四种语言的五个数据集上进行实验，覆盖多领域和多语言，增强结果的普适性。评估指标包括实体抽取的token-level F1和结构级别的图F1（NSF1和SF1），并对比不同编码方式和现有强基线。实验内容包含主实验（与主流方法对比）、不同编码方式的消融分析，并在附录中提供开发集结果，体现了全面、细致的实验设计。"
      },
      {
        "paper_id": "ARR_2022_21",
        "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
        "problem_framing": "论文通过强调话语依存分析（DDP）在自然语言理解中的基础性作用及其对下游应用的益处来引出问题，结合实际痛点（如EDU的表示困难、依存关系预测需要全局上下文）和学术gap（现有方法在表示EDU和捕捉上下文信息方面存在挑战），并通过具体实例（如科学摘要中的EDU长度变化和跨句依存）说明现有方法难以满足需求，进一步提出需要更好的上下文表示和分层分析策略。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在X方面存在不足’的逻辑，如指出传统方法和神经模型在EDU表示和上下文捕捉上不够充分，且未能有效区分句内和句间信息。具体句式包括‘不同于句法分析，话语的基本单元难以直接表示’、‘现有方法有时只考虑局部上下文，难以捕捉跨句依存’、‘前人工作虽有进展，但在分层表示和动态捕捉特征方面仍有挑战’等。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述策略，首先介绍任务分解为依存树构建和关系识别两个子任务，接着以Sent-First框架为主线，说明先句内建树再句间组装的流程。随后详细阐述如何在不同层级（句内/句间）分别进行上下文表示和关系识别，并强调模型在每一环节的创新点，如分层BERT微调和序列标注模型的设计。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验’的策略，分别在英文和中文两个话语树库上进行实验，涵盖不同语言和文本类型。实验设计围绕主任务（依存预测和关系识别）展开，详细说明数据集统计、评价指标（UAS/LAS）、模型训练细节，并通过对比传统特征工程、LSTM、BERT等多种基线方法，突出新方法的优势。此外，实验还分析了不同上下文表示策略的效果，体现消融和细粒度对比的思路。"
      },
      {
        "paper_id": "ARR_2022_125",
        "title": "Auxiliary tasks to boost Biaffine Semantic Dependency Parsing",
        "problem_framing": "论文从任务本身的结构复杂性和决策间高度相关性出发引出问题，强调语义依存分析（SDP）与传统依存句法分析（DP）在结构约束上的不同，指出SDP缺乏树结构约束导致决策间依赖更难处理。这种开篇策略结合了学术gap（结构约束缺失带来的挑战）和实际任务复杂性，聚焦于现有方法在处理依存关系决策相关性上的不足。",
        "gap_pattern": "论文通过梳理现有方法（如高阶图模型、序列决策模型、biaffine模型等），批评现有方法要么计算复杂度高（如二阶图模型O(n^3)），要么存在错误传播（如序列决策模型），或者决策完全独立（如biaffine模型），未能充分捕捉依存关系间的相互影响。批评逻辑常用‘yet at the cost of…’‘on the contrary’等转折句式，突出方法的局限性和权衡。",
        "method_story": "方法部分采用‘先整体后细节’的策略，首先明确采用简单高效的biaffine架构作为基础（O(n^2)复杂度），然后在此基础上引入辅助任务（auxiliary tasks）以增强模型能力。方法描述中强调实验配置的统一性（如法语调参、英语复用），并通过组合不同辅助任务探索最优方案，体现了由基础到增强、由单一到组合的逐步展开逻辑。",
        "experiments_story": "实验部分采用‘主实验+消融+多数据集验证’的综合策略。首先在高基线（预训练模型+Biaffine）上测试辅助任务的增益，报告多次重复的宏平均F分数，进行不同辅助任务组合的消融实验。其次，实验覆盖法语和英语两个数据集，检验方法的跨语言适用性。还对辅助任务对预测图结构准确性的影响进行分析，并与当前SOTA方法进行对比，强调方法的鲁棒性和先进性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "27.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "从问题定义、现有方法不足、提出新方法、详细实验对比到结果分析，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_125",
            "title": "Auxiliary tasks to boost Biaffine Semantic Dependency Parsing",
            "description": "从问题引入、现有方法评述、方法提出到实验验证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究动机、方法设计与实验验证的全过程"
          },
          {
            "paper_id": "ARR_2022_65",
            "title": "MuPAD: A Chinese Multi-Domain Predicate-Argument Dataset",
            "description": "先引入任务和现有问题，再提出新数据集和方法，最后通过实验验证，形成清晰的逻辑链条。",
            "type": "writing-level",
            "purpose": "引导读者顺畅理解研究动机、方法和贡献，提升整体可读性"
          }
        ]
      },
      {
        "trick_name": "问题现状对比引入",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "通过回顾已有方法的不足（如仅关注子任务、依赖中间转换等），引出自身方法直接预测情感图谱的优势和研究动机。",
            "type": "writing-level",
            "purpose": "突出当前方法的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "权威数据集覆盖",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "选用多个权威公开数据集（五个数据集、四种语言）进行实验，展示方法的广泛适用性和稳健性。",
            "type": "experiment-level",
            "purpose": "增强实验的完备性和结果的说服力"
          }
        ]
      },
      {
        "trick_name": "多指标综合评估",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "采用多种评测指标（token-level F1、NSF1、SF1）全面评估模型性能，突出方法在结构层面和局部抽取上的表现。",
            "type": "experiment-level",
            "purpose": "证明方法在不同层面上的有效性"
          }
        ]
      },
      {
        "trick_name": "与最新强基线直接对比",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "将方法与当前最优的依存句法图模型和注意力模型进行直接对比，并量化性能提升（如SF1提升6.2pp）。",
            "type": "experiment-level",
            "purpose": "突出方法的优越性和进步幅度"
          }
        ]
      },
      {
        "trick_name": "创新点明确声明",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "明确指出本方法为首个直接从文本预测情感图谱、无需启发式中间转换的模型，并借鉴了语义表示领域的最新进展。",
            "type": "writing-level",
            "purpose": "突出工作的独特性和研究贡献"
          }
        ]
      },
      {
        "trick_name": "方法原理简明转述",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "简要介绍PERIN模型的核心思想和与原始版本的区别，鼓励读者查阅原文获取细节。",
            "type": "method-level",
            "purpose": "降低理解门槛，便于读者快速把握方法核心"
          }
        ]
      },
      {
        "trick_name": "多随机种子多次实验",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "所有模型均采用5个不同随机种子重复实验，报告均值和标准差，减少偶然性影响。",
            "type": "experiment-level",
            "purpose": "提升实验结果的可靠性和可重复性"
          }
        ]
      },
      {
        "trick_name": "细致的结构性结果分析",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "分别分析不同编码方式在结构级和局部抽取任务上的表现，指出方法主要优势在结构层面。",
            "type": "experiment-level",
            "purpose": "帮助读者理解方法优势的具体来源"
          }
        ]
      },
      {
        "trick_name": "补充材料指引",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "在正文中指明附录中包含开发集结果和训练细节，方便有需要的读者深入查阅。",
            "type": "writing-level",
            "purpose": "增强论文的可查证性和细节完备性"
          }
        ]
      },
      {
        "trick_name": "主度量指标强调",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_279",
            "title": "Direct parsing to sentiment graphs",
            "description": "明确指出SF1为主度量指标，并在结果分析中重点突出该指标上的性能提升。",
            "type": "writing-level",
            "purpose": "引导评审关注最能体现方法优势的指标"
          }
        ]
      },
      {
        "trick_name": "问题动机与实例引入",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_21",
            "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
            "description": "作者通过引用具体的科学摘要实例和分析EDU长度、关系分布等实际问题，强调DDP任务的挑战性和现实意义。",
            "type": "writing-level",
            "purpose": "通过具体实例和实际挑战激发读者兴趣，突出问题的重要性和复杂性"
          }
        ]
      },
      {
        "trick_name": "层次化分析框架铺垫",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_21",
            "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
            "description": "作者介绍了将话语分析分为句内和句间两个层次的思路，并用实例说明不同层次需要不同的上下文建模，预设方法创新点。",
            "type": "writing-level",
            "purpose": "为后续方法设计做铺垫，突出分层处理的合理性和必要性"
          }
        ]
      },
      {
        "trick_name": "写作模式与结构分布挖掘",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_21",
            "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
            "description": "作者分析科学摘要常见的写作结构，说明话语关系分布具有规律性，暗示利用结构模式能提升模型表现。",
            "type": "writing-level",
            "purpose": "强调领域知识和结构模式对任务的辅助作用，提升方法的说服力"
          }
        ]
      },
      {
        "trick_name": "方法分解与流程清晰化",
        "frequency": 1,
        "percentage": "9.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_21",
            "title": "Improve Discourse Dependency Parsing with Contextualized Representations",
            "description": "作者将任务分解为依存树构建和关系识别两步，并用流程图（Figure 1）展示模型整体框架。",
            "type": "method-level",
            "purpose": "提升可解释性，让读者清楚理解模型的整体架构和各部分功能"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 11,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_279",
        "ARR_2022_21",
        "ARR_2022_125",
        "ARR_2022_250",
        "ARR_2022_65",
        "ACL_2017_654",
        "ACL_2017_355",
        "COLING_2020_15",
        "COLING_2020_44",
        "COLING_2020_46",
        "COLING_2020_19"
      ]
    }
  },
  {
    "pattern_id": 18,
    "pattern_name": "自解释模型与rationale生成",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨模型解释性，通过设计自解释模型和人类实验验证，聚焦于rationale长度与解释效果的关系。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题导向开篇，结合现有方法不足，常用tricks包括质疑主流假设、引用最新工作、分步阐述方案、对比实验结果等。\n第3段（60字）：适用场景与预期效果 - 适用于NLP任务中模型解释性研究，特别是rationale生成与人类理解相关实验，预期提升解释准确性和模型透明度。",
    "writing_guide": "写作模板：自解释模型与rationale生成\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨模型解释性，通过设计自解释模型和人类实验验证，聚焦于rationale长度与解释效果的关系。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题导向开篇，结合现有方法不足，常用tricks包括质疑主流假设、引用最新工作、分步阐述方案、对比实验结果等。\n第3段（60字）：适用场景与预期效果 - 适用于NLP任务中模型解释性研究，特别是rationale生成与人类理解相关实验，预期提升解释准确性和模型透明度。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Are Shortest Rationales the Best Explanations For Human Understanding?》\n  • 问题定位：论文通过结合实际痛点和学术gap来引出问题。首先强调神经网络在NLP任务中的高性能带来的可解释性需求，指出模型决策的可解释性对用户理解至关重要。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘仅用自动指标而未进行人类评估’的逻辑。具体指出现有自解释模型普遍假定短rationale更易于人类理解，但这一假设缺乏人类实验验证。还强调当前方法主要依赖自动化指标评估，没有系统性地考察rationale长度对人类理解的影响，凸显研究空白。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先介绍典型自解释模型的整体框架，包括输入、mask生成、rationale提取和分类器预测。随后详细分解各模块（identifier、mask生成、rationale提取、classifier），并阐述优化目标和正则化项。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+消融+人类实验’的叙述策略。首先在五个ERASER基准数据集上进行主实验，比较方法与多种基线的端任务预测性能。其次，报告模型与人工注释的一致性（Token-level F1等指标）。再次，进行消融实验分析各模块贡献。\n\n示例 2：《GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers》\n  • 问题定位：论文从学术gap出发引出问题。开篇先强调Transformer模型的卓越表现引发了对其有效性原因的关注，随后聚焦于自注意力机制的解释性分析，并指出围绕注意力权重解释的争议。接着引用最新研究表明仅用注意力权重不足以解释模型行为，提出需引入向量范数，但这些工作仍有不足。\n  • 现有研究缺口：论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y方面受限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后细节、分模块递进’的叙述策略。首先整体说明方法的目标是全局归因分析，强调要覆盖编码器层的所有主要组件。然后对比并扩展已有的norm-based分析，详细介绍如何引入第二层归一化和残差连接，指出与以往工作的区别。接着介绍如何聚合多层归因，详细解释rollout技术及其适配。\n  • 实验设计：实验部分采用‘主实验+消融分析’的策略。首先说明实验设置和所用数据集，随后对比多种归因分析方法，逐步引入不同的编码器层组件，考察各部分对整体性能的贡献（即消融分析）。主要实验是对比不同方法与梯度法的相关性，辅以消融实验分析各组件的影响。\n\n示例 3：《Locally Aggregated Feature Attribution on Natural Language Understanding》\n  • 问题定位：论文从实际应用痛点出发引出问题，强调随着深度学习模型的流行，模型可解释性和理解变得越来越重要。通过举例说明模型理解在特征发现、模型调试和决策信任等方面的关键作用，进一步指出在NLP领域，尽管深度模型表现优异，但其内部机制难以理解，亟需更好的解释方法。整体采用了‘应用需求驱动+现有挑战’的开篇策略。\n  • 现有研究缺口：论文通过对现有方法的系统梳理，指出了两类主流方法的不足：一是模型无关方法（如Shapley值、LIME）虽通用但在高维和复杂模型下计算效率低下；二是模型特定的梯度法虽然高效，但梯度本身噪声大且难以解释，尤其在NLP中由于输入为离散token且参考token难以定义，直接应用存在困难。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述顺序，首先概述提出的LAFA方法的三大步骤（邻居查找、梯度计算、梯度聚合），随后对每一步进行详细分解说明，包括如何在嵌入空间中查找相似文本、如何计算和聚合梯度，并结合动机示例说明每一步的必要性。整体结构清晰，分模块介绍，逻辑递进。\n  • 实验设计：实验部分采用‘主实验+分析实验’的叙述策略。首先在无标签和有标签两种场景下，系统比较所提方法与主流基线（Simple Gradient, Smooth Gradient等）的性能，分析不同邻居数和不同编码层的影响，并通过表格展示结果。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 引用权威文献建立背景（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者在引言中大量引用Vaswani et al., 2017等权威文献，说明Transformer及注意力机制的重要性，为后续研究提供坚实背景。\n\n2. 逻辑递进式叙事结构（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者先提出问题和挑战，再分析现有方法的不足，最后通过实验验证自己的观点，形成完整闭环。\n\n3. 问题反转与质疑主流假设（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者质疑‘最短rationale’是否真的有助于人类理解，提出与主流观点相反的问题，强调现有方法的局限性。\n\n4. 引用最新相关工作（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者广泛引用近年相关文献，说明当前主流做法和存在的不足，为自己的创新点铺垫。\n\n5. 明确提出研究问题（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者直接提出核心研究问题：‘最短rationales真的有助于人类理解吗？’并说明将系统性检验。\n\n6. 分步阐述研究方案（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者将工作分为两步：模型设计与人类实验，条理清晰地介绍整体研究流程。\n\n7. 对比实验结果与直觉（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者指出实验结果与主流直觉（最短rationale最好）相反，强调自身工作的实际意义。\n\n8. 方法模块化分解（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：作者将方法分为identifier和classifier两大模块，分别介绍其功能和优化目标。\n\n9. 公式化与变量定义（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：作者用数学公式详细定义模型流程、优化目标和变量含义。\n\n10. 多层次消融实验（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：作者设计消融实验，分析不同模型组件对最终结果的影响。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_170",
        "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
        "problem_framing": "论文通过结合实际痛点和学术gap来引出问题。首先强调神经网络在NLP任务中的高性能带来的可解释性需求，指出模型决策的可解释性对用户理解至关重要。随后引用近期工作提出“最短且足够”的rationale作为解释，并质疑该假设主要基于直觉而缺乏实证人类研究，进一步指出过短的rationale可能导致信息缺失和误导用户。最后明确提出核心研究问题：最短rationale是否真的有助于人类理解，并设定研究目标。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘仅用自动指标而未进行人类评估’的逻辑。具体指出现有自解释模型普遍假定短rationale更易于人类理解，但这一假设缺乏人类实验验证。还强调当前方法主要依赖自动化指标评估，没有系统性地考察rationale长度对人类理解的影响，凸显研究空白。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先介绍典型自解释模型的整体框架，包括输入、mask生成、rationale提取和分类器预测。随后详细分解各模块（identifier、mask生成、rationale提取、classifier），并阐述优化目标和正则化项。最后说明如何在不同长度水平下生成rationale，为后续实验和人类研究做铺垫。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验+消融+人类实验’的叙述策略。首先在五个ERASER基准数据集上进行主实验，比较方法与多种基线的端任务预测性能。其次，报告模型与人工注释的一致性（Token-level F1等指标）。再次，进行消融实验分析各模块贡献。最后，设计人类实验，考察不同长度rationale对人类准确率和信心的影响，实现自动评估与人类评估的结合。"
      },
      {
        "paper_id": "ARR_2022_314",
        "title": "GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers",
        "problem_framing": "论文从学术gap出发引出问题。开篇先强调Transformer模型的卓越表现引发了对其有效性原因的关注，随后聚焦于自注意力机制的解释性分析，并指出围绕注意力权重解释的争议。接着引用最新研究表明仅用注意力权重不足以解释模型行为，提出需引入向量范数，但这些工作仍有不足。整体策略是通过梳理已有研究的不足和争议，自然引出本文要解决的问题。",
        "gap_pattern": "论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y方面受限’的逻辑。具体表现为：指出以往的norm-based方法只分析了注意力块，忽略了编码器层的其他关键组件（如第二层归一化和残差连接）；现有研究只关注单层归因，缺乏全模型的归因聚合；即使采用跨层聚合，结果在微调模型上仍然很差；梯度法虽更健壮但计算开销大。句式上多用‘however’, ‘whereas’, ‘constrained to’, ‘ignore’等词汇，突出现有方法的局限。",
        "method_story": "方法部分采用‘先整体后细节、分模块递进’的叙述策略。首先整体说明方法的目标是全局归因分析，强调要覆盖编码器层的所有主要组件。然后对比并扩展已有的norm-based分析，详细介绍如何引入第二层归一化和残差连接，指出与以往工作的区别。接着介绍如何聚合多层归因，详细解释rollout技术及其适配。整体顺序是：先提出整体改进思路，再逐步细化每个关键模块的处理方式，最后介绍跨层聚合方法。",
        "experiments_story": "实验部分采用‘主实验+消融分析’的策略。首先说明实验设置和所用数据集，随后对比多种归因分析方法，逐步引入不同的编码器层组件，考察各部分对整体性能的贡献（即消融分析）。主要实验是对比不同方法与梯度法的相关性，辅以消融实验分析各组件的影响。整体上以定量实验为主，通过表格展示相关性指标，突出方法改进的有效性。"
      },
      {
        "paper_id": "ARR_2022_122",
        "title": "Locally Aggregated Feature Attribution on Natural Language Understanding",
        "problem_framing": "论文从实际应用痛点出发引出问题，强调随着深度学习模型的流行，模型可解释性和理解变得越来越重要。通过举例说明模型理解在特征发现、模型调试和决策信任等方面的关键作用，进一步指出在NLP领域，尽管深度模型表现优异，但其内部机制难以理解，亟需更好的解释方法。整体采用了‘应用需求驱动+现有挑战’的开篇策略。",
        "gap_pattern": "论文通过对现有方法的系统梳理，指出了两类主流方法的不足：一是模型无关方法（如Shapley值、LIME）虽通用但在高维和复杂模型下计算效率低下；二是模型特定的梯度法虽然高效，但梯度本身噪声大且难以解释，尤其在NLP中由于输入为离散token且参考token难以定义，直接应用存在困难。批评逻辑为‘现有方法虽有优点，但在实际NLP场景下存在效率或适用性问题’。",
        "method_story": "方法部分采用‘先整体后细节’的叙述顺序，首先概述提出的LAFA方法的三大步骤（邻居查找、梯度计算、梯度聚合），随后对每一步进行详细分解说明，包括如何在嵌入空间中查找相似文本、如何计算和聚合梯度，并结合动机示例说明每一步的必要性。整体结构清晰，分模块介绍，逻辑递进。",
        "experiments_story": "实验部分采用‘主实验+分析实验’的叙述策略。首先在无标签和有标签两种场景下，系统比较所提方法与主流基线（Simple Gradient, Smooth Gradient等）的性能，分析不同邻居数和不同编码层的影响，并通过表格展示结果。实验类型涵盖主实验（与基线方法对比）、参数敏感性分析（邻居数、编码层选择）、以及对有无额外标签场景的适用性分析，体现了多角度验证和细致分析。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_314",
            "title": "GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers",
            "description": "作者在引言中大量引用Vaswani et al., 2017等权威文献，说明Transformer及注意力机制的重要性，为后续研究提供坚实背景。",
            "type": "writing-level",
            "purpose": "通过引用Transformer及相关研究，建立研究背景和可信度"
          },
          {
            "paper_id": "ARR_2022_218",
            "title": "An Empirical Study on Explanations in Out-of-Domain Settings",
            "description": "通过引用Adebayo et al., 2020; Chakrabarty et al., 2019; Popat et al., 2018等权威文献，说明解释性方法在实际应用中的重要性和研究现状。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者相信所研究问题的重要性和相关性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "25.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_319",
            "title": "Logic Traps in Evaluating Attribution Scores",
            "description": "作者先提出问题和挑战，再分析现有方法的不足，最后通过实验验证自己的观点，形成完整闭环。",
            "type": "writing-level",
            "purpose": "提升叙事流畅性，通过问题提出—方法分析—实验验证的结构，增强论文整体逻辑"
          },
          {
            "paper_id": "ARR_2022_201",
            "title": "MPII: Multi-Level Mutual Promotion for Inference and Interpretation",
            "description": "从问题提出、现有方法批判、创新点介绍、方法细节、实验验证到结论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "问题反转与质疑主流假设",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者质疑‘最短rationale’是否真的有助于人类理解，提出与主流观点相反的问题，强调现有方法的局限性。",
            "type": "writing-level",
            "purpose": "激发读者兴趣并突出研究意义，通过质疑主流假设引出自己的研究问题。"
          }
        ]
      },
      {
        "trick_name": "引用最新相关工作",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者广泛引用近年相关文献，说明当前主流做法和存在的不足，为自己的创新点铺垫。",
            "type": "writing-level",
            "purpose": "展示对领域前沿的把握，增强本研究的学术背景和说服力。"
          }
        ]
      },
      {
        "trick_name": "明确提出研究问题",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者直接提出核心研究问题：‘最短rationales真的有助于人类理解吗？’并说明将系统性检验。",
            "type": "writing-level",
            "purpose": "聚焦读者注意力，清晰界定研究目标。"
          }
        ]
      },
      {
        "trick_name": "分步阐述研究方案",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者将工作分为两步：模型设计与人类实验，条理清晰地介绍整体研究流程。",
            "type": "writing-level",
            "purpose": "帮助读者把握研究全貌，降低理解门槛。"
          }
        ]
      },
      {
        "trick_name": "对比实验结果与直觉",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者指出实验结果与主流直觉（最短rationale最好）相反，强调自身工作的实际意义。",
            "type": "writing-level",
            "purpose": "增强实验说服力，通过与直觉或主流观点对比，突出自身发现的重要性。"
          }
        ]
      },
      {
        "trick_name": "方法模块化分解",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者将方法分为identifier和classifier两大模块，分别介绍其功能和优化目标。",
            "type": "method-level",
            "purpose": "提升可解释性，帮助读者理解模型结构和原理。"
          }
        ]
      },
      {
        "trick_name": "公式化与变量定义",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者用数学公式详细定义模型流程、优化目标和变量含义。",
            "type": "method-level",
            "purpose": "提升方法的严谨性和可复现性，便于学术交流。"
          }
        ]
      },
      {
        "trick_name": "多层次消融实验",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者设计消融实验，分析不同模型组件对最终结果的影响。",
            "type": "experiment-level",
            "purpose": "验证各组成部分对整体性能的贡献，增强实验的完备性。"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者在五个主流数据集上进行实验，展示方法的广泛适用性。",
            "type": "experiment-level",
            "purpose": "证明方法的通用性和结论的可靠性。"
          }
        ]
      },
      {
        "trick_name": "与多种基线方法对比",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者选取四种代表性基线方法进行系统对比，量化自身方法的改进幅度。",
            "type": "experiment-level",
            "purpose": "突出自身方法的优越性，增强说服力。"
          }
        ]
      },
      {
        "trick_name": "自动评价与人工评价结合",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者既用自动指标（如F1分数）也用人工标注一致性和人类实验，全面评估方法表现。",
            "type": "experiment-level",
            "purpose": "从多角度验证方法有效性，提升结论的可信度。"
          }
        ]
      },
      {
        "trick_name": "严格控制变量的人类实验设计",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者详细描述了如何随机分配任务、避免学习效应、严格控制参与者变量，保证人类实验的科学性。",
            "type": "experiment-level",
            "purpose": "确保实验结果的有效性，排除混淆因素。"
          }
        ]
      },
      {
        "trick_name": "分级变量设置",
        "frequency": 1,
        "percentage": "12.5%",
        "examples": [
          {
            "paper_id": "ARR_2022_170",
            "title": "Are Shortest Rationales the Best Explanations For Human Understanding?",
            "description": "作者将rationale长度分为五个等级，逐级考察其对人类理解的影响。",
            "type": "experiment-level",
            "purpose": "系统考察rationale长度对结果的影响，支持结论的细致性。"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 8,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_170",
        "ARR_2022_314",
        "ARR_2022_122",
        "ARR_2022_319",
        "ARR_2022_201",
        "ARR_2022_218",
        "ARR_2022_257",
        "ACL_2017_657"
      ]
    }
  },
  {
    "pattern_id": 19,
    "pattern_name": "对抗样本生成与验证",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型在对抗攻击和数据偏差下的脆弱性，采用生成对抗样本和生成式对抗方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过对比实验和多数据集验证方法效果，常用tricks包括引用权威文献、具体案例举例和逻辑递进的叙事结构。\n第3段（60字）：适用场景与预期效果 - 适用于NLP中的对抗攻击检测、数据偏差修正等任务，预期提升模型的鲁棒性和泛化能力，增强实际应用中的可靠性。",
    "writing_guide": "写作模板：对抗样本生成与验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型在对抗攻击和数据偏差下的脆弱性，采用生成对抗样本和生成式对抗方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过对比实验和多数据集验证方法效果，常用tricks包括引用权威文献、具体案例举例和逻辑递进的叙事结构。\n第3段（60字）：适用场景与预期效果 - 适用于NLP中的对抗攻击检测、数据偏差修正等任务，预期提升模型的鲁棒性和泛化能力，增强实际应用中的可靠性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《A Rationale-Centric Framework for Human-in-the-loop Machine Learning》\n  • 问题定位：论文首先从实际痛点出发，指出数据集中的自然伪影（artefacts）和虚假模式（spurious patterns）会导致神经网络模型性能下降，特别是在小样本学习（few-shot learning）场景下问题更为严重。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法存在局限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部、分模块介绍’的叙述策略。首先整体介绍RDL框架包含两个主要模块：静态半事实生成（Static Semi-factual Generation）和动态人工干预修正（Dynamic Human-intervened Correction）。\n  • 实验设计：实验部分采用‘主实验+多数据集验证’的策略。首先明确实验目标和研究问题（如静态半事实生成和动态修正对模型泛化能力的提升），然后在IMDb等数据集上模拟小样本学习场景进行主实验，评估方法在in-distribution和OOD（out-of-distribution）上的表现。\n\n示例 2：《Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning》\n  • 问题定位：论文从实际痛点出发引出问题，首先指出当前主流的深度神经网络（如BERT）在面对精心设计的对抗攻击时性能急剧下降，强调了这一问题在实际NLP应用中的严重性。接着梳理了已有的防御方法（如对抗数据增强、正则化、对抗训练），指出这些方法虽然有效但带来了巨大的计算开销，尤其是在大规模任务上几乎不可行。\n  • 现有研究缺口：论文批评现有方法主要采用了'现有方法在实际大规模任务中效率低下'和'现有方法依赖额外对抗样本'的逻辑。具体句式包括：'然而，生成对抗样本会极大增加训练成本，使得原始对抗训练在大规模NLP任务上几乎不可行'，以及'这些方法仍然依赖于模型自身或额外模块生成对抗样本'。\n  • 核心方法：方法部分采用了'先整体后局部'的叙述策略。首先简要介绍了Flooding-X的核心思想和与现有方法的区别，突出其无需对抗样本且计算成本与常规BERT微调相同的优势。\n  • 实验设计：实验部分采用了'多数据集验证+主实验对比'的策略。首先在五个不同规模和任务类型的数据集上进行了广泛实验，涵盖情感分析、文本蕴含、新闻分类等，验证方法的通用性和有效性。实验对比了Flooding-X与多种主流对抗训练和正则化方法，在多种攻击方式下评估鲁棒性。\n\n示例 3：《Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation》\n  • 问题定位：论文首先介绍了神经机器翻译（NMT）近年来取得的进展，但紧接着指出NMT模型在面对输入微小扰动时表现不稳定，性能大幅下降。通过引用相关文献，强调了对抗样本在NMT中的重要性和挑战，明确指出如何有效生成和利用对抗样本仍是一个开放性问题。\n  • 现有研究缺口：论文批评现有方法时，首先指出传统对抗样本生成方法严格遵循语义保持假设，导致可搜索空间受限。进一步指出，在离散文本数据上进行微小扰动很难保证语义不变，甚至可能改变或颠倒原意，从而破坏了语义保持假设。\n  • 核心方法：方法部分先简要介绍了Masked Language Model（MLM）及其在数据增强中的应用，随后说明了与相关工作的区别。接着，论文分两步展开：先提出对NMT对抗样本的新定义，再详细介绍如何基于Transformer架构的MLM构建双语对抗样本。方法细节包括模型配置、参数设置及评测指标。\n  • 实验设计：实验部分首先区分了人工噪声和自然噪声两类实验场景。人工噪声实验包括删除、交换、插入、源端替换、双端替换五种类型，并在多个噪声比例下进行。自然噪声实验则在实际数据集上测试。实验结果通过BLEU分数和回译BLEU分数进行评估，并与多种基线方法进行对比。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进的叙事结构（使用频率 3 次，占比 21.4%）\n   类型：writing-level\n   应用：先引入问题、再分析现有方法不足、提出新方法、详细分模块介绍、最后通过多维实验验证，结构严谨、层层递进。\n\n2. 与主流方法系统对比（使用频率 3 次，占比 21.4%）\n   类型：experiment-level\n   应用：在实验部分系统性地与FGM、FreeLB++、ADA、ASCC、DNE等多种方法进行对比，展示GAT的优越性。\n\n3. 对比实验设计（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：设置多组对比实验（如Static, Static+n, Duplication, Full等），并在多个数据集和场景下评测，突出新方法的性能提升。\n\n4. 多维度评价指标（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：引入Clean%、Aua%、Suc%、#Query等多项指标，全面评估模型在干净和对抗样本下的表现。\n\n5. 多数据集覆盖（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：在五个不同规模和任务的数据集上进行实验，展示方法的普适性和稳定性。\n\n6. 引用权威工作增强可信度（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：大量引用BERT、PGD、TextAttack等主流工作，增强论述的学术权威性。\n\n7. 引用权威文献建立背景（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：在引言部分大量引用NMT和对抗样本相关的经典文献，说明问题的重要性和研究的前沿性。\n\n8. 逻辑递进式叙事结构（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新点提出、方法描述到实验验证，层层递进，结构清晰。\n\n9. 领域差异强调（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：作者强调图像和NLP领域输入的本质差异，指出已有图像领域的对抗样本研究难以直接迁移到NLP领域，突出研究空白。\n\n10. 现实动机引入（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：通过强调对话系统在实际应用中面临的安全与鲁棒性挑战，强调攻击和防御研究的现实意义。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_252",
        "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
        "problem_framing": "论文首先从实际痛点出发，指出数据集中的自然伪影（artefacts）和虚假模式（spurious patterns）会导致神经网络模型性能下降，特别是在小样本学习（few-shot learning）场景下问题更为严重。通过具体举例（如 Figure 1 中的短语）说明这一问题对模型泛化能力的影响，强调在实际应用中标注数据昂贵，未标注数据丰富，进一步凸显问题的现实紧迫性。随后引出已有研究尝试通过数据增强等方式缓解该问题，为提出新方法做铺垫。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法存在局限’的逻辑。具体包括：1）人工生成反事实数据（counterfactuals）成本高昂且耗时；2）全自动方法虽然高效但通常是任务相关的（task-specific），跨领域鲁棒性和可靠性较差；3）已有方法在识别关键特征（rationales）时依赖情感词典匹配，缺乏通用性和相关性。通过这些批评，论文强调现有方法在效率、泛化性和标注方式上的不足，明确自身工作的创新空间。",
        "method_story": "方法部分采用‘先整体后局部、分模块介绍’的叙述策略。首先整体介绍RDL框架包含两个主要模块：静态半事实生成（Static Semi-factual Generation）和动态人工干预修正（Dynamic Human-intervened Correction）。随后分别详细说明每个模块的流程和关键技术点，包括人工标注rationales、同义词替换生成增强样本、模型自动检测rationales并由人工校正等。每一步都结合具体操作和流程，层层递进，逻辑清晰。",
        "experiments_story": "实验部分采用‘主实验+多数据集验证’的策略。首先明确实验目标和研究问题（如静态半事实生成和动态修正对模型泛化能力的提升），然后在IMDb等数据集上模拟小样本学习场景进行主实验，评估方法在in-distribution和OOD（out-of-distribution）上的表现。实验设计包括不同增强样本数量的对比（消融思想），并在多个数据集（SemEval-2017, SST-2, Yelp, Amazon）上进行验证，突出方法的有效性和泛化能力。"
      },
      {
        "paper_id": "ARR_2022_145",
        "title": "Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning",
        "problem_framing": "论文从实际痛点出发引出问题，首先指出当前主流的深度神经网络（如BERT）在面对精心设计的对抗攻击时性能急剧下降，强调了这一问题在实际NLP应用中的严重性。接着梳理了已有的防御方法（如对抗数据增强、正则化、对抗训练），指出这些方法虽然有效但带来了巨大的计算开销，尤其是在大规模任务上几乎不可行。通过突出实际应用中的效率和可扩展性需求，进一步引出对更高效、无需额外对抗样本的新方法的需求。",
        "gap_pattern": "论文批评现有方法主要采用了'现有方法在实际大规模任务中效率低下'和'现有方法依赖额外对抗样本'的逻辑。具体句式包括：'然而，生成对抗样本会极大增加训练成本，使得原始对抗训练在大规模NLP任务上几乎不可行'，以及'这些方法仍然依赖于模型自身或额外模块生成对抗样本'。此外，论文还指出部分方法需要大量超参数搜索，进一步增加了实际应用难度。",
        "method_story": "方法部分采用了'先整体后局部'的叙述策略。首先简要介绍了Flooding-X的核心思想和与现有方法的区别，突出其无需对抗样本且计算成本与常规BERT微调相同的优势。随后，详细解释了Flooding方法的原理，并引出Flooding-X如何通过引入梯度一致性（gradient accordance）作为关键判据，自动确定超参数。最后，对比和介绍了与Flooding-X进行对比的其他主流对抗训练和正则化方法，为后续实验做铺垫。",
        "experiments_story": "实验部分采用了'多数据集验证+主实验对比'的策略。首先在五个不同规模和任务类型的数据集上进行了广泛实验，涵盖情感分析、文本蕴含、新闻分类等，验证方法的通用性和有效性。实验对比了Flooding-X与多种主流对抗训练和正则化方法，在多种攻击方式下评估鲁棒性。评测指标全面，包括干净准确率、对抗准确率、攻击成功率和查询次数。实验结果详细分析了Flooding-X在不同数据集和攻击方式下的表现，并讨论了其在小数据集和大数据集上的差异表现。"
      },
      {
        "paper_id": "ARR_2022_55",
        "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
        "problem_framing": "论文首先介绍了神经机器翻译（NMT）近年来取得的进展，但紧接着指出NMT模型在面对输入微小扰动时表现不稳定，性能大幅下降。通过引用相关文献，强调了对抗样本在NMT中的重要性和挑战，明确指出如何有效生成和利用对抗样本仍是一个开放性问题。整体采用了从实际痛点出发，并结合学术研究现状（open question）的策略引出问题。",
        "gap_pattern": "论文批评现有方法时，首先指出传统对抗样本生成方法严格遵循语义保持假设，导致可搜索空间受限。进一步指出，在离散文本数据上进行微小扰动很难保证语义不变，甚至可能改变或颠倒原意，从而破坏了语义保持假设。随后，论文介绍了Zhang等人提出的新定义，虽然突破了语义保持的限制，但也存在两个潜在问题：一是回译涉及两个阶段，难以确定性能下降的具体来源，二是未提供生成双语对抗样本的具体方法。整体采用了‘现有方法存在限制/不足’、‘在X场景下存在问题’、‘缺乏Y能力’等批评逻辑。",
        "method_story": "方法部分先简要介绍了Masked Language Model（MLM）及其在数据增强中的应用，随后说明了与相关工作的区别。接着，论文分两步展开：先提出对NMT对抗样本的新定义，再详细介绍如何基于Transformer架构的MLM构建双语对抗样本。方法细节包括模型配置、参数设置及评测指标。整体采用了‘先总体思路，后细节实现’的顺序，并对比了与现有方法的不同点。",
        "experiments_story": "实验部分首先区分了人工噪声和自然噪声两类实验场景。人工噪声实验包括删除、交换、插入、源端替换、双端替换五种类型，并在多个噪声比例下进行。自然噪声实验则在实际数据集上测试。实验结果通过BLEU分数和回译BLEU分数进行评估，并与多种基线方法进行对比。整体采用了‘多类型噪声、多数据集、多指标’的综合验证策略，突出方法的鲁棒性和有效性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进的叙事结构",
        "frequency": 3,
        "percentage": "21.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_252",
            "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
            "description": "先引入问题、再分析现有方法不足、提出新方法、详细分模块介绍、最后通过多维实验验证，结构严谨、层层递进。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_109",
            "title": "On Length Divergence Bias in Textual Matching Models",
            "description": "依次介绍背景、问题、方法、实验和结论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题提出、方法设计、实验验证到结论的全过程"
          },
          {
            "paper_id": "ARR_2022_74",
            "title": "Detection of Adversarial Examples in NLP: Benchmark and Baseline via Robust Density Estimation",
            "description": "从问题引入、现有方法不足、提出新方法、实验验证到结果分析，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "与主流方法系统对比",
        "frequency": 3,
        "percentage": "21.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_16",
            "title": "Improving Robustness of Language Models from a Geometry-aware Perspective",
            "description": "在实验部分系统性地与FGM、FreeLB++、ADA、ASCC、DNE等多种方法进行对比，展示GAT的优越性。",
            "type": "experiment-level",
            "purpose": "突出方法优势，增强说服力"
          },
          {
            "paper_id": "ARR_2022_74",
            "title": "Detection of Adversarial Examples in NLP: Benchmark and Baseline via Robust Density Estimation",
            "description": "在方法部分详细介绍对比方法（FGWS, PPL, MLE），并在实验中系统比较各方法的性能。",
            "type": "experiment-level",
            "purpose": "通过与现有方法直接对比，突出自身方法的优越性"
          },
          {
            "paper_id": "ARR_2022_172",
            "title": "A Study of the Attention Abnormality in Trojaned BERTs",
            "description": "与CV和NLP领域的多种主流Trojan检测方法进行系统对比，展示本方法的性能优势。",
            "type": "experiment-level",
            "purpose": "凸显方法的优越性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "对比实验设计",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_252",
            "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
            "description": "设置多组对比实验（如Static, Static+n, Duplication, Full等），并在多个数据集和场景下评测，突出新方法的性能提升。",
            "type": "experiment-level",
            "purpose": "证明方法的有效性和优越性"
          },
          {
            "paper_id": "ARR_2022_106",
            "title": "Robust Conversational Agents against Imperceptible Toxicity Triggers",
            "description": "与UAT、UAT-LM等现有方法进行系统对比，量化不同方法的攻击效果。",
            "type": "experiment-level",
            "purpose": "突出方法有效性和新颖性，通过对比证明优势"
          }
        ]
      },
      {
        "trick_name": "多维度评价指标",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_145",
            "title": "Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning",
            "description": "引入Clean%、Aua%、Suc%、#Query等多项指标，全面评估模型在干净和对抗样本下的表现。",
            "type": "experiment-level",
            "purpose": "从不同角度证明方法的有效性和鲁棒性"
          },
          {
            "paper_id": "ARR_2022_55",
            "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
            "description": "不仅报告常规BLEU，还引入RTT BLEU等指标，展示模型在不同评价维度下的表现。",
            "type": "experiment-level",
            "purpose": "提升实验说服力和科学性"
          }
        ]
      },
      {
        "trick_name": "多数据集覆盖",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_145",
            "title": "Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning",
            "description": "在五个不同规模和任务的数据集上进行实验，展示方法的普适性和稳定性。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性与结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_106",
            "title": "Robust Conversational Agents against Imperceptible Toxicity Triggers",
            "description": "选用Wiki和Reddit两个数据集，覆盖中性和敏感话题，增强实验广度。",
            "type": "experiment-level",
            "purpose": "提升实验的代表性和完备性"
          }
        ]
      },
      {
        "trick_name": "引用权威工作增强可信度",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_145",
            "title": "Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning",
            "description": "大量引用BERT、PGD、TextAttack等主流工作，增强论述的学术权威性。",
            "type": "writing-level",
            "purpose": "借助领域内权威文献为方法和分析背书"
          },
          {
            "paper_id": "ARR_2022_317",
            "title": "Exposing the Limits of Video-Text Models through Contrast Sets",
            "description": "多次引用CLIP、T5、SentBERT等权威模型和相关研究，说明方法建立在可靠基础之上。",
            "type": "writing-level",
            "purpose": "借助领域内已有成果为自身方法背书，提升说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_55",
            "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
            "description": "在引言部分大量引用NMT和对抗样本相关的经典文献，说明问题的重要性和研究的前沿性。",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用领域内权威文献展示方法的研究基础和重要性"
          },
          {
            "paper_id": "ARR_2022_16",
            "title": "Improving Robustness of Language Models from a Geometry-aware Perspective",
            "description": "在引言部分引用了大量经典和最新文献，展示DNN在NLP中的成功及其脆弱性，强调对抗攻击的现实威胁。",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用大量权威文献说明问题的普遍性和重要性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_55",
            "title": "Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation",
            "description": "从问题引入、现有方法分析、创新点提出、方法描述到实验验证，层层递进，结构清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_172",
            "title": "A Study of the Attention Abnormality in Trojaned BERTs",
            "description": "先引入问题和挑战，再提出方法，最后通过实验验证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题、方法和结论，提升论文整体可读性"
          }
        ]
      },
      {
        "trick_name": "领域差异强调",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_77",
            "title": "Residue-Based Natural Language Adversarial Attack Detection",
            "description": "作者强调图像和NLP领域输入的本质差异，指出已有图像领域的对抗样本研究难以直接迁移到NLP领域，突出研究空白。",
            "type": "writing-level",
            "purpose": "突出问题的重要性和研究的必要性，增强说服力和新颖性"
          },
          {
            "paper_id": "ARR_2022_172",
            "title": "A Study of the Attention Abnormality in Trojaned BERTs",
            "description": "指出CV领域已有进展，而NLP领域由于输入离散等原因，现有方法难以迁移，强调了NLP领域的独特挑战和研究空白。",
            "type": "writing-level",
            "purpose": "突出NLP领域Trojan攻击的研究空白，凸显本文工作的必要性"
          }
        ]
      },
      {
        "trick_name": "现实动机引入",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_106",
            "title": "Robust Conversational Agents against Imperceptible Toxicity Triggers",
            "description": "通过强调对话系统在实际应用中面临的安全与鲁棒性挑战，强调攻击和防御研究的现实意义。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者意识到问题的重要性和现实影响"
          },
          {
            "paper_id": "ARR_2022_134",
            "title": "Identifying and Mitigating Spurious Correlations for Improving Robustness in NLP Models",
            "description": "通过指出深度学习模型在实际应用中对分布外数据和对抗攻击的脆弱性，强调现有方法的不足，突出研究的现实意义。",
            "type": "writing-level",
            "purpose": "强调问题的重要性和现实影响，增强说服力"
          }
        ]
      },
      {
        "trick_name": "问题背景铺垫",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_109",
            "title": "On Length Divergence Bias in Textual Matching Models",
            "description": "通过引用多个NLP应用场景和相关文献，强调文本匹配任务的广泛应用和研究价值。",
            "type": "writing-level",
            "purpose": "让读者理解任务的重要性和研究背景，建立共识"
          },
          {
            "paper_id": "ARR_2022_172",
            "title": "A Study of the Attention Abnormality in Trojaned BERTs",
            "description": "通过介绍DNNs在安全性上的脆弱性（如对Trojan攻击的易感），强调该问题的现实危害和研究价值。",
            "type": "writing-level",
            "purpose": "让读者理解问题的重要性和紧迫性，增强研究的现实意义"
          }
        ]
      },
      {
        "trick_name": "问题重要性强调",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_74",
            "title": "Detection of Adversarial Examples in NLP: Benchmark and Baseline via Robust Density Estimation",
            "description": "通过强调NLP领域对抗样本检测的重要性及其与实际应用（如评论分析、新闻分类）的关联，论证检测对抗样本的必要性。",
            "type": "writing-level",
            "purpose": "突出研究问题的实际意义和紧迫性，吸引读者关注"
          },
          {
            "paper_id": "ARR_2022_317",
            "title": "Exposing the Limits of Video-Text Models through Contrast Sets",
            "description": "通过强调视频文本关联任务的复杂性和实际应用难度，说明该领域的重要性和未解决的问题。",
            "type": "writing-level",
            "purpose": "突出任务的挑战性和研究价值，吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "引用权威文献引入问题",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_252",
            "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
            "description": "通过引用多篇权威文献（如Gururangan et al., 2018; Keith et al., 2020等），说明数据集中的spurious patterns和natural artefacts会导致模型性能下降，强调问题的现实性和紧迫性。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者相信问题的普遍性和重要性"
          }
        ]
      },
      {
        "trick_name": "具体案例举例说明",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_252",
            "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
            "description": "用‘100% bad’、‘brain cell killing’等具体短语，结合图示，区分rationales和spurious patterns，使问题和方法直观易懂。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者直观理解抽象概念"
          }
        ]
      },
      {
        "trick_name": "对现有方法的优缺点评述",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_252",
            "title": "A Rationale-Centric Framework for Human-in-the-loop Machine Learning",
            "description": "系统梳理手工和自动counterfactual数据增强的优缺点，强调现有方法的高成本或泛化性差，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "突出新方法的必要性和创新性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 14,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_252",
        "ARR_2022_145",
        "ARR_2022_55",
        "ARR_2022_353",
        "ARR_2022_77",
        "ARR_2022_106",
        "ARR_2022_109",
        "ARR_2022_134",
        "ARR_2022_4",
        "ARR_2022_16",
        "ARR_2022_74",
        "ARR_2022_317",
        "ARR_2022_172",
        "ARR_2022_111"
      ]
    }
  },
  {
    "pattern_id": 20,
    "pattern_name": "多语言预训练迁移学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨语言迁移中的数据稀缺和方法局限，采用多语言预训练模型和数据选择策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过文献回顾定位gap，方法部分采用整体到细节的叙述，实验设计多任务多语言覆盖。\n第3段（60字）：适用场景与预期效果 - 适合低资源语言的NLP任务，预期提升迁移性能和泛化能力，增强模型在未见数据上的表现。",
    "writing_guide": "写作模板：多语言预训练迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨语言迁移中的数据稀缺和方法局限，采用多语言预训练模型和数据选择策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过文献回顾定位gap，方法部分采用整体到细节的叙述，实验设计多任务多语言覆盖。\n第3段（60字）：适用场景与预期效果 - 适合低资源语言的NLP任务，预期提升迁移性能和泛化能力，增强模型在未见数据上的表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer》\n  • 问题定位：论文从实际痛点出发引入问题，强调全球语言资源极度不均衡，绝大多数语言缺乏任务相关的标注数据。通过引用权威数据（如95%的语言几乎没有标注数据）和文献，凸显了跨语言零样本迁移的现实需求和挑战，明确提出了当前NLP领域面临的资源瓶颈和应用需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视了实际应用中的关键问题’的逻辑。具体指出零样本迁移在语言类型差异大或目标语言无足够无标注数据时效果不佳，并且收集大规模目标语言标注数据既昂贵又耗时。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略，先介绍跨语言迁移和数据选择的总体框架，再逐步细化到具体的数据采样技术和参数设置。方法描述聚焦于如何在有限标注样本下优化训练数据选择，强调与主动学习和领域自适应等相关技术的联系，并明确本研究仅进行一次采样迭代以适应少量样本的实际场景。\n  • 实验设计：实验部分采用‘多任务、多语言、多参数’的主实验验证策略。首先在多语言（20种语言，涵盖不同语系）和多任务（序列标注、分类）上进行主实验，细致比较不同采样策略的效果。实验按迁移难度分组（C1、C2、C3），并报告不同参数设置下的性能提升。\n\n示例 2：《Cross-Lingual Event Detection via Optimized Adversarial Training》\n  • 问题定位：论文从学术gap出发引出问题。开篇先简要介绍事件检测（ED）的定义和重要性，指出其在信息抽取领域的地位和挑战，随后强调当前研究主要集中在单语（monolingual）场景，跨语种事件检测（CLED）则面临更多独特挑战，如触发词在不同语言中的表达差异、语义歧义等。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法在Y场景下失效”和“现有方法忽视了X”两种逻辑。具体表现为：指出大多数已有工作局限于单语环境，忽视了跨语种场景下的特殊挑战；即使是采用多语种预训练模型（如mBERT）的跨语种方法，也无法有效应对触发词表达差异和语义歧义等难点。\n  • 核心方法：方法部分采用“先整体后局部”的叙述策略。首先简要介绍了当前最优基线模型BERT-CRF的整体架构和工作流程，作为对比基础。随后，详细描述了作者提出的OACLED模型的核心创新点——如何利用目标语言的无标注数据，通过优化的对抗性训练提升模型的语言无关性。\n  • 实验设计：实验部分采用“多数据集、多语言对主实验验证”的策略。首先说明实验覆盖8种语言对，涉及ACE05和ACE05-ERE两个数据集，体现方法的广泛适用性。实验对比了两个强基线（BERT-CRF和XLM-R-CRF），并在所有语言对上报告平均结果，突出方法的稳定性和普适性。\n\n示例 3：《Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages》\n  • 问题定位：论文首先从实际痛点出发，指出当前自然语言处理任务普遍依赖于有标注数据的微调方法，但许多语言（尤其是低资源语言）缺乏任务相关的标注数据，导致主流方法难以应用。接着，论文引出跨语言微调作为潜在解决方案，并进一步指出评估跨语言泛化能力时常用的做法和其局限性，为后续问题展开铺垫。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法存在隐含假设'和'现有方法覆盖不全'的逻辑。具体地，指出现有跨语言评测通常只用英语作为源语言，隐含了英语具有代表性这一假设，但实际不同源-目标语言之间的相似性会影响迁移效果。\n  • 核心方法：方法部分采用了'先整体后细节'的叙述策略。首先整体描述了实验设计：在不同源-目标语言组合上微调预训练模型，形成一个大规模准确率矩阵。\n  • 实验设计：实验部分以主实验为核心，采用可视化（热力图）展示所有源-目标语言组合的准确率，突出单语与跨语表现的差异。随后，进行定量分析，通过混合效应回归模型评估不同预测因子的贡献，并报告模型解释度（R2）和各随机效应的方差分解。整体策略为：主实验+可视化+统计建模分析，强调对跨语言迁移表现的系统性和多角度解释。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 创新点突出（使用频率 3 次，占比 23.1%）\n   类型：method-level\n   应用：提出针对few-shot跨语言迁移的数据选择策略，并说明与传统主动学习的区别（如仅一轮选择）。\n\n2. 逻辑递进式叙事结构（使用频率 3 次，占比 23.1%）\n   类型：writing-level\n   应用：先提出问题、梳理现状，再介绍方法，最后系统实验并回扣前述问题，形成完整闭环。\n\n3. 引用权威工作（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：通过引用Conneau et al., Devlin et al.等权威文献，说明本工作与主流研究接轨，增强说服力。\n\n4. 逻辑递进式结构（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：从问题提出、现有不足、方法设计到实验验证，层层递进，逻辑清晰。\n\n5. 问题动机强化（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：通过强调多语言数据标注的高成本和实际困难，明确提出研究动机和现实背景，吸引读者关注问题的重要性。\n\n6. 现有方法局限性对比（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：作者详细分析了现有方法（如依赖外部知识库、难以获取等）的局限性，为提出新方法做铺垫。\n\n7. 数据稀缺性强调（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：通过引用权威数据（如95%的语言缺乏标注数据），强调跨语言资源分布极度不均，凸显研究的现实意义。\n\n8. 文献回顾与现有方法梳理（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：系统回顾了跨语言迁移、主动学习和数据选择相关的经典文献，说明已有方法的局限和本工作的切入点。\n\n9. 问题分层与归类（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：将语言按迁移难度分为C1、C2、C3等组，明确不同组的挑战和方法适用性。\n\n10. 参数敏感性分析（使用频率 1 次，占比 7.7%）\n   类型：experiment-level\n   应用：通过实验报告不同参数（λ和γ）设置下的效果，说明方法对参数的敏感性和最佳配置。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_20",
        "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
        "problem_framing": "论文从实际痛点出发引入问题，强调全球语言资源极度不均衡，绝大多数语言缺乏任务相关的标注数据。通过引用权威数据（如95%的语言几乎没有标注数据）和文献，凸显了跨语言零样本迁移的现实需求和挑战，明确提出了当前NLP领域面临的资源瓶颈和应用需求。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视了实际应用中的关键问题’的逻辑。具体指出零样本迁移在语言类型差异大或目标语言无足够无标注数据时效果不佳，并且收集大规模目标语言标注数据既昂贵又耗时。通过引用相关文献和实验结果，强调了现有方法的局限性，并提出需要更高效的数据选择和标注策略来弥补迁移性能的不足。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略，先介绍跨语言迁移和数据选择的总体框架，再逐步细化到具体的数据采样技术和参数设置。方法描述聚焦于如何在有限标注样本下优化训练数据选择，强调与主动学习和领域自适应等相关技术的联系，并明确本研究仅进行一次采样迭代以适应少量样本的实际场景。",
        "experiments_story": "实验部分采用‘多任务、多语言、多参数’的主实验验证策略。首先在多语言（20种语言，涵盖不同语系）和多任务（序列标注、分类）上进行主实验，细致比较不同采样策略的效果。实验按迁移难度分组（C1、C2、C3），并报告不同参数设置下的性能提升。实验还包含对比基线（RAND、DCE）、不同采样方法（PE、LE）、不同样本数量（k值变化）以及针对特定任务（NER、POS、XNLI）的细致分析，体现了系统性和全面性。"
      },
      {
        "paper_id": "ARR_2022_169",
        "title": "Cross-Lingual Event Detection via Optimized Adversarial Training",
        "problem_framing": "论文从学术gap出发引出问题。开篇先简要介绍事件检测（ED）的定义和重要性，指出其在信息抽取领域的地位和挑战，随后强调当前研究主要集中在单语（monolingual）场景，跨语种事件检测（CLED）则面临更多独特挑战，如触发词在不同语言中的表达差异、语义歧义等。通过举例说明这些跨语言难题，进一步引出当前方法在跨语种场景下的不足，明确提出需要更有效的跨语种事件检测方法。",
        "gap_pattern": "论文批评现有方法时，采用了“现有方法在Y场景下失效”和“现有方法忽视了X”两种逻辑。具体表现为：指出大多数已有工作局限于单语环境，忽视了跨语种场景下的特殊挑战；即使是采用多语种预训练模型（如mBERT）的跨语种方法，也无法有效应对触发词表达差异和语义歧义等难点。此外，论文还指出已有的对抗性训练等方法在利用无标注数据和优化语言无关特性方面存在不足，强调自身方法的改进点。",
        "method_story": "方法部分采用“先整体后局部”的叙述策略。首先简要介绍了当前最优基线模型BERT-CRF的整体架构和工作流程，作为对比基础。随后，详细描述了作者提出的OACLED模型的核心创新点——如何利用目标语言的无标注数据，通过优化的对抗性训练提升模型的语言无关性。方法介绍中，先给出整体损失函数，再解释各部分的作用，突出自身方法与基线的区别和优势。",
        "experiments_story": "实验部分采用“多数据集、多语言对主实验验证”的策略。首先说明实验覆盖8种语言对，涉及ACE05和ACE05-ERE两个数据集，体现方法的广泛适用性。实验对比了两个强基线（BERT-CRF和XLM-R-CRF），并在所有语言对上报告平均结果，突出方法的稳定性和普适性。实验分析还针对特殊情况（如某些语言对性能下降）进行解释，强调自身方法在绝大多数场景下的有效性。"
      },
      {
        "paper_id": "ARR_2022_344",
        "title": "Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages",
        "problem_framing": "论文首先从实际痛点出发，指出当前自然语言处理任务普遍依赖于有标注数据的微调方法，但许多语言（尤其是低资源语言）缺乏任务相关的标注数据，导致主流方法难以应用。接着，论文引出跨语言微调作为潜在解决方案，并进一步指出评估跨语言泛化能力时常用的做法和其局限性，为后续问题展开铺垫。",
        "gap_pattern": "论文批评现有方法时，采用了'现有方法存在隐含假设'和'现有方法覆盖不全'的逻辑。具体地，指出现有跨语言评测通常只用英语作为源语言，隐含了英语具有代表性这一假设，但实际不同源-目标语言之间的相似性会影响迁移效果。此外，现有数据集在任务和语言覆盖上存在不均衡，导致对低资源和非印欧语言的性能评估可能被高估。句式上多用'however'、'may not be true'、'does not universally yield'等表达不足和局限。",
        "method_story": "方法部分采用了'先整体后细节'的叙述策略。首先整体描述了实验设计：在不同源-目标语言组合上微调预训练模型，形成一个大规模准确率矩阵。随后，分层次介绍了如何计算整体和单一语言的跨语言表现、采用的预测因子（如语言家族、书写系统、语序、预训练覆盖、词汇相似度、训练集大小等），以及数据集筛选和模型选择过程。最后，详细说明了数据采样策略以应对训练集规模差异。",
        "experiments_story": "实验部分以主实验为核心，采用可视化（热力图）展示所有源-目标语言组合的准确率，突出单语与跨语表现的差异。随后，进行定量分析，通过混合效应回归模型评估不同预测因子的贡献，并报告模型解释度（R2）和各随机效应的方差分解。整体策略为：主实验+可视化+统计建模分析，强调对跨语言迁移表现的系统性和多角度解释。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "创新点突出",
        "frequency": 3,
        "percentage": "23.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "提出针对few-shot跨语言迁移的数据选择策略，并说明与传统主动学习的区别（如仅一轮选择）。",
            "type": "method-level",
            "purpose": "强调方法的新颖性和区别于现有工作的地方"
          },
          {
            "paper_id": "ARR_2022_110",
            "title": "CLEAR: Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations",
            "description": "明确指出跨语言和环境无关表示的学习是前人未解决的问题，并提出CLEAR方法作为创新点。",
            "type": "writing-level",
            "purpose": "强调工作的独特贡献，提升新颖性"
          },
          {
            "paper_id": "ARR_2022_249",
            "title": "Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction",
            "description": "明确提出语言无关模板是本工作的核心创新，并强调其对跨语言迁移的促进作用。",
            "type": "writing-level",
            "purpose": "让读者清晰感知工作的核心创新"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "23.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "先提出问题、梳理现状，再介绍方法，最后系统实验并回扣前述问题，形成完整闭环。",
            "type": "writing-level",
            "purpose": "引导读者顺畅理解问题、方法和结果，提升论文整体可读性"
          },
          {
            "paper_id": "ARR_2022_169",
            "title": "Cross-Lingual Event Detection via Optimized Adversarial Training",
            "description": "按照‘问题提出—现有方法—创新方法—实验验证’的顺序组织全文，层层递进，结构清晰。",
            "type": "writing-level",
            "purpose": "提升整体可读性和逻辑性，帮助读者顺畅理解研究流程"
          },
          {
            "paper_id": "ARR_2022_350",
            "title": "Learning Cross-Lingual IR from an English Retriever",
            "description": "从问题提出、现有方法分析、创新方案介绍，到方法细节和实验验证，层层递进呼应研究目标",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，帮助读者顺畅理解研究过程"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 2,
        "percentage": "15.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_344",
            "title": "Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages",
            "description": "通过引用Conneau et al., Devlin et al.等权威文献，说明本工作与主流研究接轨，增强说服力。",
            "type": "writing-level",
            "purpose": "借助已有著名工作的权威性增强自身工作的可信度和相关性"
          },
          {
            "paper_id": "ARR_2022_110",
            "title": "CLEAR: Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations",
            "description": "通过大量引用相关领域的权威文献，说明现有方法的不足和本工作的必要性。",
            "type": "writing-level",
            "purpose": "增强方法的可信度和学术背景，证明问题的普遍性和重要性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式结构",
        "frequency": 2,
        "percentage": "15.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_1",
            "title": "Prix-LM: Pretraining for Multilingual Knowledge Base Construction",
            "description": "从问题提出、现有不足、方法设计到实验验证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_302",
            "title": "On Efficiently Acquiring Annotations for Multilingual Models",
            "description": "从问题提出、现有方法梳理、创新点介绍、方法细节、实验设计到结果讨论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "问题动机强化",
        "frequency": 2,
        "percentage": "15.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_302",
            "title": "On Efficiently Acquiring Annotations for Multilingual Models",
            "description": "通过强调多语言数据标注的高成本和实际困难，明确提出研究动机和现实背景，吸引读者关注问题的重要性。",
            "type": "writing-level",
            "purpose": "突出实际需求和挑战，增强研究意义和紧迫感"
          },
          {
            "paper_id": "ARR_2022_249",
            "title": "Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction",
            "description": "通过强调零样本跨语言事件参数抽取在低资源语言中的实际需求和挑战，强化研究动机。",
            "type": "writing-level",
            "purpose": "突出任务的重要性和研究价值，吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性对比",
        "frequency": 2,
        "percentage": "15.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_75",
            "title": "Learning Disentangled Semantic Representations for Zero-Shot Cross-Lingual Transfer in Multilingual Machine Reading Comprehension",
            "description": "作者详细分析了现有方法（如依赖外部知识库、难以获取等）的局限性，为提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "凸显自身工作的必要性和创新空间"
          },
          {
            "paper_id": "ARR_2022_249",
            "title": "Multilingual Generative Language Models for Zero-Shot Cross-Lingual Event Argument Extraction",
            "description": "详细分析并指出现有生成式模型在跨语言迁移时的模板依赖和代码切换问题，铺垫自身方法的优势。",
            "type": "writing-level",
            "purpose": "突出自身工作的创新性和必要性"
          }
        ]
      },
      {
        "trick_name": "数据稀缺性强调",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "通过引用权威数据（如95%的语言缺乏标注数据），强调跨语言资源分布极度不均，凸显研究的现实意义。",
            "type": "writing-level",
            "purpose": "突出研究问题的重要性和迫切性，吸引读者关注"
          }
        ]
      },
      {
        "trick_name": "文献回顾与现有方法梳理",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "系统回顾了跨语言迁移、主动学习和数据选择相关的经典文献，说明已有方法的局限和本工作的切入点。",
            "type": "writing-level",
            "purpose": "展示作者对领域的了解，定位本工作在现有研究中的位置"
          }
        ]
      },
      {
        "trick_name": "问题分层与归类",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "将语言按迁移难度分为C1、C2、C3等组，明确不同组的挑战和方法适用性。",
            "type": "writing-level",
            "purpose": "帮助读者理解复杂问题的结构，便于后续方法和实验展开"
          }
        ]
      },
      {
        "trick_name": "参数敏感性分析",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "通过实验报告不同参数（λ和γ）设置下的效果，说明方法对参数的敏感性和最佳配置。",
            "type": "experiment-level",
            "purpose": "展示方法的灵活性和可调性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "多任务多语言覆盖",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "在20种语言、三类任务（序列标注和分类）上进行系统实验，覆盖多种语言家族和任务类型。",
            "type": "experiment-level",
            "purpose": "增强实验的完备性和结论的泛化性"
          }
        ]
      },
      {
        "trick_name": "分组平均与细粒度分析",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "对不同语言组分别统计平均增益，并分析不同采样策略在各组的表现差异。",
            "type": "experiment-level",
            "purpose": "提升结果的可解释性和对不同情景的适用性说明"
          }
        ]
      },
      {
        "trick_name": "与基线方法对比",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "将PE、LE等新方法与RAND、DCE等基线方法系统对比，报告各自的优劣。",
            "type": "experiment-level",
            "purpose": "证明所提方法优于现有方法，增强说服力"
          }
        ]
      },
      {
        "trick_name": "极端情况讨论",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "针对TH等极低迁移性能语言，讨论方法增益不稳定的原因和表现。",
            "type": "experiment-level",
            "purpose": "展示方法的局限性和适用边界，体现科学严谨"
          }
        ]
      },
      {
        "trick_name": "实验参数与细节透明披露",
        "frequency": 1,
        "percentage": "7.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_20",
            "title": "“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer",
            "description": "详细披露实验参数设置、分组标准和附录补充，便于读者理解和复现。",
            "type": "experiment-level",
            "purpose": "增强实验复现性和结论的可信度"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 13,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_20",
        "ARR_2022_169",
        "ARR_2022_344",
        "ARR_2022_1",
        "ARR_2022_302",
        "ARR_2022_128",
        "ARR_2022_110",
        "ARR_2022_75",
        "ARR_2022_94",
        "ARR_2022_263",
        "ARR_2022_249",
        "ARR_2022_50",
        "ARR_2022_350"
      ]
    }
  },
  {
    "pattern_id": 21,
    "pattern_name": "多任务验证的可控生成框架",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决可控自然语言生成中的局限性，采用新颖框架和多任务验证策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际应用痛点开篇，通过对比现有方法指出gap，方法部分采用整体框架+模块细节，实验设计多任务验证+对比。\n第3段（60字）：适用场景与预期效果 - 适用于需要多属性控制和高效生成的自然语言生成任务，预期提升可控性和生成质量。",
    "writing_guide": "写作模板：多任务验证的可控生成框架\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决可控自然语言生成中的局限性，采用新颖框架和多任务验证策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际应用痛点开篇，通过对比现有方法指出gap，方法部分采用整体框架+模块细节，实验设计多任务验证+对比。\n第3段（60字）：适用场景与预期效果 - 适用于需要多属性控制和高效生成的自然语言生成任务，预期提升可控性和生成质量。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Controllable Natural Language Generation with Contrastive Prefixes》\n  • 问题定位：论文通过介绍可控自然语言生成（NLG）的目标和实际应用场景（如话题、情感控制等），从应用需求出发引入问题。同时，作者指出现有方法在参数规模、推理速度和多属性控制等方面存在不足，结合学术gap进行问题铺垫。整体开篇策略是先点明NLG的实际需求，再逐步引入当前方法的局限性，突出改进空间。\n  • 现有研究缺口：论文批评现有方法时采用了对比和举例的逻辑，具体包括：指出某些方法（如CTRL、GeDi）参数量大、训练成本高；某些方法（如GeDi）只能单属性控制，忽略多属性需求；PPLM推理速度慢；Prefix-tuning虽轻量但每个前缀独立训练，未考虑属性间关系。\n  • 核心方法：方法部分先整体介绍prefix-tuning的基本思想和与前人工作的区别，随后详细阐述作者提出的多前缀联合训练框架，包括参数结构、训练方式（监督/无监督）、损失函数设计等。叙述顺序为：先介绍整体框架，再分模块介绍具体实现（参数结构、损失函数、训练流程），并穿插与前人工作的对比，突出创新点。\n  • 实验设计：实验部分采用主实验+消融实验的策略，覆盖多种任务（情感控制、去毒化、话题控制），并与多种基线方法（GPT2、PPLM、GeDi）进行对比。实验设计包括不同训练集规模下的鲁棒性验证、无监督方法的效果分析、消融实验（对比损失函数的作用），并对方法在不同任务上的适用性和局限性进行讨论。\n\n示例 2：《MReD: A Meta-Review Dataset for Structure-Controllable Text Generation》\n  • 问题定位：论文通过梳理文本生成领域的主要任务类型（more-to-less、less-to-more、neck-to-neck），指出现有任务设置缺乏对领域知识的深入理解，尤其是在文本摘要等应用中无法满足用户的主观结构需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统数据集和方法未能考虑领域知识和结构化控制，无法解释为何同一内容会有不同标题或结构，且现有同行评审数据集缺乏结构化标注。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。\n  • 实验设计：实验部分采用‘主实验+对比+人工评价’的策略。首先对数据集进行预处理和划分，主实验包括对比多种生成方法（extractive、transformer-based等）在不同控制设置下的表现，并用ROUGE指标进行量化评估。\n\n示例 3：《CORWA: A Citation-Oriented Related Work Annotation Dataset》\n  • 问题定位：论文从学术gap出发引出问题，强调学术研究的前沿性和创新性，指出每篇论文都需要在相关工作部分与前人工作进行比较。作者进一步指出，相关工作部分在同一领域内内容和格式高度相似，因此有自动生成相关工作部分的实际需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体指出以往方法将相关工作生成简化为句子级摘要任务，未能区分不同信息来源的异质文本片段和多样化写作风格。此外，批评现有数据集多为自动抽取，缺乏细致人工标注，未能支持更复杂的生成任务。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍整体模型架构（联合相关工作标注器），说明采用Transformer编码器对段落独立编码，并联合训练三项任务。随后分别介绍各子任务的标签方式和机制，强调多任务学习和编码器共享。整体先给出框架，再细化到各模块和任务的具体实现。\n  • 实验设计：实验部分先介绍主实验流程，包括五折交叉验证和模型性能评估。接着描述如何利用自动标注扩展数据集，并用扩展数据进一步提升模型性能。随后介绍基于LED的大规模生成基线实验，涵盖预训练、输入结构、训练细节等。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 与主流方法系统对比（使用频率 3 次，占比 30.0%）\n   类型：experiment-level\n   应用：与GPT2、PPLM、GeDi等主流方法进行系统对比，表明新方法在可控性和语言质量上的优势。\n\n2. 引用权威工作（使用频率 3 次，占比 30.0%）\n   类型：writing-level\n   应用：多次引用相关领域的最新研究和权威文献，表明作者的方法是在现有研究基础上的改进和补充。\n\n3. 逻辑递进式叙事结构（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：从问题引入、现有方法不足、创新方案提出、方法细节、实验验证到结论，层层递进，逻辑清晰。\n\n4. 问题驱动引入（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：通过指出现有Transformer模型在受控生成方面的不足，强调全局属性控制生成仍是活跃研究领域，为新方法的提出制造需求。\n\n5. 类比与直观解释（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：将方法与‘product of experts’和‘能量模型’等直观概念类比，降低理解门槛。\n\n6. 现有方法梳理与局限性突出（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者系统梳理了主流可控NLG方法（如CTRL、GeDi、PPLM、Prefix-tuning），并逐一指出它们在参数量、速度、多属性控制等方面的不足，强调新方法的切入点和价值。\n\n7. 参数效率与速度优势强调（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：通过对比GeDi和Prefix-tuning的参数量和推理速度，突出本方法引入的参数极少且推理速度接近原始GPT2，为方法的实用性背书。\n\n8. 关系建模创新点突出（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：作者提出将属性间的关系（如对立性）融入prefix训练，并用“同时训练多个prefix”与“引入判别损失”明确区别于以往单独训练prefix的做法。\n\n9. 图示辅助理解（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：多次引用和描述图（如Figure 1、Figure 2、Figure 3）来直观展示prefix控制、训练流程和生成过程，使复杂机制易于理解。\n\n10. 分层次方法讲解（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：先介绍整体框架，再分别阐述监督、无监督和半监督方法，并用公式和直观解释逐步展开损失函数设计。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_15",
        "title": "Controllable Natural Language Generation with Contrastive Prefixes",
        "problem_framing": "论文通过介绍可控自然语言生成（NLG）的目标和实际应用场景（如话题、情感控制等），从应用需求出发引入问题。同时，作者指出现有方法在参数规模、推理速度和多属性控制等方面存在不足，结合学术gap进行问题铺垫。整体开篇策略是先点明NLG的实际需求，再逐步引入当前方法的局限性，突出改进空间。",
        "gap_pattern": "论文批评现有方法时采用了对比和举例的逻辑，具体包括：指出某些方法（如CTRL、GeDi）参数量大、训练成本高；某些方法（如GeDi）只能单属性控制，忽略多属性需求；PPLM推理速度慢；Prefix-tuning虽轻量但每个前缀独立训练，未考虑属性间关系。常用句式包括“现有方法…但…”、“然而…”、“这种方法…结果是…”，强调现有方法在灵活性、效率和多属性控制方面的不足。",
        "method_story": "方法部分先整体介绍prefix-tuning的基本思想和与前人工作的区别，随后详细阐述作者提出的多前缀联合训练框架，包括参数结构、训练方式（监督/无监督）、损失函数设计等。叙述顺序为：先介绍整体框架，再分模块介绍具体实现（参数结构、损失函数、训练流程），并穿插与前人工作的对比，突出创新点。",
        "experiments_story": "实验部分采用主实验+消融实验的策略，覆盖多种任务（情感控制、去毒化、话题控制），并与多种基线方法（GPT2、PPLM、GeDi）进行对比。实验设计包括不同训练集规模下的鲁棒性验证、无监督方法的效果分析、消融实验（对比损失函数的作用），并对方法在不同任务上的适用性和局限性进行讨论。整体叙述从主结果到细节分析，层层递进，突出方法的有效性和创新性。"
      },
      {
        "paper_id": "ARR_2022_126",
        "title": "MReD: A Meta-Review Dataset for Structure-Controllable Text Generation",
        "problem_framing": "论文通过梳理文本生成领域的主要任务类型（more-to-less、less-to-more、neck-to-neck），指出现有任务设置缺乏对领域知识的深入理解，尤其是在文本摘要等应用中无法满足用户的主观结构需求。作者以实际应用痛点为切入点，强调如果能够引入结构化控制信号，生成结果将更符合用户需求，并以同行评审系统中的meta-review为例，提出新的数据集和任务，突出实际应用需求与学术研究之间的结合。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统数据集和方法未能考虑领域知识和结构化控制，无法解释为何同一内容会有不同标题或结构，且现有同行评审数据集缺乏结构化标注。作者还强调，现有可控生成方法主要关注风格或表层内容控制，而未能实现高层次结构控制，从而突出自身工作的创新点。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先介绍主流的encoder-decoder框架作为整体技术路线，然后详细说明如何将输入评论和结构控制信号组织为模型输入，接着分模块介绍具体的输入拼接方法（如rate-concat）、控制方式（sent-ctrl与seg-ctrl），并补充未受控生成（unctrl）作为对照。叙述从整体框架到具体实现细节，层层递进，便于读者理解创新点。",
        "experiments_story": "实验部分采用‘主实验+对比+人工评价’的策略。首先对数据集进行预处理和划分，主实验包括对比多种生成方法（extractive、transformer-based等）在不同控制设置下的表现，并用ROUGE指标进行量化评估。随后补充人工评测，邀请人类评审从流畅性和内容相关性等维度对生成结果进行主观评价。实验设计既有自动指标，也有人工主观评价，突出方法的有效性和实用性。"
      },
      {
        "paper_id": "ARR_2022_303",
        "title": "CORWA: A Citation-Oriented Related Work Annotation Dataset",
        "problem_framing": "论文从学术gap出发引出问题，强调学术研究的前沿性和创新性，指出每篇论文都需要在相关工作部分与前人工作进行比较。作者进一步指出，相关工作部分在同一领域内内容和格式高度相似，因此有自动生成相关工作部分的实际需求。通过批判现有相关工作生成方法仅将其视为一般的摘要任务，忽略了相关工作部分的异质性和复杂写作风格，明确提出需要更细致的自动生成方法。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体指出以往方法将相关工作生成简化为句子级摘要任务，未能区分不同信息来源的异质文本片段和多样化写作风格。此外，批评现有数据集多为自动抽取，缺乏细致人工标注，未能支持更复杂的生成任务。句式上常用‘mostly ignore’、‘neglecting’、‘not been previously used’等表达，突出现有方法的不足。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先介绍整体模型架构（联合相关工作标注器），说明采用Transformer编码器对段落独立编码，并联合训练三项任务。随后分别介绍各子任务的标签方式和机制，强调多任务学习和编码器共享。整体先给出框架，再细化到各模块和任务的具体实现。",
        "experiments_story": "实验部分先介绍主实验流程，包括五折交叉验证和模型性能评估。接着描述如何利用自动标注扩展数据集，并用扩展数据进一步提升模型性能。随后介绍基于LED的大规模生成基线实验，涵盖预训练、输入结构、训练细节等。实验类型包括主任务性能评估、远程监督数据扩展、预训练与基线模型对比，体现多数据集和多任务验证，突出模型泛化和实际应用能力。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "与主流方法系统对比",
        "frequency": 3,
        "percentage": "30.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "与GPT2、PPLM、GeDi等主流方法进行系统对比，表明新方法在可控性和语言质量上的优势。",
            "type": "experiment-level",
            "purpose": "突出新方法的优越性和实际提升"
          },
          {
            "paper_id": "ARR_2022_88",
            "title": "Learning Structural Information for Syntax-Controlled Paraphrase Generation",
            "description": "在实验中与SGCP、GuiG、SCPN、SynTrans等主流方法进行了系统对比，突出SI-SCP的优势。",
            "type": "experiment-level",
            "purpose": "证明新方法优于现有主流方法"
          },
          {
            "paper_id": "ARR_2022_165",
            "title": "PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding",
            "description": "与CTRL、GeDi、PPLM等主流约束生成方法系统对比，展示自身性能",
            "type": "experiment-level",
            "purpose": "突出自身方法的优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 3,
        "percentage": "30.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_266",
            "title": "Mix and Match: Learning-free Controllable Text Generation using Energy Language Models",
            "description": "多次引用相关领域的最新研究和权威文献，表明作者的方法是在现有研究基础上的改进和补充。",
            "type": "writing-level",
            "purpose": "增强说服力，显示对领域前沿的了解，并为方法定位提供依据"
          },
          {
            "paper_id": "ARR_2022_45",
            "title": "A Copy-Augmented Generative Model for Open-Domain Question Answering",
            "description": "广泛引用ODQA、生成模型、指针网络等相关领域的代表性工作，展示方法建立在坚实的研究基础之上。",
            "type": "writing-level",
            "purpose": "借助领域内权威文献增强自身工作的可信度和背景合理性"
          },
          {
            "paper_id": "ARR_2022_299",
            "title": "Synchronous Refinement for Language Generation",
            "description": "通过引用Vaswani et al., Bahdanau et al.等经典文献，建立方法的学术背景和相关性。",
            "type": "writing-level",
            "purpose": "借助领域内知名工作增强论述的可信度和背景权威性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_126",
            "title": "MReD: A Meta-Review Dataset for Structure-Controllable Text Generation",
            "description": "从问题引入、现有方法不足、创新方案提出、方法细节、实验验证到结论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_88",
            "title": "Learning Structural Information for Syntax-Controlled Paraphrase Generation",
            "description": "全文采用‘问题-现有方法-不足-新方法-实验验证’的逻辑递进结构，层层铺垫，环环相扣。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究动机、方法和结论"
          }
        ]
      },
      {
        "trick_name": "问题驱动引入",
        "frequency": 2,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_266",
            "title": "Mix and Match: Learning-free Controllable Text Generation using Energy Language Models",
            "description": "通过指出现有Transformer模型在受控生成方面的不足，强调全局属性控制生成仍是活跃研究领域，为新方法的提出制造需求。",
            "type": "writing-level",
            "purpose": "引导读者关注尚未解决的关键难题，为提出新方法铺垫必要性"
          },
          {
            "paper_id": "ARR_2022_88",
            "title": "Learning Structural Information for Syntax-Controlled Paraphrase Generation",
            "description": "作者首先介绍了同义句生成的应用价值，随后明确提出了当前方法面临的两个主要挑战，为后续方法创新埋下伏笔。",
            "type": "writing-level",
            "purpose": "引导读者关注领域痛点，突出研究意义"
          }
        ]
      },
      {
        "trick_name": "类比与直观解释",
        "frequency": 2,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_266",
            "title": "Mix and Match: Learning-free Controllable Text Generation using Energy Language Models",
            "description": "将方法与‘product of experts’和‘能量模型’等直观概念类比，降低理解门槛。",
            "type": "writing-level",
            "purpose": "提升可解释性，使复杂模型易于理解"
          },
          {
            "paper_id": "ARR_2022_165",
            "title": "PPL-MCTS: Constrained Textual Generation Through Discriminator-Guided MCTS Decoding",
            "description": "将文本生成过程类比为树的探索，并用图示和概率分解帮助读者理解MCTS在文本生成中的作用",
            "type": "method-level",
            "purpose": "提升可解释性，让复杂算法易于理解"
          }
        ]
      },
      {
        "trick_name": "现有方法梳理与局限性突出",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "作者系统梳理了主流可控NLG方法（如CTRL、GeDi、PPLM、Prefix-tuning），并逐一指出它们在参数量、速度、多属性控制等方面的不足，强调新方法的切入点和价值。",
            "type": "writing-level",
            "purpose": "突出当前领域的不足，为新方法铺垫必要性和创新空间"
          }
        ]
      },
      {
        "trick_name": "参数效率与速度优势强调",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "通过对比GeDi和Prefix-tuning的参数量和推理速度，突出本方法引入的参数极少且推理速度接近原始GPT2，为方法的实用性背书。",
            "type": "method-level",
            "purpose": "增强方法的说服力，让读者相信新方法在实际应用中更具优势"
          }
        ]
      },
      {
        "trick_name": "关系建模创新点突出",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "作者提出将属性间的关系（如对立性）融入prefix训练，并用“同时训练多个prefix”与“引入判别损失”明确区别于以往单独训练prefix的做法。",
            "type": "method-level",
            "purpose": "展示方法的新颖性，强调与前人工作的差异和提升"
          }
        ]
      },
      {
        "trick_name": "图示辅助理解",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "多次引用和描述图（如Figure 1、Figure 2、Figure 3）来直观展示prefix控制、训练流程和生成过程，使复杂机制易于理解。",
            "type": "writing-level",
            "purpose": "提升方法可解释性，帮助读者快速把握核心机制"
          }
        ]
      },
      {
        "trick_name": "分层次方法讲解",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "先介绍整体框架，再分别阐述监督、无监督和半监督方法，并用公式和直观解释逐步展开损失函数设计。",
            "type": "writing-level",
            "purpose": "提升可解释性和逻辑清晰度，便于读者逐步理解方法细节"
          }
        ]
      },
      {
        "trick_name": "直观动机阐述",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "用“鼓励生成/抑制生成”来解释判别损失的作用，并结合属性对立关系，直观说明方法为何能提升可控性。",
            "type": "writing-level",
            "purpose": "增强方法的合理性和易接受性，让读者理解设计背后的动因"
          }
        ]
      },
      {
        "trick_name": "多任务广泛验证",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "在情感控制、去毒化、话题控制三大任务上进行实验，覆盖单属性和多属性场景，展示方法的通用性。",
            "type": "experiment-level",
            "purpose": "证明方法的完备性和广泛适用性，增强结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "多设置鲁棒性测试",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "分别在全数据、少量数据（1000/24例）下测试，突出方法在few-shot场景下的稳健表现。",
            "type": "experiment-level",
            "purpose": "证明方法在不同数据规模下的有效性，提升结论可信度"
          }
        ]
      },
      {
        "trick_name": "多维度指标评估",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "同时评估生成文本的语言质量（困惑度）和属性对齐度，全面衡量方法性能。",
            "type": "experiment-level",
            "purpose": "增强实验的说服力和科学性，避免单一指标偏见"
          }
        ]
      },
      {
        "trick_name": "消融实验验证关键设计",
        "frequency": 1,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_15",
            "title": "Controllable Natural Language Generation with Contrastive Prefixes",
            "description": "通过去除判别损失（Ours-Ld）与原方法对比，展示该损失对可控性的提升作用。",
            "type": "experiment-level",
            "purpose": "证明方法中关键模块（如判别损失）的必要性和贡献"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 10,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_15",
        "ARR_2022_126",
        "ARR_2022_303",
        "ARR_2022_205",
        "ARR_2022_266",
        "ARR_2022_88",
        "ARR_2022_45",
        "ARR_2022_299",
        "ARR_2022_165",
        "COLING_2020_53"
      ]
    }
  },
  {
    "pattern_id": 22,
    "pattern_name": "视觉语言数据增强方法",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决视觉-语言任务中的数据规模与标注成本矛盾，通过创新方法提升模型泛化能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题驱动开篇，引入权威工作增强说服力，分步阐述创新方法并用图示辅助理解，多方法对比验证效果。\n第3段（60字）：适用场景与预期效果 - 适用于视觉问答、图像描述等任务，数据集如VQAv2、SNLI-VE，预期提升零样本和小样本学习性能。",
    "writing_guide": "写作模板：视觉语言数据增强方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决视觉-语言任务中的数据规模与标注成本矛盾，通过创新方法提升模型泛化能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题驱动开篇，引入权威工作增强说服力，分步阐述创新方法并用图示辅助理解，多方法对比验证效果。\n第3段（60字）：适用场景与预期效果 - 适用于视觉问答、图像描述等任务，数据集如VQAv2、SNLI-VE，预期提升零样本和小样本学习性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先介绍了视觉-语言理解（VLU）任务的重要性和主流做法，指出现有VLU模型依赖大量人工标注数据，数据收集和标注成本高，规模远小于NLP领域的预训练语料。\n  • 现有研究缺口：论文批评现有方法主要采用以下逻辑：1）强调现有VLU方法对人工标注数据的高度依赖，导致数据规模受限，难以扩展；2）指出CLIP虽然具备强大的零样本能力，但与传统视觉编码器存在两大不同：其一是训练数据规模大且噪声多，其二是视觉与语言的交互较浅。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分步骤递进’的叙述策略。首先指出直接应用CLIP在VLU任务上的问题，提出需要缩小自然语言描述与问答任务形式之间的差距。随后整体介绍提出的两步自动化prompt生成方法，并用图示辅助说明。\n  • 实验设计：实验部分采用‘多数据集+主实验对比’的策略。首先介绍了用于VQA和视觉蕴含的两个主流数据集（VQAv2和SNLI-VE），并说明评测指标和细节。然后对比了不同CLIP变体，以及两种零样本VL基线（Frozen和QIP），突出自身方法的有效性。\n\n示例 2：《VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems》\n  • 问题定位：论文通过回顾视觉-语言任务的发展历程，从图像到视频，再到视频对话，逐步引出随着模态复杂性提升，现有模型面临的新挑战。\n  • 现有研究缺口：论文批评现有方法主要采用了‘现有方法隐式假设推理结构’和‘在复杂场景下表现有限’的逻辑。具体句式包括指出当前主流深度神经网络虽然性能优异，但往往只隐式学习推理结构，缺乏显式可解释性，且在视频具有复杂时空动态或语言输入语义依赖复杂时，模型难以解释、易出错、推理能力受限。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了模型架构和核心思想（如VGNMN的推理结构），随后细致分解各模块：先介绍问题解析器（Question Parsers）的设计与工作原理，详细说明如何将问题解析为可执行的推理程序，再逐步讲解各个神经模块的具体实现与训练方式。\n  • 实验设计：实验部分采用了‘主实验+多数据集验证+鲁棒性分析’的策略。首先在主流基准数据集（AVSD和TGIF-QA）上进行主实验，展示模型在标准指标上的性能。实验设计包含不同输入设置（有无视频摘要）、不同特征类型（CNN特征、对象特征），并与主流方法（包括GPT-based模型）进行对比分析。\n\n示例 3：《On Vision Features in Multimodal Machine Translation》\n  • 问题定位：论文通过回顾多模态机器翻译（MMT）领域的发展，引出当前研究的问题。开篇先介绍MMT结合了计算机视觉和自然语言处理，早期模型在BLEU分数上取得了提升，激发了后续研究兴趣。随后，作者指出实际观察到的问题：视觉模态对翻译贡献有限，甚至在视觉信息缺失或与文本无关时，翻译性能影响不大。\n  • 现有研究缺口：论文批评现有方法主要采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述顺序。首先，作者介绍了用于评估视觉模态贡献的探测任务（probing tasks），为后续方法设计奠定基础。接着，系统性地描述了不同视觉特征的设计，包括如何将ViT等更强视觉模型的特征引入MMT。\n  • 实验设计：实验部分采用‘主实验+探测任务验证’的叙述策略。首先，复现并对比了不同视觉特征（如ResNet与ViT）在标准MMT数据集上的表现，验证主方法的有效性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 20.0%）\n   类型：writing-level\n   应用：先提出问题与挑战，再引入新方法，最后通过系统实验验证，前后呼应，层层递进\n\n2. 问题驱动开篇（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过阐述VLU任务的难点和现有方法的局限，提出数据规模与标注成本的矛盾，引出研究动机。\n\n3. 引用权威工作（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：大量引用领域内经典和最新文献，展示方法与主流工作的关系和改进空间。\n\n4. 图示辅助理解（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过引用和描述图表（如Figure 1, Figure 3），直观展示任务和方法流程。\n\n5. 实验细节透明化（使用频率 2 次，占比 13.3%）\n   类型：experiment-level\n   应用：详细报告数据集、模型参数、评估指标等实验细节，并在附录补充统计信息。\n\n6. 逻辑递进的叙事结构（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：先引入问题和挑战，再提出方法，最后通过实验验证，层层递进，呼应前文提出的问题。\n\n7. 现实动机引入（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过指出传统视觉任务受限于预定义类别，强调自然语言表达的必要性和与人类认知的契合，增强问题的现实意义。\n\n8. 创新点突出（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：作者强调FEWVLM结合PrefixLM和MaskedLM两种预训练目标，并在prompt设计上做创新，突出与现有工作的不同。\n\n9. 对比现有方法局限（使用频率 1 次，占比 6.7%）\n   类型：writing-level\n   应用：详细分析CLIP与传统视觉编码器的区别，以及直接应用CLIP的不足，引出自身方法的优势。\n\n10. 提出核心科学问题（使用频率 1 次，占比 6.7%）\n   类型：writing-level\n   应用：通过提出“CLIP的零样本能力能否迁移到VLU任务？”这一核心问题，设定全文主线。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_196",
        "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
        "problem_framing": "论文从学术gap出发引出问题。开篇首先介绍了视觉-语言理解（VLU）任务的重要性和主流做法，指出现有VLU模型依赖大量人工标注数据，数据收集和标注成本高，规模远小于NLP领域的预训练语料。随后引入CLIP模型，强调其在大规模、弱标注数据下取得的零样本能力，并提出关键问题：CLIP的强零样本能力能否迁移到VLU任务？这样通过对比现有方法和新模型的能力，引出本文要解决的核心问题。",
        "gap_pattern": "论文批评现有方法主要采用以下逻辑：1）强调现有VLU方法对人工标注数据的高度依赖，导致数据规模受限，难以扩展；2）指出CLIP虽然具备强大的零样本能力，但与传统视觉编码器存在两大不同：其一是训练数据规模大且噪声多，其二是视觉与语言的交互较浅。3）引用前人工作，直接将CLIP用于VLU任务时效果接近随机，说明现有prompt设计无法有效迁移CLIP的能力。批评句式包括‘现有方法 extensively utilized human-annotated training data that are expensive or require expert knowledge’、‘directly applying CLIP models for zero-shot VL tasks are infeasible’等，突出方法在实际应用和任务迁移上的不足。",
        "method_story": "方法部分采用‘先整体后局部’和‘分步骤递进’的叙述策略。首先指出直接应用CLIP在VLU任务上的问题，提出需要缩小自然语言描述与问答任务形式之间的差距。随后整体介绍提出的两步自动化prompt生成方法，并用图示辅助说明。接着分别详细介绍每一步：第一步是自动模板生成，分为基于T5的in-context demonstration和依存句法分析两种实现方式，分别说明原理和流程；第二步是利用语言模型过滤不可能的答案，形成候选集。整体逻辑是从问题提出、方案框架、再到每个子模块细节，层层递进。",
        "experiments_story": "实验部分采用‘多数据集+主实验对比’的策略。首先介绍了用于VQA和视觉蕴含的两个主流数据集（VQAv2和SNLI-VE），并说明评测指标和细节。然后对比了不同CLIP变体，以及两种零样本VL基线（Frozen和QIP），突出自身方法的有效性。主实验包括零样本VQA和小样本VQA，分别与主流方法做对比，验证了方法的有效性和泛化能力。实验还分析了不同shot数下的性能提升，体现方法的few-shot学习能力。整体实验设计以主实验和多基线对比为主，强调方法的实际提升和适用广度。"
      },
      {
        "paper_id": "ARR_2022_244",
        "title": "VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems",
        "problem_framing": "论文通过回顾视觉-语言任务的发展历程，从图像到视频，再到视频对话，逐步引出随着模态复杂性提升，现有模型面临的新挑战。开篇采用了从学术研究进展和实际任务需求出发的策略，强调多模态理解（尤其是视频和对话）对智能系统的重要性，并通过具体任务（如视频对话）举例，指出需要解决指代消解、动作识别等问题，从而自然引出对更强推理能力的需求。",
        "gap_pattern": "论文批评现有方法主要采用了‘现有方法隐式假设推理结构’和‘在复杂场景下表现有限’的逻辑。具体句式包括指出当前主流深度神经网络虽然性能优异，但往往只隐式学习推理结构，缺乏显式可解释性，且在视频具有复杂时空动态或语言输入语义依赖复杂时，模型难以解释、易出错、推理能力受限。此外，还引用了相关文献指出在图像任务中，深度模型容易利用表层视觉线索，理解能力浅显，进一步强调了现有方法的不足。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了模型架构和核心思想（如VGNMN的推理结构），随后细致分解各模块：先介绍问题解析器（Question Parsers）的设计与工作原理，详细说明如何将问题解析为可执行的推理程序，再逐步讲解各个神经模块的具体实现与训练方式。叙述顺序从输入（问题解析）到推理程序生成，再到实体定位与特征提取，层层递进，逻辑清晰。",
        "experiments_story": "实验部分采用了‘主实验+多数据集验证+鲁棒性分析’的策略。首先在主流基准数据集（AVSD和TGIF-QA）上进行主实验，展示模型在标准指标上的性能。实验设计包含不同输入设置（有无视频摘要）、不同特征类型（CNN特征、对象特征），并与主流方法（包括GPT-based模型）进行对比分析。随后补充了鲁棒性实验，考察模型在不同对话轮次、视频长度等条件下的表现，进一步验证模型的泛化和稳健性。整体叙述以结果为导向，突出模型优势与灵活性。"
      },
      {
        "paper_id": "ARR_2022_90",
        "title": "On Vision Features in Multimodal Machine Translation",
        "problem_framing": "论文通过回顾多模态机器翻译（MMT）领域的发展，引出当前研究的问题。开篇先介绍MMT结合了计算机视觉和自然语言处理，早期模型在BLEU分数上取得了提升，激发了后续研究兴趣。随后，作者指出实际观察到的问题：视觉模态对翻译贡献有限，甚至在视觉信息缺失或与文本无关时，翻译性能影响不大。通过引用相关研究，强调了视觉信息在现有MMT系统中的边缘作用。最后，作者结合CV领域从CNN到Transformer的技术演进，提出核心问题——如果采用更强大的视觉模型，MMT系统会有何表现？整体上，论文采用了“从学术gap出发”，结合实际表现和技术趋势，引出研究问题。",
        "gap_pattern": "论文批评现有方法主要采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：1）指出大多数工作仅关注如何集成现成的视觉模型（如ResNet-50），默认这些模型足以表达图像信息，忽视了视觉模型本身的表达能力；2）强调在视觉模态缺失或图像与文本无关时，MMT系统性能几乎不受影响，说明视觉信息未被充分利用；3）引用前人研究，指出视觉模态在文本信息完整时作用有限，仅在语言信息稀缺时才有帮助；4）进一步指出，现有自动评测指标（如BLEU）可能无法真实反映MMT模型对视觉信息的利用效果。整体批评策略是通过对比现有方法的假设与实际表现，揭示其局限性和被忽视的关键问题。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述顺序。首先，作者介绍了用于评估视觉模态贡献的探测任务（probing tasks），为后续方法设计奠定基础。接着，系统性地描述了不同视觉特征的设计，包括如何将ViT等更强视觉模型的特征引入MMT。随后，提出了选择性注意力机制，详细解释如何在词与图像patch之间建立关联。最后，介绍了进一步增强的特征（如目标检测和图像描述），作为对视觉信息的补充。整体上，方法部分层层递进，从评测任务到特征设计，再到具体机制与增强手段，逻辑清晰。",
        "experiments_story": "实验部分采用‘主实验+探测任务验证’的叙述策略。首先，复现并对比了不同视觉特征（如ResNet与ViT）在标准MMT数据集上的表现，验证主方法的有效性。其次，重点通过多种探测任务（如基于颜色、字符、名词的masking任务）细致分析视觉模态的真实贡献，揭示不同模型和机制在细粒度任务上的表现差异。此外，实验覆盖了多语言对（En-De、En-Fr）和多个测试集，增强了结论的普适性。整体策略为：主实验验证+细粒度探测+多数据集/多任务覆盖，突出方法的全面性和深入性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_90",
            "title": "On Vision Features in Multimodal Machine Translation",
            "description": "先提出问题与挑战，再引入新方法，最后通过系统实验验证，前后呼应，层层递进",
            "type": "writing-level",
            "purpose": "增强论文整体可读性和逻辑性，引导读者顺畅理解研究动机、方法与结论"
          },
          {
            "paper_id": "ARR_2022_124",
            "title": "Co-VQA : Answering by Interactive Sub Question Sequence",
            "description": "全文按照‘问题-方法-实验’的经典结构展开，层层递进，前后呼应，便于读者跟随作者思路。",
            "type": "writing-level",
            "purpose": "保证全文结构清晰、逻辑连贯，便于读者理解和接受"
          },
          {
            "paper_id": "ARR_2022_284",
            "title": "Image Retrieval from Contextual Descriptions",
            "description": "从问题提出、数据集设计、方法改进到实验验证，层层递进，前后呼应，逻辑清晰。",
            "type": "writing-level",
            "purpose": "清晰组织论文内容，增强整体说服力"
          }
        ]
      },
      {
        "trick_name": "问题驱动开篇",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "通过阐述VLU任务的难点和现有方法的局限，提出数据规模与标注成本的矛盾，引出研究动机。",
            "type": "writing-level",
            "purpose": "引导读者关注领域核心挑战，突出研究意义"
          },
          {
            "paper_id": "ARR_2022_133",
            "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models",
            "description": "作者首先提出领域内的关键问题（如大模型部署难、数据昂贵），并明确列出待解决的具体科学问题（Q1-Q3），为后文方法和实验做铺垫。",
            "type": "writing-level",
            "purpose": "引导读者关注领域内的挑战与核心问题，提升论文的相关性和说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "大量引用领域内经典和最新文献，展示方法与主流工作的关系和改进空间。",
            "type": "writing-level",
            "purpose": "增强说服力，证明所述问题和方法具有学术基础和现实意义"
          },
          {
            "paper_id": "ARR_2022_100",
            "title": "Leveraging Visual Knowledge in Language Tasks: An Empirical Study on Intermediate Pre-training for Cross-modal Knowledge Transfer",
            "description": "通过引用BERT、RoBERTa、T5等主流模型及相关研究，展示本研究建立在坚实的学术基础上。",
            "type": "writing-level",
            "purpose": "增强说服力和学术权威性"
          }
        ]
      },
      {
        "trick_name": "图示辅助理解",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "通过引用和描述图表（如Figure 1, Figure 3），直观展示任务和方法流程。",
            "type": "writing-level",
            "purpose": "增强可解释性，降低理解门槛"
          },
          {
            "paper_id": "ARR_2022_133",
            "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models",
            "description": "作者在引言中引用图1，直观展示方法在VQA和captioning任务上的应用流程。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者快速把握方法流程"
          }
        ]
      },
      {
        "trick_name": "实验细节透明化",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "详细报告数据集、模型参数、评估指标等实验细节，并在附录补充统计信息。",
            "type": "experiment-level",
            "purpose": "增强实验可复现性和结论可信度"
          },
          {
            "paper_id": "ARR_2022_90",
            "title": "On Vision Features in Multimodal Machine Translation",
            "description": "详细描述模型结构、训练参数、优化器配置、学习率调度、早停策略等，便于他人复现",
            "type": "experiment-level",
            "purpose": "提升实验的可复现性和严谨性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进的叙事结构",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_244",
            "title": "VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems",
            "description": "先引入问题和挑战，再提出方法，最后通过实验验证，层层递进，呼应前文提出的问题。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，引导读者顺畅理解研究思路"
          },
          {
            "paper_id": "ARR_2022_3",
            "title": "Visual Commonsense in Pretrained Unimodal and Multimodal Models",
            "description": "从问题引入、相关工作、方法设计、实验验证到结论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究流程，增强整体说服力"
          }
        ]
      },
      {
        "trick_name": "现实动机引入",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_131",
            "title": "Comprehensive Multi-Modal Interactions for Referring Image Segmentation",
            "description": "通过指出传统视觉任务受限于预定义类别，强调自然语言表达的必要性和与人类认知的契合，增强问题的现实意义。",
            "type": "writing-level",
            "purpose": "让读者意识到现有方法的局限性，强调问题的重要性和实际需求"
          },
          {
            "paper_id": "ARR_2022_3",
            "title": "Visual Commonsense in Pretrained Unimodal and Multimodal Models",
            "description": "通过指出人类语言理解发生在多模态环境中，引出视觉基础在自然语言处理中的重要性，为后续研究提供现实动机。",
            "type": "writing-level",
            "purpose": "强调研究问题的现实意义和必要性，增强说服力"
          }
        ]
      },
      {
        "trick_name": "创新点突出",
        "frequency": 2,
        "percentage": "13.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_133",
            "title": "A Good Prompt Is Worth Millions of Parameters: Low-resource Prompt-based Learning for Vision-Language Models",
            "description": "作者强调FEWVLM结合PrefixLM和MaskedLM两种预训练目标，并在prompt设计上做创新，突出与现有工作的不同。",
            "type": "writing-level",
            "purpose": "突出工作的新颖性，吸引读者关注"
          },
          {
            "paper_id": "ARR_2022_217",
            "title": "XDBERT: Distilling Visual Information to BERT via Cross-Modal Encoders to Improve Language Understanding",
            "description": "强调首次将CLIP-T作为视觉教师模型，向预训练语言模型蒸馏视觉信息，提出跨模态蒸馏新思路。",
            "type": "writing-level",
            "purpose": "明确展示工作的创新性"
          }
        ]
      },
      {
        "trick_name": "对比现有方法局限",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "详细分析CLIP与传统视觉编码器的区别，以及直接应用CLIP的不足，引出自身方法的优势。",
            "type": "writing-level",
            "purpose": "突出新方法的创新性和必要性"
          }
        ]
      },
      {
        "trick_name": "提出核心科学问题",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "通过提出“CLIP的零样本能力能否迁移到VLU任务？”这一核心问题，设定全文主线。",
            "type": "writing-level",
            "purpose": "明确研究目标，聚焦读者注意力"
          }
        ]
      },
      {
        "trick_name": "分步阐述创新方法",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "将方法拆解为自动模板生成和答案过滤两步，分别详细说明技术细节和实现方式。",
            "type": "method-level",
            "purpose": "提升可解释性，帮助读者理解方法原理和流程"
          }
        ]
      },
      {
        "trick_name": "多方法并行对比",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "设置Frozen和QIP等多种最新零样本基线，与自身方法进行系统对比。",
            "type": "experiment-level",
            "purpose": "增强对比性和说服力，凸显自身方法优势"
          }
        ]
      },
      {
        "trick_name": "分任务实验设计",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "分别在VQAv2和SNLI-VE两个主流数据集上进行实验，覆盖视觉问答和视觉蕴含两大任务。",
            "type": "experiment-level",
            "purpose": "提升完备性，确保实验覆盖主要应用场景"
          }
        ]
      },
      {
        "trick_name": "分类别结果分析",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "对不同类别（如other, number）进行细致分析，展示方法在不同场景下的表现和提升空间。",
            "type": "experiment-level",
            "purpose": "增强实验深度和结论可靠性"
          }
        ]
      },
      {
        "trick_name": "递进式叙事结构",
        "frequency": 1,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_196",
            "title": "CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment",
            "description": "先铺垫领域背景和挑战，再提出方法，最后通过实验呼应前述问题和创新点，形成闭环。",
            "type": "writing-level",
            "purpose": "提升逻辑流畅性，帮助读者逐步理解问题、方法和结论"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 15,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_196",
        "ARR_2022_244",
        "ARR_2022_90",
        "ARR_2022_70",
        "ARR_2022_131",
        "ARR_2022_72",
        "ARR_2022_3",
        "ARR_2022_133",
        "ARR_2022_217",
        "ARR_2022_100",
        "ARR_2022_124",
        "ARR_2022_284",
        "ACL_2017_481",
        "ACL_2017_501",
        "COLING_2020_9"
      ]
    }
  },
  {
    "pattern_id": 23,
    "pattern_name": "大规模预训练模型优化",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨大规模预训练模型的局限性，通过扩展任务定义和创新方法提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，通过引入权威基准和核心理论属性突出创新点，常用tricks包括详细实验设计和多维度数据分析。\n第3段（60字）：适用场景与预期效果 - 适用于需要系统评估和改进大规模预训练模型性能的NLP任务，预期提升模型在特定任务上的表现和泛化能力。",
    "writing_guide": "写作模板：大规模预训练模型优化\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨大规模预训练模型的局限性，通过扩展任务定义和创新方法提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，通过引入权威基准和核心理论属性突出创新点，常用tricks包括详细实验设计和多维度数据分析。\n第3段（60字）：适用场景与预期效果 - 适用于需要系统评估和改进大规模预训练模型性能的NLP任务，预期提升模型在特定任务上的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence》\n  • 问题定位：论文以学术gap为切入点，指出尽管大规模预训练语言模型（PLMs）在众多下游任务中表现优异，甚至在一些基准测试中超过人类，但其可靠性正受到挑战。通过引用多项研究，作者强调PLMs在句子顺序敏感性、数字理解、语义内容理解等方面存在缺陷，特别是在否定理解能力上表现不佳。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法范围有限’和‘现有方法存在实际应用障碍’的逻辑。\n  • 核心方法：方法部分的叙述顺序为：先扩展理论边界，提出将LNP（逻辑否定性质）从传统的否定表达拓展到词汇语义层面（同义词、反义词），再设计相应的评测任务和指标。整体上采用‘先整体后局部’的策略，先说明研究视角和创新点，再具体介绍如何构建任务、如何评测模型的表现。\n  • 实验设计：实验部分采用‘主实验+细致分析’的叙述策略。首先，明确采用top-k hit rate和weighted top-k hit rate等指标，系统评测PLMs在否定理解和词汇语义任务（MKR-NQ和MWR）上的表现。\n\n示例 2：《GLM: General Language Model Pretraining with Autoregressive Blank Infilling》\n  • 问题定位：论文通过回顾大规模预训练语言模型在自然语言处理任务中的显著进展作为开篇，强调模型参数规模和下游任务性能的持续提升，进而引出现有预训练框架（自回归、自动编码、编码-解码三类）各自的优势和局限，指出没有一种方法能够在所有NLP任务上表现优异。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和归纳的逻辑，逐一指出三类主流预训练模型的固有缺陷：自回归模型在NLU任务中受限于单向注意力机制，自动编码模型虽适合NLU但无法直接用于生成，编码-解码模型参数需求大且在性能上不具备全面优势。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先整体介绍GLM的核心思想——基于自回归填空的统一预训练框架，并说明其如何将NLU任务转化为可生成回答的填空问题。随后，分条列举模型架构的具体改进，包括层归一化与残差连接顺序调整、输出层简化、激活函数替换等，突出每一项设计的动机和作用。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略。首先介绍预训练设置和下游任务评测，选用GLUE和SQuAD两个主流NLP基准数据集，分别覆盖单句、句对、抽取式问答等典型任务。实验重点在于与BERT等主流模型的直接对比，突出GLM在参数规模相同情况下的性能优势。\n\n示例 3：《CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in NLP》\n  • 问题定位：论文从学术gap出发引出问题。开篇先指出迁移学习在自然语言处理中的多种形式和广泛关注，进而提出一个高层次的核心问题：不同任务之间的关系结构尚不明确，现有研究缺乏对NLP任务之间结构性关联的系统刻画。\n  • 现有研究缺口：论文通过对比视觉领域已有的Taskonomy体系，指出NLP领域在任务结构建模方面的不足。具体批评逻辑为：现有NLP任务分类体系缺乏、未能充分利用认知神经科学数据来指导任务结构的构建。\n  • 核心方法：方法部分采用分模块介绍的策略。首先整体介绍了CogTaskonomy框架的设计理念和目标，然后细分为两个主要的认知启发模块：Cognitive Representation Analytics（CRA）和Cognitive-Neural Mapping（CNM）。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略。首先在广泛使用的NLP基准数据集和认知数据上评估CogTaskonomy的有效性，核心实验为任务迁移实验（task transferring），通过源任务到目标任务的迁移性能来度量任务相似性，并以此构建oracle任务排序。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 4 次，占比 28.6%）\n   类型：writing-level\n   应用：从问题提出、现有方法分析、创新点介绍到实验设计和结果分析，层层递进，逻辑清晰。\n\n2. 引用权威工作建立背景（使用频率 3 次，占比 21.4%）\n   类型：writing-level\n   应用：通过引用多篇相关领域权威文献，强调模型与人类注意力对齐的重要性，并为后续工作奠定理论基础。\n\n3. 创新点突出（使用频率 2 次，占比 14.3%）\n   类型：method-level\n   应用：提出GLM框架，结合autoregressive和autoencoding思想，采用autoregressive blank infilling，并在方法部分具体描述两项架构改进。\n\n4. 问题驱动式引入（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：通过提出跨任务迁移学习中的核心问题（任务之间的关系），引导读者关注任务结构和任务分类的重要性。\n\n5. 实验细节透明化（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：详细说明训练轮数、学习率、模型参数规模、解码方式等实验实现细节。\n\n6. 与现有方法直接对比（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：将本方法与已有的预训练模型（如GPT2）在同一数据集上的表现进行直接对比，强调性能提升。\n\n7. 详细实验设置说明（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：详细描述数据规模、训练参数、优化器、硬件环境等关键细节，确保实验充分。\n\n8. 引用权威基准和前沿模型（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：通过引用BERT、GPT等主流PLM及GLUE/SuperGLUE等权威基准，强调研究对象的广泛影响力和当前主流模型的性能。\n\n9. 列举已知缺陷并引用相关工作（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：系统性地罗列PLM在句序、数字理解、语义理解等方面的缺陷，并广泛引用相关文献，说明问题并非孤立。\n\n10. 引入核心理论属性（LNP）（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：明确提出LNP（逻辑否定属性）作为评判标准，并说明其在语言理解任务中的重要性。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_304",
        "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
        "problem_framing": "论文以学术gap为切入点，指出尽管大规模预训练语言模型（PLMs）在众多下游任务中表现优异，甚至在一些基准测试中超过人类，但其可靠性正受到挑战。通过引用多项研究，作者强调PLMs在句子顺序敏感性、数字理解、语义内容理解等方面存在缺陷，特别是在否定理解能力上表现不佳。这种问题的提出方式是从已有成果和实际应用需求的矛盾出发，强调这些缺陷阻碍了PLMs在实际、尤其是高风险领域的应用，进而引出对PLMs在否定和词汇语义（如同义词、反义词）理解能力的系统性检验的必要性。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法范围有限’和‘现有方法存在实际应用障碍’的逻辑。具体表现为：一方面，现有工作仅关注于简单的否定表达（如‘no’和‘not’），忽视了其他生成相反语义的扰动方式，未能全面评估PLMs对否定和词汇语义的理解；另一方面，现有的改进方法（如数据增强和unlikelihood training）依赖于额外的语言资源，难以迁移到其他语言，且需要从头预训练，资源消耗大。批评句式主要为‘仅考虑了X’、‘方法依赖于Y，导致Z问题’、‘未能解决A’等。",
        "method_story": "方法部分的叙述顺序为：先扩展理论边界，提出将LNP（逻辑否定性质）从传统的否定表达拓展到词汇语义层面（同义词、反义词），再设计相应的评测任务和指标。整体上采用‘先整体后局部’的策略，先说明研究视角和创新点，再具体介绍如何构建任务、如何评测模型的表现。方法介绍注重理论扩展和实验设计的结合，突出与以往工作的区别。",
        "experiments_story": "实验部分采用‘主实验+细致分析’的叙述策略。首先，明确采用top-k hit rate和weighted top-k hit rate等指标，系统评测PLMs在否定理解和词汇语义任务（MKR-NQ和MWR）上的表现。其次，通过分模型规模（base vs. large）、分任务类型（否定、同义词、反义词）等多维度展开，分析模型在不同场景下的表现差异。实验还包含对模型错误类型的细致分析（如对反义词问题的高错误率及原因），并通过表格展示具体数据，强调模型在高置信度下仍易犯错。整体上，实验设计注重多角度、多任务、多指标的系统验证。"
      },
      {
        "paper_id": "ARR_2022_39",
        "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling",
        "problem_framing": "论文通过回顾大规模预训练语言模型在自然语言处理任务中的显著进展作为开篇，强调模型参数规模和下游任务性能的持续提升，进而引出现有预训练框架（自回归、自动编码、编码-解码三类）各自的优势和局限，指出没有一种方法能够在所有NLP任务上表现优异。这种策略属于从学术gap出发，结合实际应用需求，强调当前方法的不足和统一框架的必要性。",
        "gap_pattern": "论文批评现有方法时，采用了对比和归纳的逻辑，逐一指出三类主流预训练模型的固有缺陷：自回归模型在NLU任务中受限于单向注意力机制，自动编码模型虽适合NLU但无法直接用于生成，编码-解码模型参数需求大且在性能上不具备全面优势。随后，论文指出以往尝试统一框架（如多任务学习、UniLM）未能充分继承各自优点，强调‘简单结合无法解决根本问题’。常用句式包括‘然而…’、‘但…’、‘不能…’等。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先整体介绍GLM的核心思想——基于自回归填空的统一预训练框架，并说明其如何将NLU任务转化为可生成回答的填空问题。随后，分条列举模型架构的具体改进，包括层归一化与残差连接顺序调整、输出层简化、激活函数替换等，突出每一项设计的动机和作用。",
        "experiments_story": "实验部分采用主实验+多数据集验证的策略。首先介绍预训练设置和下游任务评测，选用GLUE和SQuAD两个主流NLP基准数据集，分别覆盖单句、句对、抽取式问答等典型任务。实验重点在于与BERT等主流模型的直接对比，突出GLM在参数规模相同情况下的性能优势。未涉及消融或可视化实验，主要通过多任务、多数据集验证方法有效性。"
      },
      {
        "paper_id": "ARR_2022_242",
        "title": "CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in NLP",
        "problem_framing": "论文从学术gap出发引出问题。开篇先指出迁移学习在自然语言处理中的多种形式和广泛关注，进而提出一个高层次的核心问题：不同任务之间的关系结构尚不明确，现有研究缺乏对NLP任务之间结构性关联的系统刻画。作者进一步强调，构建任务分类体系对于指导迁移学习、减少任务间冗余具有重要价值，并提出目前NLP领域缺乏类似视觉领域Taskonomy的任务结构研究，进而引出本文的研究动机和目标。",
        "gap_pattern": "论文通过对比视觉领域已有的Taskonomy体系，指出NLP领域在任务结构建模方面的不足。具体批评逻辑为：现有NLP任务分类体系缺乏、未能充分利用认知神经科学数据来指导任务结构的构建。此外，实验部分也通过对比现有方法（如DSE和随机排序），指出这些方法无法有效捕捉任务间关系，尤其是在TinyBERT模型下甚至表现不如随机方法，强调了现有方法的局限性。",
        "method_story": "方法部分采用分模块介绍的策略。首先整体介绍了CogTaskonomy框架的设计理念和目标，然后细分为两个主要的认知启发模块：Cognitive Representation Analytics（CRA）和Cognitive-Neural Mapping（CNM）。每个模块分别介绍其功能和实现方式，先描述如何从NLP模型中提取任务表示，再说明如何通过认知神经科学方法（如RSA）进行任务相似性估计，最后介绍如何结合两者进行任务结构学习。",
        "experiments_story": "实验部分采用主实验+多数据集验证的策略。首先在广泛使用的NLP基准数据集和认知数据上评估CogTaskonomy的有效性，核心实验为任务迁移实验（task transferring），通过源任务到目标任务的迁移性能来度量任务相似性，并以此构建oracle任务排序。随后引入任务排序分数作为评价指标，系统对比不同任务相似性估计方法（CRA、CNM、DSE、随机排序等），并分析不同模型（如TinyBERT与BERT）下的表现差异。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 4,
        "percentage": "28.6%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "从问题提出、现有方法分析、创新点介绍到实验设计和结果分析，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升文章整体可读性和逻辑性，帮助读者跟随作者思路"
          },
          {
            "paper_id": "ARR_2022_99",
            "title": "Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?",
            "description": "从问题引入、方法铺垫到实验验证，层层递进，呼应前后内容，形成清晰的逻辑流。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，引导读者逐步理解问题和方法"
          },
          {
            "paper_id": "ARR_2022_235",
            "title": "Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations",
            "description": "先提出问题和创新点，再铺垫理论基础，最后详细描述实验设计和评测流程",
            "type": "writing-level",
            "purpose": "通过层层递进的逻辑结构，帮助读者理解问题提出、方法设计到实验验证的全过程"
          }
        ]
      },
      {
        "trick_name": "引用权威工作建立背景",
        "frequency": 3,
        "percentage": "21.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_99",
            "title": "Do Transformer Models Show Similar Attention Patterns to Task-Specific Human Gaze?",
            "description": "通过引用多篇相关领域权威文献，强调模型与人类注意力对齐的重要性，并为后续工作奠定理论基础。",
            "type": "writing-level",
            "purpose": "增强说服力和学术可信度，表明问题有广泛关注和理论基础"
          },
          {
            "paper_id": "ARR_2022_24",
            "title": "Pretraining with Synthetic Language: Studying Transferable Knowledge in Language Models",
            "description": "在引言中广泛引用BERT、T5等主流预训练模型及相关研究，说明跨语言迁移的现象已被充分观察和认可。",
            "type": "writing-level",
            "purpose": "通过引用大量权威文献和主流模型，增强研究背景的权威性和可信度。"
          },
          {
            "paper_id": "ARR_2022_57",
            "title": "ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models",
            "description": "通过引用Transformer、BERT、GPT-3等知名工作，强调PLM在NLP中的主流地位和巨大进展",
            "type": "writing-level",
            "purpose": "增强说服力和权威性，让读者信服该领域的重要性和趋势"
          }
        ]
      },
      {
        "trick_name": "创新点突出",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_39",
            "title": "GLM: General Language Model Pretraining with Autoregressive Blank Infilling",
            "description": "提出GLM框架，结合autoregressive和autoencoding思想，采用autoregressive blank infilling，并在方法部分具体描述两项架构改进。",
            "type": "method-level",
            "purpose": "明确展示方法的新颖性，吸引读者关注核心贡献"
          },
          {
            "paper_id": "ARR_2022_69",
            "title": "Life after BERT: What do Other Muppets Understand about Language?",
            "description": "明确指出本工作首次对8个模型家族进行系统分析，远超以往只分析1-2个家族的工作。",
            "type": "writing-level",
            "purpose": "强调本研究的独特性和创新性，吸引读者兴趣"
          }
        ]
      },
      {
        "trick_name": "问题驱动式引入",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_242",
            "title": "CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in NLP",
            "description": "通过提出跨任务迁移学习中的核心问题（任务之间的关系），引导读者关注任务结构和任务分类的重要性。",
            "type": "writing-level",
            "purpose": "激发读者兴趣，突出研究动机和实际需求"
          },
          {
            "paper_id": "ARR_2022_306",
            "title": "In-BoXBART: Get Instructions into Biomedical Multi-task Learning",
            "description": "通过指出现有任务特定模型在计算资源和时间上的高昂成本，强调需要更高效的通用模型，明确提出研究动机。",
            "type": "writing-level",
            "purpose": "突出实际问题，激发读者兴趣并强调工作的必要性"
          }
        ]
      },
      {
        "trick_name": "实验细节透明化",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_160",
            "title": "Cross-Task Generalization via Natural Language Crowdsourcing Instructions",
            "description": "详细说明训练轮数、学习率、模型参数规模、解码方式等实验实现细节。",
            "type": "experiment-level",
            "purpose": "提升完备性和可信度，便于复现和检验"
          },
          {
            "paper_id": "ARR_2022_306",
            "title": "In-BoXBART: Get Instructions into Biomedical Multi-task Learning",
            "description": "详细说明了模型参数、硬件环境、训练轮数、数据预处理和实例筛选等关键实验细节。",
            "type": "experiment-level",
            "purpose": "提升完备性和复现性，让读者相信实验结果可靠"
          }
        ]
      },
      {
        "trick_name": "与现有方法直接对比",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_158",
            "title": "Neural Language Taskonomy: Which NLP Tasks are the most Predictive of fMRI Brain Activity?",
            "description": "将本方法与已有的预训练模型（如GPT2）在同一数据集上的表现进行直接对比，强调性能提升。",
            "type": "experiment-level",
            "purpose": "通过与已有模型（如GPT2等）的性能对比，突出新方法的优越性"
          },
          {
            "paper_id": "ARR_2022_235",
            "title": "Contrastive Visual Semantic Pretraining Magnifies the Semantics of Natural Language Representations",
            "description": "采用Bommasani et al. (2020)的实验设置，并报告GPT-2有无BOS/EOS token的结果，与CLIP LM保持一致",
            "type": "experiment-level",
            "purpose": "突出自身方法的优势或不同之处，增强说服力和对比性"
          }
        ]
      },
      {
        "trick_name": "详细实验设置说明",
        "frequency": 2,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_117",
            "title": "“Is Whole Word Masking Always Better for Chinese BERT?”: Probing on Chinese Grammatical Error Correction",
            "description": "详细描述数据规模、训练参数、优化器、硬件环境等关键细节，确保实验充分。",
            "type": "experiment-level",
            "purpose": "增强实验的可复现性和科学性，提升完备性"
          },
          {
            "paper_id": "ARR_2022_57",
            "title": "ElitePLM: An Empirical Study on General Language Ability Evaluation of Pretrained Language Models",
            "description": "详细说明实验平台、训练参数、模型配置等，便于他人复现和评估",
            "type": "experiment-level",
            "purpose": "增强实验的可复现性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "引用权威基准和前沿模型",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "通过引用BERT、GPT等主流PLM及GLUE/SuperGLUE等权威基准，强调研究对象的广泛影响力和当前主流模型的性能。",
            "type": "writing-level",
            "purpose": "增强说服力和权威性，表明研究对象具有代表性和重要性"
          }
        ]
      },
      {
        "trick_name": "列举已知缺陷并引用相关工作",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "系统性地罗列PLM在句序、数字理解、语义理解等方面的缺陷，并广泛引用相关文献，说明问题并非孤立。",
            "type": "writing-level",
            "purpose": "突出问题的普遍性和紧迫性，为后续方法铺垫合理性"
          }
        ]
      },
      {
        "trick_name": "引入核心理论属性（LNP）",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "明确提出LNP（逻辑否定属性）作为评判标准，并说明其在语言理解任务中的重要性。",
            "type": "writing-level",
            "purpose": "强化问题的理论基础，提升研究的学术深度"
          }
        ]
      },
      {
        "trick_name": "批判现有方法的局限性",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "分析前人方法只关注否定表达、依赖语言资源、训练成本高等缺点，为新方法的提出做铺垫。",
            "type": "writing-level",
            "purpose": "突出本工作的创新空间和必要性"
          }
        ]
      },
      {
        "trick_name": "扩展问题定义",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "将LNP的范围从否定词扩展到词汇语义（同义词、反义词），强调方法的创新点。",
            "type": "method-level",
            "purpose": "展示新颖性，表明工作突破了前人研究的边界"
          }
        ]
      },
      {
        "trick_name": "精确定义评价指标",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "详细定义top-k hit rate和加权hit rate指标，解释其计算方式和意义，帮助读者理解模型表现。",
            "type": "experiment-level",
            "purpose": "提升可解释性和科学性，使实验结果更具说服力"
          }
        ]
      },
      {
        "trick_name": "用具体数据和表格支撑结论",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "通过表格展示不同模型、不同任务下的具体指标数据，支撑实验结论。",
            "type": "experiment-level",
            "purpose": "增强完备性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "多维度分析实验结果",
        "frequency": 1,
        "percentage": "7.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_304",
            "title": "Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence",
            "description": "从模型规模、top-k变化、置信度、词性等多个维度分析实验结果，展示问题的复杂性和普遍性。",
            "type": "experiment-level",
            "purpose": "提升完备性和可解释性，证明实验设计充分"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 14,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_304",
        "ARR_2022_39",
        "ARR_2022_242",
        "ARR_2022_167",
        "ARR_2022_69",
        "ARR_2022_160",
        "ARR_2022_99",
        "ARR_2022_158",
        "ARR_2022_235",
        "ARR_2022_117",
        "ARR_2022_24",
        "ARR_2022_306",
        "ARR_2022_57",
        "COLING_2020_24"
      ]
    }
  },
  {
    "pattern_id": 24,
    "pattern_name": "神经机器翻译术语约束与质量评估",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决神经机器翻译中的术语约束和质量评估问题，采用新颖的训练方法和多任务框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过对比现有方法指出gap，方法部分采用先整体后局部的叙述策略，实验设计多采用多数据集验证和多指标评估。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确术语翻译和高质量自动评估的多语种神经机器翻译任务，预期提升翻译质量和评估准确性。",
    "writing_guide": "写作模板：神经机器翻译术语约束与质量评估\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决神经机器翻译中的术语约束和质量评估问题，采用新颖的训练方法和多任务框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过对比现有方法指出gap，方法部分采用先整体后局部的叙述策略，实验设计多采用多数据集验证和多指标评估。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确术语翻译和高质量自动评估的多语种神经机器翻译任务，预期提升翻译质量和评估准确性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints》\n  • 问题定位：论文首先从实际应用需求出发，指出神经机器翻译（NMT）虽然取得了成功，但在真实应用中往往需要对特定术语进行精确翻译。作者以应用痛点为切入点，强调词典和术语约束在领域自适应、交互式翻译等场景中的重要性，并指出现有方法在术语约束方面存在不足，特别是在处理低频词时存在问题。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和归纳的逻辑。首先总结现有方法主要基于自回归模型，在推断或训练阶段施加约束，但这些方法要么推断耗时、难以满足实时需求，要么不能保证约束词一定出现在输出中。对于非自回归模型，作者指出相关研究较少，且现有编辑式NAT方法在遇到低频词约束时表现脆弱。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先提出整体解决思路——Aligned Constrained Training (ACT)，并明确两大核心思想：1）约束训练以弥合训练与推断不一致，2）对齐提示以增强模型对约束词上下文的理解。\n  • 实验设计：实验部分采用多数据集验证和主实验+消融的策略。首先介绍数据集设置，包括主流通用领域（WMT14、WMT17）和实际应用相关的领域数据（OPUS医疗、法律），并详细说明约束词的提取方式和频率统计。评价指标包括BLEU和Term Usage Rate，兼顾翻译质量和约束词覆盖率。\n\n示例 2：《Why don’t people use character-level machine translation?》\n  • 问题定位：论文通过从学术gap出发引出问题。开篇先回顾了深度学习在自然语言处理领域推动的端到端学习趋势，指出输入数据的假设逐渐被弱化，但在机器翻译和NLP中，基于语言学的输入分割仍然被广泛采用。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出虽然有文献宣称字符级方法与子词模型表现相当，但字符级方法很少作为强基线，暗示其可能存在未被充分讨论的缺点。此外，批评以往研究多在小数据集上进行，且仅关注定量翻译质量，缺乏深入分析。\n  • 核心方法：方法部分采用分模块介绍和从简单到复杂的叙述策略。首先，作者概述字符级序列处理的主要挑战（如序列长度和信息密度），然后依次介绍四种架构：直接字符嵌入、Lee-style卷积编码、CANINE局部自注意力编码、Charformer平均池化编码。\n  • 实验设计：实验部分采用多数据集验证和主实验+扩展实验的叙述策略。首先，作者在中小规模IWSLT 2017数据集上对所有方法进行对比实验，详细说明数据预处理、模型实现和参数设置。\n\n示例 3：《Translation Error Detection as Rationale Extraction》\n  • 问题定位：论文通过结合实际应用需求和学术研究现状来引出问题。开篇首先介绍了质量评估（QE）在机器翻译中的重要性，强调在没有人工参考译文时预测翻译质量的实际痛点，如决定译文是否可直接发布、定位关键错误等。随后指出当前方法在句子级表现优异，但单词级预测准确率仍有提升空间，部分原因是单词级标注昂贵且耗时。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出当前主流方法在句子级QE上表现优异，但单词级预测准确率不足，归因于训练数据有限。进一步分析现有无监督或半监督方法的不足，如需要访问MT模型或依赖合成数据，未能完全摆脱单词级监督需求。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先用形式化定义描述任务和输入输出，然后介绍特征归因方法的基本原理和分类（简化、梯度、扰动等），再具体说明本研究选用的三种主流归因方法及其选择理由。最后补充说明LIME方法作为对比，强调本研究关注的是无须单词级监督的归因方法，而非归因方法的全面对比。\n  • 实验设计：实验部分采用了主实验+多指标验证的策略。首先明确实验目标是评估归因分数与人工标注错误的对应关系，针对归因方法输出连续分数而非二元标签的特点，选用AUC、平均精度、Top-K召回率、Top-1准确率等多种指标进行评估。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 10.0%）\n   类型：writing-level\n   应用：从领域现状和问题切入，逐步引出研究目标、方法设计、实验验证和结论，层层递进。\n\n2. 多指标评估（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：采用BLEU和Term Usage Rate等多种指标评估翻译质量和约束词覆盖率，确保结果可靠全面。\n\n3. 多数据集验证（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：在不同类型数据集（通用领域和专业领域）上进行实验，覆盖新闻、医疗、法律等多场景。\n\n4. 方法创新点突出（使用频率 2 次，占比 6.7%）\n   类型：method-level\n   应用：明确提出首次在MT中系统比较最新字符处理结构，并提出了新的两步解码器架构，解决字符序列过长导致的解码效率问题。\n\n5. 引用权威工作（使用频率 2 次，占比 6.7%）\n   类型：writing-level\n   应用：多次引用领域内权威论文和竞赛结果，证明现有方法的不足和新方法的必要性。\n\n6. 实验细节透明披露（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：详细描述数据预处理、模型参数、优化器设置、学习率调度等实验细节，便于他人复现。\n\n7. 问题导向开篇（使用频率 2 次，占比 6.7%）\n   类型：writing-level\n   应用：作者通过提出领域内的核心矛盾（高质量合成数据未必带来最佳性能），引出研究的根本问题，激发读者关注。\n\n8. 对比实验设计（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：作者设置多组对比，包括beam、sampling、beam*、gamma方法等，系统比较不同生成策略的效果。\n\n9. 创新点明确命名（使用频率 2 次，占比 6.7%）\n   类型：method-level\n   应用：作者提出Weighted Label Smoothing (WLS)和Masked Label Smoothing (MLS)，并给出简要定义。\n\n10. 参数敏感性分析（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：对关键超参数进行分步调优和分析，展示不同设置下的性能变化。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_276",
        "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
        "problem_framing": "论文首先从实际应用需求出发，指出神经机器翻译（NMT）虽然取得了成功，但在真实应用中往往需要对特定术语进行精确翻译。作者以应用痛点为切入点，强调词典和术语约束在领域自适应、交互式翻译等场景中的重要性，并指出现有方法在术语约束方面存在不足，特别是在处理低频词时存在问题。通过实际案例（如表1中的低频词约束失败），进一步凸显问题的严重性和实际危害，从而自然引出研究动机。",
        "gap_pattern": "论文批评现有方法时，采用了对比和归纳的逻辑。首先总结现有方法主要基于自回归模型，在推断或训练阶段施加约束，但这些方法要么推断耗时、难以满足实时需求，要么不能保证约束词一定出现在输出中。对于非自回归模型，作者指出相关研究较少，且现有编辑式NAT方法在遇到低频词约束时表现脆弱。批评句式包括“such methods either are time-consuming in real-time applications or do not ensure the appearance of constraints in the output”、“such methods are vulnerable when encountered with low-frequency words as constraints”，并归因于训练与推断不一致、模型对约束词上下文理解不足。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先提出整体解决思路——Aligned Constrained Training (ACT)，并明确两大核心思想：1）约束训练以弥合训练与推断不一致，2）对齐提示以增强模型对约束词上下文的理解。随后介绍具体实现，选用Levenshtein Transformer为基础，并与一系列已有方法进行对比。方法介绍过程中，先给出整体框架，再细化到各个对比方法和具体实验配置，层层递进，突出创新点。",
        "experiments_story": "实验部分采用多数据集验证和主实验+消融的策略。首先介绍数据集设置，包括主流通用领域（WMT14、WMT17）和实际应用相关的领域数据（OPUS医疗、法律），并详细说明约束词的提取方式和频率统计。评价指标包括BLEU和Term Usage Rate，兼顾翻译质量和约束词覆盖率。实验内容涵盖主实验（不同方法在多个数据集上的性能对比）、消融实验（对比ACT与CT的效果）、以及速度（推断延迟）等，系统性地验证方法有效性和优势。"
      },
      {
        "paper_id": "ARR_2022_343",
        "title": "Why don’t people use character-level machine translation?",
        "problem_framing": "论文通过从学术gap出发引出问题。开篇先回顾了深度学习在自然语言处理领域推动的端到端学习趋势，指出输入数据的假设逐渐被弱化，但在机器翻译和NLP中，基于语言学的输入分割仍然被广泛采用。随后，作者引用近期文献表明字符级方法在某些情况下可与子词模型媲美，但实际研究和竞赛中字符级方法很少作为强基线，暗示存在未被充分讨论的缺陷。由此，论文自然过渡到对字符级机器翻译现状的系统性调查和评估，强调对领域内未解决问题的关注。",
        "gap_pattern": "论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出虽然有文献宣称字符级方法与子词模型表现相当，但字符级方法很少作为强基线，暗示其可能存在未被充分讨论的缺点。此外，批评以往研究多在小数据集上进行，且仅关注定量翻译质量，缺乏深入分析。作者强调需要在大数据集上系统性评估字符级方法的优劣，并补充对解码策略和架构效率的考察。",
        "method_story": "方法部分采用分模块介绍和从简单到复杂的叙述策略。首先，作者概述字符级序列处理的主要挑战（如序列长度和信息密度），然后依次介绍四种架构：直接字符嵌入、Lee-style卷积编码、CANINE局部自注意力编码、Charformer平均池化编码。每种方法都先简要说明原理，再结合相关文献和自身实验调整，突出各自的创新点和差异。最后，提出两步解码器架构，作为对标准解码器效率问题的改进。整体上，方法部分先整体描述问题，再逐步细化各模块，逻辑清晰递进。",
        "experiments_story": "实验部分采用多数据集验证和主实验+扩展实验的叙述策略。首先，作者在中小规模IWSLT 2017数据集上对所有方法进行对比实验，详细说明数据预处理、模型实现和参数设置。随后，根据初步结果，进一步在大规模高资源语言对（英语-捷克、英语-德语）上用Lee-style编码器做深入实验，并探索混合编码（子词编码器+字符解码器）系统。实验类型涵盖主实验、架构对比、参数设置探索和系统扩展，强调方法在不同数据规模和语言对上的适用性和性能表现。"
      },
      {
        "paper_id": "ARR_2022_177",
        "title": "Translation Error Detection as Rationale Extraction",
        "problem_framing": "论文通过结合实际应用需求和学术研究现状来引出问题。开篇首先介绍了质量评估（QE）在机器翻译中的重要性，强调在没有人工参考译文时预测翻译质量的实际痛点，如决定译文是否可直接发布、定位关键错误等。随后指出当前方法在句子级表现优异，但单词级预测准确率仍有提升空间，部分原因是单词级标注昂贵且耗时。最后，提出无需单词级训练数据的新方法，明确学术gap和实际需求并存。",
        "gap_pattern": "论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出当前主流方法在句子级QE上表现优异，但单词级预测准确率不足，归因于训练数据有限。进一步分析现有无监督或半监督方法的不足，如需要访问MT模型或依赖合成数据，未能完全摆脱单词级监督需求。句式上多用 'however', 'still leaves room for improvement', 'requires', 'limited', 'do not require', 'need access to' 等表达现有方法的不足和局限。",
        "method_story": "方法部分采用了先整体后局部的叙述顺序。首先用形式化定义描述任务和输入输出，然后介绍特征归因方法的基本原理和分类（简化、梯度、扰动等），再具体说明本研究选用的三种主流归因方法及其选择理由。最后补充说明LIME方法作为对比，强调本研究关注的是无须单词级监督的归因方法，而非归因方法的全面对比。整体上从任务定义到方法类别，再到具体实现，层层递进。",
        "experiments_story": "实验部分采用了主实验+多指标验证的策略。首先明确实验目标是评估归因分数与人工标注错误的对应关系，针对归因方法输出连续分数而非二元标签的特点，选用AUC、平均精度、Top-K召回率、Top-1准确率等多种指标进行评估。每个指标都详细说明计算方法和适用场景，并指出某些特殊情况（如全对或全错句子）不参与评估。整体上以主实验为核心，强调多维度量化验证方法有效性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "10.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_343",
            "title": "Why don’t people use character-level machine translation?",
            "description": "从领域现状和问题切入，逐步引出研究目标、方法设计、实验验证和结论，层层递进。",
            "type": "writing-level",
            "purpose": "增强论文的逻辑性和易读性"
          },
          {
            "paper_id": "ARR_2022_226",
            "title": "Building Multilingual Machine Translation Systems That Serve Arbitrary XY Translations",
            "description": "采用‘问题-现状-挑战-方法-实验-结论’的逻辑流，层层递进，环环相扣，提升整体可读性。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题、方法和结论之间的联系"
          },
          {
            "paper_id": "ARR_2022_51",
            "title": "When do Contrastive Word Alignments Improve Many-to-many Neural Machine Translation?",
            "description": "作者先提出现有问题和动机，随后介绍创新方法，最后用实验结果呼应前述假设和动机，结构清晰。",
            "type": "writing-level",
            "purpose": "提升论文的逻辑性和易读性，通过先引出问题、再铺垫方法、最后实验呼应结论，形成闭环。"
          }
        ]
      },
      {
        "trick_name": "多指标评估",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_276",
            "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
            "description": "采用BLEU和Term Usage Rate等多种指标评估翻译质量和约束词覆盖率，确保结果可靠全面。",
            "type": "experiment-level",
            "purpose": "提升实验完备性，保证结论的全面性"
          },
          {
            "paper_id": "ACL_2017_369",
            "title": "Morphology Generation for Statistical Machine Translation using Deep Learning Techniques",
            "description": "采用多种评价指标（如分类准确率、Oracle、METEOR等）对模型进行全面评估，确保结果的客观性和可靠性。",
            "type": "experiment-level",
            "purpose": "全面评价模型性能"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_276",
            "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
            "description": "在不同类型数据集（通用领域和专业领域）上进行实验，覆盖新闻、医疗、法律等多场景。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和稳健性"
          },
          {
            "paper_id": "ARR_2022_123",
            "title": "An Empirical Study of Document-to-document Neural Machine Translation",
            "description": "作者在九个文档级数据集上进行实验，涵盖多语言和多领域，展示方法的普适性",
            "type": "experiment-level",
            "purpose": "增强完备性，通过覆盖多种语言和场景证明方法的广泛适用性和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "方法创新点突出",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_343",
            "title": "Why don’t people use character-level machine translation?",
            "description": "明确提出首次在MT中系统比较最新字符处理结构，并提出了新的两步解码器架构，解决字符序列过长导致的解码效率问题。",
            "type": "method-level",
            "purpose": "强调本工作的创新性和与现有工作的区别"
          },
          {
            "paper_id": "ARR_2022_51",
            "title": "When do Contrastive Word Alignments Improve Many-to-many Neural Machine Translation?",
            "description": "作者明确提出首次在多对多NMT中利用自动对齐词对进行词级对比学习，突出方法创新。",
            "type": "method-level",
            "purpose": "展示创新性，强调提出了词级对比学习目标，区别于以往句级或基于人工词典的方法。"
          }
        ]
      },
      {
        "trick_name": "引用权威工作",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_105",
            "title": "UniTE: Unified Translation Evaluation",
            "description": "多次引用领域内权威论文和竞赛结果，证明现有方法的不足和新方法的必要性。",
            "type": "writing-level",
            "purpose": "增强说服力，显示方法建立在已有工作的基础之上并解决其不足"
          },
          {
            "paper_id": "ARR_2022_123",
            "title": "An Empirical Study of Document-to-document Neural Machine Translation",
            "description": "作者通过大量引用NMT和DNMT领域的经典文献，说明现有方法的局限性和研究热点，增强论述的权威性和可信度",
            "type": "writing-level",
            "purpose": "增强说服力，通过引用领域内权威和主流文献证明问题的重要性和相关性"
          }
        ]
      },
      {
        "trick_name": "实验细节透明披露",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_212",
            "title": "Parallel Decoding Sequences by Glancing Discrete Latent Variables",
            "description": "详细描述数据预处理、模型参数、优化器设置、学习率调度等实验细节，便于他人复现。",
            "type": "experiment-level",
            "purpose": "增强实验的可复现性和结果的可信度"
          },
          {
            "paper_id": "ARR_2022_51",
            "title": "When do Contrastive Word Alignments Improve Many-to-many Neural Machine Translation?",
            "description": "作者详细列出所用数据集、语言对、预处理方式、模型架构等，便于他人复现和验证。",
            "type": "experiment-level",
            "purpose": "增强完备性和可复现性，通过详细说明数据集、预处理、模型配置等细节，确保实验可靠。"
          }
        ]
      },
      {
        "trick_name": "问题导向开篇",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_54",
            "title": "On Synthetic Data for Back Translation",
            "description": "作者通过提出领域内的核心矛盾（高质量合成数据未必带来最佳性能），引出研究的根本问题，激发读者关注。",
            "type": "writing-level",
            "purpose": "引发读者兴趣并明确研究动机"
          },
          {
            "paper_id": "ARR_2022_183",
            "title": "Bias Mitigation in Machine Translation Quality Estimation",
            "description": "作者首先指出机器翻译模型的不足和质量估计领域的挑战，强调没有金标准参考时的困难，吸引读者关注该问题。",
            "type": "writing-level",
            "purpose": "引发读者关注并凸显研究意义"
          }
        ]
      },
      {
        "trick_name": "对比实验设计",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_54",
            "title": "On Synthetic Data for Back Translation",
            "description": "作者设置多组对比，包括beam、sampling、beam*、gamma方法等，系统比较不同生成策略的效果。",
            "type": "experiment-level",
            "purpose": "突出新方法优越性"
          },
          {
            "paper_id": "ARR_2022_108",
            "title": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents",
            "description": "与SenNMT、单语种DocNMT等现有方法进行直接性能对比，展示新方法的改进效果。",
            "type": "experiment-level",
            "purpose": "突出方法优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "创新点明确命名",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_179",
            "title": "Focus on the Target’s Vocabulary: Masked Label Smoothing for Machine Translation",
            "description": "作者提出Weighted Label Smoothing (WLS)和Masked Label Smoothing (MLS)，并给出简要定义。",
            "type": "method-level",
            "purpose": "通过为新方法命名，突出创新性和辨识度"
          },
          {
            "paper_id": "ARR_2022_173",
            "title": "Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation",
            "description": "提出并命名‘Conditional Bilingual Mutual Information (CBMI)’，强调其区别于现有统计指标。",
            "type": "method-level",
            "purpose": "突出新颖性，便于读者记忆和理解方法创新"
          }
        ]
      },
      {
        "trick_name": "参数敏感性分析",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_173",
            "title": "Conditional Bilingual Mutual Information Based Adaptive Training for Neural Machine Translation",
            "description": "对关键超参数进行分步调优和分析，展示不同设置下的性能变化。",
            "type": "experiment-level",
            "purpose": "证明方法的稳健性和完备性，展示实验充分性"
          },
          {
            "paper_id": "ARR_2022_200",
            "title": "Language Model Augmented Monotonic Attention for Simultaneous Translation",
            "description": "通过分析λ等超参数对模型权重分配和性能的影响，解释模型行为。",
            "type": "experiment-level",
            "purpose": "增强实验的完备性和方法的可解释性"
          }
        ]
      },
      {
        "trick_name": "多维度评价指标",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_200",
            "title": "Language Model Augmented Monotonic Attention for Simultaneous Translation",
            "description": "采用延迟和BLEU等多种指标评价模型，证明方法在质量和延迟上的权衡优势。",
            "type": "experiment-level",
            "purpose": "增强实验结果的说服力和全面性"
          },
          {
            "paper_id": "ARR_2022_108",
            "title": "Multilingual Document-Level Translation Enables Zero-Shot Transfer From Sentences to Documents",
            "description": "除BLEU外，采用文档级BLEU、对比测试集和性别偏差F1等多种指标，全面评估模型性能。",
            "type": "experiment-level",
            "purpose": "增强实验结果的说服力和细致性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进结构",
        "frequency": 2,
        "percentage": "6.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_310",
            "title": "BiTIIMT: A Bilingual Text-infilling Method for Interactive Machine Translation",
            "description": "从问题引入、现有方法分析、创新方法提出、方法细节说明到实验验证，层层递进，环环相扣。",
            "type": "writing-level",
            "purpose": "保证全文叙事的连贯性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_123",
            "title": "An Empirical Study of Document-to-document Neural Machine Translation",
            "description": "作者先提出问题和现有不足，再介绍方法和实验设计，最后呼应结论，形成完整的逻辑闭环",
            "type": "writing-level",
            "purpose": "提升叙事流畅性，通过层层递进的逻辑结构引导读者理解问题、方法和结论"
          }
        ]
      },
      {
        "trick_name": "现实需求引入",
        "frequency": 1,
        "percentage": "3.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_276",
            "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
            "description": "作者首先指出实际应用中对精确术语翻译的需求，强调现有NMT方法在实际场景下的不足，为后续方法提出提供现实动机。",
            "type": "writing-level",
            "purpose": "凸显研究问题的重要性和实际价值，增强说服力"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性批判",
        "frequency": 1,
        "percentage": "3.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_276",
            "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
            "description": "通过详细分析现有约束翻译方法（如AT模型）的缺陷，如效率低、不能保证约束词出现，强调了新方法的改进空间。",
            "type": "writing-level",
            "purpose": "突出自身工作的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "类比与比喻解释",
        "frequency": 1,
        "percentage": "3.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_276",
            "title": "Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints",
            "description": "用‘a stranger’s neighbors are not necessarily strangers’类比，解释稀有词的上下文通常并不稀有，帮助读者理解方法的理论基础。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者理解方法背后的直觉"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 30,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_276",
        "ARR_2022_343",
        "ARR_2022_177",
        "ARR_2022_105",
        "ARR_2022_212",
        "ARR_2022_54",
        "ARR_2022_338",
        "ARR_2022_226",
        "ARR_2022_179",
        "ARR_2022_173",
        "ARR_2022_51",
        "ARR_2022_200",
        "ARR_2022_183",
        "ARR_2022_322",
        "ARR_2022_310",
        "ARR_2022_123",
        "ARR_2022_107",
        "ARR_2022_108",
        "ACL_2017_369",
        "ACL_2017_676",
        "ACL_2017_779",
        "ACL_2017_496",
        "ACL_2017_564",
        "ACL_2017_49",
        "ACL_2017_150",
        "COLING_2020_0",
        "COLING_2020_43",
        "COLING_2020_72",
        "COLING_2020_63",
        "COLING_2020_47"
      ]
    }
  },
  {
    "pattern_id": 25,
    "pattern_name": "对话系统评估与迁移学习",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决对话系统评估、迁移学习和连贯性评价问题，采用形式化任务定义和多基线对比实验验证方法。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过批评现有方法指出gap，采用逻辑递进的叙事结构，结合引用权威文献和多数据集覆盖增强说服力。\n\n第3段（60字）：适用场景与预期效果 - 适用于对话系统评估、多语言迁移和连贯性评价任务，预期提升模型在真实场景和多语言环境下的表现。",
    "writing_guide": "写作模板：对话系统评估与迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决对话系统评估、迁移学习和连贯性评价问题，采用形式化任务定义和多基线对比实验验证方法。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过批评现有方法指出gap，采用逻辑递进的叙事结构，结合引用权威文献和多数据集覆盖增强说服力。\n\n第3段（60字）：适用场景与预期效果 - 适用于对话系统评估、多语言迁移和连贯性评价任务，预期提升模型在真实场景和多语言环境下的表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Ditch the Gold Standard: Re-evaluating Conversational Question Answering》\n  • 问题定位：论文从应用需求和实际痛点出发引入问题，强调对话式问答（CQA）有潜力革新人机交互的信息获取方式。通过指出当前评估方式（基于预收集的对话和金标准历史）与真实应用场景之间的差距，提出了对现有评估方法有效性的质疑，并以此作为研究动机。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法忽视了实际应用场景的需求”和“现有方法在真实人机对话中失效”的逻辑。\n  • 核心方法：方法部分采用了先整体后局部、从简单到复杂的叙述策略。首先介绍了用于人类评估的四个代表性CQA模型，从最基础的BERT模型开始，逐步介绍更复杂的GraphFlow、HAM和ExCorD模型，并简要说明每个模型的核心机制和创新点。\n  • 实验设计：实验部分采用了主实验对比分析的策略。首先详细描述了CQA任务的设定和评估流程，接着进行大规模人类评估，与现有自动评估（Auto-Gold）进行对比，分析排名和模型间差距的变化。\n\n示例 2：《Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue》\n  • 问题定位：论文从实际应用需求出发引出问题，强调随着任务型对话系统（TOD）的广泛应用，系统需要支持越来越多样化的服务/API，但许多服务开发者缺乏标注数据和机器学习专业知识，因此对未见服务的零样本/少样本迁移变得至关重要。\n  • 现有研究缺口：论文批评现有方法时，首先指出主流方法依赖于大语言模型和基于描述的schema建模，但自然语言描述的编写仍需人工投入且难以精确，同时对未见服务的监督作用有限。此外，引用Lee等（2021b）的实证结果，指出现有模型对schema描述的变化不够鲁棒，准确率显著下降。\n  • 核心方法：方法部分采用先整体后局部的叙述策略，先提出核心思想——用单一对话示例替代schema描述（即Show, Don’t Tell, SDT），再具体介绍在不同T5模型规模上的应用和两种SDT变体（SDT-seq与SDT-ind）的对比。\n  • 实验设计：实验部分采用多数据集验证和主实验+对比实验的叙述策略。首先在两个主流DST数据集（SGD和MultiWOZ 2.1）上进行主实验，分别说明数据集设置和prompt构建方式。其次，详细描述与多种基线方法的对比，并对不同prompt版本做平均以保证结果稳健。\n\n示例 3：《GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems》\n  • 问题定位：论文通过结合实际应用需求与学术痛点来引出问题。首先强调人工智能领域实现自然语言交流的重要目标，并指出任务型对话系统（ToD）的广泛应用和实际价值，如酒店预订、天气查询等。随后，作者转向现实挑战，即现有系统主要服务于英语用户，限制了全球用户的可用性，核心原因是高质量多语言数据集的匮乏。\n  • 现有研究缺口：论文对现有方法的批评采用了‘现有方法忽视了实际场景需求’和‘现有方法在跨语言、本地实体检索场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘整体流程先行，分步骤详细展开’的叙述策略。先整体介绍将英文ToD数据集全球化的四步流程：模板抽取、翻译与后编辑、本地本体收集、模板实体替换。每一步骤都在后文有独立小节详细说明，强调流程的系统性和可复用性。\n  • 实验设计：实验部分采用‘主实验+多设置对比’的策略，围绕零样本（zero-shot）和小样本（few-shot）跨语言迁移两个核心实验设置展开。每个设置都明确实验假设和数据来源，分别评估模型在无目标语言标注数据和有限标注数据下的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进的叙事结构（使用频率 5 次，占比 21.7%）\n   类型：writing-level\n   应用：先引入问题和现有方法不足，再提出新方法，最后通过系统实验验证，结构清晰递进。\n\n2. 逻辑递进式叙事结构（使用频率 5 次，占比 21.7%）\n   类型：writing-level\n   应用：按照‘问题-方法-实验’的经典结构组织全文，层层递进，前后呼应\n\n3. 创新点突出（使用频率 4 次，占比 17.4%）\n   类型：method-level\n   应用：提出基于AMR的语义级扰动生成负样本，并强调其能捕捉更细致的连贯性错误\n\n4. 消融实验设计（使用频率 4 次，占比 17.4%）\n   类型：experiment-level\n   应用：系统移除方法中的关键组件，展示每个部分对整体性能的影响，证明方法设计的合理性。\n\n5. 定量与定性结果结合（使用频率 3 次，占比 13.0%）\n   类型：experiment-level\n   应用：同时报告任务成功率、语言质量指标（如BLEU、perplexity），并分析不同方法的表现差异。\n\n6. 多维度评价指标（使用频率 3 次，占比 13.0%）\n   类型：experiment-level\n   应用：采用PPL、F1、Distinct、BLEU、METEOR、ROUGE等多种自动评价指标，覆盖生成质量和多样性。\n\n7. 形式化任务定义（使用频率 2 次，占比 8.7%）\n   类型：writing-level\n   应用：对对话问答流程进行形式化定义，明确每一步的输入输出，帮助读者理解实验流程和评测标准。\n\n8. 多基线对比实验（使用频率 2 次，占比 8.7%）\n   类型：experiment-level\n   应用：在多个数据集上与多种现有方法（如SGP-DST、T5-seq等）系统对比，展示SDT的性能提升。\n\n9. 引用权威文献（使用频率 2 次，占比 8.7%）\n   类型：writing-level\n   应用：广泛引用相关领域的经典和最新文献，说明ToD系统的现状和挑战\n\n10. 多数据集覆盖（使用频率 2 次，占比 8.7%）\n   类型：experiment-level\n   应用：在多个公开数据集（如FED、DSTC9、Ubuntu、DailyDialog等）上进行训练和评测\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_227",
        "title": "Ditch the Gold Standard: Re-evaluating Conversational Question Answering",
        "problem_framing": "论文从应用需求和实际痛点出发引入问题，强调对话式问答（CQA）有潜力革新人机交互的信息获取方式。通过指出当前评估方式（基于预收集的对话和金标准历史）与真实应用场景之间的差距，提出了对现有评估方法有效性的质疑，并以此作为研究动机。开篇策略是先介绍CQA的进展和实际应用前景，再引出评估方式与实际应用不符的痛点，最终提出需要更真实、更贴近实际的评估方法。",
        "gap_pattern": "论文批评现有方法时，采用了“现有方法忽视了实际应用场景的需求”和“现有方法在真实人机对话中失效”的逻辑。具体句式包括：‘尽管当前系统在静态评估上表现极为优秀，但这种评估方式是否能真实反映模型在实际应用中的表现值得怀疑’，‘当前评估始终提供金标准历史，无论模型实际预测如何’，‘现有自动评估无法反映人机对话中的真实表现’，并通过引用相关工作指出该问题已被部分学者注意但未被充分解决。",
        "method_story": "方法部分采用了先整体后局部、从简单到复杂的叙述策略。首先介绍了用于人类评估的四个代表性CQA模型，从最基础的BERT模型开始，逐步介绍更复杂的GraphFlow、HAM和ExCorD模型，并简要说明每个模型的核心机制和创新点。随后，针对评估方法的不足，提出了新的自动评估机制，包括基于预测历史的评估和问题重写机制，详细阐述了如何检测和修正因历史变化导致的问题不可回答。",
        "experiments_story": "实验部分采用了主实验对比分析的策略。首先详细描述了CQA任务的设定和评估流程，接着进行大规模人类评估，与现有自动评估（Auto-Gold）进行对比，分析排名和模型间差距的变化。实验类型主要包括：1）大规模人类-模型对话评估，2）自动评估与人类评估结果的对比分析，3）引入预测历史和问题重写机制后的自动评估效果分析。通过这些实验，论文系统性地验证了新评估方法的有效性和与人类评判的一致性。"
      },
      {
        "paper_id": "ARR_2022_199",
        "title": "Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",
        "problem_framing": "论文从实际应用需求出发引出问题，强调随着任务型对话系统（TOD）的广泛应用，系统需要支持越来越多样化的服务/API，但许多服务开发者缺乏标注数据和机器学习专业知识，因此对未见服务的零样本/少样本迁移变得至关重要。这一现实痛点作为开篇，突出了对话系统民主化的迫切需求，并自然引入了对现有方法泛化能力的关注。",
        "gap_pattern": "论文批评现有方法时，首先指出主流方法依赖于大语言模型和基于描述的schema建模，但自然语言描述的编写仍需人工投入且难以精确，同时对未见服务的监督作用有限。此外，引用Lee等（2021b）的实证结果，指出现有模型对schema描述的变化不够鲁棒，准确率显著下降。批评逻辑采用了“现有方法在X场景下失效”和“现有方法忽视了Y实际需求”的句式，强调了方法的局限性和实际应用中的不足。",
        "method_story": "方法部分采用先整体后局部的叙述策略，先提出核心思想——用单一对话示例替代schema描述（即Show, Don’t Tell, SDT），再具体介绍在不同T5模型规模上的应用和两种SDT变体（SDT-seq与SDT-ind）的对比。方法介绍中穿插了与现有方法的对比，并明确实验设置和参数细节，逐步展开方法的细节和创新点。",
        "experiments_story": "实验部分采用多数据集验证和主实验+对比实验的叙述策略。首先在两个主流DST数据集（SGD和MultiWOZ 2.1）上进行主实验，分别说明数据集设置和prompt构建方式。其次，详细描述与多种基线方法的对比，并对不同prompt版本做平均以保证结果稳健。还包括进一步微调实验（如T5-seq在对话示例上的微调），分析方法有效性和局限性。整体上，实验设计覆盖主实验、对比实验和方法细节探究，强调结果的广泛性和可靠性。"
      },
      {
        "paper_id": "ARR_2022_42",
        "title": "GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems",
        "problem_framing": "论文通过结合实际应用需求与学术痛点来引出问题。首先强调人工智能领域实现自然语言交流的重要目标，并指出任务型对话系统（ToD）的广泛应用和实际价值，如酒店预订、天气查询等。随后，作者转向现实挑战，即现有系统主要服务于英语用户，限制了全球用户的可用性，核心原因是高质量多语言数据集的匮乏。整体开篇策略是从应用需求出发，结合学术领域的现有不足，突出多语言任务型对话系统的迫切需求。",
        "gap_pattern": "论文对现有方法的批评采用了‘现有方法忽视了实际场景需求’和‘现有方法在跨语言、本地实体检索场景下失效’的逻辑。具体包括：1）批评从零收集多语言数据集的方法成本高、语言覆盖有限；2）批评直接翻译英文数据集的方法未考虑本地实体的实际存在性，导致系统无法支持真实场景下用户对本地实体的需求；3）指出现有数据集未覆盖代码切换等真实对话现象。句式多为‘现有方法仅…而忽略了…’、‘这些方法…，但…’，突出未满足实际应用需求和学术空白。",
        "method_story": "方法部分采用‘整体流程先行，分步骤详细展开’的叙述策略。先整体介绍将英文ToD数据集全球化的四步流程：模板抽取、翻译与后编辑、本地本体收集、模板实体替换。每一步骤都在后文有独立小节详细说明，强调流程的系统性和可复用性。随后介绍基线模型的选择与改造，并提出多种数据增强训练方案，最后强调模型的通用性和可扩展性。叙述顺序为先整体后局部，分模块介绍，逻辑清晰。",
        "experiments_story": "实验部分采用‘主实验+多设置对比’的策略，围绕零样本（zero-shot）和小样本（few-shot）跨语言迁移两个核心实验设置展开。每个设置都明确实验假设和数据来源，分别评估模型在无目标语言标注数据和有限标注数据下的表现。实验内容涵盖方法对比、不同训练方案的效果评估，并在后文补充案例分析（如代码切换现象验证）。整体实验设计突出方法的实际适用性和迁移能力，强调多场景、多语言的验证。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进的叙事结构",
        "frequency": 5,
        "percentage": "21.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_199",
            "title": "Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",
            "description": "先引入问题和现有方法不足，再提出新方法，最后通过系统实验验证，结构清晰递进。",
            "type": "writing-level",
            "purpose": "提升可读性和逻辑性，帮助读者顺畅理解"
          },
          {
            "paper_id": "ARR_2022_269",
            "title": "CrossAligner & Co: Zero-Shot Transfer Methods for Task-Oriented Cross-lingual Natural Language Understanding",
            "description": "自上而下依次介绍背景、挑战、方法、实验和结论，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题、方法与结论之间的联系"
          },
          {
            "paper_id": "ARR_2022_152",
            "title": "Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation",
            "description": "采用‘问题—现有方法不足—创新方法—实验验证—结论’的逻辑递进结构，层层铺垫，环环相扣。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解研究动机、方法设计到实验验证的全过程"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 5,
        "percentage": "21.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_254",
            "title": "DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations",
            "description": "按照‘问题-方法-实验’的经典结构组织全文，层层递进，前后呼应",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和说服力"
          },
          {
            "paper_id": "ARR_2022_115",
            "title": "Context-Aware Language Modeling for Goal-Oriented Dialogue Systems",
            "description": "从问题引入、现有方法分析、创新方法提出到实验验证，层层递进，呼应前后，形成完整叙事链条。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          },
          {
            "paper_id": "ARR_2022_207",
            "title": "Learning to Mediate Disparities Towards Pragmatic Communication",
            "description": "从问题提出、现有方法不足、模型设计、实验验证逐步展开，层层递进。",
            "type": "writing-level",
            "purpose": "提升文章整体可读性和逻辑性，帮助读者逐步理解问题和解决方案"
          }
        ]
      },
      {
        "trick_name": "创新点突出",
        "frequency": 4,
        "percentage": "17.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_254",
            "title": "DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations",
            "description": "提出基于AMR的语义级扰动生成负样本，并强调其能捕捉更细致的连贯性错误",
            "type": "method-level",
            "purpose": "强调工作的独特性和贡献"
          },
          {
            "paper_id": "ARR_2022_157",
            "title": "Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation",
            "description": "明确提出直接引入知识图谱三元组而非传统特征或规则编码，突出方法创新。",
            "type": "method-level",
            "purpose": "强调方法的独特性和与传统方法的区别，增强新颖性"
          },
          {
            "paper_id": "ARR_2022_324",
            "title": "There Are a Thousand Hamlets in a Thousand People’s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory",
            "description": "明确指出‘personal memory’在KGC中的引入是前所未有的，并强调构建了首个结合外部知识和个人记忆的数据集。",
            "type": "writing-level",
            "purpose": "突出本工作的独特贡献，强调新颖性"
          }
        ]
      },
      {
        "trick_name": "消融实验设计",
        "frequency": 4,
        "percentage": "17.4%",
        "examples": [
          {
            "paper_id": "ARR_2022_115",
            "title": "Context-Aware Language Modeling for Goal-Oriented Dialogue Systems",
            "description": "系统移除方法中的关键组件，展示每个部分对整体性能的影响，证明方法设计的合理性。",
            "type": "experiment-level",
            "purpose": "突出各方法组件的必要性和贡献"
          },
          {
            "paper_id": "ARR_2022_309",
            "title": "Balancing Multi-domain Corpora Learning for Open-Domain Response Generation",
            "description": "分别测试不同方法（如加权学习、标签学习、多任务学习）对性能的影响，分析各自优劣。",
            "type": "experiment-level",
            "purpose": "验证各个方法组件的有效性，增强方法解释性"
          },
          {
            "paper_id": "ARR_2022_318",
            "title": "DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation",
            "description": "通过去除潜变量等设计不同模型变体，分析各模块对性能的贡献，增强结论的说服力。",
            "type": "experiment-level",
            "purpose": "验证方法中各组成部分的有效性"
          }
        ]
      },
      {
        "trick_name": "定量与定性结果结合",
        "frequency": 3,
        "percentage": "13.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_115",
            "title": "Context-Aware Language Modeling for Goal-Oriented Dialogue Systems",
            "description": "同时报告任务成功率、语言质量指标（如BLEU、perplexity），并分析不同方法的表现差异。",
            "type": "experiment-level",
            "purpose": "增强实验结果的全面性和可信度"
          },
          {
            "paper_id": "ARR_2022_157",
            "title": "Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation",
            "description": "同时展示自动评价分数、人工评价表格和具体预测案例，形成多层次证据链。",
            "type": "experiment-level",
            "purpose": "增强实验结果的可信度和可理解性"
          },
          {
            "paper_id": "ARR_2022_309",
            "title": "Balancing Multi-domain Corpora Learning for Open-Domain Response Generation",
            "description": "既展示自动评价分数，也通过人工打分和案例分析，双重验证方法有效性。",
            "type": "experiment-level",
            "purpose": "通过多种结果展示方式增强说服力"
          }
        ]
      },
      {
        "trick_name": "多维度评价指标",
        "frequency": 3,
        "percentage": "13.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_335",
            "title": "Learning to Express in Knowledge-Grounded Conversation",
            "description": "采用PPL、F1、Distinct、BLEU、METEOR、ROUGE等多种自动评价指标，覆盖生成质量和多样性。",
            "type": "experiment-level",
            "purpose": "提升实验的说服力和结果的全面性"
          },
          {
            "paper_id": "ARR_2022_309",
            "title": "Balancing Multi-domain Corpora Learning for Open-Domain Response Generation",
            "description": "采用自动指标（Rouge、αDF）和人工评价相结合，全面评估生成质量和相关性。",
            "type": "experiment-level",
            "purpose": "从多个角度评估模型，提升实验的完备性和结果的可信度"
          },
          {
            "paper_id": "COLING_2020_1",
            "title": "CHIME: Cross-passage Hierarchical Memory Network for Generative Review Question Answering",
            "description": "采用词汇、语义和复合评价指标（如BLEU、BERTScore、BLEURT），从不同角度对模型输出进行量化，确保评价结果的客观性和全面性。",
            "type": "method-level",
            "purpose": "全面评估生成答案的质量"
          }
        ]
      },
      {
        "trick_name": "形式化任务定义",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_227",
            "title": "Ditch the Gold Standard: Re-evaluating Conversational Question Answering",
            "description": "对对话问答流程进行形式化定义，明确每一步的输入输出，帮助读者理解实验流程和评测标准。",
            "type": "writing-level",
            "purpose": "提升方法的可解释性和科学性"
          },
          {
            "paper_id": "COLING_2020_65",
            "title": "Dual Dynamic Memory Network for End-to-End Multi-turn Task-oriented Dialog Systems",
            "description": "用数学符号和集合定义对话任务的输入输出，包括对话历史、KB三元组和生成目标，便于后续详细描述模型结构。",
            "type": "method-level",
            "purpose": "增强方法严谨性与可复现性"
          }
        ]
      },
      {
        "trick_name": "多基线对比实验",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_199",
            "title": "Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue",
            "description": "在多个数据集上与多种现有方法（如SGP-DST、T5-seq等）系统对比，展示SDT的性能提升。",
            "type": "experiment-level",
            "purpose": "证明方法有效性和优越性，增强说服力"
          },
          {
            "paper_id": "ARR_2022_254",
            "title": "DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations",
            "description": "设计多种实验设置，与多种主流基线方法进行系统性对比",
            "type": "experiment-level",
            "purpose": "增强说服力，证明新方法优于现有方法"
          }
        ]
      },
      {
        "trick_name": "引用权威文献",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_42",
            "title": "GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems",
            "description": "广泛引用相关领域的经典和最新文献，说明ToD系统的现状和挑战",
            "type": "writing-level",
            "purpose": "增强说服力，证明问题和现象已被学界关注"
          },
          {
            "paper_id": "ARR_2022_247",
            "title": "NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue",
            "description": "大量引用领域内经典和最新文献，说明问题的历史发展和当前研究热点",
            "type": "writing-level",
            "purpose": "增强说服力和学术背景，显示工作建立在坚实的前人研究基础上"
          }
        ]
      },
      {
        "trick_name": "多数据集覆盖",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_254",
            "title": "DEAM: Dialogue Coherence Evaluation using AMR-based Semantic Manipulations",
            "description": "在多个公开数据集（如FED、DSTC9、Ubuntu、DailyDialog等）上进行训练和评测",
            "type": "experiment-level",
            "purpose": "提升实验完备性和结果可靠性"
          },
          {
            "paper_id": "ARR_2022_152",
            "title": "Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation",
            "description": "在四个中英文、抽取与生成兼具的数据集上进行实验，覆盖不同语言和任务特性。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和实验的完备性"
          }
        ]
      },
      {
        "trick_name": "对比性实验设计",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_269",
            "title": "CrossAligner & Co: Zero-Shot Transfer Methods for Task-Oriented Cross-lingual Natural Language Understanding",
            "description": "系统地与Previous SOTA、常用基线（如Translate-Train）以及自身变体进行对比，量化性能提升。",
            "type": "experiment-level",
            "purpose": "突出自身方法的有效性和优越性"
          },
          {
            "paper_id": "ARR_2022_282",
            "title": "Mismatch between Multi-turn Dialogue and its Evaluation Metric in Dialogue State Tracking",
            "description": "在实验部分，作者将relative slot accuracy与joint goal accuracy和slot accuracy进行对比，展示其在区分模型性能方面的优势。",
            "type": "experiment-level",
            "purpose": "通过对比展示新方法的有效性和优势"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性强调",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_115",
            "title": "Context-Aware Language Modeling for Goal-Oriented Dialogue Systems",
            "description": "详细阐述现有管道式方法的局限，如人工设计状态与动作、领域特定性等，为提出端到端方法铺垫合理性。",
            "type": "writing-level",
            "purpose": "突出新方法的必要性和创新性"
          },
          {
            "paper_id": "ARR_2022_247",
            "title": "NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue",
            "description": "指出现有NLU数据集存在质量低、覆盖面窄、单意图假设等不足，为后续方法创新做铺垫",
            "type": "writing-level",
            "purpose": "突出新工作的必要性和创新空间"
          }
        ]
      },
      {
        "trick_name": "与主流方法对比实验",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_152",
            "title": "Enhance Incomplete Utterance Restoration by Joint Learning Token Extraction and Text Generation",
            "description": "与SARG、seq2seq等当前主流方法在多个数据集和指标上进行对比，突出自身性能提升。",
            "type": "experiment-level",
            "purpose": "突出自身方法的优越性，增强说服力"
          },
          {
            "paper_id": "ARR_2022_335",
            "title": "Learning to Express in Knowledge-Grounded Conversation",
            "description": "与BART、ZRKGC等主流方法进行对比，展示本方法在多项指标上的显著提升。",
            "type": "experiment-level",
            "purpose": "突出自身方法的优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "问题背景铺垫",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_157",
            "title": "Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation",
            "description": "通过强调语言模型通常只关注句子、短语或词语，指出对话理解需要更广泛的语义和常识知识，设置研究动机。",
            "type": "writing-level",
            "purpose": "突出对话理解的复杂性和现有方法的不足，引发读者关注"
          },
          {
            "paper_id": "ARR_2022_324",
            "title": "There Are a Thousand Hamlets in a Thousand People’s Eyes: Enhancing Knowledge-grounded Dialogue with Personal Memory",
            "description": "作者首先介绍了open-domain dialogue system存在的safe response问题，并逐步引出KGC任务及其知识选择难题，强调现有方法的不足和实际需求。",
            "type": "writing-level",
            "purpose": "让读者理解当前领域的挑战和研究动机，建立问题的重要性"
          }
        ]
      },
      {
        "trick_name": "多维度评价体系",
        "frequency": 2,
        "percentage": "8.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_157",
            "title": "Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation",
            "description": "采用自动指标（BLEU、F1、PPL、Embedding-based）和人工评价（流畅性、知识相关性等），覆盖模型表现的多个方面。",
            "type": "experiment-level",
            "purpose": "证明实验设计的完备性和结果的可靠性"
          },
          {
            "paper_id": "ARR_2022_318",
            "title": "DialogVED: A Pre-trained Latent Variable Encoder-Decoder Model for Dialog Response Generation",
            "description": "采用BLEU、Distinct等自动指标和人工评测相结合，全面评价生成质量，弥补单一指标的局限。",
            "type": "experiment-level",
            "purpose": "证明实验结果的全面性和结论的可靠性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 23,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_227",
        "ARR_2022_199",
        "ARR_2022_42",
        "ARR_2022_254",
        "ARR_2022_269",
        "ARR_2022_115",
        "ARR_2022_152",
        "ARR_2022_40",
        "ARR_2022_207",
        "ARR_2022_157",
        "ARR_2022_324",
        "ARR_2022_335",
        "ARR_2022_247",
        "ARR_2022_63",
        "ARR_2022_282",
        "ARR_2022_309",
        "ARR_2022_318",
        "ACL_2017_128",
        "ACL_2017_769",
        "ACL_2017_627",
        "ACL_2017_26",
        "COLING_2020_1",
        "COLING_2020_65"
      ]
    }
  },
  {
    "pattern_id": 26,
    "pattern_name": "时间推理问答模块设计",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决时间推理问题，采用时序知识图谱编码与问答模块设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点和学术gap引出问题，常用tricks包括挑战分层、模块化框架、联合训练和多基线对比实验。\n第3段（60字）：适用场景与预期效果 - 适用于涉及时间推理的问答任务，数据集需包含时间信息，预期提升模型在复杂时间关系上的理解能力。",
    "writing_guide": "写作模板：时间推理问答模块设计\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决时间推理问题，采用时序知识图谱编码与问答模块设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点和学术gap引出问题，常用tricks包括挑战分层、模块化框架、联合训练和多基线对比实验。\n第3段（60字）：适用场景与预期效果 - 适用于涉及时间推理的问答任务，数据集需包含时间信息，预期提升模型在复杂时间关系上的理解能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs》\n  • 问题定位：论文通过介绍时序知识图谱（Temporal Knowledge Graph, TKG）在处理涉及时间推理问题上的独特价值切入，强调其在回答涉及事件发生时间及其时序关系问题上的重要性。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法未考虑/难以处理X’和‘现有方法在Y场景下存在不足’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部，分模块介绍’的叙述策略。首先给出问题定义和整体框架，明确任务输入输出和核心挑战。随后介绍整体架构，包括两个主要模块：1）时序感知的KG编码器（time-aware TKG encoder），2）时序敏感的问答模块（time-sensitive QA module）。\n  • 实验设计：实验部分采用‘主实验+多类型问题分组+与SOTA对比’的叙述策略。首先介绍实验数据集（CRONQUESTIONS），详细说明数据集规模、问题类型（实体类与时间类）、推理复杂度分组（简单推理与复杂推理）等。接着说明评测指标（Hits@1, Hits@10）、超参数设置和实现细节。\n\n示例 2：《Challenging America: Modeling language in longer time scales》\n  • 问题定位：论文首先从当前NLP主流方法的实际应用痛点出发，指出大规模预训练语言模型（如GPT-2、RoBERTa、T5）及其在标准基准（如GLUE、SuperGLUE）上的评测已成为常态。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有资源存在Y局限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了大规模历史语料的构建过程，包括数据来源、数据规模、数据清洗（去除垃圾和噪声）、时间标注（精确到日）等核心特征。随后，方法部分会进一步细化，介绍如何基于该语料进行预训练，以及如何设计下游任务和基准测试，逐步展开每个模块的具体实现细节。\n  • 实验设计：实验部分的叙述策略以‘主实验+多角度分析’为主。首先会在新构建的历史文本基准上进行主实验，验证预训练模型在历史文本上的表现。其次，可能包含与现有模型（如现代语料预训练模型）的对比实验，突出新方法的优势。\n\n示例 3：《Good Night at 4 pm?! Time Expressions in Different Cultures》\n  • 问题定位：论文开篇从自然语言理解的实际需求出发，强调将语言表达（如颜色、空间、形容词等）映射到现实世界物理属性的重要性，继而聚焦到时间表达的落地（temporal grounding）问题。\n  • 现有研究缺口：论文批评现有方法主要采用了'现有方法忽视了文化差异'和'现有方法在多语言、多文化场景下表现有限'的逻辑。具体通过引用相关研究，指出以往方法未充分考虑不同文化、语言背景下时间表达的多样性，且现有模型在处理跨文化常识推理时存在不足。\n  • 核心方法：方法部分首先对任务进行明确定义（整体介绍），随后提出三种不同的解决方法，并按照数据来源（语料库/语言模型）和推断方式（直接/间接）两个维度进行分类。具体先介绍基于语料库的分布估计方法，再介绍基于语言模型的两种方法，并详细描述每种方法的实现细节和优化目标。\n  • 实验设计：实验部分采用了'主实验+多数据集验证+定量评估+可视化'的叙述策略。首先通过图表展示不同方法在多语言（多国家）下的预测结果与金标准的对比，随后定义细粒度的minute-level accuracy作为主要评价指标，量化各方法的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题具体化与场景举例（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过举例（如罗斯福担任总统的时间）和图示（Figure 1），具体化问题场景，突出时间推理的重要性和挑战。\n\n2. 挑战分层与归纳（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：系统归纳并分层描述三大核心挑战（时间点识别、时间关系表达、时间嵌入方式），为后续方法创新做铺垫。\n\n3. 与前沿工作的对比引用（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：引用并简述前沿方法（如Saxena et al., 2021），并指出其在复杂推理上的不足，为新方法的必要性提供论据。\n\n4. 问题定义与符号化（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：用数学符号和集合定义问题（如G = (V, E, R, T)），明确输入、输出和知识图谱结构。\n\n5. 模块化方法框架描述（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将方法分为“时间感知编码器”和“时间敏感问答”两大模块，并逐步详细介绍各自功能。\n\n6. 辅助任务设计（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：在时间感知编码器中引入辅助时间顺序学习任务，强调对时间序列的建模创新。\n\n7. 联合训练与对比学习（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：在问答模块中采用联合训练和时间敏感对比学习，提升模型对时间表达的理解能力。\n\n8. 多维度数据集与任务划分（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：详细介绍数据集规模、类型、问题分类（实体/时间、简单/复杂），确保实验覆盖多样性。\n\n9. 标准化评估指标使用（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：采用Hits@1和Hits@10等标准指标，确保结果具有可比性和可信度。\n\n10. 多基线对比实验（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：选取EmbedKGQA、T-EaE-add/replacement、CronKGQA等多种基线，系统对比各类问题的表现。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_38",
        "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
        "problem_framing": "论文通过介绍时序知识图谱（Temporal Knowledge Graph, TKG）在处理涉及时间推理问题上的独特价值切入，强调其在回答涉及事件发生时间及其时序关系问题上的重要性。开篇以实际应用场景为例（如罗斯福担任美国总统的时间段），展示了时序知识图谱能够解决的具体问题，并自然过渡到时序KG问答（KGQA）面临的核心挑战，如时间表达的识别与推理。这种策略属于从实际痛点和应用需求出发，同时结合学术挑战进行问题引出。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法未考虑/难以处理X’和‘现有方法在Y场景下存在不足’的逻辑。具体包括：1）指出以往方法难以处理需要多步时序-关系联合推理的复杂问题；2）强调现有方法未能有效识别和推断问题中隐含或显式的时间参照点；3）指出现有方法对时间关系的表达和建模过于简单，无法应对自然语言中微小词汇变化带来的时序语义变化；4）批评现有时序KG嵌入方法对时间戳的建模方式存在局限。这些批评多以‘Unlike previous work...’‘previous work still struggles to...’‘is not considered by previous work’等句式展开，逻辑清晰，层层递进。",
        "method_story": "方法部分采用‘先整体后局部，分模块介绍’的叙述策略。首先给出问题定义和整体框架，明确任务输入输出和核心挑战。随后介绍整体架构，包括两个主要模块：1）时序感知的KG编码器（time-aware TKG encoder），2）时序敏感的问答模块（time-sensitive QA module）。在整体框架基础上，分别详细阐述每个模块的设计思路和关键技术点，如辅助时序排序任务、邻域图提取、联合训练等。整体结构清晰，先总后分，突出模块化设计。",
        "experiments_story": "实验部分采用‘主实验+多类型问题分组+与SOTA对比’的叙述策略。首先介绍实验数据集（CRONQUESTIONS），详细说明数据集规模、问题类型（实体类与时间类）、推理复杂度分组（简单推理与复杂推理）等。接着说明评测指标（Hits@1, Hits@10）、超参数设置和实现细节。然后列举对比的主流SOTA方法作为baseline。主实验聚焦于不同类型问题上的整体性能对比，突出自身方法在所有类别和评测指标上的显著提升。整体实验设计以主实验为主，强调在标准数据集和指标下的全面优越性。"
      },
      {
        "paper_id": "ARR_2022_229",
        "title": "Challenging America: Modeling language in longer time scales",
        "problem_framing": "论文首先从当前NLP主流方法的实际应用痛点出发，指出大规模预训练语言模型（如GPT-2、RoBERTa、T5）及其在标准基准（如GLUE、SuperGLUE）上的评测已成为常态。随后，作者引入数据污染（data contamination）问题，强调了训练集与测试集分离的重要性，并进一步指出数字信息的时间轴扩展（新数据不断产生，历史数据不断被数字化）。通过强调历史文献的数字化和公开，作者自然引出在历史文本上构建和评估语言模型的需求，明确提出该领域缺乏合适的基准和数据集，进而引出本文的研究主题和贡献。",
        "gap_pattern": "论文批评现有方法主要采用‘现有方法忽视了X’和‘现有资源存在Y局限’的逻辑。具体表现为：1）现有NLP基准和模型主要关注现代文本，缺乏对历史文本的系统性建模和评测；2）Google Ngram Viewer等历史语料资源仅提供粗粒度的n-gram统计，且数据异质且不可完全公开，缺乏高质量、细粒度（如日级别时间戳）的历史语料；3）近期的时间感知语言模型（如Temporal T5、TempoBERT）只关注现代文本且时间分辨率较低。通过这些批评，作者突出自身工作的创新点和必要性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了大规模历史语料的构建过程，包括数据来源、数据规模、数据清洗（去除垃圾和噪声）、时间标注（精确到日）等核心特征。随后，方法部分会进一步细化，介绍如何基于该语料进行预训练，以及如何设计下游任务和基准测试，逐步展开每个模块的具体实现细节。",
        "experiments_story": "实验部分的叙述策略以‘主实验+多角度分析’为主。首先会在新构建的历史文本基准上进行主实验，验证预训练模型在历史文本上的表现。其次，可能包含与现有模型（如现代语料预训练模型）的对比实验，突出新方法的优势。此外，实验还可能涉及不同时间分辨率、不同任务（如文本分类、时间预测等）下的性能分析，展示方法的全面性和有效性。"
      },
      {
        "paper_id": "ARR_2022_198",
        "title": "Good Night at 4 pm?! Time Expressions in Different Cultures",
        "problem_framing": "论文开篇从自然语言理解的实际需求出发，强调将语言表达（如颜色、空间、形容词等）映射到现实世界物理属性的重要性，继而聚焦到时间表达的落地（temporal grounding）问题。通过引用前人关于时间表达主观性和文化差异的研究，指出该问题在实际应用（如事件排序、持续时间预测等）中的重要性和复杂性，最终提出将时间表达映射到具体小时区间的任务。整体采用了'从实际痛点出发+学术gap补充'的策略。",
        "gap_pattern": "论文批评现有方法主要采用了'现有方法忽视了文化差异'和'现有方法在多语言、多文化场景下表现有限'的逻辑。具体通过引用相关研究，指出以往方法未充分考虑不同文化、语言背景下时间表达的多样性，且现有模型在处理跨文化常识推理时存在不足。此外，还提到预训练语言模型在时间常识推理任务上的表现有限，原因是许多时间关系并未在文本中被明确表达。",
        "method_story": "方法部分首先对任务进行明确定义（整体介绍），随后提出三种不同的解决方法，并按照数据来源（语料库/语言模型）和推断方式（直接/间接）两个维度进行分类。具体先介绍基于语料库的分布估计方法，再介绍基于语言模型的两种方法，并详细描述每种方法的实现细节和优化目标。整体采用了'先整体后分类分模块介绍'的策略，逻辑清晰，便于对比。",
        "experiments_story": "实验部分采用了'主实验+多数据集验证+定量评估+可视化'的叙述策略。首先通过图表展示不同方法在多语言（多国家）下的预测结果与金标准的对比，随后定义细粒度的minute-level accuracy作为主要评价指标，量化各方法的表现。还对不同方法在不同语言下的优劣进行了分析，突出方法的适用性和局限性。整体结构围绕主实验展开，兼顾定性与定量分析。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "问题具体化与场景举例",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "通过举例（如罗斯福担任总统的时间）和图示（Figure 1），具体化问题场景，突出时间推理的重要性和挑战。",
            "type": "writing-level",
            "purpose": "增强说服力和易理解性，让读者感知问题的实际价值和复杂性"
          }
        ]
      },
      {
        "trick_name": "挑战分层与归纳",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "系统归纳并分层描述三大核心挑战（时间点识别、时间关系表达、时间嵌入方式），为后续方法创新做铺垫。",
            "type": "writing-level",
            "purpose": "突出新颖性和研究动机，展示现有方法的不足并引出创新点"
          }
        ]
      },
      {
        "trick_name": "与前沿工作的对比引用",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "引用并简述前沿方法（如Saxena et al., 2021），并指出其在复杂推理上的不足，为新方法的必要性提供论据。",
            "type": "writing-level",
            "purpose": "提升对比性和说服力，说明本工作在现有基础上的改进"
          }
        ]
      },
      {
        "trick_name": "问题定义与符号化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "用数学符号和集合定义问题（如G = (V, E, R, T)），明确输入、输出和知识图谱结构。",
            "type": "method-level",
            "purpose": "提高可解释性和完备性，帮助读者准确理解任务和方法输入输出"
          }
        ]
      },
      {
        "trick_name": "模块化方法框架描述",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "将方法分为“时间感知编码器”和“时间敏感问答”两大模块，并逐步详细介绍各自功能。",
            "type": "method-level",
            "purpose": "增强可解释性和条理性，使方法结构清晰易懂"
          }
        ]
      },
      {
        "trick_name": "辅助任务设计",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "在时间感知编码器中引入辅助时间顺序学习任务，强调对时间序列的建模创新。",
            "type": "method-level",
            "purpose": "突出创新性，通过新任务提升模型能力"
          }
        ]
      },
      {
        "trick_name": "联合训练与对比学习",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "在问答模块中采用联合训练和时间敏感对比学习，提升模型对时间表达的理解能力。",
            "type": "method-level",
            "purpose": "增强说服力和新颖性，展示模型在捕捉时间信号上的优势"
          }
        ]
      },
      {
        "trick_name": "多维度数据集与任务划分",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "详细介绍数据集规模、类型、问题分类（实体/时间、简单/复杂），确保实验覆盖多样性。",
            "type": "experiment-level",
            "purpose": "提升完备性和说服力，证明方法在多种场景下有效"
          }
        ]
      },
      {
        "trick_name": "标准化评估指标使用",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "采用Hits@1和Hits@10等标准指标，确保结果具有可比性和可信度。",
            "type": "experiment-level",
            "purpose": "增强对比性和可靠性，便于与前人工作直接比较"
          }
        ]
      },
      {
        "trick_name": "多基线对比实验",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "选取EmbedKGQA、T-EaE-add/replacement、CronKGQA等多种基线，系统对比各类问题的表现。",
            "type": "experiment-level",
            "purpose": "突出方法优势和创新性，通过与多个SOTA方法对比展示性能提升"
          }
        ]
      },
      {
        "trick_name": "细粒度结果分析",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "分别报告在复杂问题各子类型（before/after、first/last、Time Joint）上的提升幅度，并分析原因。",
            "type": "experiment-level",
            "purpose": "增强完备性和说服力，展示方法在不同子任务上的具体优势"
          }
        ]
      },
      {
        "trick_name": "显著性提升量化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "用相对提升百分比和绝对误差减少等量化指标，明确展示新方法对SOTA的显著超越。",
            "type": "experiment-level",
            "purpose": "强化说服力，通过量化提升幅度突出方法有效性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_38",
            "title": "Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs",
            "description": "从问题引入、挑战归纳，到方法提出、实验验证，层层递进，前后呼应，结构清晰。",
            "type": "writing-level",
            "purpose": "提升可读性和逻辑性，引导读者顺畅理解问题、方法和结论之间的关系"
          }
        ]
      },
      {
        "trick_name": "权威引用建立背景",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_229",
            "title": "Challenging America: Modeling language in longer time scales",
            "description": "作者引用GPT-2、RoBERTa、T5等主流模型及GLUE、SuperGLUE等基准，说明当前NLP主流做法，并为后文创新点埋下伏笔。",
            "type": "writing-level",
            "purpose": "通过引用主流模型和基准测试，建立研究背景和方法的权威性"
          }
        ]
      },
      {
        "trick_name": "问题引入与需求铺垫",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_229",
            "title": "Challenging America: Modeling language in longer time scales",
            "description": "通过讨论数字信息的时间扩展（前向新数据与后向历史数据），强调历史文本建模的重要性和未被满足的需求。",
            "type": "writing-level",
            "purpose": "引导读者关注数据时间维度和历史文本建模的需求，突出研究意义"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_38",
        "ARR_2022_229",
        "ARR_2022_198",
        "ARR_2022_301",
        "ACL_2017_12"
      ]
    }
  },
  {
    "pattern_id": 27,
    "pattern_name": "无监督学习文本摘要",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决文本摘要中的效率、质量与泛化性问题，采用无监督学习、知识蒸馏、层次结构建模等方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton开篇强调实际痛点，对比现有方法不足，方法部分采用分模块介绍与逐步递进，实验设计多数据集验证与主实验对比。\n第3段（60字）：适用场景与预期效果 - 适用于长文本摘要、对话摘要、社交媒体摘要等场景，预期提升摘要质量、效率与泛化能力，适合需要高效生成摘要的应用。",
    "writing_guide": "写作模板：无监督学习文本摘要\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决文本摘要中的效率、质量与泛化性问题，采用无监督学习、知识蒸馏、层次结构建模等方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton开篇强调实际痛点，对比现有方法不足，方法部分采用分模块介绍与逐步递进，实验设计多数据集验证与主实验对比。\n第3段（60字）：适用场景与预期效果 - 适用于长文本摘要、对话摘要、社交媒体摘要等场景，预期提升摘要质量、效率与泛化能力，适合需要高效生成摘要的应用。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization》\n  • 问题定位：论文首先从实际应用需求出发，强调文本摘要在自然语言处理中的重要性及其广泛应用场景（如新闻标题生成），随后指出主流方法依赖大规模标注数据，导致在冷门领域和小语种难以应用，进一步引出无监督方法的研究价值。整体开篇策略是结合实际痛点和学术gap，逐步聚焦到无监督文本摘要的挑战和需求。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法在实际应用中存在局限'和'现有方法忽视了效率和生成质量'的逻辑。具体表现为：指出基于循环一致性的方法训练困难且效率低下，编辑式方法虽然质量较高但推理速度慢且生成受限，容易陷入局部最优。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先总体介绍了方法框架：先用离散搜索获得目标摘要，再训练非自回归模型学习搜索结果。随后分模块详细介绍每一步，包括目标函数、非自回归模型架构（Transformer细节）、训练策略和长度控制算法。每个模块都从动机出发，逐步展开技术细节，逻辑清晰递进。\n  • 实验设计：实验部分以主实验为核心，先在主流数据集（Gigaword headline test set）与现有方法进行系统对比，分组展示不同摘要长度下的性能。\n\n示例 2：《Attention Temperature Matters in Abstractive Summarization Distillation》\n  • 问题定位：论文开篇首先介绍了自动文档摘要的任务及其两大主流方法（抽取式和生成式），随后聚焦于生成式摘要，强调其在效果和简洁性上的优势。接着指出当前最优性能依赖于大规模预训练Transformer模型，但这些模型在实际生产环境中推理速度慢，难以部署。\n  • 现有研究缺口：论文批评现有方法时，首先指出当前知识蒸馏主要用于分类任务，缺乏对序列生成任务（如摘要）的序列级知识利用。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先介绍了知识蒸馏的基本原理及其在序列到序列任务中的应用（如伪标签法），随后聚焦于教师模型注意力分布过于尖锐导致伪标签质量下降的问题，进一步分析并定义了copy bias和leading bias。\n  • 实验设计：实验部分采用了主实验+多数据集验证+人工评测的综合策略。首先在主流数据集（CNNDM和XSum）上进行ROUGE指标的主实验，涵盖不同模型和蒸馏方法的对比。其次，采用人工评测，从流畅性、忠实性和覆盖度三个维度对生成摘要进行主观评价，并通过排名方式综合评定摘要质量。\n\n示例 3：《Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions》\n  • 问题定位：论文从实际应用需求出发引出问题。开篇强调了对话内容日益增长导致信息过载，阅读完整对话耗时，因而对话摘要技术具有实际价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的句式。具体指出，现有方法要么分别为每个角色独立生成摘要，要么采用序列标注方式，但都‘忽视了不同角色摘要之间的强相关性’，未能利用其他角色的信息来增强摘要质量。通过举例说明其他角色信息如何提升摘要的完整性和判别力，进一步强调现有方法的不足。\n  • 核心方法：方法部分采用‘先整体后细节’和‘分模块介绍’的叙述策略。\n  • 实验设计：实验部分采用‘多数据集+多评价维度’的叙述策略。首先介绍了实验所用的模型、数据集和输入处理方式，然后详细说明了自动评价指标（如ROUGE、BLEU、BERTScore、MoverScore）和人工评价维度（信息性、非冗余性、流畅性），并给出评价流程。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 33.3%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新方法提出、实验验证到结论呼应，层层递进组织全文结构。\n\n2. 多数据集验证（使用频率 2 次，占比 22.2%）\n   类型：experiment-level\n   应用：在Gigaword和DUC2004两个数据集上实验，验证方法的通用性和稳定性。\n\n3. 现有方法局限性强调（使用频率 2 次，占比 22.2%）\n   类型：writing-level\n   应用：作者强调当前大模型虽然效果好但推理速度慢，难以实际部署，为提出小模型蒸馏方法做铺垫。\n\n4. 多数据集覆盖（使用频率 2 次，占比 22.2%）\n   类型：experiment-level\n   应用：在会议、电视剧、政府报告等多个领域数据集上进行实验，展示SUMMN的跨领域泛化能力和鲁棒性。\n\n5. 现实应用场景举例（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：在引言开头通过举例（如新闻标题生成）说明文本摘要的广泛应用，强调研究意义。\n\n6. 现有方法局限性对比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：详细分析并点出当前主流方法（如有监督方法、循环一致性方法、编辑式方法）的缺陷，为新方法的提出铺垫。\n\n7. 创新点列表化（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：用项目符号列出NAUS的三大优势（速度、结构对应、长度控制），直接展示创新点。\n\n8. 师生模型类比（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：将非自回归模型比作学生，从搜索型教师模型中学习，形象说明模型设计思路。\n\n9. 逐步分节讲解方法（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：方法部分分为目标函数、模型结构、训练策略和长度控制等小节，层层递进讲解。\n\n10. 与主流模型结构对比（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：强调所用的encoder-only结构与传统encoder-decoder的不同，并分析其优势。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_339",
        "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
        "problem_framing": "论文首先从实际应用需求出发，强调文本摘要在自然语言处理中的重要性及其广泛应用场景（如新闻标题生成），随后指出主流方法依赖大规模标注数据，导致在冷门领域和小语种难以应用，进一步引出无监督方法的研究价值。整体开篇策略是结合实际痛点和学术gap，逐步聚焦到无监督文本摘要的挑战和需求。",
        "gap_pattern": "论文批评现有方法时，采用了'现有方法在实际应用中存在局限'和'现有方法忽视了效率和生成质量'的逻辑。具体表现为：指出基于循环一致性的方法训练困难且效率低下，编辑式方法虽然质量较高但推理速度慢且生成受限，容易陷入局部最优。此外，通过对比现有方法只能抽取原词且顺序受限，强调其在生成流畅性和语义表达上的不足。批评句式多用'然而'、'但'、'因此受限'等。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先总体介绍了方法框架：先用离散搜索获得目标摘要，再训练非自回归模型学习搜索结果。随后分模块详细介绍每一步，包括目标函数、非自回归模型架构（Transformer细节）、训练策略和长度控制算法。每个模块都从动机出发，逐步展开技术细节，逻辑清晰递进。",
        "experiments_story": "实验部分以主实验为核心，先在主流数据集（Gigaword headline test set）与现有方法进行系统对比，分组展示不同摘要长度下的性能。实验内容包括：主实验（与各类基线方法对比）、效率评估（推理速度对比）、不同长度控制策略的效果分析，并在另一个数据集（DUC2004）做多数据集验证。整体策略是主实验+效率分析+多数据集验证，突出方法的性能和实际应用价值。"
      },
      {
        "paper_id": "ARR_2022_260",
        "title": "Attention Temperature Matters in Abstractive Summarization Distillation",
        "problem_framing": "论文开篇首先介绍了自动文档摘要的任务及其两大主流方法（抽取式和生成式），随后聚焦于生成式摘要，强调其在效果和简洁性上的优势。接着指出当前最优性能依赖于大规模预训练Transformer模型，但这些模型在实际生产环境中推理速度慢，难以部署。由此，论文从应用需求和实际痛点出发，引出对高效、小型模型的需求，并提出通过知识蒸馏来解决这一问题。",
        "gap_pattern": "论文批评现有方法时，首先指出当前知识蒸馏主要用于分类任务，缺乏对序列生成任务（如摘要）的序列级知识利用。其次，针对生成式摘要的蒸馏方法（如伪标签法），论文通过数据分析展示了教师模型生成伪标签存在“copy bias”和“leading bias”，即伪标签过度复制原文和过度关注文档开头部分，导致学生模型学习效果受限。批评逻辑采用了“现有方法在X方面存在不足/偏差”、“现有方法未充分利用Y”以及“通过实证数据揭示具体问题”的方式。",
        "method_story": "方法部分采用了先整体后局部的叙述顺序。首先介绍了知识蒸馏的基本原理及其在序列到序列任务中的应用（如伪标签法），随后聚焦于教师模型注意力分布过于尖锐导致伪标签质量下降的问题，进一步分析并定义了copy bias和leading bias。最后，提出针对性改进策略（如调整注意力温度），并通过具体实验设置展示方法细节。",
        "experiments_story": "实验部分采用了主实验+多数据集验证+人工评测的综合策略。首先在主流数据集（CNNDM和XSum）上进行ROUGE指标的主实验，涵盖不同模型和蒸馏方法的对比。其次，采用人工评测，从流畅性、忠实性和覆盖度三个维度对生成摘要进行主观评价，并通过排名方式综合评定摘要质量。实验设计还包含不同模型架构（如BART 12-3、BART 12-6）和伪标签生成方式（如不同注意力温度设置）的对比，体现了消融和参数敏感性分析。"
      },
      {
        "paper_id": "ARR_2022_268",
        "title": "Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions",
        "problem_framing": "论文从实际应用需求出发引出问题。开篇强调了对话内容日益增长导致信息过载，阅读完整对话耗时，因而对话摘要技术具有实际价值。进一步指出，不同角色有各自的观点和目标，因此除了整体摘要，还需针对每个角色生成摘要（role-oriented summarization），并举例说明该技术在客服、医疗、法庭等场景的实际需求和应用价值。通过具体场景和应用痛点引出研究主题。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’的句式。具体指出，现有方法要么分别为每个角色独立生成摘要，要么采用序列标注方式，但都‘忽视了不同角色摘要之间的强相关性’，未能利用其他角色的信息来增强摘要质量。通过举例说明其他角色信息如何提升摘要的完整性和判别力，进一步强调现有方法的不足。",
        "method_story": "方法部分采用‘先整体后细节’和‘分模块介绍’的叙述策略。首先介绍了两大主流seq2seq模型（PGN和BERTAbs）作为基础架构，随后分别说明了如何在这两类模型中引入角色交互机制（cross attention和self-attention），并详细描述了各自的实现细节和不同变体（如PGN-single、PGN-multi、PGN-cross、PGN-self、PGN-both等），从基础到增强逐步展开。",
        "experiments_story": "实验部分采用‘多数据集+多评价维度’的叙述策略。首先介绍了实验所用的模型、数据集和输入处理方式，然后详细说明了自动评价指标（如ROUGE、BLEU、BERTScore、MoverScore）和人工评价维度（信息性、非冗余性、流畅性），并给出评价流程。实验内容涵盖主实验（主模型与各变体的对比）、多数据集（CSDS和MC）、多指标评价，并通过统计检验（如t检验）验证结果显著性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "33.3%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "从问题引入、现有方法分析、创新方法提出、实验验证到结论呼应，层层递进组织全文结构。",
            "type": "writing-level",
            "purpose": "提升整体可读性和逻辑性，便于读者跟随思路"
          },
          {
            "paper_id": "ARR_2022_260",
            "title": "Attention Temperature Matters in Abstractive Summarization Distillation",
            "description": "先引入任务背景和痛点，分析现有方法不足，再提出新方法，最后通过充分实验论证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "帮助读者顺畅理解问题、方法和结论的因果关系"
          },
          {
            "paper_id": "ARR_2022_191",
            "title": "SUMM : A Multi-Stage Summarization Framework for Long Input Dialogues and Documents",
            "description": "从问题引入、现有方法分析、提出新方法、方法细节、实验验证到结论呼应，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 2,
        "percentage": "22.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "在Gigaword和DUC2004两个数据集上实验，验证方法的通用性和稳定性。",
            "type": "experiment-level",
            "purpose": "增强完备性和结论的可靠性"
          },
          {
            "paper_id": "ARR_2022_32",
            "title": "Should We Trust This Summary? Bayesian Abstractive Summarization to The Rescue",
            "description": "在多个主流摘要数据集上进行实验，展示方法在不同场景下的有效性",
            "type": "experiment-level",
            "purpose": "证明方法的通用性和实验结果的完备性"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性强调",
        "frequency": 2,
        "percentage": "22.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_260",
            "title": "Attention Temperature Matters in Abstractive Summarization Distillation",
            "description": "作者强调当前大模型虽然效果好但推理速度慢，难以实际部署，为提出小模型蒸馏方法做铺垫。",
            "type": "writing-level",
            "purpose": "突出自身工作的必要性和创新性"
          },
          {
            "paper_id": "ARR_2022_206",
            "title": "HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information",
            "description": "指出主流Transformer模型只考虑线性顺序，未显式利用层次结构，为新方法铺垫合理性。",
            "type": "writing-level",
            "purpose": "突出研究空白，增强新方法的必要性和创新性"
          }
        ]
      },
      {
        "trick_name": "多数据集覆盖",
        "frequency": 2,
        "percentage": "22.2%",
        "examples": [
          {
            "paper_id": "ARR_2022_191",
            "title": "SUMM : A Multi-Stage Summarization Framework for Long Input Dialogues and Documents",
            "description": "在会议、电视剧、政府报告等多个领域数据集上进行实验，展示SUMMN的跨领域泛化能力和鲁棒性。",
            "type": "experiment-level",
            "purpose": "证明方法的完备性和广泛适用性"
          },
          {
            "paper_id": "ARR_2022_206",
            "title": "HiStruct+: Improving Extractive Text Summarization with Hierarchical Structure Information",
            "description": "在短文（CNN/DailyMail）和长文（PubMed、arXiv）三个主流数据集上系统评测方法性能。",
            "type": "experiment-level",
            "purpose": "证明方法适用性广泛，增强实验完备性和结论可靠性"
          }
        ]
      },
      {
        "trick_name": "现实应用场景举例",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "在引言开头通过举例（如新闻标题生成）说明文本摘要的广泛应用，强调研究意义。",
            "type": "writing-level",
            "purpose": "增强说服力，让读者感受到问题的重要性和实际价值"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "详细分析并点出当前主流方法（如有监督方法、循环一致性方法、编辑式方法）的缺陷，为新方法的提出铺垫。",
            "type": "writing-level",
            "purpose": "突出自身工作的必要性和创新空间"
          }
        ]
      },
      {
        "trick_name": "创新点列表化",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "用项目符号列出NAUS的三大优势（速度、结构对应、长度控制），直接展示创新点。",
            "type": "writing-level",
            "purpose": "突出新颖性，让创新点一目了然"
          }
        ]
      },
      {
        "trick_name": "师生模型类比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "将非自回归模型比作学生，从搜索型教师模型中学习，形象说明模型设计思路。",
            "type": "method-level",
            "purpose": "增强可解释性，帮助读者理解模型训练流程"
          }
        ]
      },
      {
        "trick_name": "逐步分节讲解方法",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "方法部分分为目标函数、模型结构、训练策略和长度控制等小节，层层递进讲解。",
            "type": "writing-level",
            "purpose": "提升可解释性和条理性，降低理解门槛"
          }
        ]
      },
      {
        "trick_name": "与主流模型结构对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "强调所用的encoder-only结构与传统encoder-decoder的不同，并分析其优势。",
            "type": "method-level",
            "purpose": "突出自身方法的独特性和适用性"
          }
        ]
      },
      {
        "trick_name": "特殊符号机制设计",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "详细介绍引入blank token及其在动态规划中的作用，解释如何生成短于输入的摘要。",
            "type": "method-level",
            "purpose": "提升可解释性，说明模型如何实现长度控制"
          }
        ]
      },
      {
        "trick_name": "与现有方法分组对比实验",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "将对比方法按摘要长度分组，分别展示各组下的性能，确保对比公平且全面。",
            "type": "experiment-level",
            "purpose": "增强说服力，证明方法在不同设置下均优于现有方法"
          }
        ]
      },
      {
        "trick_name": "效率与效果双重对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "不仅对比ROUGE分数，还量化推理速度提升（如1300倍），强调实际部署价值。",
            "type": "experiment-level",
            "purpose": "突出自身方法的综合优势"
          }
        ]
      },
      {
        "trick_name": "消融与深入分析",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_339",
            "title": "Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization",
            "description": "通过对比不同模型变体（如自回归与非自回归），分析各设计选择的影响。",
            "type": "experiment-level",
            "purpose": "提升完备性，分析方法各组成部分的作用"
          }
        ]
      },
      {
        "trick_name": "引用权威文献增强信服力",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_260",
            "title": "Attention Temperature Matters in Abstractive Summarization Distillation",
            "description": "多次引用领域内权威工作（如Raffel et al., 2020; Lewis et al., 2020等），说明本工作建立在成熟理论和实践基础上。",
            "type": "writing-level",
            "purpose": "借助已有研究成果提升自身方法的可信度"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 9,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_339",
        "ARR_2022_260",
        "ARR_2022_268",
        "ARR_2022_191",
        "ARR_2022_32",
        "ARR_2022_206",
        "ACL_2017_333",
        "COLING_2020_13",
        "COLING_2020_50"
      ]
    }
  },
  {
    "pattern_id": 28,
    "pattern_name": "端到端实体-关系联合抽取",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦实体和关系联合抽取的挑战，采用端到端建模和新颖视角，覆盖文档级和联合抽取任务。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法局限性对比开篇，常用tricks包括新颖视角命名、方法流程分步阐述、图示辅助理解等。\n第3段（60字）：适用场景与预期效果 - 适用于实体和关系联合抽取任务，多场景实验验证方法的有效性和泛化能力，预期提升F1分数。",
    "writing_guide": "写作模板：端到端实体-关系联合抽取\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦实体和关系联合抽取的挑战，采用端到端建模和新颖视角，覆盖文档级和联合抽取任务。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法局限性对比开篇，常用tricks包括新颖视角命名、方法流程分步阐述、图示辅助理解等。\n第3段（60字）：适用场景与预期效果 - 适用于实体和关系联合抽取任务，多场景实验验证方法的有效性和泛化能力，预期提升F1分数。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction》\n  • 问题定位：论文通过强调关系抽取在构建知识库及其下游应用（如搜索引擎、问答系统）中的重要性，从实际应用需求出发引出问题。随后指出，尽管已有大量研究，但在多实体多关系的复杂场景（如文档级关系抽取和联合实体关系抽取）下仍面临挑战，进一步聚焦于现有方法的局限性，形成学术gap。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法主要从实体视角出发，忽略了关系与实体及上下文之间的丰富交互’的逻辑。具体句式包括‘现有方法大多关注实体间的交互’，‘关系被当作原子标签或独立搜索’，‘关系层面的互信息被忽略’，并通过举例说明在特定场景下（如多三元组抽取）现有方法难以充分建模三元组间的相关性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略，首先提出整体创新视角（joint triple perspective），再逐步细化方法流程：先显式构造关系嵌入表示，接着通过注意力融合模块细化关系与实体的表示，最后在联合空间中通过新颖的对齐函数（Tucker分解）实现三元组抽取。\n  • 实验设计：实验部分采用‘多数据集验证+主流对比’的策略，分别在文档级关系抽取和联合实体关系抽取两个任务场景下，选用三大主流数据集（DocRED、NYT、WebNLG）进行全面实验。实验内容包括与强基线方法的直接对比，并报告在各数据集上的性能提升，同时补充与多种已有方法的横向比较，突出方法的普适性和优越性。\n\n示例 2：《Enhanced Multi-Channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction》\n  • 问题定位：论文通过结合学术gap和实际任务挑战来引出问题。首先介绍了ASTE任务的定义及其重要性，随后指出当前方法在处理三元组元素之间的关联性和利用语言学特征方面存在不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：批评pipeline方法独立提取三元组元素，忽略了它们之间的相互作用，导致错误传播和额外成本；指出MRC和end-to-end方法虽然有所改进，但仍未充分利用词间多样关系和语言学特征。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了EMC-GCN模型的框架和设计思路，随后依次详细说明输入与编码层、biaffine attention模块、multi-channel GCN模块等关键组成部分。\n  • 实验设计：实验部分采用‘主实验+多数据集验证’的策略。首先在主实验中对比了EMC-GCN与pipeline、end-to-end和MRC-based方法的性能，突出模型在F1指标上的优势。实验结果涵盖不同数据集（D1和D2），并分析了BERT与BiLSTM编码器的性能差异。\n\n示例 3：《PARE: A Simple and Strong Baseline for Monolingual and Multilingual Distantly Supervised Relation Extraction》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先介绍了关系抽取任务的基本定义和主流的远程监督方法，随后指出主流神经网络方法普遍采用了将每个句子独立编码的设计选择。作者明确提出这一设计可能导致对数据利用不充分，并假设如果能让句子间信息交互，编码效果会更好，从而引出本文的研究动机和核心问题。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体地，作者指出主流方法都将每个句子独立编码，未能充分利用同一实体对相关句子间的信息。通过‘我们认为这种选择导致了对可用数据的次优利用’等表达，强调了现有方法的局限性。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略。首先整体介绍了PARE模型的核心思想——将所有相关句子拼接为一个长文本整体编码，随后详细说明了具体实现流程，包括如何利用BERT编码、如何引入关系查询向量、如何通过注意力机制生成关系感知的摘要并进行预测。\n  • 实验设计：实验部分采用了‘多数据集验证+主实验+消融分析+细致对比’的策略。首先在四个主流数据集（包括英文和多语言）上与多种现有方法进行系统对比，验证主方法的有效性。其次，实验包含消融分析和注意力机制的进一步分析，以探究模型性能的原因和细节。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 举例说明问题（使用频率 2 次，占比 22.2%）\n   类型：writing-level\n   应用：通过具体例子（如basin country为unseen relation）说明零样本关系分类的实际困难，使问题更具象、易于理解。\n\n2. 借鉴跨领域方法（使用频率 2 次，占比 22.2%）\n   类型：method-level\n   应用：受计算机视觉领域零样本学习的启发，提出将输入样本特征空间映射到语义空间的思路，拓展了自然语言处理的解决方案。\n\n3. 场景驱动的问题引入（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：通过强调多实体多关系场景下的挑战，引出现有方法的不足，铺垫新方法的必要性\n\n4. 现有方法局限性对比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：详细描述现有方法仅关注实体视角，忽略关系与实体、上下文的交互，为提出新视角做铺垫\n\n5. 新颖视角命名与强调（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：明确提出“joint triple perspective”并与传统“entity perspective”对比，突出方法的新颖性\n\n6. 方法流程分步阐述（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：简要分步介绍EmRel的三个阶段：创建关系表示、联合建模、对齐推断\n\n7. 图示辅助理解（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：提及Figure 1对方法的直观展示，降低理解门槛\n\n8. 与知识图谱类比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：将三元组视角比作小型上下文相关知识图谱，便于读者理解方法的本质\n\n9. 创新性技术点突出（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：提出基于Tucker分解的对齐函数，作为方法创新的核心技术点\n\n10. 多场景实验覆盖（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：在引言和实验部分均强调覆盖文档级和联合抽取两大场景，使用多个主流数据集\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_237",
        "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
        "problem_framing": "论文通过强调关系抽取在构建知识库及其下游应用（如搜索引擎、问答系统）中的重要性，从实际应用需求出发引出问题。随后指出，尽管已有大量研究，但在多实体多关系的复杂场景（如文档级关系抽取和联合实体关系抽取）下仍面临挑战，进一步聚焦于现有方法的局限性，形成学术gap。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法主要从实体视角出发，忽略了关系与实体及上下文之间的丰富交互’的逻辑。具体句式包括‘现有方法大多关注实体间的交互’，‘关系被当作原子标签或独立搜索’，‘关系层面的互信息被忽略’，并通过举例说明在特定场景下（如多三元组抽取）现有方法难以充分建模三元组间的相关性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略，首先提出整体创新视角（joint triple perspective），再逐步细化方法流程：先显式构造关系嵌入表示，接着通过注意力融合模块细化关系与实体的表示，最后在联合空间中通过新颖的对齐函数（Tucker分解）实现三元组抽取。每一步都突出与现有方法的区别和创新点。",
        "experiments_story": "实验部分采用‘多数据集验证+主流对比’的策略，分别在文档级关系抽取和联合实体关系抽取两个任务场景下，选用三大主流数据集（DocRED、NYT、WebNLG）进行全面实验。实验内容包括与强基线方法的直接对比，并报告在各数据集上的性能提升，同时补充与多种已有方法的横向比较，突出方法的普适性和优越性。"
      },
      {
        "paper_id": "ARR_2022_323",
        "title": "Enhanced Multi-Channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction",
        "problem_framing": "论文通过结合学术gap和实际任务挑战来引出问题。首先介绍了ASTE任务的定义及其重要性，随后指出当前方法在处理三元组元素之间的关联性和利用语言学特征方面存在不足。作者通过具体示例（如图1中的句子分析）展示了任务中的关键难点，强调了对词间关系和语言学特征的需求，明确提出了两个核心科学问题，从而将研究动机与实际痛点紧密结合。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：批评pipeline方法独立提取三元组元素，忽略了它们之间的相互作用，导致错误传播和额外成本；指出MRC和end-to-end方法虽然有所改进，但仍未充分利用词间多样关系和语言学特征。批评句式包括‘忽略了...’，‘存在...挑战’，‘仍有...问题’，并通过对比具体例子和任务需求，强化了现有方法的不足。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了EMC-GCN模型的框架和设计思路，随后依次详细说明输入与编码层、biaffine attention模块、multi-channel GCN模块等关键组成部分。每个模块先给出动机，再介绍具体实现和数学公式，层层递进，逻辑清晰，便于读者理解模型如何逐步解决前述科学问题。",
        "experiments_story": "实验部分采用‘主实验+多数据集验证’的策略。首先在主实验中对比了EMC-GCN与pipeline、end-to-end和MRC-based方法的性能，突出模型在F1指标上的优势。实验结果涵盖不同数据集（D1和D2），并分析了BERT与BiLSTM编码器的性能差异。通过详细结果和对比分析，验证了方法的有效性和泛化能力，突出模型在利用词间关系和语言学知识方面的提升。"
      },
      {
        "paper_id": "ARR_2022_49",
        "title": "PARE: A Simple and Strong Baseline for Monolingual and Multilingual Distantly Supervised Relation Extraction",
        "problem_framing": "论文从学术gap出发引出问题。开篇首先介绍了关系抽取任务的基本定义和主流的远程监督方法，随后指出主流神经网络方法普遍采用了将每个句子独立编码的设计选择。作者明确提出这一设计可能导致对数据利用不充分，并假设如果能让句子间信息交互，编码效果会更好，从而引出本文的研究动机和核心问题。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体地，作者指出主流方法都将每个句子独立编码，未能充分利用同一实体对相关句子间的信息。通过‘我们认为这种选择导致了对可用数据的次优利用’等表达，强调了现有方法的局限性。此外，作者还指出现有方法普遍依赖于“至少有一句表达关系”的假设，未能处理跨句综合表达的关系场景。",
        "method_story": "方法部分采用了‘先整体后局部’的叙述策略。首先整体介绍了PARE模型的核心思想——将所有相关句子拼接为一个长文本整体编码，随后详细说明了具体实现流程，包括如何利用BERT编码、如何引入关系查询向量、如何通过注意力机制生成关系感知的摘要并进行预测。方法描述中还对参数量的计算和与其他模型的差异进行了补充说明，突出模型的简洁性与优势。",
        "experiments_story": "实验部分采用了‘多数据集验证+主实验+消融分析+细致对比’的策略。首先在四个主流数据集（包括英文和多语言）上与多种现有方法进行系统对比，验证主方法的有效性。其次，实验包含消融分析和注意力机制的进一步分析，以探究模型性能的原因和细节。实验还详细描述了评测指标、数据统计、训练细节和复现过程，保证结果的可靠性和可比性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "举例说明问题",
        "frequency": 2,
        "percentage": "22.2%",
        "examples": [
          {
            "paper_id": "COLING_2020_4",
            "title": "Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification",
            "description": "通过具体例子（如basin country为unseen relation）说明零样本关系分类的实际困难，使问题更具象、易于理解。",
            "type": "writing-level",
            "purpose": "具体化抽象问题，帮助读者理解研究动机"
          },
          {
            "paper_id": "COLING_2020_51",
            "title": "Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training",
            "description": "通过具体数据集示例，展示多关系句子中模型混淆的现象，帮助读者直观理解问题。",
            "type": "writing-level",
            "purpose": "增强问题描述的直观性和说服力"
          }
        ]
      },
      {
        "trick_name": "借鉴跨领域方法",
        "frequency": 2,
        "percentage": "22.2%",
        "examples": [
          {
            "paper_id": "COLING_2020_4",
            "title": "Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification",
            "description": "受计算机视觉领域零样本学习的启发，提出将输入样本特征空间映射到语义空间的思路，拓展了自然语言处理的解决方案。",
            "type": "method-level",
            "purpose": "引入其他领域的先进思想，提升创新性"
          },
          {
            "paper_id": "COLING_2020_51",
            "title": "Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training",
            "description": "说明受到计算机视觉领域few-shot learning方法的启发，并引用相关文献，突出方法的新颖性和合理性。",
            "type": "writing-level",
            "purpose": "展示研究的创新点和理论基础"
          }
        ]
      },
      {
        "trick_name": "场景驱动的问题引入",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "通过强调多实体多关系场景下的挑战，引出现有方法的不足，铺垫新方法的必要性",
            "type": "writing-level",
            "purpose": "突出实际应用中的挑战，增强问题的现实意义和紧迫感"
          }
        ]
      },
      {
        "trick_name": "现有方法局限性对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "详细描述现有方法仅关注实体视角，忽略关系与实体、上下文的交互，为提出新视角做铺垫",
            "type": "writing-level",
            "purpose": "突出自身工作的创新点和改进空间"
          }
        ]
      },
      {
        "trick_name": "新颖视角命名与强调",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "明确提出“joint triple perspective”并与传统“entity perspective”对比，突出方法的新颖性",
            "type": "writing-level",
            "purpose": "强化创新性，让读者记住方法的独特视角"
          }
        ]
      },
      {
        "trick_name": "方法流程分步阐述",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "简要分步介绍EmRel的三个阶段：创建关系表示、联合建模、对齐推断",
            "type": "method-level",
            "purpose": "提升可解释性，让读者清楚理解方法的每一步"
          }
        ]
      },
      {
        "trick_name": "图示辅助理解",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "提及Figure 1对方法的直观展示，降低理解门槛",
            "type": "writing-level",
            "purpose": "增强可解释性，帮助读者快速把握方法核心"
          }
        ]
      },
      {
        "trick_name": "与知识图谱类比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "将三元组视角比作小型上下文相关知识图谱，便于读者理解方法的本质",
            "type": "writing-level",
            "purpose": "借助熟悉概念帮助理解方法的原理和优势"
          }
        ]
      },
      {
        "trick_name": "创新性技术点突出",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "提出基于Tucker分解的对齐函数，作为方法创新的核心技术点",
            "type": "method-level",
            "purpose": "强调方法的技术创新，提升说服力和新颖性"
          }
        ]
      },
      {
        "trick_name": "多场景实验覆盖",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "在引言和实验部分均强调覆盖文档级和联合抽取两大场景，使用多个主流数据集",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和实验结论的完备性"
          }
        ]
      },
      {
        "trick_name": "与强基线直接对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "选用TPLinker和Xu等人方法作为强基线，直接复现并对比实验结果",
            "type": "experiment-level",
            "purpose": "增强实验说服力，突出自身性能优势"
          }
        ]
      },
      {
        "trick_name": "量化提升细致呈现",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "详细列举各数据集上F1提升的具体数值，突出方法的实际效果",
            "type": "experiment-level",
            "purpose": "具体化方法优势，增强结果的说服力"
          }
        ]
      },
      {
        "trick_name": "与多项前沿方法对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "不仅与直接基线，还与多项近期代表性方法（如BERT-TS、CorefBERT等）进行对比",
            "type": "experiment-level",
            "purpose": "展示方法在领域内的领先地位"
          }
        ]
      },
      {
        "trick_name": "实验细节补充说明",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "说明数据集和实现细节可在附录中查阅，体现实验的严谨性和透明度",
            "type": "experiment-level",
            "purpose": "提升实验的可复现性和结论的可信度"
          }
        ]
      },
      {
        "trick_name": "首尾呼应的结构设计",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_237",
            "title": "EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction",
            "description": "引言提出joint triple perspective的优势，实验部分用结果呼应并验证该观点",
            "type": "writing-level",
            "purpose": "增强论文整体逻辑流畅性和说服力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 9,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_237",
        "ARR_2022_323",
        "ARR_2022_49",
        "ACL_2017_376",
        "ACL_2017_222",
        "ACL_2017_557",
        "ACL_2017_562",
        "COLING_2020_4",
        "COLING_2020_51"
      ]
    }
  },
  {
    "pattern_id": 29,
    "pattern_name": "低频词表示端到端神经网络",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低频词表示与上下文建模问题，采用端到端神经网络设计和视觉信息融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以文献综述引入研究背景，常用tricks包括层次结构模型对比、基线模型设定、参数共享机制和端到端反向传播训练。\n第3段（60字）：适用场景与预期效果 - 适用于字符级和词级建模任务，特别是处理罕见词和低频词，预期提升模型对罕见词和形态丰富语言的表示能力。",
    "writing_guide": "写作模板：低频词表示端到端神经网络\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低频词表示与上下文建模问题，采用端到端神经网络设计和视觉信息融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以文献综述引入研究背景，常用tricks包括层次结构模型对比、基线模型设定、参数共享机制和端到端反向传播训练。\n第3段（60字）：适用场景与预期效果 - 适用于字符级和词级建模任务，特别是处理罕见词和低频词，预期提升模型对罕见词和形态丰富语言的表示能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning Character-level Compositionality with Visual Features》\n  • 问题定位：论文通过定义组合性（compositionality）为自然语言的核心特征，并回顾神经模型在句子表征中的应用，强调了理解词以下层级的组合对于语言理解的重要性。引言以理论基础和技术进展为铺垫，逐步引出研究问题。\n  • 现有研究缺口：作者指出现有模型多依赖于词级或字符级的查找式嵌入，忽视了字符视觉特征的潜力。通过回顾相关文献，强调需要探索基于字符视觉信息的表征方法，从而填补现有方法在低频字符处理上的不足。\n  • 核心方法：方法部分采用对比叙述策略，先介绍基线Lookup模型的传统字符嵌入方式，再引出创新的Visual模型，强调其通过CNN从字符视觉外观学习表征。整体流程清晰，便于突出新旧方法的差异。\n  • 实验设计：实验部分按递进逻辑展开，先验证新模型的基本有效性，再针对低频字符优势进行对比，最后探讨多模型融合效果。每步实验目标明确，参数设置详尽，突出实验设计的系统性和针对性。\n\n示例 2：《Semi-supervised sequence tagging with bidirectional language models》\n  • 问题定位：论文在引言部分采用了现有技术回顾与实际需求结合的策略，先强调预训练词嵌入在NLP中的普遍性及有效性，并引用权威文献支持其语义和句法信息捕获能力，随后通过具体例子指出词嵌入在上下文表达上的局限，引出对上下文敏感表示的需求。\n  • 现有研究缺口：作者通过对比词嵌入的优势与实际任务需求，批评了其在处理上下文相关信息上的不足，强调现有方法无法区分同一词在不同语境下的角色，进而提出当前序列标注模型需更好地编码上下文，明确了研究的创新空间。\n  • 核心方法：方法部分采用结构化分层叙述，先整体介绍模型架构并与近期相关工作对齐，随后详细分解每个模块的输入、处理方式和参数化细节，通过公式和引用说明字符级与词级信息融合，突出模型对形态和语义的联合建模能力。\n  • 实验设计：实验部分以标准任务为切入点，选用广泛认可的基准数据集和评价指标，严格遵循前人工作设定（如标签方案和预处理），通过分任务描述和细节复现，确保结果的可比性和方法有效性，突出实验设计的规范性和透明度。\n\n示例 3：《Rare Entity Prediction: Language Understanding with External Knowledge using Hierarchical LSTMs》\n  • 问题定位：论文通过强调自然语言处理领域中模型获取世界知识的核心难题引入研究主题，明确提出模型可通过非结构化文本和结构化知识库两种方式获取知识，并以阅读理解作为检验模型能力的自然场景，聚焦于模型知识获取能力的评估。\n  • 现有研究缺口：作者批评现有阅读理解任务（如Daily Mail/CNN数据集）主要依赖基础语言建模，缺乏对推理能力的考察，指出当前任务在知识获取和推理层面存在不足，从而为新任务和方法的提出奠定基础。\n  • 核心方法：方法部分采用先介绍模型整体思路，再细致说明核心技术（RNN与LSTM），通过解释其结构和优势，突出模型对顺序数据和语言问题的适用性，为后续实验验证提供理论支撑。\n  • 实验设计：实验部分详细描述数据集划分、上下文与定义的具体设置，并报告对不同参数配置的尝试及其效果，采用逐步试错和对比分析的方法，突出实验设计的系统性和结果的客观性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 文献综述引入法（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过引用大量相关工作（如Szabó, 2010; Iyyer et al., 2015等），介绍组合性在自然语言处理中的重要性和当前主流模型方法，为后续研究动机做铺垫。\n\n2. 层次结构模型对比（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：对比从简单到复杂的模型（如Bag-of-Words、RNN、树结构、CNN），展示方法发展脉络，并引出自身模型的独特性。\n\n3. 子词级别建模（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：强调组合性不仅在词之间存在，也在词内部，通过字符级、形态级建模提升对罕见词的表示能力。\n\n4. 基线模型设定（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：明确设置Lookup模型作为基线，用字符嵌入查找表实现字符表示，为后续新方法提供对比。\n\n5. 端到端神经网络设计（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：采用端到端结构：字符表示—RNN—句子表示—softmax分类，体现现代神经网络的整体设计理念。\n\n6. 视觉信息融合（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：创新地将字符转为图片，利用CNN提取视觉特征，生成字符嵌入，提升对低频及形近字符的参数共享能力。\n\n7. 参数共享机制（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：通过视觉特征映射，实现参数在形近字符间共享，提高模型对低频字符的学习效果。\n\n8. 图示辅助说明（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过图示（如Fig. 3）直观展示模型结构和流程，帮助读者理解复杂方法。\n\n9. 端到端反向传播训练（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：整个模型参数，包括CNN部分，通过分类损失端到端反向传播优化，保证特征与任务紧密结合。\n\n10. 引用前人工作建立背景（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过引用多篇前人工作（如Mikolov et al., 2013; Pennington et al., 2014），阐述预训练词嵌入在NLP中的广泛应用和有效性，从而自然引出当前研究的动机。\n",
    "skeleton_examples": [
      {
        "paper_id": "ACL_2017_543",
        "title": "Learning Character-level Compositionality with Visual Features",
        "problem_framing": "论文通过定义组合性（compositionality）为自然语言的核心特征，并回顾神经模型在句子表征中的应用，强调了理解词以下层级的组合对于语言理解的重要性。引言以理论基础和技术进展为铺垫，逐步引出研究问题。",
        "gap_pattern": "作者指出现有模型多依赖于词级或字符级的查找式嵌入，忽视了字符视觉特征的潜力。通过回顾相关文献，强调需要探索基于字符视觉信息的表征方法，从而填补现有方法在低频字符处理上的不足。",
        "method_story": "方法部分采用对比叙述策略，先介绍基线Lookup模型的传统字符嵌入方式，再引出创新的Visual模型，强调其通过CNN从字符视觉外观学习表征。整体流程清晰，便于突出新旧方法的差异。",
        "experiments_story": "实验部分按递进逻辑展开，先验证新模型的基本有效性，再针对低频字符优势进行对比，最后探讨多模型融合效果。每步实验目标明确，参数设置详尽，突出实验设计的系统性和针对性。"
      },
      {
        "paper_id": "ACL_2017_561",
        "title": "Semi-supervised sequence tagging with bidirectional language models",
        "problem_framing": "论文在引言部分采用了现有技术回顾与实际需求结合的策略，先强调预训练词嵌入在NLP中的普遍性及有效性，并引用权威文献支持其语义和句法信息捕获能力，随后通过具体例子指出词嵌入在上下文表达上的局限，引出对上下文敏感表示的需求。",
        "gap_pattern": "作者通过对比词嵌入的优势与实际任务需求，批评了其在处理上下文相关信息上的不足，强调现有方法无法区分同一词在不同语境下的角色，进而提出当前序列标注模型需更好地编码上下文，明确了研究的创新空间。",
        "method_story": "方法部分采用结构化分层叙述，先整体介绍模型架构并与近期相关工作对齐，随后详细分解每个模块的输入、处理方式和参数化细节，通过公式和引用说明字符级与词级信息融合，突出模型对形态和语义的联合建模能力。",
        "experiments_story": "实验部分以标准任务为切入点，选用广泛认可的基准数据集和评价指标，严格遵循前人工作设定（如标签方案和预处理），通过分任务描述和细节复现，确保结果的可比性和方法有效性，突出实验设计的规范性和透明度。"
      },
      {
        "paper_id": "ACL_2017_588",
        "title": "Rare Entity Prediction: Language Understanding with External Knowledge using Hierarchical LSTMs",
        "problem_framing": "论文通过强调自然语言处理领域中模型获取世界知识的核心难题引入研究主题，明确提出模型可通过非结构化文本和结构化知识库两种方式获取知识，并以阅读理解作为检验模型能力的自然场景，聚焦于模型知识获取能力的评估。",
        "gap_pattern": "作者批评现有阅读理解任务（如Daily Mail/CNN数据集）主要依赖基础语言建模，缺乏对推理能力的考察，指出当前任务在知识获取和推理层面存在不足，从而为新任务和方法的提出奠定基础。",
        "method_story": "方法部分采用先介绍模型整体思路，再细致说明核心技术（RNN与LSTM），通过解释其结构和优势，突出模型对顺序数据和语言问题的适用性，为后续实验验证提供理论支撑。",
        "experiments_story": "实验部分详细描述数据集划分、上下文与定义的具体设置，并报告对不同参数配置的尝试及其效果，采用逐步试错和对比分析的方法，突出实验设计的系统性和结果的客观性。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "文献综述引入法",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "通过引用大量相关工作（如Szabó, 2010; Iyyer et al., 2015等），介绍组合性在自然语言处理中的重要性和当前主流模型方法，为后续研究动机做铺垫。",
            "type": "writing-level",
            "purpose": "建立研究背景，展示领域现状"
          }
        ]
      },
      {
        "trick_name": "层次结构模型对比",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "对比从简单到复杂的模型（如Bag-of-Words、RNN、树结构、CNN），展示方法发展脉络，并引出自身模型的独特性。",
            "type": "writing-level",
            "purpose": "突出自身方法的创新点"
          }
        ]
      },
      {
        "trick_name": "子词级别建模",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "强调组合性不仅在词之间存在，也在词内部，通过字符级、形态级建模提升对罕见词的表示能力。",
            "type": "method-level",
            "purpose": "提升对低频词和形态丰富语言的建模能力"
          }
        ]
      },
      {
        "trick_name": "基线模型设定",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "明确设置Lookup模型作为基线，用字符嵌入查找表实现字符表示，为后续新方法提供对比。",
            "type": "experiment-level",
            "purpose": "为新方法效果对比提供参考"
          }
        ]
      },
      {
        "trick_name": "端到端神经网络设计",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "采用端到端结构：字符表示—RNN—句子表示—softmax分类，体现现代神经网络的整体设计理念。",
            "type": "method-level",
            "purpose": "简化流程，提升模型表达能力"
          }
        ]
      },
      {
        "trick_name": "视觉信息融合",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "创新地将字符转为图片，利用CNN提取视觉特征，生成字符嵌入，提升对低频及形近字符的参数共享能力。",
            "type": "method-level",
            "purpose": "利用字符视觉特征提升泛化能力"
          }
        ]
      },
      {
        "trick_name": "参数共享机制",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "通过视觉特征映射，实现参数在形近字符间共享，提高模型对低频字符的学习效果。",
            "type": "method-level",
            "purpose": "缓解低频字符学习难题"
          }
        ]
      },
      {
        "trick_name": "图示辅助说明",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "通过图示（如Fig. 3）直观展示模型结构和流程，帮助读者理解复杂方法。",
            "type": "writing-level",
            "purpose": "提升模型结构表达清晰度"
          }
        ]
      },
      {
        "trick_name": "端到端反向传播训练",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_543",
            "title": "Learning Character-level Compositionality with Visual Features",
            "description": "整个模型参数，包括CNN部分，通过分类损失端到端反向传播优化，保证特征与任务紧密结合。",
            "type": "method-level",
            "purpose": "优化模型参数"
          }
        ]
      },
      {
        "trick_name": "引用前人工作建立背景",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "通过引用多篇前人工作（如Mikolov et al., 2013; Pennington et al., 2014），阐述预训练词嵌入在NLP中的广泛应用和有效性，从而自然引出当前研究的动机。",
            "type": "writing-level",
            "purpose": "引入研究背景并展示现有方法的优点与不足"
          }
        ]
      },
      {
        "trick_name": "举例说明问题",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "通过举例（如‘Central’在不同短语中的含义）说明词在不同上下文中的语义变化，强调上下文敏感表示的重要性。",
            "type": "writing-level",
            "purpose": "具体化抽象问题，帮助读者理解任务需求"
          }
        ]
      },
      {
        "trick_name": "分层神经网络结构设计",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "采用分层结构，首先将字符级表示与词嵌入拼接，然后通过多层双向RNN进行上下文编码，实现对形态和语义信息的联合建模。",
            "type": "method-level",
            "purpose": "增强模型对词形和上下文信息的捕获能力"
          }
        ]
      },
      {
        "trick_name": "字符级表示与词嵌入拼接",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "每个token的表示由字符级表示（如CNN或RNN）和词嵌入拼接而成，使模型兼具词形和词义信息。",
            "type": "method-level",
            "purpose": "结合词形特征与词语语义表示，提升模型鲁棒性"
          }
        ]
      },
      {
        "trick_name": "预训练词嵌入初始化",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "词嵌入初始化采用预训练模型（如Word2Vec/Glove），并在训练过程中进行微调，以更好适应下游任务。",
            "type": "method-level",
            "purpose": "利用外部语料知识提升模型初始性能"
          }
        ]
      },
      {
        "trick_name": "双向RNN捕获上下文信息",
        "frequency": 1,
        "percentage": "14.3%",
        "examples": [
          {
            "paper_id": "ACL_2017_561",
            "title": "Semi-supervised sequence tagging with bidirectional language models",
            "description": "通过双向RNN结构，将每个位置的前向和后向隐藏状态拼接，获得包含全部上下文信息的token表示。",
            "type": "method-level",
            "purpose": "充分利用前后文信息，提升序列标注准确性"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 7,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ACL_2017_543",
        "ACL_2017_561",
        "ACL_2017_588",
        "ACL_2017_554",
        "ACL_2017_760",
        "ACL_2017_371",
        "ACL_2017_792"
      ]
    }
  },
  {
    "pattern_id": 30,
    "pattern_name": "多目标训练长文本模型",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决长文本理解与生成问题，采用多目标训练和参数共享策略提升模型长距离依赖能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以学术gap开篇，通过理论与实际对比解释方法必要性，常用tricks包括参数敏感性分析和分任务实验设计。\n第3段（60字）：适用场景与预期效果 - 适用于长文档理解、问答、文本生成等任务，预期提升模型在长距离依赖上的表现和泛化能力。",
    "writing_guide": "写作模板：多目标训练长文本模型\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决长文本理解与生成问题，采用多目标训练和参数共享策略提升模型长距离依赖能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以学术gap开篇，通过理论与实际对比解释方法必要性，常用tricks包括参数敏感性分析和分任务实验设计。\n第3段（60字）：适用场景与预期效果 - 适用于长文档理解、问答、文本生成等任务，预期提升模型在长距离依赖上的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Boosting coherence of language models》\n  • 问题定位：论文从学术gap出发引出问题，强调当前语言模型虽然在生成、排序和分类任务上表现良好，但由于训练数据可能违反语用规范，以及模型训练目标与实际推断时的上下文条件不一致，导致长距离语义连贯性不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统的n-gram和早期神经语言模型虽然尝试平衡短距离统计约束与长距离结构，但仍然对远距离内容或语法不敏感，并容易受到近期上下文的偏见影响。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先介绍多目标训练的整体框架，解释模型如何同时拟合不同长度上下文的预测器，并分析训练与推断时上下文分布的差异。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+横向对比’的策略。首先在LAMBADA数据集上进行主实验，验证方法在长距离依赖预测上的有效性，并通过参数搜索展示模型表现的提升。\n\n示例 2：《QuALITY: Question Answering with Long Input Texts, Yes!》\n  • 问题定位：论文从实际痛点和应用需求出发引出问题。开篇强调当前自然语言理解模型受限于只能处理几百个词，无法应对需要整体理解长篇文本的任务，这限制了在新闻理解、摘要和问答等实际应用中的能力。作者进一步指出，突破这一限制将带来新的应用可能，并认为建立新的基准数据集是解决该问题的关键路径。\n  • 现有研究缺口：论文通过学术gap的逻辑批评现有方法。首先指出现有数据集大多只包含人类几分钟可读的短文本，无法支持长文档整体理解。其次，虽然有部分开放域问答数据集涉及长文本，但通常只需检索短片段即可回答问题，未能真正考验长文档理解能力。\n  • 核心方法：方法部分采用分模块介绍和先整体后局部的叙述策略。首先介绍了长文本输入的模型（Longformer及其变体），再介绍了基于检索的抽取式方法，包括三种不同的句子相关性评分方法。\n  • 实验设计：实验部分采用主实验+多基线+难度分组的策略。首先展示各模型在主测试集上的表现，并与人类表现进行对比，突出模型与人类的差距。其次，分析不同训练数据（QuALITY、RACE、RACE→QuALITY）对模型性能的影响。\n\n示例 3：《LongT5: Efficient Text-To-Text Transformer for Long Sequences》\n  • 问题定位：论文采用了从学术gap出发的开篇策略。首先回顾了Transformer模型（如BERT、T5等）在NLP任务中的优异表现，并指出近期长输入Transformer的进展表明扩大输入长度和模型规模能带来性能提升。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了LongT5的设计思想，即在T5架构基础上同时扩展输入长度和模型规模。\n  • 实验设计：实验部分采用了‘多数据集验证+主实验’的策略。首先在多种摘要任务（涵盖不同输入长度）上与主流方法进行对比，使用ROUGE等标准指标评估，突出LongT5在长输入场景下的优势。其次在问答任务（NQ和TriviaQA）上验证模型的长上下文理解能力，采用EM和F1指标。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 实验细节透明披露（使用频率 2 次，占比 40.0%）\n   类型：experiment-level\n   应用：作者详细说明实验设置、参数选择、数据处理和代码开放，确保读者可以复现结果。\n\n2. 问题引入与动机铺垫（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：作者首先指出现有语言模型在长距离连贯性上的失败，并用具体模型（GPT-2/3）和数据分布偏差举例，强调问题的普遍性和重要性。\n\n3. 创新方法简明预告（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：作者在引言末尾直接提出了coherence boosting方法，并简要说明其原理和优势，为后文详细展开做铺垫。\n\n4. 理论与实际场景对比（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：作者详细分析了训练时多目标优化与推理时单目标分布的区别，指出现有训练方式导致长距离依赖建模不足，为新方法的必要性提供理论基础。\n\n5. 参数共享与优化困境阐释（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：通过阐述参数共享和长短上下文损失的权衡，解释模型在长距离依赖建模上的天然劣势。\n\n6. 分任务实验设计（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：作者将实验分为五大类任务（完形填空、问答、文本分类、自然语言推断、知识检索），覆盖15个数据集，确保方法在多种场景下都有效。\n\n7. 与主流模型直接对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：在LAMBADA等任务上，作者将coherence boosting后的模型与原始GPT-2/3进行准确率对比，展示显著提升，甚至小模型超过大模型。\n\n8. 参数敏感性分析（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过对混合参数的网格搜索和分析，作者揭示最佳参数随模型规模变化的规律，解释大模型对长距离依赖的天然优势。\n\n9. 自然场景与基准任务结合（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：作者在通用文本生成和对话任务中评估方法，展示生成文本中长距离依赖词的分布接近自然文本。\n\n10. 逻辑递进式叙事结构（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：全文结构从问题引入、理论分析、方法提出到分层实验验证，层层递进，逻辑清晰。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_312",
        "title": "Boosting coherence of language models",
        "problem_framing": "论文从学术gap出发引出问题，强调当前语言模型虽然在生成、排序和分类任务上表现良好，但由于训练数据可能违反语用规范，以及模型训练目标与实际推断时的上下文条件不一致，导致长距离语义连贯性不足。作者通过展示GPT-2和GPT-3在长距离连贯性上的失败案例，提出现有模型对远距离上下文敏感性不足，进而引出需要改进的方法。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统的n-gram和早期神经语言模型虽然尝试平衡短距离统计约束与长距离结构，但仍然对远距离内容或语法不敏感，并容易受到近期上下文的偏见影响。此外，现有推断时的采样和截断方法只在局部修改分布，未能根本解决长距离连贯性问题。论文通过引用相关文献和实验结果，系统性地批评了现有方案的局限性。",
        "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先介绍多目标训练的整体框架，解释模型如何同时拟合不同长度上下文的预测器，并分析训练与推断时上下文分布的差异。随后，详细阐述参数共享带来的训练难点、长距离上下文的稀缺性以及分布偏移问题，逐步聚焦到为何需要将不同上下文长度的模型集成，从而引出作者提出的coherence boosting方法。",
        "experiments_story": "实验部分采用‘多数据集验证+主实验+横向对比’的策略。首先在LAMBADA数据集上进行主实验，验证方法在长距离依赖预测上的有效性，并通过参数搜索展示模型表现的提升。随后，扩展到15个数据集，涵盖Cloze任务、问答、文本分类、自然语言推断和事实检索等五大类任务，强调方法的广泛适用性和在高连贯性场景下的优势。实验中还包含参数分析和模型规模对结果的影响，增强结论的说服力。"
      },
      {
        "paper_id": "ARR_2022_142",
        "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
        "problem_framing": "论文从实际痛点和应用需求出发引出问题。开篇强调当前自然语言理解模型受限于只能处理几百个词，无法应对需要整体理解长篇文本的任务，这限制了在新闻理解、摘要和问答等实际应用中的能力。作者进一步指出，突破这一限制将带来新的应用可能，并认为建立新的基准数据集是解决该问题的关键路径。",
        "gap_pattern": "论文通过学术gap的逻辑批评现有方法。首先指出现有数据集大多只包含人类几分钟可读的短文本，无法支持长文档整体理解。其次，虽然有部分开放域问答数据集涉及长文本，但通常只需检索短片段即可回答问题，未能真正考验长文档理解能力。作者还批评了现有长文本数据集（如NarrativeQA）的问题，包括答案短、问题类型单一、数据来源易被训练数据覆盖，以及生成式评测难以公平衡量模型表现等。通过这些批评，作者明确现有方法在长文档理解和评测方面存在明显不足。",
        "method_story": "方法部分采用分模块介绍和先整体后局部的叙述策略。首先介绍了长文本输入的模型（Longformer及其变体），再介绍了基于检索的抽取式方法，包括三种不同的句子相关性评分方法。随后，作者描述了如何将抽取的内容输入到多种主流问答模型中，并设立了oracle抽取和仅用问题的基线以测试模型对上下文的利用。最后，补充了跨数据集训练的细节，形成由整体到细节、分模块递进的结构。",
        "experiments_story": "实验部分采用主实验+多基线+难度分组的策略。首先展示各模型在主测试集上的表现，并与人类表现进行对比，突出模型与人类的差距。其次，分析不同训练数据（QuALITY、RACE、RACE→QuALITY）对模型性能的影响。再次，比较不同抽取策略（如DPR、ROUGE、fastText）及oracle抽取的上限表现。还设置了仅用问题的基线以检验数据集是否存在伪相关性。最后，针对经过speed-validation筛选的更难子集（QuALITY-HARD）进行实验，验证模型在更高难度下的表现。整体上，实验设计系统性强，涵盖主实验、基线、难度分组和上限分析。"
      },
      {
        "paper_id": "ARR_2022_29",
        "title": "LongT5: Efficient Text-To-Text Transformer for Long Sequences",
        "problem_framing": "论文采用了从学术gap出发的开篇策略。首先回顾了Transformer模型（如BERT、T5等）在NLP任务中的优异表现，并指出近期长输入Transformer的进展表明扩大输入长度和模型规模能带来性能提升。接着，作者提出当前尚未系统探索同时扩展输入长度和模型规模的效果，明确提出了这一未被充分研究的学术空白，并以此为切入点引出本文的研究目标——提出LongT5模型以填补这一gap。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。具体表现为：指出BERT等预训练方法虽然有效，但其MLM目标限制了生成任务能力；T5和BART虽改进了预训练目标，但未考虑超长输入的预训练；Transformer架构本身因注意力机制的二次复杂度，难以处理超长文本。此外，部分长文本建模方法（如ETC）需要针对每个任务设计额外的全局输入，增加了使用门槛。整体上，批评现有方法在长文本建模和预训练方面存在局限，未能兼顾输入长度和模型规模的扩展。",
        "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了LongT5的设计思想，即在T5架构基础上同时扩展输入长度和模型规模。随后分模块详细介绍了两大核心创新：一是提出TGlobal注意力机制，通过动态合成全局token，减少对额外输入的依赖并提升长输入处理能力；二是采用PEGASUS的预训练策略，将关键句mask并要求模型生成总结，从而提升生成和理解长文本的能力。每个模块都结合现有方法进行对比，突出创新点。",
        "experiments_story": "实验部分采用了‘多数据集验证+主实验’的策略。首先在多种摘要任务（涵盖不同输入长度）上与主流方法进行对比，使用ROUGE等标准指标评估，突出LongT5在长输入场景下的优势。其次在问答任务（NQ和TriviaQA）上验证模型的长上下文理解能力，采用EM和F1指标。实验设计体现了对不同任务类型和输入长度的系统性验证，强调模型在主流和极端场景下的性能表现。此外，实验中还对比了不同输入长度和模型规模的效果，分析了扩展带来的性能提升。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "实验细节透明披露",
        "frequency": 2,
        "percentage": "40.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者详细说明实验设置、参数选择、数据处理和代码开放，确保读者可以复现结果。",
            "type": "experiment-level",
            "purpose": "增强实验的可复现性和可信度"
          },
          {
            "paper_id": "ARR_2022_349",
            "title": "CHAPTERBREAK: A Challenge Dataset for Long-Range Language Models",
            "description": "详细说明各模型训练细节、数据来源、评测范围（如GPT-3因成本仅评估230例），并补充附录说明。",
            "type": "writing-level",
            "purpose": "增强实验完备性和可复现性，提升论文可信度"
          }
        ]
      },
      {
        "trick_name": "问题引入与动机铺垫",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者首先指出现有语言模型在长距离连贯性上的失败，并用具体模型（GPT-2/3）和数据分布偏差举例，强调问题的普遍性和重要性。",
            "type": "writing-level",
            "purpose": "突出当前主流语言模型在长距离连贯性上的不足，激发读者关注和兴趣"
          }
        ]
      },
      {
        "trick_name": "创新方法简明预告",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者在引言末尾直接提出了coherence boosting方法，并简要说明其原理和优势，为后文详细展开做铺垫。",
            "type": "writing-level",
            "purpose": "在引言中提前介绍“coherence boosting”方法，突出工作的创新点和核心贡献"
          }
        ]
      },
      {
        "trick_name": "理论与实际场景对比",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者详细分析了训练时多目标优化与推理时单目标分布的区别，指出现有训练方式导致长距离依赖建模不足，为新方法的必要性提供理论基础。",
            "type": "method-level",
            "purpose": "帮助读者理解训练与推理阶段的分歧，解释方法设计的合理性"
          }
        ]
      },
      {
        "trick_name": "参数共享与优化困境阐释",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "通过阐述参数共享和长短上下文损失的权衡，解释模型在长距离依赖建模上的天然劣势。",
            "type": "method-level",
            "purpose": "增强方法可解释性，让读者理解模型为何难以兼顾长短距离依赖"
          }
        ]
      },
      {
        "trick_name": "分任务实验设计",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者将实验分为五大类任务（完形填空、问答、文本分类、自然语言推断、知识检索），覆盖15个数据集，确保方法在多种场景下都有效。",
            "type": "experiment-level",
            "purpose": "证明方法的广泛适用性和充分性，提升结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "与主流模型直接对比",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "在LAMBADA等任务上，作者将coherence boosting后的模型与原始GPT-2/3进行准确率对比，展示显著提升，甚至小模型超过大模型。",
            "type": "experiment-level",
            "purpose": "突出方法的性能提升和实际价值，增强说服力"
          }
        ]
      },
      {
        "trick_name": "参数敏感性分析",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "通过对混合参数的网格搜索和分析，作者揭示最佳参数随模型规模变化的规律，解释大模型对长距离依赖的天然优势。",
            "type": "experiment-level",
            "purpose": "展示方法的可控性和解释性，帮助理解模型行为"
          }
        ]
      },
      {
        "trick_name": "自然场景与基准任务结合",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "作者在通用文本生成和对话任务中评估方法，展示生成文本中长距离依赖词的分布接近自然文本。",
            "type": "experiment-level",
            "purpose": "证明方法不仅在标准任务有效，也能提升实际文本生成质量"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "全文结构从问题引入、理论分析、方法提出到分层实验验证，层层递进，逻辑清晰。",
            "type": "writing-level",
            "purpose": "让读者顺畅理解问题提出、方法设计、理论分析和实验验证的全过程"
          }
        ]
      },
      {
        "trick_name": "与现有文献呼应",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_312",
            "title": "Boosting coherence of language models",
            "description": "多次引用GPT-2/3、LAMBADA等主流工作，说明本方法在现有框架下的改进和超越。",
            "type": "writing-level",
            "purpose": "增强工作的学术背景和权威性，说明与前人工作的联系和突破"
          }
        ]
      },
      {
        "trick_name": "现实需求引入",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_142",
            "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
            "description": "通过指出现有模型在长文本理解上的局限性及其对实际应用（如新闻理解、摘要、问答）的影响，强调突破该限制的必要性。",
            "type": "writing-level",
            "purpose": "强调研究的重要性和实际应用前景，增强说服力"
          }
        ]
      },
      {
        "trick_name": "现有工作梳理与缺陷点明",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_142",
            "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
            "description": "系统梳理已有数据集和方法的不足（如上下文太短、答案类型单一、评测难度低、评测标准不理想），为新数据集和方法的提出做铺垫。",
            "type": "writing-level",
            "purpose": "突出自身工作的创新点和必要性"
          }
        ]
      },
      {
        "trick_name": "新数据集设计亮点突出",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_142",
            "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
            "description": "详细介绍QuALITY数据集的设计理念，包括长文本、多选题、创意众包流程和速度验证，突出其在挑战性和评测友好性上的创新。",
            "type": "method-level",
            "purpose": "展示工作的创新性和独特性"
          }
        ]
      },
      {
        "trick_name": "评测方式合理化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ARR_2022_142",
            "title": "QuALITY: Question Answering with Long Input Texts, Yes!",
            "description": "解释选择多项选择题格式而非生成式问答的原因，指出这样可以简化评测、避免主观性，并引用相关文献支持。",
            "type": "writing-level",
            "purpose": "增强方法的可解释性和说服力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_312",
        "ARR_2022_142",
        "ARR_2022_29",
        "ARR_2022_349",
        "ARR_2022_346"
      ]
    }
  },
  {
    "pattern_id": 31,
    "pattern_name": "神经序列模型与预训练嵌入",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义解析和自然语言理解中的表达能力和特征工程难题，采用神经序列模型直接生成目标语言，结合在线学习和预训练嵌入提升性能。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和研究缺口开篇，方法部分采用分步叙述和公式补充，常用tricks包括在线部署、预训练嵌入拼接、全局注意力机制等，实验设计注重对比验证和实际应用。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要将自然语言转换为目标语言的任务，如SQL生成、程序构建等，预期提升模型的表达能力和泛化性能，减少特征工程成本。",
    "writing_guide": "写作模板：神经序列模型与预训练嵌入\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义解析和自然语言理解中的表达能力和特征工程难题，采用神经序列模型直接生成目标语言，结合在线学习和预训练嵌入提升性能。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和研究缺口开篇，方法部分采用分步叙述和公式补充，常用tricks包括在线部署、预训练嵌入拼接、全局注意力机制等，实验设计注重对比验证和实际应用。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要将自然语言转换为目标语言的任务，如SQL生成、程序构建等，预期提升模型的表达能力和泛化性能，减少特征工程成本。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning a Neural Semantic Parser from User Feedback》\n  • 问题定位：论文通过对现有语义解析方法的局限性进行概述，突出自然语言接口构建中的两大难题：中间表示的表达能力不足和特征工程的高成本。作者以实际应用部署难度为切入点，强调亟需更高效、易用的解决方案。\n  • 现有研究缺口：作者采用对比批评策略，指出现有方法要么牺牲查询语言的表达力，要么依赖繁琐的特征工程，导致难以迁移和扩展。通过明确现有工作的不足，为提出新方法奠定理论基础和实际需求。\n  • 核心方法：方法部分采用分步叙述，先总体介绍神经序列模型如何直接映射自然语言到SQL，随后详细说明模型架构、输入处理和解码机制，并用公式补充技术细节，突出创新点和实现路径。\n  • 实验设计：实验部分以对比验证为主线，先展示模型在标准数据集上的表现，强调直接生成SQL的难度和突破。通过与前人工作的结果对比，突出新方法无需特征工程即可达到同等性能，强化方法有效性和实用价值。\n\n示例 2：《Probabilistic Regular Graph Languages》\n  • 问题定位：论文通过指出当前NLP系统在处理机器翻译、摘要和复述等任务时，常因仅以词袋或语法树建模语言而无法保持句子和文档的组合语义，从而引出语义保留的重要性，强调语义建模的必要性。\n  • 现有研究缺口：作者批评现有方法忽视了语言的组合语义，仅依赖表层结构，导致语义丢失。通过列举已有语义标注数据集，提出现有数据虽丰富，但缺乏有效的概率图模型来充分利用这些资源。\n  • 核心方法：方法部分以需求为驱动，明确提出为利用配对语义图的数据集，必须开发概率图模型。此策略将方法的提出与前述语义保留需求紧密关联，形成逻辑递进。\n  • 实验设计：实验部分通常围绕验证所提概率图模型的有效性展开，通过与现有方法或基线进行对比，展示模型在语义保留和下游任务上的优势，结构上强调方法与实际应用之间的联系。\n\n示例 3：《Robust Incremental Neural Semantic Graph Parsing》\n  • 问题定位：论文通过强调自然语言理解（NLU）中将句子解析为结构化、可解释语义表示的重要性，引出研究主题。作者指出这些结构对于查询执行、推理等任务至关重要，并以当前端到端模型在浅层解析任务中的优势为切入点，逐步聚焦到深层语义解析的挑战。\n  • 现有研究缺口：作者批评现有方法多局限于浅层解析（如双词依存），缺乏对深层语义结构的有效处理。通过对比传统管道方法和最新端到端模型，指出当前研究在解析深层语义表示（如MRS）方面存在不足，明确了论文的创新空间和研究价值。\n  • 核心方法：方法部分采用递进式叙述，先介绍对硬注意力模型的扩展，再详细说明如何结合过渡系统堆栈特征，并引用相关工作以增强方法的合理性。通过具体公式和结构描述，突出方法的创新点和与前人工作的联系与区别。\n  • 实验设计：实验部分以评价指标为核心，先介绍EDM指标的定义和适用性，再通过与Smatch等其他指标的对比，突出所选指标对MRS解析的针对性。实验设计注重细节，如对标注误差的容忍度，体现了对实际应用场景的考虑。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. Bypassing Intermediate Representations（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用神经序列模型将自然语言直接映射到SQL查询，避免使用中间语义表示，从而可以充分利用SQL的查询能力并减少特定领域的特征工程。\n\n2. Online Deployment for Interactive Learning（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：将模型立即部署到线上，收集用户的问题和对结果的反馈，利用真实交互数据进行模型优化，并减少SQL标注工作量。\n\n3. Crowdsourcing SQL Annotations（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：通过技能型众包市场获取SQL标注，这些标注既能直接用于模型训练，也比传统的逻辑语义标注更容易获得和更经济。\n\n4. Encoder-Decoder with Global Attention（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用带有全局注意力机制的编码-解码结构，编码端使用双向LSTM，解码端直接输出SQL查询token，通过注意力机制动态聚焦输入的不同部分。\n\n5. Combining Pre-trained and Learned Embeddings（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将预训练的word2vec词向量与在训练数据上学习到的源词嵌入进行拼接，丰富词语表达，提升模型性能。\n\n6. Conditional Token Prediction in Decoder（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：解码器在生成下一个SQL token时，基于之前生成的token、编码器隐藏状态的注意力以及前一时刻的注意力信号，计算条件概率分布，从而实现上下文相关的生成。\n\n7. Formal Mathematical Description of Model Components（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：用数学公式详细描述解码器分布、上下文向量和注意力权重的计算方法，使模型实现过程清晰、规范，便于他人复现。\n\n8. Rapid Domain Adaptation via Short-term Deployment（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过仅三天的在线部署，在学术领域成功训练出语义解析器，展示了方法在新领域的高效部署和学习能力。\n\n9. Comparative Reference to Related Work（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：将本方法与直接生成程序、基于众包获取释义等相关技术进行对比，强调本方法的优势和创新之处。\n\n10. 指出现有方法的局限性（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过批判现有方法（如bag-of-words和句法树）未能保留组合语义，引出对语义建模的需求，为后续研究铺垫背景。\n",
    "skeleton_examples": [
      {
        "paper_id": "ACL_2017_726",
        "title": "Learning a Neural Semantic Parser from User Feedback",
        "problem_framing": "论文通过对现有语义解析方法的局限性进行概述，突出自然语言接口构建中的两大难题：中间表示的表达能力不足和特征工程的高成本。作者以实际应用部署难度为切入点，强调亟需更高效、易用的解决方案。",
        "gap_pattern": "作者采用对比批评策略，指出现有方法要么牺牲查询语言的表达力，要么依赖繁琐的特征工程，导致难以迁移和扩展。通过明确现有工作的不足，为提出新方法奠定理论基础和实际需求。",
        "method_story": "方法部分采用分步叙述，先总体介绍神经序列模型如何直接映射自然语言到SQL，随后详细说明模型架构、输入处理和解码机制，并用公式补充技术细节，突出创新点和实现路径。",
        "experiments_story": "实验部分以对比验证为主线，先展示模型在标准数据集上的表现，强调直接生成SQL的难度和突破。通过与前人工作的结果对比，突出新方法无需特征工程即可达到同等性能，强化方法有效性和实用价值。"
      },
      {
        "paper_id": "ACL_2017_503",
        "title": "Probabilistic Regular Graph Languages",
        "problem_framing": "论文通过指出当前NLP系统在处理机器翻译、摘要和复述等任务时，常因仅以词袋或语法树建模语言而无法保持句子和文档的组合语义，从而引出语义保留的重要性，强调语义建模的必要性。",
        "gap_pattern": "作者批评现有方法忽视了语言的组合语义，仅依赖表层结构，导致语义丢失。通过列举已有语义标注数据集，提出现有数据虽丰富，但缺乏有效的概率图模型来充分利用这些资源。",
        "method_story": "方法部分以需求为驱动，明确提出为利用配对语义图的数据集，必须开发概率图模型。此策略将方法的提出与前述语义保留需求紧密关联，形成逻辑递进。",
        "experiments_story": "实验部分通常围绕验证所提概率图模型的有效性展开，通过与现有方法或基线进行对比，展示模型在语义保留和下游任务上的优势，结构上强调方法与实际应用之间的联系。"
      },
      {
        "paper_id": "ACL_2017_578",
        "title": "Robust Incremental Neural Semantic Graph Parsing",
        "problem_framing": "论文通过强调自然语言理解（NLU）中将句子解析为结构化、可解释语义表示的重要性，引出研究主题。作者指出这些结构对于查询执行、推理等任务至关重要，并以当前端到端模型在浅层解析任务中的优势为切入点，逐步聚焦到深层语义解析的挑战。",
        "gap_pattern": "作者批评现有方法多局限于浅层解析（如双词依存），缺乏对深层语义结构的有效处理。通过对比传统管道方法和最新端到端模型，指出当前研究在解析深层语义表示（如MRS）方面存在不足，明确了论文的创新空间和研究价值。",
        "method_story": "方法部分采用递进式叙述，先介绍对硬注意力模型的扩展，再详细说明如何结合过渡系统堆栈特征，并引用相关工作以增强方法的合理性。通过具体公式和结构描述，突出方法的创新点和与前人工作的联系与区别。",
        "experiments_story": "实验部分以评价指标为核心，先介绍EDM指标的定义和适用性，再通过与Smatch等其他指标的对比，突出所选指标对MRS解析的针对性。实验设计注重细节，如对标注误差的容忍度，体现了对实际应用场景的考虑。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "Bypassing Intermediate Representations",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "采用神经序列模型将自然语言直接映射到SQL查询，避免使用中间语义表示，从而可以充分利用SQL的查询能力并减少特定领域的特征工程。",
            "type": "method-level",
            "purpose": "简化语义解析流程并充分利用SQL语言的表达能力"
          }
        ]
      },
      {
        "trick_name": "Online Deployment for Interactive Learning",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "将模型立即部署到线上，收集用户的问题和对结果的反馈，利用真实交互数据进行模型优化，并减少SQL标注工作量。",
            "type": "experiment-level",
            "purpose": "通过用户反馈持续改进模型性能，降低人工标注成本"
          }
        ]
      },
      {
        "trick_name": "Crowdsourcing SQL Annotations",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "通过技能型众包市场获取SQL标注，这些标注既能直接用于模型训练，也比传统的逻辑语义标注更容易获得和更经济。",
            "type": "method-level",
            "purpose": "快速、低成本获取高质量训练数据以提升模型性能"
          }
        ]
      },
      {
        "trick_name": "Encoder-Decoder with Global Attention",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "采用带有全局注意力机制的编码-解码结构，编码端使用双向LSTM，解码端直接输出SQL查询token，通过注意力机制动态聚焦输入的不同部分。",
            "type": "method-level",
            "purpose": "提升模型对输入句子不同部分的关注度，实现更精确的SQL生成"
          }
        ]
      },
      {
        "trick_name": "Combining Pre-trained and Learned Embeddings",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "将预训练的word2vec词向量与在训练数据上学习到的源词嵌入进行拼接，丰富词语表达，提升模型性能。",
            "type": "method-level",
            "purpose": "提升模型对词语语义的理解能力，增强泛化能力"
          }
        ]
      },
      {
        "trick_name": "Conditional Token Prediction in Decoder",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "解码器在生成下一个SQL token时，基于之前生成的token、编码器隐藏状态的注意力以及前一时刻的注意力信号，计算条件概率分布，从而实现上下文相关的生成。",
            "type": "method-level",
            "purpose": "确保SQL生成过程的上下文相关性和准确性"
          }
        ]
      },
      {
        "trick_name": "Formal Mathematical Description of Model Components",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "用数学公式详细描述解码器分布、上下文向量和注意力权重的计算方法，使模型实现过程清晰、规范，便于他人复现。",
            "type": "writing-level",
            "purpose": "提升论文的严谨性和可复现性"
          }
        ]
      },
      {
        "trick_name": "Rapid Domain Adaptation via Short-term Deployment",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "通过仅三天的在线部署，在学术领域成功训练出语义解析器，展示了方法在新领域的高效部署和学习能力。",
            "type": "experiment-level",
            "purpose": "验证方法在新领域的快速适应能力和实际可用性"
          }
        ]
      },
      {
        "trick_name": "Comparative Reference to Related Work",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_726",
            "title": "Learning a Neural Semantic Parser from User Feedback",
            "description": "将本方法与直接生成程序、基于众包获取释义等相关技术进行对比，强调本方法的优势和创新之处。",
            "type": "writing-level",
            "purpose": "突出方法创新点，定位本研究在领域内的价值"
          }
        ]
      },
      {
        "trick_name": "指出现有方法的局限性",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "通过批判现有方法（如bag-of-words和句法树）未能保留组合语义，引出对语义建模的需求，为后续研究铺垫背景。",
            "type": "writing-level",
            "purpose": "引出研究动机，说明现有NLP系统的不足"
          }
        ]
      },
      {
        "trick_name": "引用和总结相关数据集",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "系统性地列举和引用多个与组合语义相关的数据集（如AMR、Prague Treebank等），体现对领域工作的熟悉，并为后续方法提供数据基础。",
            "type": "writing-level",
            "purpose": "展示领域现状和研究基础"
          }
        ]
      },
      {
        "trick_name": "引入新型语义表示（DAG）",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "强调采用有向无环图（DAG）作为组合语义的表示方式，突破传统的线性或树状结构，更好地捕捉语义信息。",
            "type": "method-level",
            "purpose": "提出更适合语义建模的表示方法"
          }
        ]
      },
      {
        "trick_name": "任务分解与形式化建模",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "将复杂任务（如机器翻译）分解为两步：先从源句生成语义图，再从语义图生成目标句，并用概率模型P(t, G|s)形式化描述，明确每一步的目标。",
            "type": "method-level",
            "purpose": "清晰地分解任务流程，便于后续建模和实现"
          }
        ]
      },
      {
        "trick_name": "概率模型分解",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "将联合概率模型P(t, G|s)分解为P(t|G)和P(G|s)，分别对应语义解析和生成，降低建模复杂度，使每一步可以独立优化。",
            "type": "method-level",
            "purpose": "简化建模难度，便于实现和优化"
          }
        ]
      },
      {
        "trick_name": "结合同步文法进行建模",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_503",
            "title": "Probabilistic Regular Graph Languages",
            "description": "借鉴Jones等人的工作，采用概率同步文法对字符串和图的域进行联合建模，实现语义图与语言之间的映射。",
            "type": "method-level",
            "purpose": "利用已有理论工具提升模型能力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ACL_2017_726",
        "ACL_2017_503",
        "ACL_2017_578",
        "ACL_2017_706",
        "ACL_2017_606"
      ]
    }
  },
  {
    "pattern_id": 32,
    "pattern_name": "文本分类与情感分析模型验证",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨文本分类与情感分析中的简单模型有效性，通过系统性文献回顾和对比性实验设计验证假设。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以问题引入和任务演进铺垫，常用tricks包括系统性文献回顾、方法家族归纳、对比性实验设计和多数据集验证。\n\n第3段（60字）：适用场景与预期效果 - 适用于文本分类、情感分析等NLP任务，特别是需要验证简单模型有效性的场景，预期提升模型的泛化能力和解释性。",
    "writing_guide": "写作模板：文本分类与情感分析模型验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨文本分类与情感分析中的简单模型有效性，通过系统性文献回顾和对比性实验设计验证假设。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以问题引入和任务演进铺垫，常用tricks包括系统性文献回顾、方法家族归纳、对比性实验设计和多数据集验证。\n\n第3段（60字）：适用场景与预期效果 - 适用于文本分类、情感分析等NLP任务，特别是需要验证简单模型有效性的场景，预期提升模型的泛化能力和解释性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP》\n  • 问题定位：论文通过强调文本分类领域方法众多、研究活跃这一现实切入，展示了当前方法的多样性和复杂性，进而引出自身的研究问题。开篇采用了从学术现状和方法繁多的实际痛点出发的策略，指出尽管有许多复杂模型，但是否简单的BoW模型也能很好完成任务仍值得探究。\n  • 现有研究缺口：论文通过对现有方法的系统梳理，指出当前主流方法分为BoW、图模型和序列模型三大类，并分别描述其代表性方法和特点。隐含批评在于：尽管有大量复杂模型（如图模型、Transformer等），但简单的BoW模型是否被低估了其有效性尚未被充分研究。\n  • 核心方法：方法部分采用了‘先整体后局部’的策略，首先将所有方法划分为三大类（BoW、图模型、序列模型），再通过表格总结各自关键属性，突出不同方法的本质区别。整体介绍后，逐一细化每类方法的代表性实现和核心机制。\n  • 实验设计：实验部分采用‘多方法、多数据集对比’的策略，既有从文献中汇报的结果，也有作者自行复现的实验。对16种方法在5个数据集上进行系统性对比，突出主实验的全面性，强调横向对比和结果的代表性。\n\n示例 2：《A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction》\n  • 问题定位：论文首先从领域重要性和实际需求出发，介绍了细粒度情感分析（ABSA）作为自然语言处理中的重要研究方向，强调其在挖掘特定方面意见和情感上的价值。随后通过回顾ABSA的三个基本子任务及其发展，逐步引出当前研究热点——方面情感三元组抽取（ASTE），并明确指出这是本文的研究目标。\n  • 现有研究缺口：论文通过对现有方法（如BMRC）进行评价，指出其存在的具体问题：例如共享分类器可能导致查询冲突，影响模型性能；忽略了词分割、span匹配和概率生成等重要策略。批评逻辑以“现有方法在特定结构下存在缺陷”以及“忽视关键策略”两种句式展开，强调了方法在实际应用中的不足和改进空间。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先简要回顾了BMRC的基本原理，作为背景铺垫，然后逐项详细介绍了本文提出的四项改进，包括专属分类器设计、词分割、span匹配优化和概率生成优化。每项改进都紧扣前述gap，突出针对性和创新性，整体结构清晰、层层递进。\n  • 实验设计：实验部分采用了多数据集验证和多类型实验的策略。首先介绍了实验所用的数据集、评价指标和对比基线，确保实验的公平性和权威性。主实验对比了改进前后的模型性能，并在多个公开数据集上验证了方法的有效性。随后通过消融实验（如F1分数提升分析）进一步证明各项改进的贡献。\n\n示例 3：《Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network》\n  • 问题定位：论文通过强调情感与讽刺检测在社交媒体分析、推荐和对话系统中的核心地位，直接切入研究主题。引言中结合实际应用场景，突出了该问题的现实意义和研究价值，吸引读者关注。\n  • 现有研究缺口：作者通过回顾已有文献，指出传统方法虽能处理词汇和句法层面的问题，但在语义和语用层面存在显著不足，尤其难以捕捉复杂的语境和讽刺表达，从而明确提出研究空白和挑战。\n  • 核心方法：方法部分采用分步叙述策略，先简要介绍整体技术路线，再细化为不同的模型变体，并通过引用相关章节（如4.1）提示后文详细说明，层层递进，增强逻辑性和可读性。\n  • 实验设计：实验部分以“逐项列举”的方式展开，先介绍数据集来源、规模及其独特性（如眼动数据），再依次说明实验设置和模型变体，条理清晰，便于读者快速把握实验设计的全貌。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 系统性文献回顾（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者详细回顾了领域内主流方法及其代表性文献，梳理了BoW、图模型和序列模型三大类方法，为自己的研究定位提供了坚实背景。\n\n2. 方法家族归纳（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：将现有方法归纳为BoW-based、graph-based和sequence-based三大类，并在方法部分用表格对比其关键属性。\n\n3. 对比性实验设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：明确指出将16种方法分为三大类进行系统对比，并结合文献结果和自有实验，确保对比的广度和深度。\n\n4. 多数据集验证（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：在5个公开文本分类数据集上进行实验，覆盖不同任务场景，提升实验的完备性。\n\n5. 自设假设驱动（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：明确提出“简单但有效的BoW模型可以很好地完成文本分类”这一假设，为全文实验和讨论定下主线。\n\n6. 属性对比表格（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过表格形式对比三类模型在图结构、词序、文本长度、归纳能力等维度的差异。\n\n7. 文献实验结果引用与自有实验结合（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：部分方法直接引用文献中的实验结果，部分方法由作者自行复现，兼顾实验的广度与深度。\n\n8. 逻辑递进式叙事（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：先提出领域问题和主流方法，再归纳方法类别，最后引出自己的研究假设和实验设计。\n\n9. 任务演进铺垫（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过梳理ABSA领域的任务演进，从基础子任务到复杂任务（如ASTE），逐步引出本文关注的研究目标，显示问题的重要性和研究的自然延伸。\n\n10. 引用权威与前沿工作（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：大量引用领域内权威和最新文献，说明该方向受到广泛关注，并明确自己的工作与前人工作的关系。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_230",
        "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
        "problem_framing": "论文通过强调文本分类领域方法众多、研究活跃这一现实切入，展示了当前方法的多样性和复杂性，进而引出自身的研究问题。开篇采用了从学术现状和方法繁多的实际痛点出发的策略，指出尽管有许多复杂模型，但是否简单的BoW模型也能很好完成任务仍值得探究。",
        "gap_pattern": "论文通过对现有方法的系统梳理，指出当前主流方法分为BoW、图模型和序列模型三大类，并分别描述其代表性方法和特点。隐含批评在于：尽管有大量复杂模型（如图模型、Transformer等），但简单的BoW模型是否被低估了其有效性尚未被充分研究。批评逻辑为：现有研究多关注复杂模型，缺乏对简单模型系统性、深入的对比和分析。",
        "method_story": "方法部分采用了‘先整体后局部’的策略，首先将所有方法划分为三大类（BoW、图模型、序列模型），再通过表格总结各自关键属性，突出不同方法的本质区别。整体介绍后，逐一细化每类方法的代表性实现和核心机制。",
        "experiments_story": "实验部分采用‘多方法、多数据集对比’的策略，既有从文献中汇报的结果，也有作者自行复现的实验。对16种方法在5个数据集上进行系统性对比，突出主实验的全面性，强调横向对比和结果的代表性。"
      },
      {
        "paper_id": "ARR_2022_351",
        "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
        "problem_framing": "论文首先从领域重要性和实际需求出发，介绍了细粒度情感分析（ABSA）作为自然语言处理中的重要研究方向，强调其在挖掘特定方面意见和情感上的价值。随后通过回顾ABSA的三个基本子任务及其发展，逐步引出当前研究热点——方面情感三元组抽取（ASTE），并明确指出这是本文的研究目标。整体采用了由广到窄、逐步聚焦的开篇策略，既体现了学术背景，也强调了实际应用需求。",
        "gap_pattern": "论文通过对现有方法（如BMRC）进行评价，指出其存在的具体问题：例如共享分类器可能导致查询冲突，影响模型性能；忽略了词分割、span匹配和概率生成等重要策略。批评逻辑以“现有方法在特定结构下存在缺陷”以及“忽视关键策略”两种句式展开，强调了方法在实际应用中的不足和改进空间。",
        "method_story": "方法部分采用了先整体后局部的叙述顺序。首先简要回顾了BMRC的基本原理，作为背景铺垫，然后逐项详细介绍了本文提出的四项改进，包括专属分类器设计、词分割、span匹配优化和概率生成优化。每项改进都紧扣前述gap，突出针对性和创新性，整体结构清晰、层层递进。",
        "experiments_story": "实验部分采用了多数据集验证和多类型实验的策略。首先介绍了实验所用的数据集、评价指标和对比基线，确保实验的公平性和权威性。主实验对比了改进前后的模型性能，并在多个公开数据集上验证了方法的有效性。随后通过消融实验（如F1分数提升分析）进一步证明各项改进的贡献。整体叙述以结果为导向，突出方法的实际效果和先进性。"
      },
      {
        "paper_id": "ACL_2017_387",
        "title": "Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network",
        "problem_framing": "论文通过强调情感与讽刺检测在社交媒体分析、推荐和对话系统中的核心地位，直接切入研究主题。引言中结合实际应用场景，突出了该问题的现实意义和研究价值，吸引读者关注。",
        "gap_pattern": "作者通过回顾已有文献，指出传统方法虽能处理词汇和句法层面的问题，但在语义和语用层面存在显著不足，尤其难以捕捉复杂的语境和讽刺表达，从而明确提出研究空白和挑战。",
        "method_story": "方法部分采用分步叙述策略，先简要介绍整体技术路线，再细化为不同的模型变体，并通过引用相关章节（如4.1）提示后文详细说明，层层递进，增强逻辑性和可读性。",
        "experiments_story": "实验部分以“逐项列举”的方式展开，先介绍数据集来源、规模及其独特性（如眼动数据），再依次说明实验设置和模型变体，条理清晰，便于读者快速把握实验设计的全貌。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "系统性文献回顾",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "作者详细回顾了领域内主流方法及其代表性文献，梳理了BoW、图模型和序列模型三大类方法，为自己的研究定位提供了坚实背景。",
            "type": "writing-level",
            "purpose": "展示对领域现状的全面把握，为后续工作定位创新点和必要性"
          }
        ]
      },
      {
        "trick_name": "方法家族归纳",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "将现有方法归纳为BoW-based、graph-based和sequence-based三大类，并在方法部分用表格对比其关键属性。",
            "type": "writing-level",
            "purpose": "帮助读者快速理解领域内主要方法的分类和核心差异，提升可解释性"
          }
        ]
      },
      {
        "trick_name": "对比性实验设计",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "明确指出将16种方法分为三大类进行系统对比，并结合文献结果和自有实验，确保对比的广度和深度。",
            "type": "experiment-level",
            "purpose": "通过多方法对比，增强自身方法说服力和结论的可靠性"
          }
        ]
      },
      {
        "trick_name": "多数据集验证",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "在5个公开文本分类数据集上进行实验，覆盖不同任务场景，提升实验的完备性。",
            "type": "experiment-level",
            "purpose": "证明实验结果的广泛适用性和结论的稳健性"
          }
        ]
      },
      {
        "trick_name": "自设假设驱动",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "明确提出“简单但有效的BoW模型可以很好地完成文本分类”这一假设，为全文实验和讨论定下主线。",
            "type": "writing-level",
            "purpose": "引导读者关注作者关注的问题，突出研究动机和创新点"
          }
        ]
      },
      {
        "trick_name": "属性对比表格",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "通过表格形式对比三类模型在图结构、词序、文本长度、归纳能力等维度的差异。",
            "type": "writing-level",
            "purpose": "提升方法可解释性，帮助读者直观理解不同模型的优劣和适用场景"
          }
        ]
      },
      {
        "trick_name": "文献实验结果引用与自有实验结合",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "部分方法直接引用文献中的实验结果，部分方法由作者自行复现，兼顾实验的广度与深度。",
            "type": "experiment-level",
            "purpose": "确保实验结果的全面性和客观性，提升结论的权威性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_230",
            "title": "Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP",
            "description": "先提出领域问题和主流方法，再归纳方法类别，最后引出自己的研究假设和实验设计。",
            "type": "writing-level",
            "purpose": "增强论文的逻辑流畅性和说服力，引导读者逐步接受作者观点"
          }
        ]
      },
      {
        "trick_name": "任务演进铺垫",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "通过梳理ABSA领域的任务演进，从基础子任务到复杂任务（如ASTE），逐步引出本文关注的研究目标，显示问题的重要性和研究的自然延伸。",
            "type": "writing-level",
            "purpose": "突出研究背景和任务发展，强调当前研究的必要性和前沿性"
          }
        ]
      },
      {
        "trick_name": "引用权威与前沿工作",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "大量引用领域内权威和最新文献，说明该方向受到广泛关注，并明确自己的工作与前人工作的关系。",
            "type": "writing-level",
            "purpose": "增强说服力，显示对领域现状的把握和工作的前沿性"
          }
        ]
      },
      {
        "trick_name": "问题诊断与方法动机",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "明确指出BMRC存在的具体问题（如共享分类器导致冲突、忽略分词等），为后续方法改进埋下伏笔。",
            "type": "writing-level",
            "purpose": "突出现有方法的不足，为提出新方法提供合理动机"
          }
        ]
      },
      {
        "trick_name": "贡献点分条列举",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "以条目形式总结论文的三大贡献，简洁明了地传达创新点。",
            "type": "writing-level",
            "purpose": "清晰突出创新点和主要贡献，便于读者快速把握论文价值"
          }
        ]
      },
      {
        "trick_name": "方法细节分步展开",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "先回顾BMRC基础，再分条详细介绍四项改进措施，层层递进，便于理解。",
            "type": "method-level",
            "purpose": "提升可解释性，让读者易于理解方法原理和改进点"
          }
        ]
      },
      {
        "trick_name": "实验多数据集验证",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "在多个公开基准数据集上进行实验，覆盖不同场景，显示方法的通用性和有效性。",
            "type": "experiment-level",
            "purpose": "增强完备性和说服力，证明方法的广泛适用性和稳定性"
          }
        ]
      },
      {
        "trick_name": "与强基线对比",
        "frequency": 1,
        "percentage": "16.7%",
        "examples": [
          {
            "paper_id": "ARR_2022_351",
            "title": "A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction",
            "description": "选用领域内公认的强基线（如原BMRC和Span-ASTE）进行对比，突出改进带来的性能提升。",
            "type": "experiment-level",
            "purpose": "突出方法的优越性，增强对比性和说服力"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 6,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_230",
        "ARR_2022_351",
        "ACL_2017_387",
        "ACL_2017_33",
        "COLING_2020_76",
        "COLING_2020_73"
      ]
    }
  },
  {
    "pattern_id": 33,
    "pattern_name": "多Span阅读理解技术",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多span阅读理解问题，采用模块化方法设计和多指标评估体系。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法梳理为基础，常用tricks包括问题空白强调、数据集创新展示和多指标评估体系。\n第3段（60字）：适用场景与预期效果 - 适用于多span阅读理解任务，数据集多样，目标是提升模型在复杂场景下的表现和泛化能力。",
    "writing_guide": "写作模板：多Span阅读理解技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多span阅读理解问题，采用模块化方法设计和多指标评估体系。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法梳理为基础，常用tricks包括问题空白强调、数据集创新展示和多指标评估体系。\n第3段（60字）：适用场景与预期效果 - 适用于多span阅读理解任务，数据集多样，目标是提升模型在复杂场景下的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《MultiSpanQA: A Dataset for Multi-Span Question Answering》\n  • 问题定位：论文首先从学术进展和实际需求出发，引入阅读理解任务的最新发展，指出现有系统已在主流数据集上接近甚至超越人类表现。随后，作者强调实际应用中答案常常由多个部分组成，而现有研究几乎全部局限于单一可抽取或计算的答案片段。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体地，指出现有数据集和方法都假定答案为单一片段，忽略了多片段答案的普遍性和复杂性。通过举例说明实际问题，并强调缺乏相关数据集和系统性研究，进一步论证现有方法的局限性。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先回顾相关工作，梳理多片段预测的主流技术路径及其缺陷。随后，正式定义多片段QA任务，提出自己的方法框架。\n  • 实验设计：实验部分采用‘主实验+多基线对比’的策略，聚焦于新数据集MultiSpanQA的性能验证。首先详细说明实验设置，包括模型结构、训练参数和评价指标。随后，分组报告不同模型（单片段、序列标注、联合预测等）在基础数据集和扩展数据集（含不可回答和单片段问题）上的表现。\n\n示例 2：《Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension》\n  • 问题定位：论文首先从实际应用需求出发，指出机器阅读理解（MRC）系统在自然语言处理中的重要性，并强调当前主流系统在公开数据集上已超越人类表现。但作者进一步提出，在实际部署中，MRC系统并不总是需要回答所有问题，特别是在存在答案不确定性或问题无解的情况下。\n  • 现有研究缺口：论文批评现有工作的逻辑主要体现在两个方面：一方面，指出已有大量工作关注span-based MRC中的无解性，但在多项选择题MRC中对此关注有限；另一方面，强调大部分相关研究仅专注于提升默认任务的性能，而忽视了对无解性和答案不确定性的系统性研究。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍了所用数据集（ReClor）及其默认配置，然后详细说明了为研究答案不确定性和无解性而设计的数据集变体（如TRN-mixed, TRN-ans, DEV-mixed），以及各自的构成比例。\n  • 实验设计：实验部分主要采用主实验+对比实验的叙述策略。首先基于不同的数据集配置（如默认、混合、仅可答）进行实验，系统地分析了ELECTRA模型在不同设置下的表现，并与其他主流预训练语言模型（PrLMs）及代表性系统（如DAGN、FocalReasoner）进行对比。\n\n示例 3：《Evaluation Metrics for Reading Comprehension: Prerequisite Skills and Readability》\n  • 问题定位：论文引言通过强调自然语言处理（NLP）目标——让智能体理解自然语言——引入研究问题，并以阅读理解（RC）任务为测试手段，突出RC能力的复杂性和多步骤特性，凸显其研究价值和挑战性。\n  • 现有研究缺口：作者批评当前RC数据集主要以表层类别（如问题类型）进行分类，忽视了对系统实际能力的细致刻画，指出仅用简单准确率衡量系统不足，强调需要更丰富的评测维度以推动RC系统发展。\n  • 核心方法：方法部分采用逐一说明数据集选择与样本筛选过程，详细列举所用RC数据集（QA4MRE、MCTest、SQuAD）及其抽样策略，突出实验设计的代表性和覆盖性，为后续分析奠定基础。\n  • 实验设计：实验部分以理论为依据，明确提出两大评价维度（前提技能与可读性），并结合前人工作细化技能分类，强调评价指标的科学性和系统性，展示实验设计的理论支撑和创新点。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题空白强调（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：作者指出现有阅读理解数据集几乎都只关注单一span答案，忽略了实际中常见的多span问题，强调了研究空白。\n\n2. 数据集创新展示（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：作者详细介绍了MultiSpanQA数据集的构建过程和规模，强调其是首个高质量多span阅读理解数据集。\n\n3. 多维度贡献总结（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：通过列举数据集、标签体系、模型和指标等多方面贡献，系统性地总结工作亮点。\n\n4. 现有方法梳理与不足分析（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：作者系统回顾了多span相关方法，指出它们在捕获全局信息、结构预测等方面的不足。\n\n5. 模块化方法设计（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：将模型分为编码器、序列标注器、span数预测器、结构预测器和调整模块等，清晰分解任务流程。\n\n6. 公式推导与逐步说明（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：通过逐步列出公式和模块输入输出，详细解释每一步的原理和实现方式。\n\n7. 多指标评估体系（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：采用精确匹配、部分匹配、F1、结构预测准确率等多种指标，全面评估模型性能。\n\n8. 多种基线对比（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：与单span模型、序列标注模型等多种基线进行对比，展示新方法的性能提升。\n\n9. 分组难度分析（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：按答案类型和span数量分组报告结果，分析模型在不同类别上的表现和难点。\n\n10. 逻辑递进式叙事结构（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：从问题引入、现有方法梳理、创新方法提出、实验验证到结论呼应，层层递进组织全文。\n",
    "skeleton_examples": [
      {
        "paper_id": "ARR_2022_130",
        "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
        "problem_framing": "论文首先从学术进展和实际需求出发，引入阅读理解任务的最新发展，指出现有系统已在主流数据集上接近甚至超越人类表现。随后，作者强调实际应用中答案常常由多个部分组成，而现有研究几乎全部局限于单一可抽取或计算的答案片段。通过举例和数据集现状，突出多片段（multi-span）答案的缺失，明确提出当前研究的痛点和学术空白，为后续工作奠定基础。",
        "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体地，指出现有数据集和方法都假定答案为单一片段，忽略了多片段答案的普遍性和复杂性。通过举例说明实际问题，并强调缺乏相关数据集和系统性研究，进一步论证现有方法的局限性。此外，方法部分也批评了现有模型在捕捉全局信息和处理多片段结构上的不足。",
        "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先回顾相关工作，梳理多片段预测的主流技术路径及其缺陷。随后，正式定义多片段QA任务，提出自己的方法框架。方法介绍先给出整体架构，再分模块详细说明：包括序列编码、初步片段预测、全局信息预测（片段数与结构）、损失函数设计、以及最终的片段调整模块。每个模块都与前述问题和现有方法的不足相呼应，突出创新点。",
        "experiments_story": "实验部分采用‘主实验+多基线对比’的策略，聚焦于新数据集MultiSpanQA的性能验证。首先详细说明实验设置，包括模型结构、训练参数和评价指标。随后，分组报告不同模型（单片段、序列标注、联合预测等）在基础数据集和扩展数据集（含不可回答和单片段问题）上的表现。通过精确匹配和部分重叠F1分数、结构预测准确率等多维度指标，系统比较各方法优劣，突出新方法的优势。实验叙述以结果分析和现象总结收尾，强调主模型的性能提升和发现。"
      },
      {
        "paper_id": "ARR_2022_330",
        "title": "Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension",
        "problem_framing": "论文首先从实际应用需求出发，指出机器阅读理解（MRC）系统在自然语言处理中的重要性，并强调当前主流系统在公开数据集上已超越人类表现。但作者进一步提出，在实际部署中，MRC系统并不总是需要回答所有问题，特别是在存在答案不确定性或问题无解的情况下。通过引入负分机制和区分答案不确定性与无解性，论文自然引出对这两类情境的关注，强调了现有系统在这方面的不足和实际需求。",
        "gap_pattern": "论文批评现有工作的逻辑主要体现在两个方面：一方面，指出已有大量工作关注span-based MRC中的无解性，但在多项选择题MRC中对此关注有限；另一方面，强调大部分相关研究仅专注于提升默认任务的性能，而忽视了对无解性和答案不确定性的系统性研究。常用句式包括‘limited work has been completed with regard to unanswerability for multiple-choice reading comprehension datasets’和‘most work focuses on developing state-of-the-art systems on the default task’，突出学术gap。",
        "method_story": "方法部分采用先整体后局部的叙述策略。首先介绍了所用数据集（ReClor）及其默认配置，然后详细说明了为研究答案不确定性和无解性而设计的数据集变体（如TRN-mixed, TRN-ans, DEV-mixed），以及各自的构成比例。接着，描述了模型训练、评估和主要不确定性度量（如expected entropy），并在最后简要提及了其他不确定性度量的结果见附录，体现了从整体到细节、兼顾主次的结构。",
        "experiments_story": "实验部分主要采用主实验+对比实验的叙述策略。首先基于不同的数据集配置（如默认、混合、仅可答）进行实验，系统地分析了ELECTRA模型在不同设置下的表现，并与其他主流预训练语言模型（PrLMs）及代表性系统（如DAGN、FocalReasoner）进行对比。实验还考察了集成策略和预训练数据集（如RACE）对性能的提升，突出模型的泛化能力和不确定性度量在负分机制及无解检测中的作用。整体上，实验设计兼顾数据集变体、模型对比和训练策略，验证全面。"
      },
      {
        "paper_id": "ACL_2017_148",
        "title": "Evaluation Metrics for Reading Comprehension: Prerequisite Skills and Readability",
        "problem_framing": "论文引言通过强调自然语言处理（NLP）目标——让智能体理解自然语言——引入研究问题，并以阅读理解（RC）任务为测试手段，突出RC能力的复杂性和多步骤特性，凸显其研究价值和挑战性。",
        "gap_pattern": "作者批评当前RC数据集主要以表层类别（如问题类型）进行分类，忽视了对系统实际能力的细致刻画，指出仅用简单准确率衡量系统不足，强调需要更丰富的评测维度以推动RC系统发展。",
        "method_story": "方法部分采用逐一说明数据集选择与样本筛选过程，详细列举所用RC数据集（QA4MRE、MCTest、SQuAD）及其抽样策略，突出实验设计的代表性和覆盖性，为后续分析奠定基础。",
        "experiments_story": "实验部分以理论为依据，明确提出两大评价维度（前提技能与可读性），并结合前人工作细化技能分类，强调评价指标的科学性和系统性，展示实验设计的理论支撑和创新点。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "问题空白强调",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "作者指出现有阅读理解数据集几乎都只关注单一span答案，忽略了实际中常见的多span问题，强调了研究空白。",
            "type": "writing-level",
            "purpose": "突出当前领域的不足，为新工作合理性和必要性铺垫"
          }
        ]
      },
      {
        "trick_name": "数据集创新展示",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "作者详细介绍了MultiSpanQA数据集的构建过程和规模，强调其是首个高质量多span阅读理解数据集。",
            "type": "method-level",
            "purpose": "突出工作的创新性和独特贡献"
          }
        ]
      },
      {
        "trick_name": "多维度贡献总结",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "通过列举数据集、标签体系、模型和指标等多方面贡献，系统性地总结工作亮点。",
            "type": "writing-level",
            "purpose": "增强说服力，突出工作价值"
          }
        ]
      },
      {
        "trick_name": "现有方法梳理与不足分析",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "作者系统回顾了多span相关方法，指出它们在捕获全局信息、结构预测等方面的不足。",
            "type": "writing-level",
            "purpose": "为新方法的提出做铺垫，突出自身方法的针对性和改进空间"
          }
        ]
      },
      {
        "trick_name": "模块化方法设计",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "将模型分为编码器、序列标注器、span数预测器、结构预测器和调整模块等，清晰分解任务流程。",
            "type": "method-level",
            "purpose": "提升可解释性和方法扩展性，便于理解和复现"
          }
        ]
      },
      {
        "trick_name": "公式推导与逐步说明",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "通过逐步列出公式和模块输入输出，详细解释每一步的原理和实现方式。",
            "type": "method-level",
            "purpose": "增强方法的可解释性和技术细节透明度"
          }
        ]
      },
      {
        "trick_name": "多指标评估体系",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "采用精确匹配、部分匹配、F1、结构预测准确率等多种指标，全面评估模型性能。",
            "type": "experiment-level",
            "purpose": "证明实验设计的完备性和结果的可靠性"
          }
        ]
      },
      {
        "trick_name": "多种基线对比",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "与单span模型、序列标注模型等多种基线进行对比，展示新方法的性能提升。",
            "type": "experiment-level",
            "purpose": "突出自身方法的优势，增强说服力"
          }
        ]
      },
      {
        "trick_name": "分组难度分析",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "按答案类型和span数量分组报告结果，分析模型在不同类别上的表现和难点。",
            "type": "experiment-level",
            "purpose": "深入理解模型表现，证明实验分析的细致性"
          }
        ]
      },
      {
        "trick_name": "逻辑递进式叙事结构",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "从问题引入、现有方法梳理、创新方法提出、实验验证到结论呼应，层层递进组织全文。",
            "type": "writing-level",
            "purpose": "提升论文整体可读性和逻辑性，帮助读者顺畅理解"
          }
        ]
      },
      {
        "trick_name": "实验细节透明化",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "详细说明模型参数、训练过程、优化器设置等实验细节，便于他人复现。",
            "type": "experiment-level",
            "purpose": "增强实验可复现性和可信度"
          }
        ]
      },
      {
        "trick_name": "性能指标可视化与量化",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_130",
            "title": "MultiSpanQA: A Dataset for Multi-Span Question Answering",
            "description": "通过表格展示各模型在不同数据集和指标上的具体分数，突出新方法的性能优势。",
            "type": "experiment-level",
            "purpose": "直观展示方法效果，增强说服力"
          }
        ]
      },
      {
        "trick_name": "引用权威文献建立背景",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_330",
            "title": "Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension",
            "description": "通过大量引用MRC领域的权威文献和主流数据集、模型排行榜等，说明该领域的研究现状和进展，强调MRC系统的实际意义和挑战。",
            "type": "writing-level",
            "purpose": "增强说服力和权威性，使读者相信所述问题的重要性和研究的基础扎实"
          }
        ]
      },
      {
        "trick_name": "问题细分与概念区分",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_330",
            "title": "Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension",
            "description": "明确区分了answer uncertainty和unanswerability两个概念，并详细解释其差异和各自的实际意义。",
            "type": "writing-level",
            "purpose": "提升可解释性，帮助读者清晰理解研究对象和创新点"
          }
        ]
      },
      {
        "trick_name": "现实场景动机引入",
        "frequency": 1,
        "percentage": "11.1%",
        "examples": [
          {
            "paper_id": "ARR_2022_330",
            "title": "Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension",
            "description": "通过描述部署系统中负分机制和不确定性带来的风险，强调研究answer uncertainty和unanswerability的现实必要性。",
            "type": "writing-level",
            "purpose": "增强说服力，让研究问题与实际应用需求紧密结合"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 9,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ARR_2022_130",
        "ARR_2022_330",
        "ACL_2017_148",
        "ACL_2017_684",
        "ACL_2017_117",
        "ACL_2017_18",
        "ACL_2017_335",
        "COLING_2020_83",
        "COLING_2020_57"
      ]
    }
  },
  {
    "pattern_id": 34,
    "pattern_name": "神经网络多任务学习分词",
    "pattern_summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决中文分词任务中的多语料兼容性和标注成本问题，采用神经网络模型和多任务学习方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和文献综述开篇，常用tricks包括举例说明分歧、强调特征工程的最小化和文献综述引入研究背景。\n第3段（60字）：适用场景与预期效果 - 适用于需要处理多语料和大规模标注数据的中文分词任务，预期提升模型的泛化能力和标注效率。",
    "writing_guide": "写作模板：神经网络多任务学习分词\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决中文分词任务中的多语料兼容性和标注成本问题，采用神经网络模型和多任务学习方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和文献综述开篇，常用tricks包括举例说明分歧、强调特征工程的最小化和文献综述引入研究背景。\n第3段（60字）：适用场景与预期效果 - 适用于需要处理多语料和大规模标注数据的中文分词任务，预期提升模型的泛化能力和标注效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Adversarial Multi-Criteria Learning for Chinese Word Segmentation》\n  • 问题定位：论文通过强调中文分词在自然语言处理中的基础性和重要性，引入当前主流方法依赖大规模人工标注语料库的高成本问题，突出任务的现实意义和挑战性，为后续研究动机做铺垫。\n  • 现有研究缺口：作者指出已有分词语料库虽取得进展，但因分词标准不一致导致资源难以充分利用，批评现有方法在多语料兼容性上的不足，强调资源浪费和研究空白，明确提出需要更好利用多语料库的需求。\n  • 核心方法：方法部分采用由浅入深的叙述策略，先介绍分词任务的主流建模方式（序列标注），再列举传统与神经网络方法，突出神经网络在特征工程上的优势，并具体说明任务的标签体系和输入输出形式，逻辑清晰递进。\n  • 实验设计：实验部分详细说明参数设置和数据预处理策略，针对不同数据集规模调整批次大小，描述dropout和参数初始化方法，统一字符嵌入矩阵以保证跨语料一致性，并与前人工作对齐，突出实验设计的规范性和可复现性。\n\n示例 2：《Neural Word Segmentation with Rich Pretraining》\n  • 问题定位：论文通过回顾分词领域从统计方法到深度学习的研究转向，强调神经网络模型在特征组合和非稀疏表示上的优势，引出当前神经分词器已达到或超过传统方法的准确率，顺势引入自身工作的研究背景和意义。\n  • 现有研究缺口：作者指出，尽管神经分词器表现优异，但现有方法主要依赖字符嵌入以减少n-gram稀疏性，暗示当前模型在特征利用和结构设计上仍有改进空间，为后续提出新方法埋下伏笔。\n  • 核心方法：方法部分采用逐步递进的叙述策略，先整体描述分词器的增量式处理流程，再形式化定义状态和转移操作，结合图示说明，帮助读者直观理解模型的工作机制和创新点。\n  • 实验设计：实验部分详细说明数据集选择与分割，既遵循前人工作以保证可比性，又引入多样测试集验证模型鲁棒性，并具体描述预训练过程，突出实验设计的全面性和严谨性。\n\n示例 3：《None》\n  • 问题定位：论文通过强调词素切分在多个NLP任务中的核心作用引入研究问题，引用相关领域（如信息检索、语音识别、机器翻译）的文献，凸显该任务的基础性和广泛应用价值，增强问题的重要性和现实意义。\n  • 现有研究缺口：作者批评以往研究过度依赖正字法特征，忽视了语义信息，导致词语被过度切分。通过具体例子说明表层形式变化并不总能准确反映形态变化，从而指出现有方法的局限性和改进空间。\n  • 核心方法：方法部分采用对比叙述策略，首先介绍自身系统MORSE的性能评估方式，并明确与主流工具Morfessor的对比。通过多语言测试和数据集创新，突出方法的普适性和创新性，强调语义信息的引入。\n  • 实验设计：实验部分结构清晰，先进行本体性能评估，再跨三种形态复杂度不同的语言测试算法通用性，随后批判现有基准数据集并提出新数据集，最后通过特定词汇集比较语义信息对切分效果的影响，层层递进展示方法优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 引入研究背景和痛点（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过介绍中文分词任务的重要性、现有方法的局限（如高昂的标注语料成本和语料不兼容问题），有效引出研究动机和本文工作的意义。\n\n2. 举例说明分歧（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过具体句子“姚明进入总决赛”在不同语料库的切分结果，直观展示分词标准不统一的问题，增强问题的现实感。\n\n3. 文献综述与现有方法评述（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：简要回顾已有利用异构标注数据的方法，分析其采用的技术（如stacking或多任务架构）及存在的不足（如共享特征空间设计复杂），为后文提出新方法做铺垫。\n\n4. 问题形式化建模（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将中文分词任务形式化为基于字符的序列标注问题，明确每个字符的标签集合（B, M, E, S），并给出数学表达式，提升表达的科学性和严谨性。\n\n5. 通用神经网络架构分层描述（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将神经网络分为字符嵌入层、特征提取层和标签推断层三个部分，分别说明各层作用，使读者对整体架构有清晰把握。\n\n6. 采用先进模型结构（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用双向长短时记忆网络（Bi-LSTM）结合条件随机场（CRF）作为标签推断层，引用最新研究，说明所用架构为当前最优方法之一。\n\n7. 强调特征工程的最小化（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：指出神经网络能自动学习特征，减少人工特征工程工作，突出方法的实用性和先进性。\n\n8. 充分利用异构语料资源（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：提出利用多种分词标准的异构语料，通过多任务学习等方式，解决语料不兼容和资源浪费的问题。\n\n9. 文献综述引入研究背景（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过回顾统计方法到深度学习的研究转变，引用多个相关文献，突出当前深度学习在分词任务中的重要性和主流地位。\n\n10. 强调神经网络的非稀疏表示能力（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：强调神经网络在表示学习和特征组合上的非稀疏性和非线性能力，为后文介绍embedding和网络结构做理论基础。\n",
    "skeleton_examples": [
      {
        "paper_id": "ACL_2017_326",
        "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
        "problem_framing": "论文通过强调中文分词在自然语言处理中的基础性和重要性，引入当前主流方法依赖大规模人工标注语料库的高成本问题，突出任务的现实意义和挑战性，为后续研究动机做铺垫。",
        "gap_pattern": "作者指出已有分词语料库虽取得进展，但因分词标准不一致导致资源难以充分利用，批评现有方法在多语料兼容性上的不足，强调资源浪费和研究空白，明确提出需要更好利用多语料库的需求。",
        "method_story": "方法部分采用由浅入深的叙述策略，先介绍分词任务的主流建模方式（序列标注），再列举传统与神经网络方法，突出神经网络在特征工程上的优势，并具体说明任务的标签体系和输入输出形式，逻辑清晰递进。",
        "experiments_story": "实验部分详细说明参数设置和数据预处理策略，针对不同数据集规模调整批次大小，描述dropout和参数初始化方法，统一字符嵌入矩阵以保证跨语料一致性，并与前人工作对齐，突出实验设计的规范性和可复现性。"
      },
      {
        "paper_id": "ACL_2017_343",
        "title": "Neural Word Segmentation with Rich Pretraining",
        "problem_framing": "论文通过回顾分词领域从统计方法到深度学习的研究转向，强调神经网络模型在特征组合和非稀疏表示上的优势，引出当前神经分词器已达到或超过传统方法的准确率，顺势引入自身工作的研究背景和意义。",
        "gap_pattern": "作者指出，尽管神经分词器表现优异，但现有方法主要依赖字符嵌入以减少n-gram稀疏性，暗示当前模型在特征利用和结构设计上仍有改进空间，为后续提出新方法埋下伏笔。",
        "method_story": "方法部分采用逐步递进的叙述策略，先整体描述分词器的增量式处理流程，再形式化定义状态和转移操作，结合图示说明，帮助读者直观理解模型的工作机制和创新点。",
        "experiments_story": "实验部分详细说明数据集选择与分割，既遵循前人工作以保证可比性，又引入多样测试集验证模型鲁棒性，并具体描述预训练过程，突出实验设计的全面性和严谨性。"
      },
      {
        "paper_id": "ACL_2017_723",
        "title": null,
        "problem_framing": "论文通过强调词素切分在多个NLP任务中的核心作用引入研究问题，引用相关领域（如信息检索、语音识别、机器翻译）的文献，凸显该任务的基础性和广泛应用价值，增强问题的重要性和现实意义。",
        "gap_pattern": "作者批评以往研究过度依赖正字法特征，忽视了语义信息，导致词语被过度切分。通过具体例子说明表层形式变化并不总能准确反映形态变化，从而指出现有方法的局限性和改进空间。",
        "method_story": "方法部分采用对比叙述策略，首先介绍自身系统MORSE的性能评估方式，并明确与主流工具Morfessor的对比。通过多语言测试和数据集创新，突出方法的普适性和创新性，强调语义信息的引入。",
        "experiments_story": "实验部分结构清晰，先进行本体性能评估，再跨三种形态复杂度不同的语言测试算法通用性，随后批判现有基准数据集并提出新数据集，最后通过特定词汇集比较语义信息对切分效果的影响，层层递进展示方法优势。"
      }
    ],
    "common_tricks": [
      {
        "trick_name": "引入研究背景和痛点",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "通过介绍中文分词任务的重要性、现有方法的局限（如高昂的标注语料成本和语料不兼容问题），有效引出研究动机和本文工作的意义。",
            "type": "writing-level",
            "purpose": "突出研究的必要性和前沿性"
          }
        ]
      },
      {
        "trick_name": "举例说明分歧",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "通过具体句子“姚明进入总决赛”在不同语料库的切分结果，直观展示分词标准不统一的问题，增强问题的现实感。",
            "type": "writing-level",
            "purpose": "具体化问题，增强说服力"
          }
        ]
      },
      {
        "trick_name": "文献综述与现有方法评述",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "简要回顾已有利用异构标注数据的方法，分析其采用的技术（如stacking或多任务架构）及存在的不足（如共享特征空间设计复杂），为后文提出新方法做铺垫。",
            "type": "writing-level",
            "purpose": "展示对领域现状的把握，突出创新点"
          }
        ]
      },
      {
        "trick_name": "问题形式化建模",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "将中文分词任务形式化为基于字符的序列标注问题，明确每个字符的标签集合（B, M, E, S），并给出数学表达式，提升表达的科学性和严谨性。",
            "type": "method-level",
            "purpose": "清晰定义任务，便于后续方法展开"
          }
        ]
      },
      {
        "trick_name": "通用神经网络架构分层描述",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "将神经网络分为字符嵌入层、特征提取层和标签推断层三个部分，分别说明各层作用，使读者对整体架构有清晰把握。",
            "type": "method-level",
            "purpose": "结构化展示方法，便于理解和复现"
          }
        ]
      },
      {
        "trick_name": "采用先进模型结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "采用双向长短时记忆网络（Bi-LSTM）结合条件随机场（CRF）作为标签推断层，引用最新研究，说明所用架构为当前最优方法之一。",
            "type": "method-level",
            "purpose": "提升模型性能，体现技术前沿性"
          }
        ]
      },
      {
        "trick_name": "强调特征工程的最小化",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "指出神经网络能自动学习特征，减少人工特征工程工作，突出方法的实用性和先进性。",
            "type": "writing-level",
            "purpose": "突出神经网络方法的优势"
          }
        ]
      },
      {
        "trick_name": "充分利用异构语料资源",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_326",
            "title": "Adversarial Multi-Criteria Learning for Chinese Word Segmentation",
            "description": "提出利用多种分词标准的异构语料，通过多任务学习等方式，解决语料不兼容和资源浪费的问题。",
            "type": "method-level",
            "purpose": "提升模型泛化能力和资源利用率"
          }
        ]
      },
      {
        "trick_name": "文献综述引入研究背景",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "通过回顾统计方法到深度学习的研究转变，引用多个相关文献，突出当前深度学习在分词任务中的重要性和主流地位。",
            "type": "writing-level",
            "purpose": "展示研究趋势和现有成果，为自己的方法定位"
          }
        ]
      },
      {
        "trick_name": "强调神经网络的非稀疏表示能力",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "强调神经网络在表示学习和特征组合上的非稀疏性和非线性能力，为后文介绍embedding和网络结构做理论基础。",
            "type": "writing-level",
            "purpose": "突出神经网络模型的优势，为后续方法设计做铺垫"
          }
        ]
      },
      {
        "trick_name": "使用实例说明embedding优势",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "举例说明embedding如何将不同但结构相似的短语联系起来，展示其减少稀疏性的实际效果。",
            "type": "writing-level",
            "purpose": "通过具体例子让技术细节更易理解"
          }
        ]
      },
      {
        "trick_name": "分层描述神经网络结构",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "将模型划分为表示层、评分层等多个层次，分别解释每一层的输入输出和作用，帮助读者系统把握模型设计。",
            "type": "method-level",
            "purpose": "清晰表达模型结构，便于理解和复现"
          }
        ]
      },
      {
        "trick_name": "状态转移系统形式化建模",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "将分词描述为状态转移过程，每个状态由已识别词序列、当前词、未处理字符组成，定义明确的转移动作（APP/SEP），便于模型设计和推理。",
            "type": "method-level",
            "purpose": "将分词过程形式化，便于算法实现和理论分析"
          }
        ]
      },
      {
        "trick_name": "借鉴并对比已有方法",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "明确指出与已有工作（如Zhang et al., Cai and Zhao等）的相同和不同之处，突出自身模型在结构或评分方式上的差异和创新。",
            "type": "writing-level",
            "purpose": "突出自身方法的创新点和进步"
          }
        ]
      },
      {
        "trick_name": "全局结构评分策略",
        "frequency": 1,
        "percentage": "20.0%",
        "examples": [
          {
            "paper_id": "ACL_2017_343",
            "title": "Neural Word Segmentation with Rich Pretraining",
            "description": "采用全局结构模型，对整个状态序列进行评分，整体优化分词序列，提升歧义消解能力。",
            "type": "method-level",
            "purpose": "提升分词准确性，避免局部最优"
          }
        ]
      }
    ],
    "metadata": {
      "cluster_size": 5,
      "coherence_score": 0.75,
      "all_paper_ids": [
        "ACL_2017_326",
        "ACL_2017_343",
        "ACL_2017_723",
        "COLING_2020_8",
        "COLING_2020_79"
      ]
    }
  }
]