[
  {
    "pattern_id": "pattern_1",
    "name": "语言分布特性训练策略",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决词义消歧和语义表示问题，采用基于语言分布特性的训练策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过数据分布分析指出问题，引入理论依据并明确创新点，多采用对比实验和消融分析验证方法效果。\n第3段（60字）：适用场景与预期效果 - 适用于词义消歧、语义表示和多词表达建模任务，预期提升模型在稀有和零样本词义上的性能，增强泛化能力。",
    "writing_guide": "写作模板：语言分布特性训练策略\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决词义消歧和语义表示问题，采用基于语言分布特性的训练策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过数据分布分析指出问题，引入理论依据并明确创新点，多采用对比实验和消融分析验证方法效果。\n第3段（60字）：适用场景与预期效果 - 适用于词义消歧、语义表示和多词表达建模任务，预期提升模型在稀有和零样本词义上的性能，增强泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Rare and Zero-shot Word Sense Disambiguation using Z-Reweighting》\n  • 问题定位：论文首先从自然语言处理领域的长期难题——词义消歧（WSD）任务切入，强调其对机器翻译、信息检索等下游应用的重要性（从应用需求出发）。通过举例说明词义消歧的实际困难，进一步指出常见语义与罕见语义在数据分布上的极度不平衡，进而引出稀有和零样本词义的挑战（结合实际痛点和数据分布问题）。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法局限于...’的逻辑。\n  • 核心方法：方法部分采用‘先整体后对比’的叙述策略。首先说明方法的核心思想（Z-reweighting策略），随后对比不同主干模型（Bert-base与Bert-large）在该策略下的表现。\n  • 实验设计：实验部分采用‘主实验+细粒度分析+消融与参数影响’的叙述策略。首先介绍数据集和评测指标，然后展示不同训练策略下的整体性能对比（主实验）。接着，细致分析了方法在最常见语义（MCS）、最少见语义（LCS）和零样本语义上的提升效果（细粒度分组分析）。\n\n示例 2：《Using Ontology-Grounded Token Embeddings To Predict Prepositional Phrase Attachments》\n  • 问题定位：论文通过定义type-level word embeddings及其在下游任务中的泛化能力，引入了词类型与词实例的区分，结合具体例子（如‘pool’）说明现有模型的局限，为后续研究设定了明确的背景和动机。\n  • 现有研究缺口：作者指出大多数词向量模型仅为每个词类型定义单一向量，忽视了同一词在不同上下文中的多样语义，暗示现有方法在处理词义歧义和上下文相关性方面存在不足，明确了研究的创新空间。\n  • 核心方法：方法部分采用‘先总后分’策略，先整体描述模型结构（bi-LSTM编码序列），再细致阐述候选头词的打分流程、损失函数和预测方式，逻辑清晰，便于读者理解模型设计与实现细节。\n  • 实验设计：实验部分先介绍数据集来源、规模及分割，强调数据集的现实性和挑战性，并通过与经典数据集的对比突出所选数据集的优势，随后详细说明输入结构和任务设置，确保实验设计的合理性与可复现性。\n\n示例 3：《How to evaluate word embeddings? On importance of data efficiency and simple supervised tasks》\n  • 问题定位：论文通过回顾词向量在NLP中的核心地位和广泛应用，引出其在实际任务迁移中的重要性。作者以引用权威文献的方式，强调词表示学习对领域进步的推动作用，设定了研究的现实背景和理论基础。\n  • 现有研究缺口：作者指出当前领域的主要不足在于缺乏系统、原则性的评估方法，这阻碍了词向量研究的进一步发展。同时，训练和调优词向量面临多重挑战，现有评测手段难以有效指导模型选择，明确提出了研究的gap。\n  • 核心方法：方法部分采用分类叙述策略，系统地将评测数据集分为四类，详细说明每类数据的构成和来源。通过枚举具体数据集，展示方法的全面性和实验设计的严谨性，为后续实验奠定基础。\n  • 实验设计：实验部分以问题驱动的方式展开，围绕三个核心科学问题组织实验设计。每个问题都对应具体的评测指标和分析目标，强调实验对方法有效性的实证验证，逻辑清晰地串联起研究假设与实验结果。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 实际应用场景举例（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：通过举例说明WSD在机器翻译和信息检索等下游任务中的作用，强调该问题的广泛影响\n\n2. 数据分布分析（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：分析SemCor语料的常见/稀有/零样本词义分布，强调训练样本不均衡的问题\n\n3. 现有方法归纳与不足（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：总结前人方法（数据集设计、外部知识引入）并指出其局限，为新方法做铺垫\n\n4. 理论依据引入（使用频率 1 次，占比 5.3%）\n   类型：method-level\n   应用：引用Zipf定律及相关语言学理论，解释词频与词义多样性的关系，为方法设计提供理论支撑\n\n5. 创新点明确声明（使用频率 1 次，占比 5.3%）\n   类型：writing-level\n   应用：明确指出首次利用语言分布规律解决WSD训练偏差，强调方法的独特性\n\n6. 方法原理分步解释（使用频率 1 次，占比 5.3%）\n   类型：method-level\n   应用：分步介绍从语料统计、数学拟合到训练权重分配的过程，层层递进解释方法设计\n\n7. 参数设置透明化（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：详细说明模型初始化、参数选择和训练设置，便于他人复现\n\n8. 多策略对比实验（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：同时对比B-reweighting、Z-reweighting、B-resampling等多种训练策略，展示各自效果\n\n9. 主干模型消融分析（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：比较Bert-base与Bert-large作为主干模型的表现，结合效率选择最终模型\n\n10. 分组细粒度结果分析（使用频率 1 次，占比 5.3%）\n   类型：experiment-level\n   应用：分别分析常见词义（MCS）、稀有词义（LCS）和零样本词义的性能提升\n",
    "cluster_size": 19,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_246",
      "ACL_2017_691",
      "ACL_2017_239",
      "ACL_2017_768",
      "ACL_2017_553",
      "ACL_2017_477",
      "ACL_2017_178",
      "ACL_2017_145",
      "ACL_2017_563",
      "ACL_2017_395",
      "ACL_2017_56",
      "ACL_2017_318",
      "ACL_2017_201",
      "ACL_2017_494",
      "ACL_2017_251",
      "ACL_2017_173",
      "COLING_2020_45",
      "COLING_2020_60",
      "COLING_2020_71"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "实际应用场景举例",
        "frequency": 1,
        "percentage": "5.3%"
      },
      {
        "name": "数据分布分析",
        "frequency": 1,
        "percentage": "5.3%"
      },
      {
        "name": "现有方法归纳与不足",
        "frequency": 1,
        "percentage": "5.3%"
      },
      {
        "name": "理论依据引入",
        "frequency": 1,
        "percentage": "5.3%"
      },
      {
        "name": "创新点明确声明",
        "frequency": 1,
        "percentage": "5.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_2",
    "name": "跨领域泛化模块化方法",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨领域泛化和复杂结构理解问题，采用新数据集设计和模块化方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过现有方法不足对比引出问题，方法部分采用模块化设计和多数据集验证。\n第3段（60字）：适用场景与预期效果 - 适用于表格解析、数学题理解等复杂结构任务，预期提升泛化能力和模型鲁棒性。",
    "writing_guide": "写作模板：跨领域泛化模块化方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨领域泛化和复杂结构理解问题，采用新数据集设计和模块化方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用需求出发，通过现有方法不足对比引出问题，方法部分采用模块化设计和多数据集验证。\n第3段（60字）：适用场景与预期效果 - 适用于表格解析、数学题理解等复杂结构任务，预期提升泛化能力和模型鲁棒性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Bridging the Generalization Gap in Text-to-SQL Parsing with Schema Expansion》\n  • 问题定位：论文从实际应用需求出发引出问题，指出在真实场景中用户需要对大表格进行查询以提升生产力，但现有的 text-to-SQL 解析器在遇到未见过的新领域表格时泛化能力很差。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，具体指出虽然最新的神经语义解析器在大规模数据集上表现良好，但在 out-of-domain（跨领域）泛化方面远未成功。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先明确提出要构建具备跨领域泛化能力的评测基准（包括合成数据集和 SQUALL 数据集的新划分），然后提出一种简单但有效的基线方法，作为未来工作的参考点。\n  • 实验设计：实验部分采用‘多数据集验证+多配置对比’的叙述策略。首先在两个新提出的基准（合成数据集和 SQUALL 新划分）以及原有 SQUALL 基准上进行实验，覆盖不同领域。每个实验均采用交叉领域（train/test 不同领域）和 i.i.d.（同分布）两种划分。\n\n示例 2：《Text-to-Table: A New Way of Information Extraction》\n  • 问题定位：论文首先从信息抽取（IE）这一广泛应用的任务切入，强调其在结构化数据提取和下游应用（如文本挖掘）中的重要性。随后，作者提出了一个新的设置——text-to-table，指出其与传统IE的不同之处，特别是在能够从长文本中提取复杂结构化数据、无需显式定义schema等方面。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先，系统梳理了NER、RE、EE等主流IE方法，指出它们均依赖预定义schema且多针对短文本，难以直接应用于text-to-table任务。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述顺序。首先，简要介绍整体思路——基于seq2seq模型实现text-to-table，并支持多表输出。\n  • 实验设计：实验部分采用‘主实验+多数据集验证+对比分析’的策略。首先，在Rotowire数据集上与doc-level RE、sent-level RE等基线方法进行主实验对比，突出自身方法的优势。其次，在E2E、WikiTableText、WikiBio等多个数据集上进一步验证方法的通用性和有效性。\n\n示例 3：《Turning Tables: Generating Examples from Semi-structured Tables for Endowing Language Models with Reasoning Skills》\n  • 问题定位：论文从学术gap出发引出问题，首先指出大规模预训练语言模型已成为自然语言处理的核心，但在符号推理（如事实组合、数值运算、量化等）方面表现不足，且需要大量额外数据才能提升相关能力。通过引用前人工作，强调当前模型在推理任务上的局限性，明确提出需要新的数据生成和训练方法以提升模型的推理能力。\n  • 现有研究缺口：论文批评现有方法时采用了对比和归类的逻辑，指出过去的工作主要有两类：一类是为特定推理技能添加专用组件，另一类是大规模合成数据生成。作者强调这些方法要么针对性强、扩展性有限，要么数据生成方式受限，未能充分利用结构化资源。\n  • 核心方法：方法部分采用先整体后局部的叙述策略，首先介绍整体思路：利用半结构化表格自动生成多种推理类型的阅读理解训练数据。随后详细说明数据生成流程，包括表格爬取、16种推理技能的模板化生成器、自动填充变量和答案计算、上下文构造等。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略，首先在下游阅读理解数据集上进行主实验，验证方法的有效性。随后在合成数据上进行补充实验，分析模型在生成数据上的表现。实验设计突出对比不同采样策略和模型规模，并说明数据集去重处理，保证实验公正性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 指标多样化（使用频率 2 次，占比 25.0%）\n   类型：experiment-level\n   应用：采用Execution Accuracy、Spurious Program Rate等多种指标，全面衡量模型性能和鲁棒性。\n\n2. 现有方法局限性批判（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者指出现有预训练目标忽视数值关系，合成SQL/问题仅适用于数据库表，难以保证真实性\n\n3. 现实场景动机引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过描述真实用户在处理大型表格时遇到的挑战，引出研究问题并强调其实际意义。\n\n4. 现有方法不足对比（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：引用最新文献指出当前SOTA方法在跨领域泛化上的不足，为提出新方法做铺垫。\n\n5. 问题分解与细化（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：将泛化难题细分为列匹配和列操作两大类，分别举例说明具体挑战。\n\n6. 新基准数据集设计（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：提出两个新的评测基准（合成数据集和SQUALL重划分），专门用于量化列操作的跨域泛化能力。\n\n7. 方法简化与模块化（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：将方法拆分为schema expansion和schema pruning两个独立模块，可与任意现有parser结合。\n\n8. 直观类比与实例说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过具体例子（如“Income”映射到不同表的不同列组合）和图示，帮助读者把握抽象操作的实际含义。\n\n9. 现实约束假设说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：说明schema expansion基于列类型假设，强调方法对新领域的适用性和可扩展性。\n\n10. 实验对比分组设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：设计四种配置（Base, Base+P, Base+E, Base+P+E）系统性对比，清晰展示各模块贡献。\n",
    "cluster_size": 8,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_52",
      "ARR_2022_138",
      "ARR_2022_87",
      "ARR_2022_221",
      "ARR_2022_293",
      "ARR_2022_62",
      "ARR_2022_119",
      "ARR_2022_292"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "指标多样化",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "现有方法局限性批判",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "现实场景动机引入",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "现有方法不足对比",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "问题分解与细化",
        "frequency": 1,
        "percentage": "12.5%"
      }
    ]
  },
  {
    "pattern_id": "pattern_3",
    "name": "多语言验证+统计显著性检验",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨语言模型在特定语言学理论上的表现，通过对比实验和多语言验证展示模型能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，采用'多语言验证+统计显著性检验'，常用tricks包括理论对比、心理语言学证据铺垫和消除表层词汇偏差。\n第3段（60字）：适用场景与预期效果 - 适用于评估语言模型在复杂语言现象上的表现，预期提升模型的跨语言泛化能力和理论解释力。",
    "writing_guide": "写作模板：多语言验证+统计显著性检验\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨语言模型在特定语言学理论上的表现，通过对比实验和多语言验证展示模型能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，采用'多语言验证+统计显著性检验'，常用tricks包括理论对比、心理语言学证据铺垫和消除表层词汇偏差。\n第3段（60字）：适用场景与预期效果 - 适用于评估语言模型在复杂语言现象上的表现，预期提升模型的跨语言泛化能力和理论解释力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Neural reality of argument structure constructions》\n  • 问题定位：论文通过回顾预训练Transformer语言模型（如BERT和RoBERTa）在自然语言任务上的成功，引出了一个新的跨学科研究领域：将语言模型与语言学理论对齐，并探究其语言能力。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法忽视了X'的逻辑。具体指出：大多数探究工作假设生成语法框架，关注句子的语言可接受性，较少从建构语法出发，关注多词构式及其交互。此外，现有方法未充分探究语言模型对论元结构构式（ASC）的神经表征，忽略了建构语法在心理语言学中的实证基础。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍了所用模型（MiniBERTa、RoBERTa、mBERT及各语言单语模型），并说明不同模型用于模拟不同语言能力水平。随后详细描述了刺激句子的生成流程，包括模板设计、随机填充以及多轮采样，确保实验样本充足。\n  • 实验设计：实验部分采用主实验+多语言验证的策略。首先在英语数据上进行主实验，分析不同预训练数据量下模型对构式与动词排序的偏好，并与人类实验结果对比。随后在德语、意大利语和西班牙语进行多语言实验，验证结论的跨语言适用性。\n\n示例 2：《Learning the Ordering of Coordinate Compounds and Elaborate Expressions in Hmong, Lahu, and Chinese》\n  • 问题定位：论文通过介绍东亚和东南亚语言中广泛存在的无显性连接词的并列结构（coordinate compounds, CCs 和 elaborate expressions, EEs），以丰富的实例说明该现象的普遍性和重要性，进而引出对其构成顺序预测的科学问题。\n  • 现有研究缺口：论文批评现有方法时，首先指出早期研究多基于音系特征（如元音质量、声调）提出顺序预测规则，但这些规则难以用语音学原理合理解释，且与主流语言学理论（如形态句法优先于音系，音系应以语音学为基础）相悖。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略，首先提出研究目标——探究（计算）学习者需要什么数据才能习得这些顺序规律，随后介绍使用的机器学习模型（如决策树），并说明仅用音系特征即可高准确率预测顺序。方法介绍简明，突出核心变量和模型，未分模块细化，强调实验设计的简洁性和针对性。\n  • 实验设计：实验部分采用了‘多数据集验证’的策略，分别在Hmong和Lahu两种语言上进行主实验，报告了模型在不同语言上的预测准确率（96%和79%）。实验叙述聚焦于主实验结果，突出模型的有效性，未涉及消融或可视化等辅助实验，强调跨语言的泛化能力和方法的实用性。\n\n示例 3：《Discontinuous Constituency and BERT: A Case Study of Dutch》\n  • 问题定位：论文从学术gap出发引出问题。开篇先回顾了BERT及其变体在语言学理论自动获取方面的突出表现，并指出主流做法是通过浅层探针模型检测BERT内部编码的语言学信息。接着，作者指出当前探针研究主要集中在英语，这种语言本身语法结构较简单，接近上下文无关语言，因此不能代表其他语言的复杂性。\n  • 现有研究缺口：论文批评现有方法的逻辑为：现有探针研究过度依赖英语，忽视了英语语法的简单性和上下文无关性，导致对BERT语法能力的结论不能泛化到其他更复杂的语言。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了探针模型的输入输出流程，即如何从BERT的上下文表示中聚合动词和名词短语，再通过交叉注意力机制建立动词-名词映射。随后详细分步介绍了每个模块：短语聚合、注意力分数计算、低维映射、点积注意力、最终的主语选择机制。\n  • 实验设计：实验部分采用‘多阶段+多数据集验证’的策略。首先描述了如何自动筛选和标注真实语料，构建自然数据集用于训练探针。然后详细介绍了如何基于形式语法生成人工数据，测试模型在不同复杂度和生成参数下的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 创新点突出（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者明确指出以往的音系排序难以用语音学解释，并提出要用计算学习方法探究这些模式的可习得性，突出研究创新。\n\n2. 理论对比引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过对比生成语法和构式语法在动词论元结构分析上的分歧，引出构式语法视角下探测语言模型的研究空白。\n\n3. 心理语言学证据铺垫（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：引用大量心理语言学实验（如句子分类、启动、虚构动词实验）证明构式语法理论的心理现实性，为后续神经网络探针实验提供理论支撑。\n\n4. 跨语言实验设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：在多种语言（英语、德语、意大利语、西班牙语）上复现实验，展示方法的普适性和稳健性。\n\n5. 模型规模与人类能力类比（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：通过不同规模的语言模型和不同熟练度的非母语者对比，类比人类语言习得过程，说明模型能力与数据量的关系。\n\n6. 消除表层词汇偏差（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：采用模板填充和随机词生成（Jabberwocky句子），避免模型依赖表层词汇，确保测试的是结构性知识而非词汇记忆。\n\n7. 与经典实验对齐（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：将神经网络实验设计与Bencini and Goldberg (2000)等经典心理语言学实验对齐，便于读者理解实验逻辑和创新点。\n\n8. 聚类与距离度量（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：采用聚类和欧氏距离等直观的量化指标，明确展示模型内部嵌入对构式与动词的区分能力。\n\n9. 统计显著性检验（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：对主要实验结果进行统计显著性检验（如p < .001），确保观察到的效果非偶然。\n\n10. 实验局限性讨论（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：主动讨论实验设计和数据来源的局限性，警示读者对结论的适用范围，避免过度解读。\n",
    "cluster_size": 8,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_161",
      "ARR_2022_224",
      "ARR_2022_164",
      "ACL_2017_524",
      "ACL_2017_193",
      "COLING_2020_66",
      "COLING_2020_37",
      "COLING_2020_29"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "创新点突出",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "理论对比引入",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "心理语言学证据铺垫",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "跨语言实验设计",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "模型规模与人类能力类比",
        "frequency": 1,
        "percentage": "12.5%"
      }
    ]
  },
  {
    "pattern_id": "pattern_4",
    "name": "多基线对比与多数据集验证",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决NLP领域数据集和基准不足的问题，采用多基线对比和多数据集验证的技术路线。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从现状梳理开篇，通过贡献清单式总结突出创新点，方法部分采用任务三元组框架化和数据集质量标准化，实验设计强调分步逻辑结构安排和数据集公开复现性。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要构建高质量数据集和基准的NLP任务，预期提升模型的公平性、泛化能力和实验结果的可信度。",
    "writing_guide": "写作模板：多基线对比与多数据集验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决NLP领域数据集和基准不足的问题，采用多基线对比和多数据集验证的技术路线。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从现状梳理开篇，通过贡献清单式总结突出创新点，方法部分采用任务三元组框架化和数据集质量标准化，实验设计强调分步逻辑结构安排和数据集公开复现性。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要构建高质量数据集和基准的NLP任务，预期提升模型的公平性、泛化能力和实验结果的可信度。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《MUKAYESE: Turkish NLP Strikes Back》\n  • 问题定位：论文从学术gap出发引出问题，指出虽然土耳其语并非资源稀缺语言，但由于研究社区规模小，缺乏有组织的基准和基线，导致其在NLP领域落后。\n  • 现有研究缺口：论文通过对现有工作的批评，强调了缺乏有组织的基准和基线是土耳其语NLP发展缓慢的主要原因。采用了‘缺失/不足’的批评逻辑，如‘我们观察到缺乏有组织的基准和研究’、‘缺乏基准会导致研究落后于NLP领域的最前沿’等句式，突出当前方法的局限和不足。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略。首先，整体定义了基准的三要素（数据集、评测、基线），并逐一详细解释每个要素的构建标准和注意事项。随后，针对具体任务（如语言建模），分模块介绍了数据集的构建、评价指标的选择和基线模型的设置。\n  • 实验设计：实验部分（根据方法和引言的描述）采用了多数据集验证和多基线对比的策略。每个任务至少包含两个基线模型，并在新构建和现有的多个数据集上进行评测，确保结果的全面性和可复现性。实验内容涵盖了数据集统计、评测细节、基线方法效果等，强调了系统性和公平性，突出新基准和方法在土耳其语NLP任务上的有效性。\n\n示例 2：《Systematicity, Compositionality and Transitivity of Deep NLP Models: a Metamorphic Testing Perspective》\n  • 问题定位：论文从学术gap出发引出问题。首先指出NLP领域近年来的进步主要得益于无标注数据的利用，强调了这种方法在训练阶段带来的优势和趋势。随后，作者对比了训练和测试阶段，指出当前NLP模型的测试极度依赖于有标注的groundtruth数据，这种依赖限制了测试用例的数量和质量。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法过度关注单一行为类型’的逻辑。具体来说，作者指出大多数已提出的元变关系都集中在鲁棒性（robustness）上，即模型输出在输入微小扰动下应保持稳定。\n  • 核心方法：由于未提供方法部分内容，无法详细分析其具体叙述策略。但从引言推断，方法部分可能会先整体介绍元变测试的基本思想和适用范围，然后针对鲁棒性以外的语言属性提出新的元变关系，可能采用分模块介绍或从简单到复杂的顺序，逐步展开对不同类型元变关系的定义与实现。\n  • 实验设计：由于未提供实验部分内容，无法具体分析实验叙述策略。从引言内容推测，实验部分可能包括对不同类型元变关系的实证验证，涵盖主实验（验证新提出的元变关系对模型测试的有效性），并可能涉及多任务或多数据集的对比实验，以展示新方法的广泛适用性和优越性。\n\n示例 3：《Dataset Geography: Mapping Language Data to Language Users》\n  • 问题定位：论文首先从学术领域的痛点和现实需求出发，指出NLP研究在语言、类型和地理多样性上的缺失已被广泛认可和记录。接着，作者强调多语言模型的出现为服务弱势语言用户带来了希望，但要实现覆盖全球近7000种语言的目标极具挑战。\n  • 现有研究缺口：论文批评现有工作的逻辑主要有两方面：一是现有研究虽然关注了数据可用性、模型公平性和系统效用等，但‘缺乏评估数据集代表性的方法’，即现有方法未能判断数据是否真实反映目标语言用户；二是相关工作中，现有多语言模型和数据集在跨语言一致性、数据偏见等方面存在明显不足，且资源分布极不均衡。\n  • 核心方法：方法部分采用‘先定义核心概念，再提出具体方法，最后报告实验细节’的顺序。首先界定了‘跨语言一致性’的具体含义，针对实体相关任务提出了适用的定义。随后介绍了如何利用平行语料、自动标注和词级对齐工具，计算跨语言一致性指标。整体上，方法叙述由概念定义到具体实现，层层递进，兼顾理论和实践。\n  • 实验设计：实验部分采用‘模型对比+多语言验证+定量分析+人工分析’的策略。先介绍了对比的两类模型（SpaCy单语模型和mBERT多语模型），再说明训练和评测流程，覆盖多种语言（希腊语、意大利语、中文、英语）。实验内容包括主实验（跨语言一致性评测）、不同模型对比、标签类型分析，并补充了人工误差分析。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题设定与现状梳理（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过引用权威文献和指出土耳其语NLP领域缺乏组织化基准和研究，强调研究空白和实际需求。\n\n2. 贡献清单式总结（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：用条目式列出工作贡献，包括数据集、基准、分割方式、基线和方法等，突出创新和系统性。\n\n3. 任务三元组框架化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将每个基准任务分为数据集、评估、基线三要素，系统阐述方法构建流程。\n\n4. 数据集质量与规模标准化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：详细说明数据集的规模、质量、可访问性等标准，强调手工标注一致性和领域泛化能力。\n\n5. 评价指标合理性分析（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：针对每个任务讨论评价指标的合理性、与人类判断的相关性及潜在问题，提升评估科学性。\n\n6. 多样化基线设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：为每个任务设置至少两个不同类型的基线，包括预训练与非预训练、规则与训练、监督与非监督等多种方法。\n\n7. 与现有数据集和方法对齐（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：新数据集设计参考英文主流数据集（如WikiText），并与已有方法结果进行对比。\n\n8. 分步逻辑结构安排（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：明确说明论文结构安排，逐步引入背景、方法、数据、实验和结论，形成环环相扣的逻辑流。\n\n9. 数据集公开与复现性强调（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：公开数据集原始和处理版本，强调可复现性和公平性（如数据集分割），增加研究透明度。\n\n10. 案例分析与领域泛化说明（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：通过具体案例（如句子分割在社交媒体与编辑文本的差异）说明方法泛化能力和局限性。\n",
    "cluster_size": 6,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_329",
      "ARR_2022_103",
      "ARR_2022_259",
      "ARR_2022_46",
      "ACL_2017_382",
      "COLING_2020_64"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "问题设定与现状梳理",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "贡献清单式总结",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "任务三元组框架化",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "数据集质量与规模标准化",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "评价指标合理性分析",
        "frequency": 1,
        "percentage": "16.7%"
      }
    ]
  },
  {
    "pattern_id": "pattern_5",
    "name": "分层多任务迁移学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决大规模预训练语言模型在数据稀缺和迁移学习中的不足，采用分层结构和多任务迁移方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点和学术gap开篇，通过引用主流模型和竞赛结果建立背景，多采用分层结构和多数据集验证，结合自动和人工评测增强说服力。\n第3段（60字）：适用场景与预期效果 - 适用于文本生成、迁移学习和零样本任务，预期提升模型在低资源条件下的性能和泛化能力。",
    "writing_guide": "写作模板：分层多任务迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决大规模预训练语言模型在数据稀缺和迁移学习中的不足，采用分层结构和多任务迁移方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点和学术gap开篇，通过引用主流模型和竞赛结果建立背景，多采用分层结构和多数据集验证，结合自动和人工评测增强说服力。\n第3段（60字）：适用场景与预期效果 - 适用于文本生成、迁移学习和零样本任务，预期提升模型在低资源条件下的性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Hierarchical Recurrent Aggregative Generation for Few-Shot NLG》\n  • 问题定位：论文通过介绍大规模预训练语言模型（PLMs）在自然语言生成（NLG）领域带来的研究兴趣转变，引出当前在概念到文本生成任务中的挑战。开篇首先强调了PLMs在领域适应和迁移学习中的重要性，并指出在数据稀缺（few-shot/zero-shot）场景下，迁移学习成为主流且有效的方案。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在低资源/小样本场景下研究不足’和‘现有方法依赖人工模板或领域特定资源，成本高且泛化性差’的逻辑。具体通过引用相关工作，指出前人方法要么依赖合成数据、人工模板，或是未能充分利用迁移学习在不同子任务上的潜力，尤其是在词汇化和聚合阶段的迁移能力差异未被深入探讨。\n  • 核心方法：方法部分采用分模块介绍的策略，先整体描述提出的分层模型HRAG的架构与设计理念，再细致分解为三个模块：词汇化、聚合和后编辑。每个模块对应传统NLG流程中的关键阶段，并结合其在迁移学习中的潜力进行阐述。通过图示和具体例子，展示各模块的输出及其协同工作方式，体现从局部到整体、由简单到复杂的递进叙述顺序。\n  • 实验设计：实验部分采用多数据集、多训练规模验证的策略，系统性比较HRAG与主流端到端T5模型在不同数据量和领域上的表现。包含主实验（自动评测指标如BLEU、BLEURT、MER）、极低资源条件下的性能分析、跨域/零样本泛化能力测试，以及人类评测。\n\n示例 2：《ELLE: Efficient Lifelong Pre-training for Emerging Data》\n  • 问题定位：论文从实际痛点和应用需求出发引出问题。开篇指出预训练语言模型（PLM）在NLP任务中的突破性进展，但现有PLM通常基于静态快照训练，忽略了现实世界中数据是持续流入且分布变化的场景。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法忽视了X”与“现有方法在Y场景下失效”的逻辑。具体地，指出大多数现有PLM只在静态数据上训练，忽略了流式、多源、分布变化的数据场景。此外，现有终身学习方法主要关注记忆回放、参数巩固或动态结构，但很少考虑多源流数据的顺序集成和训练效率问题。\n  • 核心方法：方法部分采用“先整体后局部、分模块介绍”的叙述策略。首先整体介绍为提升知识增长效率，提出在每次新数据到来时对模型宽度和深度进行扩展。随后分别详细介绍宽度扩展和深度扩展的具体实现，包括函数保持初始化（FPI）和分层插入等技术细节，并对比现有方法，指出创新点和改进之处。\n  • 实验设计：实验部分采用“主实验+多数据集验证+消融分析”的叙述策略。首先模拟多领域流式数据场景，涵盖5个不同领域的数据集，验证方法在真实终身学习场景下的有效性。其次，详细描述模型架构、训练细节和评测指标，确保实验可复现和公平。\n\n示例 3：《Compression of Generative Pre-trained Language Models via Quantization》\n  • 问题定位：论文开篇先强调了Transformer类生成式预训练语言模型（PLMs）在多任务和小样本学习上的强大能力及其在各类任务中的卓越表现，随后指出其计算和存储开销巨大是实际应用中的主要痛点。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性揭示的策略。\n  • 核心方法：方法部分先指出直接用传统量化方法训练低比特生成式PLM存在挑战，随后简要回顾量化背景。接着，基于前文观察，分两大模块提出创新方法：1）token-level对比蒸馏提升词嵌入可区分性，2）module-wise动态缩放提升量化器适应性。\n  • 实验设计：实验部分采用了多数据集、多任务验证的策略。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 5 次，占比 45.5%）\n   类型：writing-level\n   应用：从领域背景、问题分析、方法提出到实验验证，层层递进，前后呼应，逻辑清晰地展开全文。\n\n2. 现实场景动机引入（使用频率 2 次，占比 18.2%）\n   类型：writing-level\n   应用：通过举例说明现实中数据持续增长（如新闻、论文等），强调现有PLM静态训练的局限性，凸显研究问题的现实意义。\n\n3. 引用主流模型和竞赛结果建立背景（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过引用BERT、GPT-3、T5等主流PLM模型及WebNLG+ Shared Task竞赛结果，强调当前研究热点和主流方法，说明本工作顺应趋势。\n\n4. 细分子任务揭示转移学习潜力差异（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：分析NLG传统子任务（如lexicalisation和aggregation）在迁移学习中的表现差异，论证现有端到端方法的不足，为提出分层结构做铺垫。\n\n5. 提出分层结构以提升可解释性（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：明确将模型分为lexicalisation、aggregation、postedit三模块，对应传统NLG流程，帮助读者理解每一模块的功能和分工。\n\n6. 图示模型结构和流程（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过图1、图2展示模型整体结构和各阶段输出，直观帮助读者理解方法流程。\n\n7. 多数据集、多设置全面实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：在FewShotSGD、FewShotWeb、MultiWoZ等多个数据集上，分别在few-shot、zero-shot等多种设置下进行实验，覆盖广泛应用场景。\n\n8. 多指标量化评估（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：采用BLEU、BLEURT、MER等多种自动评测指标，结合人工评测，全面评价模型性能。\n\n9. 与主流强基线系统对比（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：与端到端T5系统在各数据集和设置下进行直接对比，展示HRAG的性能提升和优势。\n\n10. 分析异常现象并解释原因（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：对E2E T5在某些设置下MER异常高但流畅性差的现象进行剖析，解释模型行为，避免误导性结论。\n",
    "cluster_size": 11,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_97",
      "ARR_2022_27",
      "ARR_2022_352",
      "ARR_2022_289",
      "ARR_2022_171",
      "ARR_2022_223",
      "ARR_2022_347",
      "ARR_2022_116",
      "ARR_2022_274",
      "ARR_2022_194",
      "ARR_2022_225"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 5,
        "percentage": "45.5%"
      },
      {
        "name": "现实场景动机引入",
        "frequency": 2,
        "percentage": "18.2%"
      },
      {
        "name": "引用主流模型和竞赛结果建立背景",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "细分子任务揭示转移学习潜力差异",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "提出分层结构以提升可解释性",
        "frequency": 1,
        "percentage": "9.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_6",
    "name": "多模态虚假信息检测方法",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多模态虚假信息检测问题，采用跨文档或多模态融合方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以社会痛点开篇，通过现有方法局限对比铺垫，方法部分采用模块化和技术细节分步阐述，实验设计注重多层次对比与消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于多模态虚假信息检测任务，数据集包含文本、图片、视频等，预期提升检测准确性和泛化能力。",
    "writing_guide": "写作模板：多模态虚假信息检测方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多模态虚假信息检测问题，采用跨文档或多模态融合方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以社会痛点开篇，通过现有方法局限对比铺垫，方法部分采用模块化和技术细节分步阐述，实验设计注重多层次对比与消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于多模态虚假信息检测任务，数据集包含文本、图片、视频等，预期提升检测准确性和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Cross-document Misinformation Detection based on Event Graph Reasoning》\n  • 问题定位：论文从实际社会痛点出发，强调虚假新闻传播已成为重要社会问题，并指出在复杂突发事件中，读者通常会接触到多个来源的新闻文档，其中有真有假。通过具体案例（如美国国会袭击事件中关于死亡事件的报道），展示了单独判断新闻难以识别虚假信息，但跨文档的信息冲突和互补可以帮助检测虚假信息。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法局限于单文档判断’、‘未利用跨文档信息’、‘相关工作仅关注知识三元组或事实验证，无法处理复杂结构’等逻辑。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先整体介绍方法流程（如图2所示），即先对每个文档构建知识图谱，再通过事件共指将各文档知识图谱连接为跨文档知识图谱。随后介绍具体技术细节，如使用异构GNN进行检测，并说明如何将事件级检测结果用于文档级检测，体现模块化和层次化的结构。\n  • 实验设计：实验部分采用多数据集验证、主实验+消融分析的策略。首先介绍主实验设计，包括与现有主流方法的对比（文档级）、以及针对新任务的启发式基线（事件级）。随后通过消融实验分析各组件（如事件共指、事件级检测）的作用，并在不同数据集和集群规模下验证方法有效性。\n\n示例 2：《Twitter-COMMs: Detecting Climate, COVID, and Military Multimodal Misinformation》\n  • 问题定位：论文首先从实际痛点出发，强调了‘out-of-context images’作为一种廉价却极具危害性的虚假信息形式，尤其在社会和国家安全相关领域影响巨大。通过举例说明该问题在COVID-19、气候变化和军事领域的现实影响，明确了研究的应用需求和社会价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。具体指出：已有数据集要么规模小，要么仅关注文本虚假声明，未覆盖多模态不一致性；部分方法依赖外部知识库，限制了通用性和可扩展性。通过对比，强调了本工作在多模态、规模和自动化标注方面的创新。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了基于CLIP模型的多模态嵌入与分类框架，然后细化到具体的融合方式（如Concat、Concat+Dot、Multiply），并通过实验对比三种融合策略，说明最终选择Multiply。\n  • 实验设计：实验部分采用‘多数据集验证+消融分析+任务难点分析’的策略。首先在合成数据（Dev）和两个人工构造的真实场景数据集（hNews、hTwitter）上验证主方法性能，并与基线方法对比。随后进行消融实验，分析不同融合方式和模型设计对性能的影响。\n\n示例 3：《MM-Claims: A Dataset for Multimodal Claim Detection in Social Media》\n  • 问题定位：论文首先从实际社会痛点出发，强调新冠疫情期间错误信息（misinformation）对社会的危害，提出‘信息疫情’（infodemic）的概念，并引用联合国的呼吁，凸显问题的紧迫性和现实影响。\n  • 现有研究缺口：论文通过梳理现有文献，指出当前研究主要集中在单一模态（尤其是文本）上的claim检测，虽然有部分多模态相关的数据集和模型，但大多关注于真假（veracity）判定或仅限于单一主题（如COVID-19），缺乏对多主题、多模态claim检测的系统研究。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先回顾claim检测领域的发展脉络，从早期基于结构和特征的方法到当前主流的transformer模型，涵盖了不同场景（如跨领域、跨语言等）和数据集。随后，介绍多模态相关工作，指出已有数据集和方法的不足，最后聚焦到自身提出的数据集和模型设计。\n  • 实验设计：实验部分采用‘主实验+多角度分析’的策略。首先介绍实验设置，包括特征、基线模型和评价指标。主实验围绕新提出的数据集，测试多种特征和最新的多模态模型，报告二分类和三分类的准确率和Macro-F1。其次，分析模型在视觉相关与非视觉相关claim上的表现，探讨模型对不同模态的偏好。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 37.5%）\n   类型：writing-level\n   应用：作者采用问题提出-方法介绍-实验验证的经典结构，层层递进，呼应研究目标与结论。\n\n2. 现实问题引入（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：通过COVID-19疫情期间的信息误导问题引入，强调打击虚假信息的重要性，激发读者关注\n\n3. 场景化问题引入（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：以假新闻传播为社会问题切入，强调现实影响，增强问题的紧迫性和相关性。\n\n4. 案例驱动说明（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过Rosanne Boyland事件的多文档知识图谱，展示跨文档信息冲突与互补，直观体现方法价值。\n\n5. 现有方法局限对比（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：指出现有方法仅能单文档判断，无法利用跨文档信息，铺垫新任务的必要性。\n\n6. 任务分层细化（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：将检测任务分为文档级和事件级，明确各自目标和意义。\n\n7. 数据集创新与构建说明（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：首次构建包含话题相关文档簇的假新闻检测数据集，并详细说明生成过程。\n\n8. 方法流程图展示（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：用图示（Figure 2）展示整体流程，包括KG构建、跨文档连接和检测步骤。\n\n9. 技术细节分步阐述（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：分步骤介绍KG构建、跨文档事件共指、异构GNN检测及事件级结果融合。\n\n10. 多层次对比实验设计（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：分别在文档级与事件级任务上与多种基线方法对比，包括现有模型和启发式方法。\n",
    "cluster_size": 8,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_355",
      "ARR_2022_236",
      "ARR_2022_155",
      "ARR_2022_150",
      "ARR_2022_2",
      "ACL_2017_729",
      "COLING_2020_69",
      "COLING_2020_75"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "37.5%"
      },
      {
        "name": "现实问题引入",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "场景化问题引入",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "案例驱动说明",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "现有方法局限对比",
        "frequency": 1,
        "percentage": "12.5%"
      }
    ]
  },
  {
    "pattern_id": "pattern_7",
    "name": "多模态融合多任务学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决命名实体识别中的复杂场景问题，采用多模态融合和多任务学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过引用权威工作铺垫背景，常用tricks包括多数据集验证、与主流方法对比和强基线设定。\n第3段（60字）：适用场景与预期效果 - 适用于复杂场景的命名实体识别任务，如嵌套实体、金融XBRL标签和口语NER，预期提升模型性能和泛化能力。",
    "writing_guide": "写作模板：多模态融合多任务学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决命名实体识别中的复杂场景问题，采用多模态融合和多任务学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过引用权威工作铺垫背景，常用tricks包括多数据集验证、与主流方法对比和强基线设定。\n第3段（60字）：适用场景与预期效果 - 适用于复杂场景的命名实体识别任务，如嵌套实体、金融XBRL标签和口语NER，预期提升模型性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Fusing Heterogeneous Factors with Triaffine Mechanism for Nested Named Entity Recognition》\n  • 问题定位：论文首先从实际应用出发，指出命名实体识别（NER）作为基础的自然语言处理任务已被广泛研究，尤其是平坦实体识别。随后，论文强调在真实场景中嵌套实体广泛存在，且具有多粒度语义，现有序列标注框架难以处理嵌套实体。\n  • 现有研究缺口：论文批评现有方法主要采用两种逻辑：一是指出现有的span-based方法虽然借助预训练语言模型取得了不错效果，但结构过于简单，未能显式建模关键特征（如边界、标签感知、相关span间的交互）；二是具体分析这些特征对嵌套实体识别的重要性，并举例说明仅依赖边界或单一特征无法充分区分不同类型的嵌套实体...\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先通过图示给出方法的整体框架，明确核心创新点为triaffine变换用于融合多种异质特征。随后，分步骤详细介绍triaffine变换的原理和作用，再具体讲解基于该变换的模型结构和实现细节。整体逻辑清晰，由总到分，突出创新点。\n  • 实验设计：实验部分采用‘多数据集主实验+与主流方法对比’的策略。通过在ACE2004、ACE2005、GENIA和KBP2017等多个公开数据集上与多种主流方法（包括不同范式和不同编码器）进行全面对比，突出方法的优越性。此外，实验结果细致呈现不同编码器下的性能，强调模型在各场景下的领先表现。\n\n示例 2：《FiNER: Financial Numeric Entity Recognition for XBRL Tagging》\n  • 问题定位：论文从应用需求和实际痛点出发引出问题。首先强调金融领域自然语言处理（NLP）的重要性和现有应用场景，如股市预测、情感分析、事件检测等，指出金融数据不仅存在于结构化表格，还大量分布于非结构化文本（如公司报告、分析师评论、新闻）。\n  • 现有研究缺口：论文通过对比现有实体抽取方法（如NER和合同元素抽取），批评其在金融XBRL标签任务上的局限。主要逻辑是：现有方法通常只处理少量通用实体类型（如人名、机构名），而XBRL标签类型数量巨大（6k），且绝大多数标签对象为数字型token，正确标签高度依赖上下文。\n  • 核心方法：方法部分采用从整体到局部、从简单到复杂的叙述策略。首先介绍主流NLP工具spaCy作为基线，随后依次介绍更复杂的模型：bilstm（双向LSTM）、bert（预训练Transformer），并分别说明其输入嵌入和训练数据。\n  • 实验设计：实验部分采用主实验为主、分析模型表现差异的策略。首先统一采用微平均F1和宏平均F1作为评价指标，确保不同模型可直接比较。主实验涵盖spaCy、bilstm、bert及其与CRF结合的多种模型，重点分析各模型在实体级别的表现及其原因。\n\n示例 3：《MINER: Improving Out-of-Vocabulary Named Entity Recognition from an Information Theoretic Perspective》\n  • 问题定位：论文首先从实际应用场景出发，强调命名实体识别（NER）在信息检索、问答系统、对话系统等领域的重要性，进而指出传统方法和深度学习方法在公开基准上取得了较好表现，但在处理未见实体（OOV）时存在显著性能下降的问题。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在OOV场景下失效’的逻辑。具体地，作者指出当前NER模型主要依赖于已见实体的记忆，导致在未见实体预测时表现不佳。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先，作者介绍了NER任务从序列标注向Span预测的范式转变，并阐述选择SpanNER作为基础架构的原因。随后，详细说明SpanNER的三大模块，并突出本方法在架构中插入信息瓶颈层以优化信息。\n  • 实验设计：实验部分采用‘主实验+多数据集验证+对比分析’的叙述策略。作者在五个OOV数据集上验证了所提方法的性能，并与多种现有方法进行了系统对比。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 多数据集验证（使用频率 3 次，占比 25.0%）\n   类型：experiment-level\n   应用：在多个公开数据集（ACE2004, ACE2005, GENIA, KBP2017）上进行实验，覆盖不同领域，证明方法的普适性和稳定性。\n\n2. 具体案例引入（使用频率 2 次，占比 16.7%）\n   类型：writing-level\n   应用：通过具体的例子（如“NF - chi B site”）说明嵌套实体识别中标签和边界的复杂性，帮助读者理解方法设计动机。\n\n3. 消融实验设计（使用频率 2 次，占比 16.7%）\n   类型：experiment-level\n   应用：通过对比有无CRF层、不同tokenization（word/subword）等设置，细致分析模型表现差异，支持机制解释。\n\n4. 多维度问题分解（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：作者将嵌套实体识别任务分解为多个关键因素（tokens、边界、标签、相关span），逐一阐述每个因素的必要性和挑战性，为后续方法设计铺垫理论基础。\n\n5. 引用权威工作（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：通过大量引用领域内代表性工作，说明现有方法的局限和发展趋势，为新方法的提出做铺垫。\n\n6. 方法核心突出（使用频率 1 次，占比 8.3%）\n   类型：method-level\n   应用：在方法部分开头直接强调“triaffine transformations”为模型核心，突出该技术在融合多种异质特征上的创新性。\n\n7. 分步式方法介绍（使用频率 1 次，占比 8.3%）\n   类型：writing-level\n   应用：先介绍核心技术，再分步骤描述整体模型结构，帮助读者逐步建立对方法原理的认知。\n\n8. 与主流方法全面对比（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：与多种主流方法（如BENSC, Pyramid, TreeCRF, Biaffine, Locate and Label, Sequence to Set）进行详细对比，并量化性能提升。\n\n9. 强基线设定（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：采用BERT和ALBERT等强大的预训练模型作为编码器，确保对比结果具有代表性和说服力。\n\n10. 量化性能提升（使用频率 1 次，占比 8.3%）\n   类型：experiment-level\n   应用：通过具体的F1分数和提升幅度（如“+0.70”、“+2.49”），清晰呈现新方法的性能优势。\n",
    "cluster_size": 12,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_320",
      "ARR_2022_36",
      "ARR_2022_37",
      "ARR_2022_127",
      "ARR_2022_181",
      "ARR_2022_256",
      "ARR_2022_248",
      "ARR_2022_83",
      "ARR_2022_333",
      "ACL_2017_107",
      "ACL_2017_108",
      "COLING_2020_33"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "多数据集验证",
        "frequency": 3,
        "percentage": "25.0%"
      },
      {
        "name": "具体案例引入",
        "frequency": 2,
        "percentage": "16.7%"
      },
      {
        "name": "消融实验设计",
        "frequency": 2,
        "percentage": "16.7%"
      },
      {
        "name": "多维度问题分解",
        "frequency": 1,
        "percentage": "8.3%"
      },
      {
        "name": "引用权威工作",
        "frequency": 1,
        "percentage": "8.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_8",
    "name": "基于预训练模型的多标签分类",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多标签分类中的不平衡和复杂性问题，采用基于预训练模型的方法并结合新颖的注意力机制和评价指标。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用痛点出发，通过问题-方法-实验三段式结构展开，常用tricks包括引用前沿文献、多指标评估和复现与开源承诺。\n第3段（60字）：适用场景与预期效果 - 适用于大规模、多标签、不平衡和复杂语义的文本分类任务，预期提升模型性能和实际应用效果，增强研究的透明度和可验证性。",
    "writing_guide": "写作模板：基于预训练模型的多标签分类\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多标签分类中的不平衡和复杂性问题，采用基于预训练模型的方法并结合新颖的注意力机制和评价指标。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际应用痛点出发，通过问题-方法-实验三段式结构展开，常用tricks包括引用前沿文献、多指标评估和复现与开源承诺。\n第3段（60字）：适用场景与预期效果 - 适用于大规模、多标签、不平衡和复杂语义的文本分类任务，预期提升模型性能和实际应用效果，增强研究的透明度和可验证性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Improved Multi-label Classification under Temporal Concept Drift: Rethinking Group-Robust Algorithms in a Label-Wise Setting》\n  • 问题定位：论文通过从实际应用需求出发引入问题，强调多标签文档分类在科学出版物、医疗记录、法律法规和产品描述等领域的广泛应用。作者指出该任务面临大规模标签空间和标签分布极度不均衡的挑战，并进一步提出时间概念漂移问题，强调现实世界中标签分布随时间变化，凸显了任务的复杂性和实际痛点。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体来说，作者指出现有关于时间漂移的工作主要是诊断性分析，缺乏针对类不平衡和时间概念漂移的技术解决方案。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先介绍了基线模型的整体架构，包括使用预训练BERT模型进行文档表示，然后详细描述了Label-Wise Attention Network（LWAN）与BERT结合的具体实现，逐步解释每个模块的作用和技术细节。\n  • 实验设计：实验部分采用‘多数据集验证’和‘主实验+多指标评估’的策略。作者在多个法律和生物医学数据集上进行实验，比较不同模型（如LEGAL-BERT、BERT-LWAN）的表现，详细说明训练和评估细节。\n\n示例 2：《Evaluating Extreme Hierarchical Multi-label Classification》\n  • 问题定位：论文从实际应用痛点出发引出问题，强调自然语言处理中的分类任务广泛存在于情感分析、实体链接等场景，但评价指标的充分性仍是未解决的问题。通过具体举例（如准确率与宏平均准确率在多类别分布下的表现差异），逐步引出多标签、多层级、极端不均衡分类等复杂场景下评价难题，明确提出当前评价标准难以适应实际复杂需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’的逻辑，指出不同评价指标（如Accuracy、F-measure、MAAC）在多标签、层级结构、类别极度不均衡等情形下表现不一致，无法全面反映系统优劣。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序，首先介绍了Information Contrast Model (ICM)的整体思想和理论基础，明确其统一了特征集和信息论的相似性度量。随后具体给出ICM的数学定义和计算方式，解释各参数的含义和直觉，并指出ICM如何推广现有的相似性度量方法。\n  • 实验设计：实验部分采用‘多维度测试+对比验证’的策略。首先通过构造大规模、极度不均衡的层级多标签合成数据集，系统性地考察不同评价指标在各类评价属性（如错误率敏感性、类别特异性、层级结构等）下的表现。实验类型包括：1）合成数据上的敏感性和属性测试，2）多指标横向对比，3）真实案例（医学文档）应用验证。\n\n示例 3：《KenMeSH: Knowledge-enhanced End-to-end Biomedical Text Labelling》\n  • 问题定位：论文从实际应用需求和痛点出发引出问题。首先介绍了PubMed/MEDLINE数据库的规模和MeSH索引在生物医学文本挖掘中的重要性，强调了人工标注的高成本和效率低下，结合文献引用和统计数据展示了人工索引的不可持续性，进而提出自动化MeSH索引的迫切需求。\n  • 现有研究缺口：论文通过描述现有人工方法的高成本和低效率，批评了当前依赖人工标注的局限性，并指出随着数据规模的增长，现有做法难以为继。此外，通过具体数据（如标签数量、标签分布不均、每篇文章标签数差异大等）强调了现有方法难以应对大规模和复杂语义的挑战。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先将MeSH索引形式化为多标签分类问题，给出整体建模框架。随后，分模块介绍模型的各个组成部分，包括多通道文档表示、标签特征学习、动态语义掩码注意力模块和分类器，层层递进，突出每个模块在整体架构中的作用。\n  • 实验设计：实验部分聚焦于主实验，采用多种主流评价指标（Microaverage、example-based、ranking-based）对模型进行系统评估。通过与五种主流方法（包括只用摘要/标题和用全文训练的系统）进行对比，突出自身方法的优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 应用场景举例（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过列举科学出版物、医疗记录、法律文本和商品描述等多种实际应用场景，强调多标签文档分类的广泛用途和现实意义。\n\n2. 问题难点细化（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：详细分析了类别不平衡和时序概念漂移等实际难点，说明现有方法的局限性和研究空白。\n\n3. 引用前沿文献（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：广泛引用近年来的重要文献，说明所关注问题和采用方法均有坚实的学术基础。\n\n4. 对比分割策略（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：对比随机分割和时间顺序分割，证明后者能更真实地反映模型在实际应用中的表现。\n\n5. 多指标评估（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：同时报告m-RP、micro-F1和macro-F1等多种评价指标，全面衡量模型性能和类别间差异。\n\n6. 复现与开源承诺（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：承诺开源全部代码，并为审稿人提供内部代码包，方便复现和后续研究。\n\n7. 方法细节可解释化（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：详细描述BERT-LWAN模型每一步的计算流程和直观解释，如每个标签独立注意力头如何关注不同文本片段。\n\n8. 与SOTA方法对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：引用并复现BERT-LWAN等当前最优方法，展示本方法在公开数据集上的性能对比。\n\n9. 实验设置细致说明（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：详细说明模型配置、训练参数、分组采样策略等实验细节，确保实验过程透明。\n\n10. 问题-方法-实验三段式结构（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：采用先引入问题，再提出方法，最后通过实验验证的经典三段式结构，逻辑清晰、层层递进。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_255",
      "ARR_2022_264",
      "ARR_2022_33",
      "ACL_2017_384",
      "COLING_2020_16"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "应用场景举例",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "问题难点细化",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "引用前沿文献",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "对比分割策略",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "多指标评估",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_9",
    "name": "低资源语音自监督学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低资源语音处理问题，采用自监督学习和多模态融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点开篇，通过理论定义引入核心概念，常用tricks包括优势对比论证、创新问题设定和详细基线对比。\n第3段（60字）：适用场景与预期效果 - 适用于低资源语言和多模态语音任务，预期提升模型在小数据集上的性能和泛化能力。",
    "writing_guide": "写作模板：低资源语音自监督学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低资源语音处理问题，采用自监督学习和多模态融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点开篇，通过理论定义引入核心概念，常用tricks包括优势对比论证、创新问题设定和详细基线对比。\n第3段（60字）：适用场景与预期效果 - 适用于低资源语言和多模态语音任务，预期提升模型在小数据集上的性能和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Self-supervised Semantic-driven Phoneme Discovery for Zero-resource Speech Recognition》\n  • 问题定位：论文从实际痛点和应用需求出发引入问题。首先指出传统的有监督语音处理系统（如自动语音识别）高度依赖大量文本标注，这在低资源语言中难以实现。接着强调自监督语音表示学习的最新进展为无需完整文本转录的语音处理系统带来了新希望，尤其适用于标注稀缺或不可用的语言。\n  • 现有研究缺口：论文批评现有方法时，主要采用“现有方法忽视了X”以及“现有方法在Y方面存在不足”的逻辑。具体而言，早期无监督语音表示学习方法只关注声学相似性（phones），未考虑语义信息。神经网络方法虽然能学习离散表示，但其生成的码本远大于实际音素数量，导致在标准音素发现指标上表现不佳。\n  • 核心方法：方法部分采用分模块介绍和先整体后局部的叙述策略。首先简要说明整体流程（如预分割阶段、编码器和判别器结构），然后分别详细介绍各模块的实现，包括预分割模型、编码器（CPC模型）、判别器结构、损失函数的具体设计与优化细节。\n  • 实验设计：实验部分采用多数据集验证和主实验+基准对比的策略。首先详细介绍了用于训练和测试的多种数据集，包括英语和低资源语言（Mboshi），并说明数据集构建方式及标注量远低于以往工作。实验类型涵盖主任务（音素发现）、标准基准测试（TIMIT和Mboshi）、以及与四种主流基线方法的系统性对比。\n\n示例 2：《Language-Agnostic Meta-Learning for Low-Resource Text-to-Speech with Articulatory Features》\n  • 问题定位：论文从学术gap出发引出问题。开篇先回顾了深度学习推动下TTS的巨大进步，列举了多个主流模型和声码器，强调了这些方法在数据充足时表现优异。随后，作者指出跨语言数据利用仍是TTS领域的关键挑战，尤其是大多数语言属于低资源，现有方法难以适用。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在X场景下失效’和‘现有方法需要复杂改动’的逻辑。具体包括：1) 现有跨语言迁移方法需要复杂的结构调整，难以与主流TTS架构结合；2) 直接混合多语言训练虽然可行，但训练过程复杂；3) 以往尝试用发音特征或音系特征，但依赖额外工具或数据，且方法局限。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述策略。首先介绍MAML的总体目标和基本流程（外循环、内循环、参数更新），再补充说明计算复杂度问题及其变体（如一阶MAML）。方法描述逻辑清晰，先给出核心思想，再逐步展开细节和相关改进，便于读者理解整体框架及其适用性。\n  • 实验设计：实验部分采用‘主实验+多数据集+对比验证’的策略。首先在单语言场景下评估发音特征输入的效果，随后在跨语言场景下结合LAML和发音特征进行自动和人工评测。\n\n示例 3：《Cross-modal Contrastive Learning for Speech Translation》\n  • 问题定位：论文首先从实际应用需求出发，强调端到端语音到文本翻译（E2E ST）在产品和真实应用中的重要性。接着对比传统级联模型和E2E模型的性能，指出虽然E2E模型表现接近甚至优于传统方法，但受限于平行数据较少。\n  • 现有研究缺口：论文批评现有方法主要采用以下逻辑：首先，指出现有ST方法大多关注于利用MT和ASR的额外数据，如预训练、多任务训练等，但这些方法主要解决数据稀缺问题。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体描述了端到端语音翻译的输入输出和数据结构，然后介绍模型的四个子模块（语音编码器、词嵌入层、Transformer编码器和解码器），并说明其统一框架可支持ST、MT、ASR多任务。\n  • 实验设计：实验部分采用‘多数据集验证+主实验对比’的策略。首先介绍使用的ST和MT数据集及其规模，确保实验具有代表性。然后详细说明模型配置和实验细节，保证可复现性。主实验包括与现有端到端ST模型的对比，分为不使用和使用外部MT数据两种设置，突出方法的普适性和优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 消融实验（使用频率 2 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过逐步移除或替换系统组件，展示不同部分对整体性能的影响，证明各模块的有效性。\n\n2. 问题驱动开篇（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者首先强调了自监督语音表示学习的最新进展，并指出传统方法依赖大量标注，强调在低资源语言中的困难，明确提出亟需无需文本转录的语音处理系统。\n\n3. 理论定义引入（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者引用标准语言学定义（Swadesh, 1934）对音素进行解释，阐明音素与词语的关系，为后续方法选择音素作为离散表示做理论铺垫。\n\n4. 优势对比论证（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：通过与词语表示的对比，论证音素在样本复杂度、分布均衡性和泛化能力上的优势，层层递进地说服读者。\n\n5. 创新问题设定（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：将音素库学习问题重新表述为自监督学习问题，并引入少量语义监督，区别于完全无监督或全监督的传统方法。\n\n6. 多数据集覆盖（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：实验覆盖多个英语和低资源语言数据集，包括标准基准和自建词语数据集，确保方法在不同场景下的有效性。\n\n7. 详细基线对比（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：与多种连续和离散表示的基线方法进行系统对比，包括CPC+k-means、Gumbel VIB、DIB等，且所有模型共享同一编码器，确保公平性。\n\n8. 低资源场景强调（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：多次强调方法在低资源语言和极低标注条件下的表现，说明所需标注远低于前人工作，突出应用潜力。\n\n9. 方法细节透明化（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：详细说明模型架构、训练参数、优化策略和离散化细节，引用相关文献并给出具体数值，便于读者理解和复现。\n\n10. 标准评价指标使用（使用频率 1 次，占比 10.0%）\n   类型：experiment-level\n   应用：采用标准评价指标（如NMI）对模型进行评估，确保实验结果具有权威性和可比性。\n",
    "cluster_size": 10,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_8",
      "ARR_2022_238",
      "ARR_2022_168",
      "ARR_2022_189",
      "ARR_2022_278",
      "ARR_2022_348",
      "ARR_2022_359",
      "ARR_2022_17",
      "ACL_2017_484",
      "COLING_2020_80"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "消融实验",
        "frequency": 2,
        "percentage": "20.0%"
      },
      {
        "name": "问题驱动开篇",
        "frequency": 1,
        "percentage": "10.0%"
      },
      {
        "name": "理论定义引入",
        "frequency": 1,
        "percentage": "10.0%"
      },
      {
        "name": "优势对比论证",
        "frequency": 1,
        "percentage": "10.0%"
      },
      {
        "name": "创新问题设定",
        "frequency": 1,
        "percentage": "10.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_10",
    "name": "无监督预训练对比学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决稠密检索和句子表示学习中的数据依赖和泛化问题，采用无监督预训练和对比学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过权威基准对比指出现有方法不足，方法部分采用整体框架+模块细节，实验设计多数据集验证+消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于低资源和跨领域场景的检索和表示学习任务，预期提升模型泛化能力和效率。",
    "writing_guide": "写作模板：无监督预训练对比学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决稠密检索和句子表示学习中的数据依赖和泛化问题，采用无监督预训练和对比学习技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过权威基准对比指出现有方法不足，方法部分采用整体框架+模块细节，实验设计多数据集验证+消融分析。\n第3段（60字）：适用场景与预期效果 - 适用于低资源和跨领域场景的检索和表示学习任务，预期提升模型泛化能力和效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《LaPraDoR: Unsupervised Pretrained Dense Retriever for Zero-Shot Text Retrieval》\n  • 问题定位：论文开篇从实际痛点和应用需求出发，首先介绍了 dense retrieval 在效率上的优势（可毫秒级运行），但随即指出其对大规模有标注数据的依赖以及在跨领域（out-of-domain, OOD）场景下性能下降的问题。\n  • 现有研究缺口：论文批评现有方法时，采用了多层逻辑：首先指出现有 dense retrieval 方法（如 cross-encoder、late-interaction、DPR、RocketQA 等）虽然在部分数据集上有效，但在 BEIR 基准测试中暴露出主要缺点——无法很好地泛化到域外数据（out-of-d...\n  • 核心方法：方法部分采用先整体后局部的叙述顺序。首先整体介绍 LaPraDoR 的设计理念——无监督预训练、兼顾语义与词法匹配。随后，聚焦于训练效率的关键挑战，详细阐述提出的 Iterative Contrastive Learning (ICoL) 机制，包括缓存机制、权重共享、模型结构选择等细节。\n  • 实验设计：实验部分采用多数据集、多设置验证的策略。首先在 BEIR 基准上进行主实验，覆盖18个异构数据集，强调模型的跨领域泛化能力。实验指标采用标准的 NDCG@10。其次，详细介绍模型设置与训练细节，包括预训练和微调流程。再次，进行消融实验（如模型层数、权重共享等），分析设计选择的影响。\n\n示例 2：《MCSE: Multimodal Contrastive Learning of Sentence Embeddings》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先强调句子表征学习在NLP中的基础地位，随后指出尽管预训练语言模型（如BERT）取得了巨大成功，但其未经微调的句子表征在语义相似度任务上甚至不如简单的Glove词向量平均。\n  • 现有研究缺口：论文批评现有方法的逻辑为：1）指出PLM未微调时效果不佳，甚至不如简单方法（如Glove平均）；2）现有无监督方法虽有进展，但纯文本模型难以捕捉超越文本分布的深层语义（即缺乏现实世界语义锚定）；3）引用相关文献，强调文本模型在语义理解上的局限性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先简要介绍采用SimCSE作为文本基线，然后说明其扩展为多模态对比学习目标。具体地，先描述整体框架如何结合视觉和文本信息，再分别介绍文本对比目标和多模态对比目标，突出方法的创新点和与现有工作的区别。\n  • 实验设计：实验部分采用‘多数据集验证+消融分析+机制解释’的叙述策略。首先在标准STS基准上进行主实验，比较不同模型（如BERT、RoBERTa、SimCSE、MCSE）的表现。其次，通过消融实验（如仅用多模态数据、打乱图像配对、替换图像编码器）分析各模块和设计的有效性。\n\n示例 3：《Efficient Cluster-based k-Nearest-Neighbor Machine Translation》\n  • 问题定位：论文通过结合实际应用痛点和学术研究空白来引出问题。开篇先介绍了非参数方法在神经机器翻译领域的成功应用，强调其在领域自适应中的优势，随后指出尽管这些方法在翻译质量上有显著提升，但对其核心组件——datastore的行为分析尚未充分展开，特别是在检索延迟和语义分布两个方面存在不足。\n  • 现有研究缺口：论文对现有方法的批评采用了‘现有方法在实际场景下存在不足’和‘现有方法忽视了关键行为分析’的逻辑。具体通过实验数据和可视化分析指出传统datastore构建方式在检索延迟和语义分布上不理想，导致实际应用中效率低下和语义噪声，影响检索效果。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了方法的核心思想——通过聚类信号进行特征压缩和规模剪枝以重构datastore。随后细致分模块介绍了四种具体剪枝策略（距离剪枝、低概率剪枝、高概率剪枝、随机剪枝），并对每种策略的设计动机和实际效果进行阐述。\n  • 实验设计：实验部分采用‘多数据集验证+剪枝率消融+大规模实验’的策略。首先在多个领域（如IT、Koran等）进行主实验，比较不同剪枝策略的性能。其次在大规模数据集（Subtitles）上测试剪枝方法的极限表现，分析剪枝率变化对性能的影响，属于消融实验。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 8 次，占比 40.0%）\n   类型：writing-level\n   应用：先提出问题和挑战，再介绍方法创新，最后通过实验验证，层层递进，呼应开篇问题。\n\n2. 逻辑递进的叙事结构（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：先引入问题和动机，再提出方法，最后通过系统实验和分析呼应前述假设和创新点，形成闭环。\n\n3. 现有方法不足对比（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：详细分析了稠密检索和查询增强等现有方法的局限，如标注数据稀缺、生成成本高、无法处理未标注文档等。\n\n4. 引用权威工作（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：作者在引言中广泛引用了领域内的权威工作，展示该领域已有的成果和不足，强化自身工作的合理性和必要性\n\n5. 图示辅助理解（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：作者在引言和方法部分分别用图1和图2展示事件关系和方法整体框架，降低理解门槛\n\n6. 引用权威文献建立背景（使用频率 2 次，占比 10.0%）\n   类型：writing-level\n   应用：通过大量引用相关领域的权威文献，展示该问题的研究基础和前人工作。\n\n7. 对比实验设计（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：实验部分通过与多种主流方法在实体聚类和主题建模任务上的对比，展示了新方法的性能提升。\n\n8. 消融实验（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：通过SR w/o QU、SR w/o PE等消融实验，分析各组件对整体性能的影响。\n\n9. 多数据集验证（使用频率 2 次，占比 10.0%）\n   类型：experiment-level\n   应用：在WebQSP和CWQ两个主流数据集上进行实验，证明方法的通用性和稳健性。\n\n10. 问题驱动开篇（使用频率 1 次，占比 5.0%）\n   类型：writing-level\n   应用：作者首先指出现有Dense Retrieval方法在跨域泛化和低资源场景下的局限性，突出实际应用难题，吸引读者关注。\n",
    "cluster_size": 20,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_7",
      "ARR_2022_154",
      "ARR_2022_143",
      "ARR_2022_345",
      "ARR_2022_291",
      "ARR_2022_202",
      "ARR_2022_285",
      "ARR_2022_240",
      "ARR_2022_141",
      "ARR_2022_56",
      "ARR_2022_251",
      "ARR_2022_294",
      "ARR_2022_101",
      "ARR_2022_219",
      "ARR_2022_151",
      "ARR_2022_163",
      "ARR_2022_185",
      "ARR_2022_22",
      "ARR_2022_84",
      "COLING_2020_68"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 8,
        "percentage": "40.0%"
      },
      {
        "name": "逻辑递进的叙事结构",
        "frequency": 2,
        "percentage": "10.0%"
      },
      {
        "name": "现有方法不足对比",
        "frequency": 2,
        "percentage": "10.0%"
      },
      {
        "name": "引用权威工作",
        "frequency": 2,
        "percentage": "10.0%"
      },
      {
        "name": "图示辅助理解",
        "frequency": 2,
        "percentage": "10.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_11",
    "name": "模型压缩与知识蒸馏",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型压缩与知识蒸馏中的问题，采用元学习和双层优化框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以现实类比和引用权威文献增强说服力，方法命名突出创新性，实验设计全面对比多种基线。\n第3段（60字）：适用场景与预期效果 - 适用于NLP和CV领域，需要模型压缩和知识蒸馏的场景，预期提升模型效率和性能。",
    "writing_guide": "写作模板：模型压缩与知识蒸馏\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型压缩与知识蒸馏中的问题，采用元学习和双层优化框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以现实类比和引用权威文献增强说服力，方法命名突出创新性，实验设计全面对比多种基线。\n第3段（60字）：适用场景与预期效果 - 适用于NLP和CV领域，需要模型压缩和知识蒸馏的场景，预期提升模型效率和性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《BERT Learns to Teach: Knowledge Distillation with Meta Learning》\n  • 问题定位：论文通过实际应用需求和学术痛点双重策略引出问题。首先指出随着大规模神经网络的普及，模型压缩对于高效、环保的机器学习部署变得重要，强调了知识蒸馏作为主流压缩技术的有效性。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y方面存在不足’的逻辑。具体地，指出传统知识蒸馏中教师模型对学生模型的能力和学习进度不敏感，且教师模型仅优化自身表现而非知识迁移能力。通过类比现实教育场景（如博士生与教授的区别），进一步强调教师模型缺乏“教学技能”。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了MetaDistil框架的核心思想，即利用元学习动态调整教师模型以适应学生模型的学习进度。随后，进一步细化，提出了基于双层优化的元学习机制，并创新性地引入了‘pilot update’机制以协同教师和学生的学习过程。\n  • 实验设计：实验部分采用‘多数据集验证+主流对比+公平性控制’的策略。首先在自然语言处理和计算机视觉两个主流领域的多个分类基准数据集上进行验证，涵盖GLUE等多个细分任务。\n\n示例 2：《Domain Knowledge Transferring for Pre-trained Language Model via Calibrated Activation Boundary Distillation》\n  • 问题定位：论文首先从自然语言处理领域Transformer模型的成功应用切入，强调预训练-微调范式已成为主流，并以BERT等模型为例，指出其广泛应用。接着，作者指出这些模型在需要领域知识的任务（如生物医学、金融）中存在局限，因为它们主要基于通用语料进行预训练。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和举例的策略。首先指出现有主流做法（领域额外预训练）虽能提升领域任务表现，但存在明显缺陷：需要大量训练数据和算力资源、训练时间长、每有新模型出现需重新执行等。具体通过BioBERT需23天8卡训练的例子，突出成本高昂。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序。首先简要回顾了Transformer及主流PLM（BERT、ALBERT、RoBERTa）的架构和发展，铺垫领域背景。随后，聚焦介绍DoKTra框架，作为主方法。方法介绍强调其与传统领域适应方法的不同，突出其高效性和创新性。\n  • 实验设计：实验部分采用‘主实验+多模型/多任务验证’的策略。首先说明实验设置，包括教师模型（BioBERT）和两种学生模型（ALBERT-xlarge、RoBERTa-large），并详细描述了参数设置和调优过程。实验在五个生物医学和临床分类任务上进行，采用F1分数作为指标。\n\n示例 3：《RAIL-KD: RAndom Intermediate Layer Mapping for Knowledge Distillation》\n  • 问题定位：论文首先从应用需求出发，指出虽然预训练语言模型（如BERT、RoBERTa、XLNet）在自然语言理解任务上表现优异，但其在实际应用（如边缘设备）中部署存在模型体积大、推理时间长等挑战。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下存在不足’的句式。例如，指出已有的中间层蒸馏方法多采用固定的层映射，忽视了层选择对性能的影响，导致难以找到最优的层匹配方案（即layer skip and search问题）。\n  • 核心方法：方法部分未给出详细内容，但从相关工作和实验部分可推测，方法叙述策略为‘先整体后局部’，即先介绍知识蒸馏及中间层蒸馏的基本框架和常见做法，然后聚焦于层选择问题，逐步引出并细化本文提出的新方法（如RAIL-KD），并与现有方法进行对比。可能还会分模块介绍方法的不同组成部分或创新点。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+对比实验’的策略。首先在GLUE基准的8个任务上进行主实验，涵盖分类和回归任务，验证方法的普适性。其次，为检验方法的泛化能力，还在跨领域（OOD）数据集上进行测试。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 2 次，占比 40.0%）\n   类型：writing-level\n   应用：从现有方法局限入手，逐步引出自身方法，再通过系统实验验证，最后回扣前述问题，形成闭环。\n\n2. 现实类比增强说服力（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过将教师模型与博士生、教授的教学过程类比，形象说明教师模型需要专门训练以提升知识传递能力，增强问题设定的现实感和说服力。\n\n3. 引用大量权威文献（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：在介绍知识蒸馏和学生中心学习时，密集引用相关领域的经典和最新文献，显示方法建立在坚实的学术基础上。\n\n4. 明确指出现有方法的不足（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：系统总结并批判现有知识蒸馏方法的两大缺陷（教师不关心学生、教师未针对蒸馏优化），为新方法的提出做铺垫。\n\n5. 引入教育学理论支持（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：引用教育学中“以学生为中心”的学习理论，论证让教师关注学生能力的合理性和有效性。\n\n6. 方法命名和框架包装（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：为方法命名为MetaDistil，并用“知识蒸馏+元学习”框架包装，强调其创新性和理论深度。\n\n7. 机制创新点突出（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：提出“pilot update”机制，强调其在双层优化（bi-level optimization）中的独特作用，突出方法细节创新。\n\n8. 流程图辅助理解（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过Figure 1展示MetaDistil的整体流程，使复杂的训练过程一目了然。\n\n9. 细致的任务和数据集覆盖（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：在NLP和CV两个领域、多个主流任务和数据集（如GLUE、BERT压缩）上进行评测，覆盖多种任务类型。\n\n10. 与多种强基线全面对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：系统对比vanilla KD、PKD、Theseus、TinyBERT、MiniLM等多种主流和最新压缩方法，展示自身优势。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_231",
      "ARR_2022_180",
      "ARR_2022_214",
      "ARR_2022_300",
      "ARR_2022_159"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "40.0%"
      },
      {
        "name": "现实类比增强说服力",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "引用大量权威文献",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "明确指出现有方法的不足",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "引入教育学理论支持",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_12",
    "name": "多任务学习扩展分类体系",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦于自动扩展分类体系（如WordNet），采用多任务学习框架实现attach和merge操作的统一建模。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际应用需求和学术gap开篇，通过多版本方法设计和多指标实验评估增强说服力，常用tricks包括问题重要性强调、现有方法不足归纳等。\n第3段（60字）：适用场景与预期效果 - 适用于词汇资源扩展和多语言语义层级构建等任务，预期提升模型在多数据集上的泛化能力和性能表现。",
    "writing_guide": "写作模板：多任务学习扩展分类体系\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦于自动扩展分类体系（如WordNet），采用多任务学习框架实现attach和merge操作的统一建模。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际应用需求和学术gap开篇，通过多版本方法设计和多指标实验评估增强说服力，常用tricks包括问题重要性强调、现有方法不足归纳等。\n第3段（60字）：适用场景与预期效果 - 适用于词汇资源扩展和多语言语义层级构建等任务，预期提升模型在多数据集上的泛化能力和性能表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《TEAM: A multitask learning based Taxonomy Expansion approach for Attach and Merge》\n  • 问题定位：论文首先强调了分类体系（如 WordNet）在自然语言处理中的重要性，指出其在信息检索、信息抽取、文本分类和摘要等任务中的核心作用。接着指出现有 WordNet 主要依赖人工构建，导致覆盖面有限，由此引出自动化扩展分类体系的必要性。\n  • 现有研究缺口：论文批评现有方法时，首先将其分为两大类（多分类体系对齐和基于机器学习的子图评分），并进一步细分为只做 merge 或只做 attach 的子类。通过归纳总结指出：‘所有现有方法要么只做 merge，要么只做 attach’，而 WordNet 扩展本质上是两者的结合任务。\n  • 核心方法：方法部分先明确目标，即在单一模型中集成 attach 和 merge 两种操作，并提出采用多任务学习框架（TEAM）。接着说明该框架如何实现任务间信息流动和相互促进。\n  • 实验设计：实验部分首先介绍了数据集和评价指标，强调多语言多数据集（Assamese、Bengali、Hindi WordNet）验证的广泛性。随后明确对比基线（TaxoExpan、TMN）及自身方法的不同变体（TEAM-RG、TEAM-CL 及任务特定版本）。\n\n示例 2：《Constructing Semantic Hierarchies via Fusion Learning Architecture》\n  • 问题定位：论文在引言部分通过强调本体和语义词库在自然语言处理中的重要性，聚焦于其核心组成——语义层级结构，并以WordNet为例具体说明“is-a”关系，快速让读者了解研究对象及其关键关系，建立研究背景。\n  • 现有研究缺口：作者指出现有如WordNet、YAGO等语义层级多依赖人工构建，面临覆盖范围与人工成本的权衡难题，进而引出自动化构建语义层级的必要性，明确当前方法的不足与改进空间。\n  • 核心方法：方法部分以具体任务为切入点，明确目标是根据词的hypernyms列表自动构建语义层级，随后区分并介绍判别式和生成式两种主流架构，突出自身方法的定位与创新点，并辅以流程图辅助理解。\n  • 实验设计：实验部分按逻辑顺序展开，先介绍实验准备与数据集，接着报告融合架构及其组件的性能表现，再与已有方法多维度对比，并通过具体示例展示语义层级构建效果，突出方法有效性与实用性。\n\n示例 3：《None》\n  • 问题定位：引言部分通过定义paraphrase及其在自然语言处理中的重要性，强调大规模同义资源对应用的促进作用。作者以实际应用需求为切入点，逐步引出自动获取同义词资源的研究背景，建立了问题的现实意义和研究基础。\n  • 现有研究缺口：作者指出现有同义词资源（如PPDB）虽然规模庞大，但未能充分区分多义词的不同语义，导致同义词集合混杂。通过举例说明词语多义性带来的挑战，明确当前资源在语义细粒度划分上的不足，形成研究切入点。\n  • 核心方法：方法部分采用先介绍整体流程，再细化模型选择的策略。作者先说明需要高质量词语替换排名作为基础，随后分别介绍两种模型的原理、特征和上下文处理方式，突出模型选择的合理性和创新性。\n  • 实验设计：实验部分以具体任务为导向，详细说明数据选取、参数设置和阈值选择的依据，强调实验设计的科学性。通过描述聚类算法的参数选择和评估方法，展现实验流程的系统性和对结果可靠性的重视。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题重要性强调（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过列举WordNet在NLP各类任务中的核心作用，并指出人工构建的局限性，强调自动扩展taxonomy的必要性。\n\n2. 现有方法不足归纳（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：系统梳理现有工作仅关注attach或merge操作，未有统一模型，强调自身工作的独特切入点。\n\n3. 任务创新点明确（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：首次提出可同时执行attach和merge操作的多任务学习框架，并将taxonomy扩展任务转化为分类与回归两类问题。\n\n4. 多版本方法设计（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：提出TEAM-RG和TEAM-CL两种版本，分别对应回归和分类目标，满足不同任务需求。\n\n5. 原理可视化举例（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：通过具体例子（如Mango和Nutrient）及图示，直观展示attach与merge操作的区别和应用场景。\n\n6. 多任务学习框架阐释（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：详细说明如何通过多任务学习实现信息流动和任务互助，解释模型设计的合理性。\n\n7. 多指标实验评估（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：采用多种评价指标（MR, Hit@k, MRR, Accuracy, F1等）从不同角度衡量模型性能。\n\n8. 多数据集验证（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：在Assamese、Bengali和Hindi三种WordNet taxonomy上进行实验，验证方法的适用性。\n\n9. 与主流方法对比（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：与Taxo-Expan和TMN等SOTA方法进行系统对比，展示TEAM在各项指标上的优越表现。\n\n10. 方法变体消融分析（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：对TEAM的attach、merge、merge+attach等变体进行对比，探讨不同任务组合的效果。\n",
    "cluster_size": 8,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_358",
      "ACL_2017_67",
      "ACL_2017_614",
      "ACL_2017_21",
      "ACL_2017_741",
      "COLING_2020_26",
      "COLING_2020_74",
      "COLING_2020_5"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "问题重要性强调",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "现有方法不足归纳",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "任务创新点明确",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "多版本方法设计",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "原理可视化举例",
        "frequency": 1,
        "percentage": "12.5%"
      }
    ]
  },
  {
    "pattern_id": "pattern_13",
    "name": "多尺度表征自动评价技术",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决自动评价和生成任务中的评估难题，采用多尺度表征和创新指标设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过多数据集验证和对比实验突出方法优势，常用tricks包括领域背景铺垫、方法分类梳理、引用权威数据集。\n第3段（60字）：适用场景与预期效果 - 适用于自动作文评分、对话生成、视觉故事评估等任务，预期提升模型的准确性和解释性，增强评估的可靠性和公平性。",
    "writing_guide": "写作模板：多尺度表征自动评价技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决自动评价和生成任务中的评估难题，采用多尺度表征和创新指标设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过多数据集验证和对比实验突出方法优势，常用tricks包括领域背景铺垫、方法分类梳理、引用权威数据集。\n第3段（60字）：适用场景与预期效果 - 适用于自动作文评分、对话生成、视觉故事评估等任务，预期提升模型的准确性和解释性，增强评估的可靠性和公平性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《On the Use of Bert for Automated Essay Scoring: Joint Learning of Multi-Scale Essay Representation》\n  • 问题定位：论文通过强调自动作文评分（AES）在减轻教师评分负担和推动自动化评测发展中的实际价值来引出问题，采用了从实际痛点和应用需求出发的开篇策略。作者指出，随着在线教育的兴起，AES 领域受到越来越多关注，进一步凸显了该问题的现实紧迫性和研究意义。\n  • 现有研究缺口：论文对现有方法的批评采用了分层对比和局限性剖析的逻辑。\n  • 核心方法：方法部分采用了先整体后局部、分模块介绍的叙述策略。\n  • 实验设计：实验部分采用了多数据集验证和主实验+对比分析的叙述策略。首先介绍了ASAP和CRP两个公开数据集及其评价指标（QWK和RMSE），并描述了数据集划分和实验设置。随后，通过表格展示基线模型与所提多尺度模型的性能对比，并在长文本场景下与最新方法进行详细对比，突出模型优势。\n\n示例 2：《Bidimensional Leaderboards: Generate and Evaluate Language Hand in Hand》\n  • 问题定位：论文从学术gap和实际痛点双重角度引出问题。首先指出自然语言生成领域（如机器翻译、摘要）近年来取得了显著进展，但主流评测方式依赖于自动分数（如BLEU、ROUGE），这些分数与人类评判的相关性在模型能力提升或模型类型变化时会显著下降。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述顺序。首先介绍了BILLBOARDs的总体框架和设计理念，即将生成模型和评测指标作为两类独立的提交对象，动态关联模型排名与最优评测指标。\n  • 实验设计：实验部分采用‘对比分析+多数据集验证+主实验为主’的策略。首先强调实验初始化依赖于人工评测（专家与众包），并通过元评测（meta-evaluation）对比专家评测和众包评测的一致性，揭示众包评测的局限性。\n\n示例 3：《Many Hands Make Light Work: Using Essay Traits to Automatically Score Essays》\n  • 问题定位：论文首先从实际痛点出发，指出人工对作文进行定性评价耗时且资源消耗大，进而引出自动作文评分（AEG）领域的产生。随后，作者进一步从学术gap出发，强调现有研究主要关注整体分数的预测，而较少关注作文各个特征（traits）在整体分数中的作用。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑，明确指出大部分AEG领域的研究只关注整体评分，忽视了作文特征（traits）对整体分数的解释和贡献。此外，论文还指出现有的主流方法（如BERT）虽然效果较好，但存在参数量大、输入长度受限等实际应用中的缺陷，进一步强调了自身方法的轻量性和适用性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了多任务学习（MTL）框架在作文评分中的应用，说明模型结构和任务分配（主任务与辅助任务）。随后，详细描述了模型的各个组成部分，如共享词嵌入层、特征学习模块、损失函数设计等。最后结合实验设置，说明了模型选择、参数设置和与主流方法的对比方式。\n  • 实验设计：实验部分采用‘多配置对比+主实验+扩展实验’的策略。首先明确评价指标的选择及其合理性，然后在不同模型配置（STL-LSTM, STL-BiLSTM, MTL-LSTM, MTL-BiLSTM）下进行主实验，比较整体评分效果。其次，与已有的字符串核方法和BERT基线进行对比，验证方法有效性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 4 次，占比 36.4%）\n   类型：writing-level\n   应用：作者依次引入问题、分析现状、提出方法、描述实现、展示实验和总结优势，形成完整的逻辑闭环。\n\n2. 创新点突出（使用频率 2 次，占比 18.2%）\n   类型：method-level\n   应用：作者强调提出了多尺度（document、token、segment）联合表征和评分机制，区别于以往单一尺度或特征方式。\n\n3. 多指标评测（使用频率 2 次，占比 18.2%）\n   类型：experiment-level\n   应用：作者在多个数据集（ASAP、CRP）和多种评价指标（QWK、RMSE）下验证模型性能，采用5折交叉验证保证结果稳健。\n\n4. 领域背景铺垫（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者首先介绍AES任务的价值和应用场景，强调其在自动化评估和减轻教师负担中的作用，并结合在线教育趋势，突出研究的必要性。\n\n5. 方法分类梳理（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者将AES方法分为传统、深度神经网络和预训练三类，并分别介绍优缺点和发展历程，形成清晰的技术脉络。\n\n6. 引用权威与数据集（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者多次引用领域内权威论文和公开数据集（如ASAP、CRP），说明研究基础扎实。\n\n7. 现有方法局限性分析（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者详细分析传统方法、深度神经网络和预训练方法的局限，如特征设计复杂、迁移性差、预训练效果有限等。\n\n8. 结构化方法描述（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：作者用分步描述和公式推导，明确各个模块（BERT、LSTM、Attention、回归层）如何协同工作，配合图示（Figure 1）增强直观性。\n\n9. 与主流方法对比实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：作者将新方法与领域内主流模型（如BERT、LSTM、传统方法）进行直接性能对比，详细列出指标提升幅度。\n\n10. 实验结果总结与分析（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：作者对实验结果进行归纳总结，指出模型在长文本和多尺度表征上的优势，并分析与其他方法的性能差异。\n",
    "cluster_size": 11,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_121",
      "ARR_2022_321",
      "ARR_2022_80",
      "ARR_2022_93",
      "ARR_2022_216",
      "ARR_2022_174",
      "ARR_2022_25",
      "ACL_2017_367",
      "COLING_2020_38",
      "COLING_2020_40",
      "COLING_2020_11"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 4,
        "percentage": "36.4%"
      },
      {
        "name": "创新点突出",
        "frequency": 2,
        "percentage": "18.2%"
      },
      {
        "name": "多指标评测",
        "frequency": 2,
        "percentage": "18.2%"
      },
      {
        "name": "领域背景铺垫",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "方法分类梳理",
        "frequency": 1,
        "percentage": "9.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_14",
    "name": "量化生成式事件抽取",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦事件检测与抽取中的类型差异与低资源问题，采用量化方法和生成式框架提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引出问题，常用tricks包括典型案例对比、数据反常现象强调、新概念命名与定义、量化指标设计等。\n第3段（60字）：适用场景与预期效果 - 适用于事件检测、低资源事件抽取等任务，预期显著提升模型在不同类型和数据集上的鲁棒性和性能。",
    "writing_guide": "写作模板：量化生成式事件抽取\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦事件检测与抽取中的类型差异与低资源问题，采用量化方法和生成式框架提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引出问题，常用tricks包括典型案例对比、数据反常现象强调、新概念命名与定义、量化指标设计等。\n第3段（60字）：适用场景与预期效果 - 适用于事件检测、低资源事件抽取等任务，预期显著提升模型在不同类型和数据集上的鲁棒性和性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Saliency as Evidence: Event Detection with Trigger Saliency Attribution》\n  • 问题定位：论文从实际痛点和学术gap双重角度引出问题。首先指出事件检测（ED）作为事件抽取的关键步骤，在不同事件类型上的表现极度不均衡，并以ACE基准数据为例，展示了最先进模型在不同类型上的巨大性能差异。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了事件类型差异’和‘现有方法在某些场景下失效’的逻辑。具体地，指出大多数方法将所有事件类型一视同仁，训练单一模型，导致对不同类型的事件表现不均衡。引用相关工作表明，尽管有研究关注上下文依赖型事件，但这些工作主要是提升性能而非探究根本原因。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先提出核心概念——触发词显著性归因（trigger saliency attribution），并解释其如何量化事件对触发词或上下文的依赖。\n  • 实验设计：实验部分采用‘多数据集验证+多指标分析’的策略。首先在ACE 2005和MAVEN两个数据集上进行主实验，确保结果具有广泛适用性。实验内容包括：数据集统计、评价指标（相关性、精确率、召回率、F1、Macro F1）、实现细节和超参数设置。\n\n示例 2：《DEGREE: A Data-Efficient Generation-Based Event Extraction Model》\n  • 问题定位：论文首先从实际痛点出发，指出事件抽取任务需要大量高质量标注数据，而这些数据的获取成本极高，限制了模型在新领域和新事件类型上的扩展能力。通过举例说明如ACE 2005数据集的高标注成本，强调了低资源事件抽取的现实需求和研究价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在低资源场景下失效’的逻辑。具体做法包括：一方面，指出主流方法依赖大量标注数据，难以扩展到新领域；另一方面，分析了分类式和生成式方法的局限，如TANL和BART-Gen等生成式方法采用管道式结构，无法充分共享知识，且输出格式不便于利用标签语义。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍DEGREE的生成式框架及其优势，随后细致拆解为DEGREE、DEGREE(ED)、DEGREE(EAE)三个子模块，分别对应事件检测和事件参数抽取，并详细说明各自的prompt设计与输出格式。\n  • 实验设计：实验部分采用‘多数据集验证+主实验’的策略。首先说明所用数据集和低资源划分方式，确保实验覆盖广泛场景。随后介绍评价指标和对比基线，包括分类式和生成式方法。主实验聚焦于不同训练数据比例下的性能对比，突出低资源场景下DEGREE的优势。实验结果以表格和可视化图展示，强调在极低数据量下的显著性能提升。\n\n示例 3：《Event Detection for Suicide Understanding》\n  • 问题定位：论文从实际社会痛点出发，指出自杀是一个严重且日益增长的问题，强调现有临床访谈方法在高自杀风险人群中难以获得参与。同时，结合应用需求，提出社交媒体数据作为新的诊断信息来源，并指出自动化分析工具的重要性。\n  • 现有研究缺口：论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体而言，指出以往自杀检测工作主要关注用户自杀倾向的整体文本分类，未能细粒度分析和识别自杀相关事件；同时，现有事件检测数据集和方法多针对一般事件类型和正式文本，缺乏针对社交媒体自杀相关事件的专用数据和方法。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先介绍了为理解自杀相关话题而进行的主题建模分析（LDA），说明数据处理和分析的总体流程。随后，展示主题分析结果，并将其归纳为学校、工作和家庭三大类，体现了方法的应用和分析深度。整体上，方法部分以数据分析为切入点，突出数据特征和事件来源。\n  • 实验设计：实验部分采用‘主实验+对比+领域适应’的策略。首先对多种主流事件检测模型进行性能评估，包括CNN、DMBERT、BERTED、BERTGCN、GatedGCN和EEGCN，涵盖了非图模型和图模型。其次，设计了领域自适应实验，通过在Reddit数据上微调BERT，分析领域定制对模型性能的影响。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 50.0%）\n   类型：writing-level\n   应用：先引入问题和现象，再提出新方法，最后通过实验验证，形成闭环。\n\n2. 典型案例对比引入（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者用DIVORCE和START-POSITION两个事件类型的极端性能差异作为切入点，直观展示现有模型的局限性。\n\n3. 数据反常现象强调（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：指出DIVORCE类型训练数据远少于START-POSITION但性能却远高，说明现有方法存在未被关注的问题。\n\n4. 提出关键科学问题（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者提出两个关键问题：如何量化事件模式、如何利用该模式提升模型鲁棒性。\n\n5. 新概念命名与定义（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：首次提出trigger saliency attribution概念，并详细解释其含义和作用。\n\n6. 类比与可解释方法借鉴（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：借鉴特征归因方法，将每个词视为特征，计算其对事件语义的贡献，帮助读者理解方法原理。\n\n7. 量化指标设计（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将trigger对事件的贡献量化为saliency value，便于后续分析和模型设计。\n\n8. 分组检测思想（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：提出按事件模式分组检测而非一刀切，展示方法的差异化优势。\n\n9. 多指标综合评估（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：采用多种指标评估方法，兼顾相关性、整体性能和类别均衡性。\n\n10. 与现有解释性指标对比（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：将trigger saliency attribution与其他解释性指标进行相关性对比，显示其相关性最高。\n",
    "cluster_size": 6,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_190",
      "ARR_2022_296",
      "ARR_2022_26",
      "ACL_2017_350",
      "ACL_2017_16",
      "COLING_2020_42"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "50.0%"
      },
      {
        "name": "典型案例对比引入",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "数据反常现象强调",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "提出关键科学问题",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "新概念命名与定义",
        "frequency": 1,
        "percentage": "16.7%"
      }
    ]
  },
  {
    "pattern_id": "pattern_15",
    "name": "高质量问题生成技术",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦教育场景下的高质量问题生成，采用QAG系统分步骤设计与SOTA方法对比验证。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引入，通过现有工作局限对比铺垫，专家标注数据集背书增强权威性，分步法流程清晰化提升可解释性，多维度评价体系确保科学性。\n\n第3段（60字）：适用场景与预期效果 - 适用于教育、对话系统等需要高质量问题生成的任务，预期提升模型生成问题的相关性和教育意义。",
    "writing_guide": "写作模板：高质量问题生成技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦教育场景下的高质量问题生成，采用QAG系统分步骤设计与SOTA方法对比验证。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点引入，通过现有工作局限对比铺垫，专家标注数据集背书增强权威性，分步法流程清晰化提升可解释性，多维度评价体系确保科学性。\n\n第3段（60字）：适用场景与预期效果 - 适用于教育、对话系统等需要高质量问题生成的任务，预期提升模型生成问题的相关性和教育意义。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《It is AI’s Turn to Ask Human a Question: Question and Answer Pair Generation for Children Storybooks in FairytaleQA Dataset》\n  • 问题定位：论文通过结合学术gap与应用需求来引出问题。首先强调了高质量、大规模阅读理解（RC）数据集对训练先进问答（QA）模型的重要性，指出现有数据集在教育领域应用时存在质量和有效性风险，尤其是在自动化生成QA对用于教育目的时表现不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视关键需求’的逻辑。具体指出现有数据集多为众包或自动检索生成，导致标注QA对的质量和有效性不足，尤其在教育场景下不适用。此外，现有QA模型虽能生成事实正确的QA对，但难以满足教育用途的有效性需求。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了QAG系统的三步流程：答案抽取、问题生成、QA对排序。随后分别详细描述每个步骤的实现方式，包括基于教育学框架的答案抽取、利用SOTA语言模型的问题生成，以及基于阈值的QA对筛选。\n  • 实验设计：实验部分采用‘主实验+多指标验证’的策略。首先明确自动化评估和人工评估两种实验类型，针对QAG任务的特殊性设计了MAP@N指标，详细说明了评估流程和理由。实验在自建数据集FairytaleQA的验证集和测试集上进行，比较了不同QAG系统在不同候选数量阈值下的表现。\n\n示例 2：《A Feasibility Study of Answer-Unaware Question Generation for Education》\n  • 问题定位：论文从实际应用需求出发引出问题，强调编写高质量、针对性强的问题（如测验题）既困难又耗时，自动化问题生成（QG）可以显著减少人工负担。通过描述教育场景下教师和学生的具体痛点（如教师出题慢、学生复习效率低），自然引出对自动化、无需人工标注答案的QG系统的需求。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法依赖于人工选择答案片段'、'在缺乏明确关键术语列表时不适用'等逻辑，指出主流的answer-aware QG模型需要人工高亮答案span，增加了使用门槛和负担，并在某些实际教育场景下不适用。\n  • 核心方法：方法部分采用了'先整体后细节'的叙述顺序。首先介绍了整体思路：借鉴多任务微调（QA+QG+答案抽取）提升模型能力，选择T5模型并说明其任务分离优势。\n  • 实验设计：实验部分采用了'多场景对比验证'的策略，设计了三类输入（原始教材文本、人写摘要、自动摘要）下的主实验，分别评估模型在不同输入条件下的表现。每类实验都详细描述了数据来源、处理方式和生成的QA对数量。\n\n示例 3：《Fantastic Questions and Where to Find Them: FairytaleQA— An Authentic Dataset for Narrative Comprehension》\n  • 问题定位：论文首先从阅读理解作为复杂认知过程的实际教育需求出发，强调高质量问题对于评估和提升学生阅读理解能力的重要性，指出现有问题生成资源和工具难以满足教育场景的精细化需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有数据集不适合/不具备/忽视了’等句式，逻辑上先指出主流数据集未围绕阅读理解子技能结构化设计，缺乏对测试子技能的信息，导致模型只能输出粗粒度分数，无法细致评估；进一步指出现有数据集多由众包工人生成，缺乏教育领域知识，难以保证问题有效性和一致性。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先简要说明FairytaleQA数据集可用于QA和QG任务，随后分别介绍QA任务的评测方法和QG任务的生成流程。QG部分进一步细分为三步：规则生成候选答案、BART生成问题、排序器验证，体现从简单到复杂、逐步细化的叙述顺序。\n  • 实验设计：实验部分采用‘主实验+多模型对比+分任务验证+细粒度分析’的叙述策略。首先对比多种主流预训练模型（BERT, BART, DistilBERT）在QA任务上的表现，确定最佳主干模型。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 现实需求铺垫（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过指出现有QA数据集在教育领域的不足和RC技能对儿童成长的重要性，强调高质量RC数据集的迫切需求。\n\n2. 现有工作局限对比（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：详细列举现有数据集和自动生成方法的缺陷，说明它们在教育领域应用时的不足，为提出新方法做铺垫。\n\n3. 专家标注数据集背书（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：强调FairytaleQA数据集由教育专家标注，并基于教育研究中的理论框架，增强数据集的科学性和适用性。\n\n4. 分步法流程清晰化（使用频率 1 次，占比 16.7%）\n   类型：method-level\n   应用：将QAG系统流程分为三个步骤（答案抽取、问题生成、QA对排序），用清晰的分步描述帮助读者把握整体架构。\n\n5. 与SOTA方法直接对比（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：明确提出与两种现有SOTA QAG系统进行对比，并在实验部分详细报告对比结果。\n\n6. 定制化评价指标设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：针对QAG任务的特殊性设计MAP@N指标，合理解决不同系统生成QA对数量不一的问题。\n\n7. 多维度评价体系（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：采用自动评价和人工评价相结合，全面考察系统性能。\n\n8. 缺陷自省与改进动机（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：指出Rouge-L指标的局限性，并说明将进一步进行人工评价，体现对实验结论的负责态度。\n\n9. 逻辑递进式叙事（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：从问题引入、现有方法不足、提出新方法、实验验证到结果分析，层层递进，逻辑清晰。\n\n10. 实际应用场景模拟（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：在评价指标选择上考虑实际应用中每段故事平均QA对数量，强调方法与真实教育场景的契合。\n",
    "cluster_size": 6,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_129",
      "ARR_2022_11",
      "ARR_2022_95",
      "ARR_2022_41",
      "ARR_2022_265",
      "COLING_2020_25"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "现实需求铺垫",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "现有工作局限对比",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "专家标注数据集背书",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "分步法流程清晰化",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "与SOTA方法直接对比",
        "frequency": 1,
        "percentage": "16.7%"
      }
    ]
  },
  {
    "pattern_id": "pattern_16",
    "name": "Siamese Network与Label Tuning",
    "summary": "第1段（60字）：针对文本分类任务中的数据稀缺问题，采用Siamese Network和Label Tuning等方法提升效率和鲁棒性。\n第2段（60字）：skeleton以实际痛点开篇，通过对比现有方法指出不足，采用‘先整体后局部’和‘分模块介绍’策略，结合实验多样性与消融分析增强说服力。\n第3段（60字）：适用于低资源文本分类任务，尤其在多语言和细粒度场景下，预期提升模型性能和部署效率。",
    "writing_guide": "写作模板：Siamese Network与Label Tuning\n\n【模板聚焦】\n第1段（60字）：针对文本分类任务中的数据稀缺问题，采用Siamese Network和Label Tuning等方法提升效率和鲁棒性。\n第2段（60字）：skeleton以实际痛点开篇，通过对比现有方法指出不足，采用‘先整体后局部’和‘分模块介绍’策略，结合实验多样性与消融分析增强说服力。\n第3段（60字）：适用于低资源文本分类任务，尤其在多语言和细粒度场景下，预期提升模型性能和部署效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Few-Shot Learning with Siamese Networks and Label Tuning》\n  • 问题定位：论文通过介绍 few-shot 和 zero-shot 学习的实际挑战引出问题，强调在文本分类任务中标注数据稀缺的痛点，并指出近年来相关方法的兴起。开篇策略结合了实际应用需求（数据稀缺带来的挑战）和学术发展趋势（zero-shot/few-shot 方法的兴起），同时用任务定义和方法现状为后文铺垫。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出主流的 Cross Attention（CA）模型虽然理论上分类准确率高，但推理效率低（每个输入需与所有标签组合），部署难度大。其次，强调常规的模型微调方式导致参数无法共享，难以大规模部署。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述顺序。先整体介绍 Siamese Network 的架构和基本原理，再细分为零样本分类的直接应用、few-shot 分类的微调方式（包括常规微调和创新的 Label Tuning），并详细给出优化目标和正则化策略。\n  • 实验设计：实验部分采用‘多基线+多数据集+对比分析’的策略。先介绍多种基线方法（随机、词向量、SVM、CA、SN等），再说明模型训练和数据集设置，涵盖英语及多语言场景。\n\n示例 2：《Incremental Intent Detection for Medical Domain with Contrast Replay Networks》\n  • 问题定位：论文首先从医疗场景的实际应用需求出发，强调医疗意图识别对于医疗问答系统的重要性。随后指出现有方法依赖预定义的固定类别集合，无法应对新意图类别的不断出现，进一步强调存储和计算成本的实际痛点。最后引入增量学习作为解决方案，形成从应用需求到方法创新的自然过渡。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在实际应用中失效’的逻辑。具体指出传统方法无法处理新类别（out-of-set问题），且重新训练不可行。对于主流的记忆回放方法，进一步指出在医疗领域面临‘训练数据不均衡’和‘医疗领域稀有词’两大新挑战，使用‘然而’、‘但是’等转折句式突出不足。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先整体介绍提出的CRN方法及其三大组成部分，然后分别详细阐述每个模块的功能和作用。描述过程中，先给出整体流程，再逐步细化到模型结构、数据处理、损失函数等细节，逻辑清晰递进。\n  • 实验设计：实验部分采用‘主实验+消融实验+多数据集验证’的策略。首先在两个基准数据集上进行主实验，报告整体准确率和最后一步的表现。随后通过消融实验分别验证方法各组成部分的有效性，分析不同模块对性能的影响。实验指标包括宏平均和微平均，参数设置详细，此外还在附录中补充了额外实验，保证结果的全面性和可靠性。\n\n示例 3：《Ranking-Constrained Learning with Rationales for Text Classification》\n  • 问题定位：论文通过实际应用需求引出问题，强调文本分类在多个现实场景（如法律文档、新闻、社交媒体分析等）中的重要性，并指出在这些场景下标注数据稀缺，人工标注成本高且难以大规模获取。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先回顾了早期和近期的 rationale 利用方法，指出这些方法要么依赖于大量标注数据（如深度学习模型需要大规模数据），要么在特征表达上有限（如仅用 bag-of-words 表示），或者在模型结构上对数据规模有较高要求（如句子级别训练）。\n  • 核心方法：方法部分的具体内容未给出，但从相关工作和实验部分推断，论文采用了先整体后局部的叙述策略。先介绍整体框架（如基于 BERT 的模型及 ranking-constrained loss），再细化到输入处理（如句子级别嵌入、截断策略）、模型结构（如隐藏层设置、激活函数选择）、参数规模和训练细节。\n  • 实验设计：实验部分采用多数据集验证的策略，涵盖了三个不同的数据集。实验流程包括主实验（对比多个 baseline 方法）、参数调优（网格搜索超参数）、学习曲线分析（不同标注预算下的表现）、结果可视化（平均曲线和误差条）、扩展实验（更大标注预算下的趋势验证）。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 与主流方法系统对比（使用频率 2 次，占比 28.6%）\n   类型：experiment-level\n   应用：与Cross Attention、Word Embedding、Char-SVM等主流和经典方法进行系统对比，展示性能。\n\n2. 创新点明确提出（使用频率 2 次，占比 28.6%）\n   类型：method-level\n   应用：明确提出Prompt-based Data Augmentation (PromDA)的核心思想，并强调仅微调soft prompts而非整个模型以避免过拟合。\n\n3. 逻辑递进式叙事结构（使用频率 2 次，占比 28.6%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新方法提出、再到实验验证，层层递进呼应结论。\n\n4. 问题极端化引入（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过介绍few-shot和zero-shot学习的极端情况，强调无标注数据下文本分类的难度和研究价值。\n\n5. 现有方法梳理与定位（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：系统梳理了当前主流的entailment/NLI方法，明确指出其优缺点，为后续提出Siamese Network方法做对比和铺垫。\n\n6. 理论与实践对比预设悬念（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：指出理论上Cross Attention模型应优于Siamese Network，但实际差距很小，激发读者好奇心。\n\n7. 方法优势突出（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：强调Siamese Network支持label embedding预计算，推理时只需一次模型调用，便于大规模部署。\n\n8. 创新点命名与概念化（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：将只微调label embedding的方法命名为Label Tuning (LT)，并系统化描述其流程和优缺点。\n\n9. 实验多样性与完备性（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：选用多种任务、多语言、多数据集进行实验，覆盖topic、情感、主观性等多种文本分类场景。\n\n10. 消融与细粒度分析（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：对比不同label verbalization、不同微调策略（如label tuning与全模型微调），分析性能变化。\n",
    "cluster_size": 7,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_298",
      "ARR_2022_43",
      "ARR_2022_176",
      "ARR_2022_313",
      "ARR_2022_47",
      "ARR_2022_311",
      "COLING_2020_3"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "与主流方法系统对比",
        "frequency": 2,
        "percentage": "28.6%"
      },
      {
        "name": "创新点明确提出",
        "frequency": 2,
        "percentage": "28.6%"
      },
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "28.6%"
      },
      {
        "name": "问题极端化引入",
        "frequency": 1,
        "percentage": "14.3%"
      },
      {
        "name": "现有方法梳理与定位",
        "frequency": 1,
        "percentage": "14.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_17",
    "name": "结构图谱预测方法",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义分析任务中的结构建模难题，采用直接预测结构图谱的方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以学术gap开篇，通过多数据集验证和多指标评估增强实验说服力，常用tricks包括直接对比强基线、多随机种子实验和明确声明创新点。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确结构建模的语义分析任务，如情感分析、依存句法分析和语义角色标注，预期提升结构表示和预测准确性。",
    "writing_guide": "写作模板：结构图谱预测方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义分析任务中的结构建模难题，采用直接预测结构图谱的方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以学术gap开篇，通过多数据集验证和多指标评估增强实验说服力，常用tricks包括直接对比强基线、多随机种子实验和明确声明创新点。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确结构建模的语义分析任务，如情感分析、依存句法分析和语义角色标注，预期提升结构表示和预测准确性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Direct parsing to sentiment graphs》\n  • 问题定位：论文通过介绍结构化情感分析（SSA）任务的定义和复杂性引出问题，强调该任务需要识别句子中的完整情感元组（包括极性表达、持有者、目标和极性），并指出虽然相关语料库已有多年，但现有研究多聚焦于子任务而非整体结构，突出学术上的gap。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法只能处理部分结构或需要信息损失的转换’的逻辑。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述策略。首先简要介绍所采用的PERIN模型及其适应SSA任务的修改，随后说明与现有依存句法分析方法的对比实验设计。方法介绍较为简明，强调模型的整体架构和创新点，细节部分则建议参考原始文献，突出本工作的改进和实验对比的公正性。\n  • 实验设计：实验部分采用‘多数据集验证+多指标评估’的策略。首先说明在四种语言的五个数据集上进行实验，覆盖多领域和多语言，增强结果的普适性。评估指标包括实体抽取的token-level F1和结构级别的图F1（NSF1和SF1），并对比不同编码方式和现有强基线。\n\n示例 2：《Improve Discourse Dependency Parsing with Contextualized Representations》\n  • 问题定位：论文通过强调话语依存分析（DDP）在自然语言理解中的基础性作用及其对下游应用的益处来引出问题，结合实际痛点（如EDU的表示困难、依存关系预测需要全局上下文）和学术gap（现有方法在表示EDU和捕捉上下文信息方面存在挑战），并通过具体实例（如科学摘要中的EDU长度变化和跨句依存）说明现有方法难以...\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在X方面存在不足’的逻辑，如指出传统方法和神经模型在EDU表示和上下文捕捉上不够充分，且未能有效区分句内和句间信息。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略，首先介绍任务分解为依存树构建和关系识别两个子任务，接着以Sent-First框架为主线，说明先句内建树再句间组装的流程。\n  • 实验设计：实验部分采用‘多数据集验证+主实验’的策略，分别在英文和中文两个话语树库上进行实验，涵盖不同语言和文本类型。实验设计围绕主任务（依存预测和关系识别）展开，详细说明数据集统计、评价指标（UAS/LAS）、模型训练细节，并通过对比传统特征工程、LSTM、BERT等多种基线方法，突出新方法的优势。\n\n示例 3：《Auxiliary tasks to boost Biaffine Semantic Dependency Parsing》\n  • 问题定位：论文从任务本身的结构复杂性和决策间高度相关性出发引出问题，强调语义依存分析（SDP）与传统依存句法分析（DP）在结构约束上的不同，指出SDP缺乏树结构约束导致决策间依赖更难处理。这种开篇策略结合了学术gap（结构约束缺失带来的挑战）和实际任务复杂性，聚焦于现有方法在处理依存关系决策相关性上的不足。\n  • 现有研究缺口：论文通过梳理现有方法（如高阶图模型、序列决策模型、biaffine模型等），批评现有方法要么计算复杂度高（如二阶图模型O(n^3)），要么存在错误传播（如序列决策模型），或者决策完全独立（如biaffine模型），未能充分捕捉依存关系间的相互影响。\n  • 核心方法：方法部分采用‘先整体后细节’的策略，首先明确采用简单高效的biaffine架构作为基础（O(n^2)复杂度），然后在此基础上引入辅助任务（auxiliary tasks）以增强模型能力。\n  • 实验设计：实验部分采用‘主实验+消融+多数据集验证’的综合策略。首先在高基线（预训练模型+Biaffine）上测试辅助任务的增益，报告多次重复的宏平均F分数，进行不同辅助任务组合的消融实验。其次，实验覆盖法语和英语两个数据集，检验方法的跨语言适用性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 27.3%）\n   类型：writing-level\n   应用：从问题定义、现有方法不足、提出新方法、详细实验对比到结果分析，层层递进，逻辑清晰。\n\n2. 问题现状对比引入（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：通过回顾已有方法的不足（如仅关注子任务、依赖中间转换等），引出自身方法直接预测情感图谱的优势和研究动机。\n\n3. 权威数据集覆盖（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：选用多个权威公开数据集（五个数据集、四种语言）进行实验，展示方法的广泛适用性和稳健性。\n\n4. 多指标综合评估（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：采用多种评测指标（token-level F1、NSF1、SF1）全面评估模型性能，突出方法在结构层面和局部抽取上的表现。\n\n5. 与最新强基线直接对比（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：将方法与当前最优的依存句法图模型和注意力模型进行直接对比，并量化性能提升（如SF1提升6.2pp）。\n\n6. 创新点明确声明（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：明确指出本方法为首个直接从文本预测情感图谱、无需启发式中间转换的模型，并借鉴了语义表示领域的最新进展。\n\n7. 方法原理简明转述（使用频率 1 次，占比 9.1%）\n   类型：method-level\n   应用：简要介绍PERIN模型的核心思想和与原始版本的区别，鼓励读者查阅原文获取细节。\n\n8. 多随机种子多次实验（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：所有模型均采用5个不同随机种子重复实验，报告均值和标准差，减少偶然性影响。\n\n9. 细致的结构性结果分析（使用频率 1 次，占比 9.1%）\n   类型：experiment-level\n   应用：分别分析不同编码方式在结构级和局部抽取任务上的表现，指出方法主要优势在结构层面。\n\n10. 补充材料指引（使用频率 1 次，占比 9.1%）\n   类型：writing-level\n   应用：在正文中指明附录中包含开发集结果和训练细节，方便有需要的读者深入查阅。\n",
    "cluster_size": 11,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_279",
      "ARR_2022_21",
      "ARR_2022_125",
      "ARR_2022_250",
      "ARR_2022_65",
      "ACL_2017_654",
      "ACL_2017_355",
      "COLING_2020_15",
      "COLING_2020_44",
      "COLING_2020_46",
      "COLING_2020_19"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "27.3%"
      },
      {
        "name": "问题现状对比引入",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "权威数据集覆盖",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "多指标综合评估",
        "frequency": 1,
        "percentage": "9.1%"
      },
      {
        "name": "与最新强基线直接对比",
        "frequency": 1,
        "percentage": "9.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_18",
    "name": "自解释模型与rationale生成",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨模型解释性，通过设计自解释模型和人类实验验证，聚焦于rationale长度与解释效果的关系。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题导向开篇，结合现有方法不足，常用tricks包括质疑主流假设、引用最新工作、分步阐述方案、对比实验结果等。\n第3段（60字）：适用场景与预期效果 - 适用于NLP任务中模型解释性研究，特别是rationale生成与人类理解相关实验，预期提升解释准确性和模型透明度。",
    "writing_guide": "写作模板：自解释模型与rationale生成\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨模型解释性，通过设计自解释模型和人类实验验证，聚焦于rationale长度与解释效果的关系。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题导向开篇，结合现有方法不足，常用tricks包括质疑主流假设、引用最新工作、分步阐述方案、对比实验结果等。\n第3段（60字）：适用场景与预期效果 - 适用于NLP任务中模型解释性研究，特别是rationale生成与人类理解相关实验，预期提升解释准确性和模型透明度。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Are Shortest Rationales the Best Explanations For Human Understanding?》\n  • 问题定位：论文通过结合实际痛点和学术gap来引出问题。首先强调神经网络在NLP任务中的高性能带来的可解释性需求，指出模型决策的可解释性对用户理解至关重要。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘仅用自动指标而未进行人类评估’的逻辑。具体指出现有自解释模型普遍假定短rationale更易于人类理解，但这一假设缺乏人类实验验证。还强调当前方法主要依赖自动化指标评估，没有系统性地考察rationale长度对人类理解的影响，凸显研究空白。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的策略。首先介绍典型自解释模型的整体框架，包括输入、mask生成、rationale提取和分类器预测。随后详细分解各模块（identifier、mask生成、rationale提取、classifier），并阐述优化目标和正则化项。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+消融+人类实验’的叙述策略。首先在五个ERASER基准数据集上进行主实验，比较方法与多种基线的端任务预测性能。其次，报告模型与人工注释的一致性（Token-level F1等指标）。再次，进行消融实验分析各模块贡献。\n\n示例 2：《GlobEnc: Quantifying Global Token Attribution by Incorporating the Whole Encoder Layer in Transformers》\n  • 问题定位：论文从学术gap出发引出问题。开篇先强调Transformer模型的卓越表现引发了对其有效性原因的关注，随后聚焦于自注意力机制的解释性分析，并指出围绕注意力权重解释的争议。接着引用最新研究表明仅用注意力权重不足以解释模型行为，提出需引入向量范数，但这些工作仍有不足。\n  • 现有研究缺口：论文批评现有方法时采用了‘现有方法忽视了X’和‘现有方法在Y方面受限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后细节、分模块递进’的叙述策略。首先整体说明方法的目标是全局归因分析，强调要覆盖编码器层的所有主要组件。然后对比并扩展已有的norm-based分析，详细介绍如何引入第二层归一化和残差连接，指出与以往工作的区别。接着介绍如何聚合多层归因，详细解释rollout技术及其适配。\n  • 实验设计：实验部分采用‘主实验+消融分析’的策略。首先说明实验设置和所用数据集，随后对比多种归因分析方法，逐步引入不同的编码器层组件，考察各部分对整体性能的贡献（即消融分析）。主要实验是对比不同方法与梯度法的相关性，辅以消融实验分析各组件的影响。\n\n示例 3：《Locally Aggregated Feature Attribution on Natural Language Understanding》\n  • 问题定位：论文从实际应用痛点出发引出问题，强调随着深度学习模型的流行，模型可解释性和理解变得越来越重要。通过举例说明模型理解在特征发现、模型调试和决策信任等方面的关键作用，进一步指出在NLP领域，尽管深度模型表现优异，但其内部机制难以理解，亟需更好的解释方法。整体采用了‘应用需求驱动+现有挑战’的开篇策略。\n  • 现有研究缺口：论文通过对现有方法的系统梳理，指出了两类主流方法的不足：一是模型无关方法（如Shapley值、LIME）虽通用但在高维和复杂模型下计算效率低下；二是模型特定的梯度法虽然高效，但梯度本身噪声大且难以解释，尤其在NLP中由于输入为离散token且参考token难以定义，直接应用存在困难。\n  • 核心方法：方法部分采用‘先整体后细节’的叙述顺序，首先概述提出的LAFA方法的三大步骤（邻居查找、梯度计算、梯度聚合），随后对每一步进行详细分解说明，包括如何在嵌入空间中查找相似文本、如何计算和聚合梯度，并结合动机示例说明每一步的必要性。整体结构清晰，分模块介绍，逻辑递进。\n  • 实验设计：实验部分采用‘主实验+分析实验’的叙述策略。首先在无标签和有标签两种场景下，系统比较所提方法与主流基线（Simple Gradient, Smooth Gradient等）的性能，分析不同邻居数和不同编码层的影响，并通过表格展示结果。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 引用权威文献建立背景（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者在引言中大量引用Vaswani et al., 2017等权威文献，说明Transformer及注意力机制的重要性，为后续研究提供坚实背景。\n\n2. 逻辑递进式叙事结构（使用频率 2 次，占比 25.0%）\n   类型：writing-level\n   应用：作者先提出问题和挑战，再分析现有方法的不足，最后通过实验验证自己的观点，形成完整闭环。\n\n3. 问题反转与质疑主流假设（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者质疑‘最短rationale’是否真的有助于人类理解，提出与主流观点相反的问题，强调现有方法的局限性。\n\n4. 引用最新相关工作（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者广泛引用近年相关文献，说明当前主流做法和存在的不足，为自己的创新点铺垫。\n\n5. 明确提出研究问题（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者直接提出核心研究问题：‘最短rationales真的有助于人类理解吗？’并说明将系统性检验。\n\n6. 分步阐述研究方案（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者将工作分为两步：模型设计与人类实验，条理清晰地介绍整体研究流程。\n\n7. 对比实验结果与直觉（使用频率 1 次，占比 12.5%）\n   类型：writing-level\n   应用：作者指出实验结果与主流直觉（最短rationale最好）相反，强调自身工作的实际意义。\n\n8. 方法模块化分解（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：作者将方法分为identifier和classifier两大模块，分别介绍其功能和优化目标。\n\n9. 公式化与变量定义（使用频率 1 次，占比 12.5%）\n   类型：method-level\n   应用：作者用数学公式详细定义模型流程、优化目标和变量含义。\n\n10. 多层次消融实验（使用频率 1 次，占比 12.5%）\n   类型：experiment-level\n   应用：作者设计消融实验，分析不同模型组件对最终结果的影响。\n",
    "cluster_size": 8,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_170",
      "ARR_2022_314",
      "ARR_2022_122",
      "ARR_2022_319",
      "ARR_2022_201",
      "ARR_2022_218",
      "ARR_2022_257",
      "ACL_2017_657"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "引用权威文献建立背景",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "25.0%"
      },
      {
        "name": "问题反转与质疑主流假设",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "引用最新相关工作",
        "frequency": 1,
        "percentage": "12.5%"
      },
      {
        "name": "明确提出研究问题",
        "frequency": 1,
        "percentage": "12.5%"
      }
    ]
  },
  {
    "pattern_id": "pattern_19",
    "name": "对抗样本生成与验证",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型在对抗攻击和数据偏差下的脆弱性，采用生成对抗样本和生成式对抗方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过对比实验和多数据集验证方法效果，常用tricks包括引用权威文献、具体案例举例和逻辑递进的叙事结构。\n第3段（60字）：适用场景与预期效果 - 适用于NLP中的对抗攻击检测、数据偏差修正等任务，预期提升模型的鲁棒性和泛化能力，增强实际应用中的可靠性。",
    "writing_guide": "写作模板：对抗样本生成与验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决模型在对抗攻击和数据偏差下的脆弱性，采用生成对抗样本和生成式对抗方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过对比实验和多数据集验证方法效果，常用tricks包括引用权威文献、具体案例举例和逻辑递进的叙事结构。\n第3段（60字）：适用场景与预期效果 - 适用于NLP中的对抗攻击检测、数据偏差修正等任务，预期提升模型的鲁棒性和泛化能力，增强实际应用中的可靠性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《A Rationale-Centric Framework for Human-in-the-loop Machine Learning》\n  • 问题定位：论文首先从实际痛点出发，指出数据集中的自然伪影（artefacts）和虚假模式（spurious patterns）会导致神经网络模型性能下降，特别是在小样本学习（few-shot learning）场景下问题更为严重。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法存在局限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部、分模块介绍’的叙述策略。首先整体介绍RDL框架包含两个主要模块：静态半事实生成（Static Semi-factual Generation）和动态人工干预修正（Dynamic Human-intervened Correction）。\n  • 实验设计：实验部分采用‘主实验+多数据集验证’的策略。首先明确实验目标和研究问题（如静态半事实生成和动态修正对模型泛化能力的提升），然后在IMDb等数据集上模拟小样本学习场景进行主实验，评估方法在in-distribution和OOD（out-of-distribution）上的表现。\n\n示例 2：《Flooding-X: Improving BERT’s Resistance to Adversarial Attacks via Loss-Restricted Fine-Tuning》\n  • 问题定位：论文从实际痛点出发引出问题，首先指出当前主流的深度神经网络（如BERT）在面对精心设计的对抗攻击时性能急剧下降，强调了这一问题在实际NLP应用中的严重性。接着梳理了已有的防御方法（如对抗数据增强、正则化、对抗训练），指出这些方法虽然有效但带来了巨大的计算开销，尤其是在大规模任务上几乎不可行。\n  • 现有研究缺口：论文批评现有方法主要采用了'现有方法在实际大规模任务中效率低下'和'现有方法依赖额外对抗样本'的逻辑。具体句式包括：'然而，生成对抗样本会极大增加训练成本，使得原始对抗训练在大规模NLP任务上几乎不可行'，以及'这些方法仍然依赖于模型自身或额外模块生成对抗样本'。\n  • 核心方法：方法部分采用了'先整体后局部'的叙述策略。首先简要介绍了Flooding-X的核心思想和与现有方法的区别，突出其无需对抗样本且计算成本与常规BERT微调相同的优势。\n  • 实验设计：实验部分采用了'多数据集验证+主实验对比'的策略。首先在五个不同规模和任务类型的数据集上进行了广泛实验，涵盖情感分析、文本蕴含、新闻分类等，验证方法的通用性和有效性。实验对比了Flooding-X与多种主流对抗训练和正则化方法，在多种攻击方式下评估鲁棒性。\n\n示例 3：《Generating Authentic Adversarial Examples beyond Meaning-preserving with Doubly Round-trip Translation》\n  • 问题定位：论文首先介绍了神经机器翻译（NMT）近年来取得的进展，但紧接着指出NMT模型在面对输入微小扰动时表现不稳定，性能大幅下降。通过引用相关文献，强调了对抗样本在NMT中的重要性和挑战，明确指出如何有效生成和利用对抗样本仍是一个开放性问题。\n  • 现有研究缺口：论文批评现有方法时，首先指出传统对抗样本生成方法严格遵循语义保持假设，导致可搜索空间受限。进一步指出，在离散文本数据上进行微小扰动很难保证语义不变，甚至可能改变或颠倒原意，从而破坏了语义保持假设。\n  • 核心方法：方法部分先简要介绍了Masked Language Model（MLM）及其在数据增强中的应用，随后说明了与相关工作的区别。接着，论文分两步展开：先提出对NMT对抗样本的新定义，再详细介绍如何基于Transformer架构的MLM构建双语对抗样本。方法细节包括模型配置、参数设置及评测指标。\n  • 实验设计：实验部分首先区分了人工噪声和自然噪声两类实验场景。人工噪声实验包括删除、交换、插入、源端替换、双端替换五种类型，并在多个噪声比例下进行。自然噪声实验则在实际数据集上测试。实验结果通过BLEU分数和回译BLEU分数进行评估，并与多种基线方法进行对比。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进的叙事结构（使用频率 3 次，占比 21.4%）\n   类型：writing-level\n   应用：先引入问题、再分析现有方法不足、提出新方法、详细分模块介绍、最后通过多维实验验证，结构严谨、层层递进。\n\n2. 与主流方法系统对比（使用频率 3 次，占比 21.4%）\n   类型：experiment-level\n   应用：在实验部分系统性地与FGM、FreeLB++、ADA、ASCC、DNE等多种方法进行对比，展示GAT的优越性。\n\n3. 对比实验设计（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：设置多组对比实验（如Static, Static+n, Duplication, Full等），并在多个数据集和场景下评测，突出新方法的性能提升。\n\n4. 多维度评价指标（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：引入Clean%、Aua%、Suc%、#Query等多项指标，全面评估模型在干净和对抗样本下的表现。\n\n5. 多数据集覆盖（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：在五个不同规模和任务的数据集上进行实验，展示方法的普适性和稳定性。\n\n6. 引用权威工作增强可信度（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：大量引用BERT、PGD、TextAttack等主流工作，增强论述的学术权威性。\n\n7. 引用权威文献建立背景（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：在引言部分大量引用NMT和对抗样本相关的经典文献，说明问题的重要性和研究的前沿性。\n\n8. 逻辑递进式叙事结构（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新点提出、方法描述到实验验证，层层递进，结构清晰。\n\n9. 领域差异强调（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：作者强调图像和NLP领域输入的本质差异，指出已有图像领域的对抗样本研究难以直接迁移到NLP领域，突出研究空白。\n\n10. 现实动机引入（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：通过强调对话系统在实际应用中面临的安全与鲁棒性挑战，强调攻击和防御研究的现实意义。\n",
    "cluster_size": 14,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_252",
      "ARR_2022_145",
      "ARR_2022_55",
      "ARR_2022_353",
      "ARR_2022_77",
      "ARR_2022_106",
      "ARR_2022_109",
      "ARR_2022_134",
      "ARR_2022_4",
      "ARR_2022_16",
      "ARR_2022_74",
      "ARR_2022_317",
      "ARR_2022_172",
      "ARR_2022_111"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进的叙事结构",
        "frequency": 3,
        "percentage": "21.4%"
      },
      {
        "name": "与主流方法系统对比",
        "frequency": 3,
        "percentage": "21.4%"
      },
      {
        "name": "对比实验设计",
        "frequency": 2,
        "percentage": "14.3%"
      },
      {
        "name": "多维度评价指标",
        "frequency": 2,
        "percentage": "14.3%"
      },
      {
        "name": "多数据集覆盖",
        "frequency": 2,
        "percentage": "14.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_20",
    "name": "多语言预训练迁移学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨语言迁移中的数据稀缺和方法局限，采用多语言预训练模型和数据选择策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过文献回顾定位gap，方法部分采用整体到细节的叙述，实验设计多任务多语言覆盖。\n第3段（60字）：适用场景与预期效果 - 适合低资源语言的NLP任务，预期提升迁移性能和泛化能力，增强模型在未见数据上的表现。",
    "writing_guide": "写作模板：多语言预训练迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决跨语言迁移中的数据稀缺和方法局限，采用多语言预训练模型和数据选择策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过文献回顾定位gap，方法部分采用整体到细节的叙述，实验设计多任务多语言覆盖。\n第3段（60字）：适用场景与预期效果 - 适合低资源语言的NLP任务，预期提升迁移性能和泛化能力，增强模型在未见数据上的表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《“Diversity and Uncertainty in Moderation” are the Key to Data Selection for Multilingual Few-shot Transfer》\n  • 问题定位：论文从实际痛点出发引入问题，强调全球语言资源极度不均衡，绝大多数语言缺乏任务相关的标注数据。通过引用权威数据（如95%的语言几乎没有标注数据）和文献，凸显了跨语言零样本迁移的现实需求和挑战，明确提出了当前NLP领域面临的资源瓶颈和应用需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法在特定场景下失效’和‘忽视了实际应用中的关键问题’的逻辑。具体指出零样本迁移在语言类型差异大或目标语言无足够无标注数据时效果不佳，并且收集大规模目标语言标注数据既昂贵又耗时。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略，先介绍跨语言迁移和数据选择的总体框架，再逐步细化到具体的数据采样技术和参数设置。方法描述聚焦于如何在有限标注样本下优化训练数据选择，强调与主动学习和领域自适应等相关技术的联系，并明确本研究仅进行一次采样迭代以适应少量样本的实际场景。\n  • 实验设计：实验部分采用‘多任务、多语言、多参数’的主实验验证策略。首先在多语言（20种语言，涵盖不同语系）和多任务（序列标注、分类）上进行主实验，细致比较不同采样策略的效果。实验按迁移难度分组（C1、C2、C3），并报告不同参数设置下的性能提升。\n\n示例 2：《Cross-Lingual Event Detection via Optimized Adversarial Training》\n  • 问题定位：论文从学术gap出发引出问题。开篇先简要介绍事件检测（ED）的定义和重要性，指出其在信息抽取领域的地位和挑战，随后强调当前研究主要集中在单语（monolingual）场景，跨语种事件检测（CLED）则面临更多独特挑战，如触发词在不同语言中的表达差异、语义歧义等。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法在Y场景下失效”和“现有方法忽视了X”两种逻辑。具体表现为：指出大多数已有工作局限于单语环境，忽视了跨语种场景下的特殊挑战；即使是采用多语种预训练模型（如mBERT）的跨语种方法，也无法有效应对触发词表达差异和语义歧义等难点。\n  • 核心方法：方法部分采用“先整体后局部”的叙述策略。首先简要介绍了当前最优基线模型BERT-CRF的整体架构和工作流程，作为对比基础。随后，详细描述了作者提出的OACLED模型的核心创新点——如何利用目标语言的无标注数据，通过优化的对抗性训练提升模型的语言无关性。\n  • 实验设计：实验部分采用“多数据集、多语言对主实验验证”的策略。首先说明实验覆盖8种语言对，涉及ACE05和ACE05-ERE两个数据集，体现方法的广泛适用性。实验对比了两个强基线（BERT-CRF和XLM-R-CRF），并在所有语言对上报告平均结果，突出方法的稳定性和普适性。\n\n示例 3：《Make the Best of Cross-lingual Transfer: Evidence from POS Tagging with over 100 Languages》\n  • 问题定位：论文首先从实际痛点出发，指出当前自然语言处理任务普遍依赖于有标注数据的微调方法，但许多语言（尤其是低资源语言）缺乏任务相关的标注数据，导致主流方法难以应用。接着，论文引出跨语言微调作为潜在解决方案，并进一步指出评估跨语言泛化能力时常用的做法和其局限性，为后续问题展开铺垫。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法存在隐含假设'和'现有方法覆盖不全'的逻辑。具体地，指出现有跨语言评测通常只用英语作为源语言，隐含了英语具有代表性这一假设，但实际不同源-目标语言之间的相似性会影响迁移效果。\n  • 核心方法：方法部分采用了'先整体后细节'的叙述策略。首先整体描述了实验设计：在不同源-目标语言组合上微调预训练模型，形成一个大规模准确率矩阵。\n  • 实验设计：实验部分以主实验为核心，采用可视化（热力图）展示所有源-目标语言组合的准确率，突出单语与跨语表现的差异。随后，进行定量分析，通过混合效应回归模型评估不同预测因子的贡献，并报告模型解释度（R2）和各随机效应的方差分解。整体策略为：主实验+可视化+统计建模分析，强调对跨语言迁移表现的系统性和多角度解释。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 创新点突出（使用频率 3 次，占比 23.1%）\n   类型：method-level\n   应用：提出针对few-shot跨语言迁移的数据选择策略，并说明与传统主动学习的区别（如仅一轮选择）。\n\n2. 逻辑递进式叙事结构（使用频率 3 次，占比 23.1%）\n   类型：writing-level\n   应用：先提出问题、梳理现状，再介绍方法，最后系统实验并回扣前述问题，形成完整闭环。\n\n3. 引用权威工作（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：通过引用Conneau et al., Devlin et al.等权威文献，说明本工作与主流研究接轨，增强说服力。\n\n4. 逻辑递进式结构（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：从问题提出、现有不足、方法设计到实验验证，层层递进，逻辑清晰。\n\n5. 问题动机强化（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：通过强调多语言数据标注的高成本和实际困难，明确提出研究动机和现实背景，吸引读者关注问题的重要性。\n\n6. 现有方法局限性对比（使用频率 2 次，占比 15.4%）\n   类型：writing-level\n   应用：作者详细分析了现有方法（如依赖外部知识库、难以获取等）的局限性，为提出新方法做铺垫。\n\n7. 数据稀缺性强调（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：通过引用权威数据（如95%的语言缺乏标注数据），强调跨语言资源分布极度不均，凸显研究的现实意义。\n\n8. 文献回顾与现有方法梳理（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：系统回顾了跨语言迁移、主动学习和数据选择相关的经典文献，说明已有方法的局限和本工作的切入点。\n\n9. 问题分层与归类（使用频率 1 次，占比 7.7%）\n   类型：writing-level\n   应用：将语言按迁移难度分为C1、C2、C3等组，明确不同组的挑战和方法适用性。\n\n10. 参数敏感性分析（使用频率 1 次，占比 7.7%）\n   类型：experiment-level\n   应用：通过实验报告不同参数（λ和γ）设置下的效果，说明方法对参数的敏感性和最佳配置。\n",
    "cluster_size": 13,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_20",
      "ARR_2022_169",
      "ARR_2022_344",
      "ARR_2022_1",
      "ARR_2022_302",
      "ARR_2022_128",
      "ARR_2022_110",
      "ARR_2022_75",
      "ARR_2022_94",
      "ARR_2022_263",
      "ARR_2022_249",
      "ARR_2022_50",
      "ARR_2022_350"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "创新点突出",
        "frequency": 3,
        "percentage": "23.1%"
      },
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "23.1%"
      },
      {
        "name": "引用权威工作",
        "frequency": 2,
        "percentage": "15.4%"
      },
      {
        "name": "逻辑递进式结构",
        "frequency": 2,
        "percentage": "15.4%"
      },
      {
        "name": "问题动机强化",
        "frequency": 2,
        "percentage": "15.4%"
      }
    ]
  },
  {
    "pattern_id": "pattern_21",
    "name": "多任务验证的可控生成框架",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决可控自然语言生成中的局限性，采用新颖框架和多任务验证策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际应用痛点开篇，通过对比现有方法指出gap，方法部分采用整体框架+模块细节，实验设计多任务验证+对比。\n第3段（60字）：适用场景与预期效果 - 适用于需要多属性控制和高效生成的自然语言生成任务，预期提升可控性和生成质量。",
    "writing_guide": "写作模板：多任务验证的可控生成框架\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决可控自然语言生成中的局限性，采用新颖框架和多任务验证策略。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际应用痛点开篇，通过对比现有方法指出gap，方法部分采用整体框架+模块细节，实验设计多任务验证+对比。\n第3段（60字）：适用场景与预期效果 - 适用于需要多属性控制和高效生成的自然语言生成任务，预期提升可控性和生成质量。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Controllable Natural Language Generation with Contrastive Prefixes》\n  • 问题定位：论文通过介绍可控自然语言生成（NLG）的目标和实际应用场景（如话题、情感控制等），从应用需求出发引入问题。同时，作者指出现有方法在参数规模、推理速度和多属性控制等方面存在不足，结合学术gap进行问题铺垫。整体开篇策略是先点明NLG的实际需求，再逐步引入当前方法的局限性，突出改进空间。\n  • 现有研究缺口：论文批评现有方法时采用了对比和举例的逻辑，具体包括：指出某些方法（如CTRL、GeDi）参数量大、训练成本高；某些方法（如GeDi）只能单属性控制，忽略多属性需求；PPLM推理速度慢；Prefix-tuning虽轻量但每个前缀独立训练，未考虑属性间关系。\n  • 核心方法：方法部分先整体介绍prefix-tuning的基本思想和与前人工作的区别，随后详细阐述作者提出的多前缀联合训练框架，包括参数结构、训练方式（监督/无监督）、损失函数设计等。叙述顺序为：先介绍整体框架，再分模块介绍具体实现（参数结构、损失函数、训练流程），并穿插与前人工作的对比，突出创新点。\n  • 实验设计：实验部分采用主实验+消融实验的策略，覆盖多种任务（情感控制、去毒化、话题控制），并与多种基线方法（GPT2、PPLM、GeDi）进行对比。实验设计包括不同训练集规模下的鲁棒性验证、无监督方法的效果分析、消融实验（对比损失函数的作用），并对方法在不同任务上的适用性和局限性进行讨论。\n\n示例 2：《MReD: A Meta-Review Dataset for Structure-Controllable Text Generation》\n  • 问题定位：论文通过梳理文本生成领域的主要任务类型（more-to-less、less-to-more、neck-to-neck），指出现有任务设置缺乏对领域知识的深入理解，尤其是在文本摘要等应用中无法满足用户的主观结构需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统数据集和方法未能考虑领域知识和结构化控制，无法解释为何同一内容会有不同标题或结构，且现有同行评审数据集缺乏结构化标注。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。\n  • 实验设计：实验部分采用‘主实验+对比+人工评价’的策略。首先对数据集进行预处理和划分，主实验包括对比多种生成方法（extractive、transformer-based等）在不同控制设置下的表现，并用ROUGE指标进行量化评估。\n\n示例 3：《CORWA: A Citation-Oriented Related Work Annotation Dataset》\n  • 问题定位：论文从学术gap出发引出问题，强调学术研究的前沿性和创新性，指出每篇论文都需要在相关工作部分与前人工作进行比较。作者进一步指出，相关工作部分在同一领域内内容和格式高度相似，因此有自动生成相关工作部分的实际需求。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体指出以往方法将相关工作生成简化为句子级摘要任务，未能区分不同信息来源的异质文本片段和多样化写作风格。此外，批评现有数据集多为自动抽取，缺乏细致人工标注，未能支持更复杂的生成任务。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍整体模型架构（联合相关工作标注器），说明采用Transformer编码器对段落独立编码，并联合训练三项任务。随后分别介绍各子任务的标签方式和机制，强调多任务学习和编码器共享。整体先给出框架，再细化到各模块和任务的具体实现。\n  • 实验设计：实验部分先介绍主实验流程，包括五折交叉验证和模型性能评估。接着描述如何利用自动标注扩展数据集，并用扩展数据进一步提升模型性能。随后介绍基于LED的大规模生成基线实验，涵盖预训练、输入结构、训练细节等。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 与主流方法系统对比（使用频率 3 次，占比 30.0%）\n   类型：experiment-level\n   应用：与GPT2、PPLM、GeDi等主流方法进行系统对比，表明新方法在可控性和语言质量上的优势。\n\n2. 引用权威工作（使用频率 3 次，占比 30.0%）\n   类型：writing-level\n   应用：多次引用相关领域的最新研究和权威文献，表明作者的方法是在现有研究基础上的改进和补充。\n\n3. 逻辑递进式叙事结构（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：从问题引入、现有方法不足、创新方案提出、方法细节、实验验证到结论，层层递进，逻辑清晰。\n\n4. 问题驱动引入（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：通过指出现有Transformer模型在受控生成方面的不足，强调全局属性控制生成仍是活跃研究领域，为新方法的提出制造需求。\n\n5. 类比与直观解释（使用频率 2 次，占比 20.0%）\n   类型：writing-level\n   应用：将方法与‘product of experts’和‘能量模型’等直观概念类比，降低理解门槛。\n\n6. 现有方法梳理与局限性突出（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：作者系统梳理了主流可控NLG方法（如CTRL、GeDi、PPLM、Prefix-tuning），并逐一指出它们在参数量、速度、多属性控制等方面的不足，强调新方法的切入点和价值。\n\n7. 参数效率与速度优势强调（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：通过对比GeDi和Prefix-tuning的参数量和推理速度，突出本方法引入的参数极少且推理速度接近原始GPT2，为方法的实用性背书。\n\n8. 关系建模创新点突出（使用频率 1 次，占比 10.0%）\n   类型：method-level\n   应用：作者提出将属性间的关系（如对立性）融入prefix训练，并用“同时训练多个prefix”与“引入判别损失”明确区别于以往单独训练prefix的做法。\n\n9. 图示辅助理解（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：多次引用和描述图（如Figure 1、Figure 2、Figure 3）来直观展示prefix控制、训练流程和生成过程，使复杂机制易于理解。\n\n10. 分层次方法讲解（使用频率 1 次，占比 10.0%）\n   类型：writing-level\n   应用：先介绍整体框架，再分别阐述监督、无监督和半监督方法，并用公式和直观解释逐步展开损失函数设计。\n",
    "cluster_size": 10,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_15",
      "ARR_2022_126",
      "ARR_2022_303",
      "ARR_2022_205",
      "ARR_2022_266",
      "ARR_2022_88",
      "ARR_2022_45",
      "ARR_2022_299",
      "ARR_2022_165",
      "COLING_2020_53"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "与主流方法系统对比",
        "frequency": 3,
        "percentage": "30.0%"
      },
      {
        "name": "引用权威工作",
        "frequency": 3,
        "percentage": "30.0%"
      },
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 2,
        "percentage": "20.0%"
      },
      {
        "name": "问题驱动引入",
        "frequency": 2,
        "percentage": "20.0%"
      },
      {
        "name": "类比与直观解释",
        "frequency": 2,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_22",
    "name": "视觉语言数据增强方法",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决视觉-语言任务中的数据规模与标注成本矛盾，通过创新方法提升模型泛化能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题驱动开篇，引入权威工作增强说服力，分步阐述创新方法并用图示辅助理解，多方法对比验证效果。\n第3段（60字）：适用场景与预期效果 - 适用于视觉问答、图像描述等任务，数据集如VQAv2、SNLI-VE，预期提升零样本和小样本学习性能。",
    "writing_guide": "写作模板：视觉语言数据增强方法\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决视觉-语言任务中的数据规模与标注成本矛盾，通过创新方法提升模型泛化能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton采用问题驱动开篇，引入权威工作增强说服力，分步阐述创新方法并用图示辅助理解，多方法对比验证效果。\n第3段（60字）：适用场景与预期效果 - 适用于视觉问答、图像描述等任务，数据集如VQAv2、SNLI-VE，预期提升零样本和小样本学习性能。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《CLIP Models are Few-shot Learners: Empirical Studies on VQA and Visual Entailment》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先介绍了视觉-语言理解（VLU）任务的重要性和主流做法，指出现有VLU模型依赖大量人工标注数据，数据收集和标注成本高，规模远小于NLP领域的预训练语料。\n  • 现有研究缺口：论文批评现有方法主要采用以下逻辑：1）强调现有VLU方法对人工标注数据的高度依赖，导致数据规模受限，难以扩展；2）指出CLIP虽然具备强大的零样本能力，但与传统视觉编码器存在两大不同：其一是训练数据规模大且噪声多，其二是视觉与语言的交互较浅。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分步骤递进’的叙述策略。首先指出直接应用CLIP在VLU任务上的问题，提出需要缩小自然语言描述与问答任务形式之间的差距。随后整体介绍提出的两步自动化prompt生成方法，并用图示辅助说明。\n  • 实验设计：实验部分采用‘多数据集+主实验对比’的策略。首先介绍了用于VQA和视觉蕴含的两个主流数据集（VQAv2和SNLI-VE），并说明评测指标和细节。然后对比了不同CLIP变体，以及两种零样本VL基线（Frozen和QIP），突出自身方法的有效性。\n\n示例 2：《VGNMN: Video-grounded Neural Module Networks for Video-Grounded Dialogue Systems》\n  • 问题定位：论文通过回顾视觉-语言任务的发展历程，从图像到视频，再到视频对话，逐步引出随着模态复杂性提升，现有模型面临的新挑战。\n  • 现有研究缺口：论文批评现有方法主要采用了‘现有方法隐式假设推理结构’和‘在复杂场景下表现有限’的逻辑。具体句式包括指出当前主流深度神经网络虽然性能优异，但往往只隐式学习推理结构，缺乏显式可解释性，且在视频具有复杂时空动态或语言输入语义依赖复杂时，模型难以解释、易出错、推理能力受限。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了模型架构和核心思想（如VGNMN的推理结构），随后细致分解各模块：先介绍问题解析器（Question Parsers）的设计与工作原理，详细说明如何将问题解析为可执行的推理程序，再逐步讲解各个神经模块的具体实现与训练方式。\n  • 实验设计：实验部分采用了‘主实验+多数据集验证+鲁棒性分析’的策略。首先在主流基准数据集（AVSD和TGIF-QA）上进行主实验，展示模型在标准指标上的性能。实验设计包含不同输入设置（有无视频摘要）、不同特征类型（CNN特征、对象特征），并与主流方法（包括GPT-based模型）进行对比分析。\n\n示例 3：《On Vision Features in Multimodal Machine Translation》\n  • 问题定位：论文通过回顾多模态机器翻译（MMT）领域的发展，引出当前研究的问题。开篇先介绍MMT结合了计算机视觉和自然语言处理，早期模型在BLEU分数上取得了提升，激发了后续研究兴趣。随后，作者指出实际观察到的问题：视觉模态对翻译贡献有限，甚至在视觉信息缺失或与文本无关时，翻译性能影响不大。\n  • 现有研究缺口：论文批评现有方法主要采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述顺序。首先，作者介绍了用于评估视觉模态贡献的探测任务（probing tasks），为后续方法设计奠定基础。接着，系统性地描述了不同视觉特征的设计，包括如何将ViT等更强视觉模型的特征引入MMT。\n  • 实验设计：实验部分采用‘主实验+探测任务验证’的叙述策略。首先，复现并对比了不同视觉特征（如ResNet与ViT）在标准MMT数据集上的表现，验证主方法的有效性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 20.0%）\n   类型：writing-level\n   应用：先提出问题与挑战，再引入新方法，最后通过系统实验验证，前后呼应，层层递进\n\n2. 问题驱动开篇（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过阐述VLU任务的难点和现有方法的局限，提出数据规模与标注成本的矛盾，引出研究动机。\n\n3. 引用权威工作（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：大量引用领域内经典和最新文献，展示方法与主流工作的关系和改进空间。\n\n4. 图示辅助理解（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过引用和描述图表（如Figure 1, Figure 3），直观展示任务和方法流程。\n\n5. 实验细节透明化（使用频率 2 次，占比 13.3%）\n   类型：experiment-level\n   应用：详细报告数据集、模型参数、评估指标等实验细节，并在附录补充统计信息。\n\n6. 逻辑递进的叙事结构（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：先引入问题和挑战，再提出方法，最后通过实验验证，层层递进，呼应前文提出的问题。\n\n7. 现实动机引入（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：通过指出传统视觉任务受限于预定义类别，强调自然语言表达的必要性和与人类认知的契合，增强问题的现实意义。\n\n8. 创新点突出（使用频率 2 次，占比 13.3%）\n   类型：writing-level\n   应用：作者强调FEWVLM结合PrefixLM和MaskedLM两种预训练目标，并在prompt设计上做创新，突出与现有工作的不同。\n\n9. 对比现有方法局限（使用频率 1 次，占比 6.7%）\n   类型：writing-level\n   应用：详细分析CLIP与传统视觉编码器的区别，以及直接应用CLIP的不足，引出自身方法的优势。\n\n10. 提出核心科学问题（使用频率 1 次，占比 6.7%）\n   类型：writing-level\n   应用：通过提出“CLIP的零样本能力能否迁移到VLU任务？”这一核心问题，设定全文主线。\n",
    "cluster_size": 15,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_196",
      "ARR_2022_244",
      "ARR_2022_90",
      "ARR_2022_70",
      "ARR_2022_131",
      "ARR_2022_72",
      "ARR_2022_3",
      "ARR_2022_133",
      "ARR_2022_217",
      "ARR_2022_100",
      "ARR_2022_124",
      "ARR_2022_284",
      "ACL_2017_481",
      "ACL_2017_501",
      "COLING_2020_9"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "20.0%"
      },
      {
        "name": "问题驱动开篇",
        "frequency": 2,
        "percentage": "13.3%"
      },
      {
        "name": "引用权威工作",
        "frequency": 2,
        "percentage": "13.3%"
      },
      {
        "name": "图示辅助理解",
        "frequency": 2,
        "percentage": "13.3%"
      },
      {
        "name": "实验细节透明化",
        "frequency": 2,
        "percentage": "13.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_23",
    "name": "大规模预训练模型优化",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨大规模预训练模型的局限性，通过扩展任务定义和创新方法提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，通过引入权威基准和核心理论属性突出创新点，常用tricks包括详细实验设计和多维度数据分析。\n第3段（60字）：适用场景与预期效果 - 适用于需要系统评估和改进大规模预训练模型性能的NLP任务，预期提升模型在特定任务上的表现和泛化能力。",
    "writing_guide": "写作模板：大规模预训练模型优化\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨大规模预训练模型的局限性，通过扩展任务定义和创新方法提升模型性能。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从学术gap出发，通过引入权威基准和核心理论属性突出创新点，常用tricks包括详细实验设计和多维度数据分析。\n第3段（60字）：适用场景与预期效果 - 适用于需要系统评估和改进大规模预训练模型性能的NLP任务，预期提升模型在特定任务上的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence》\n  • 问题定位：论文以学术gap为切入点，指出尽管大规模预训练语言模型（PLMs）在众多下游任务中表现优异，甚至在一些基准测试中超过人类，但其可靠性正受到挑战。通过引用多项研究，作者强调PLMs在句子顺序敏感性、数字理解、语义内容理解等方面存在缺陷，特别是在否定理解能力上表现不佳。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法范围有限’和‘现有方法存在实际应用障碍’的逻辑。\n  • 核心方法：方法部分的叙述顺序为：先扩展理论边界，提出将LNP（逻辑否定性质）从传统的否定表达拓展到词汇语义层面（同义词、反义词），再设计相应的评测任务和指标。整体上采用‘先整体后局部’的策略，先说明研究视角和创新点，再具体介绍如何构建任务、如何评测模型的表现。\n  • 实验设计：实验部分采用‘主实验+细致分析’的叙述策略。首先，明确采用top-k hit rate和weighted top-k hit rate等指标，系统评测PLMs在否定理解和词汇语义任务（MKR-NQ和MWR）上的表现。\n\n示例 2：《GLM: General Language Model Pretraining with Autoregressive Blank Infilling》\n  • 问题定位：论文通过回顾大规模预训练语言模型在自然语言处理任务中的显著进展作为开篇，强调模型参数规模和下游任务性能的持续提升，进而引出现有预训练框架（自回归、自动编码、编码-解码三类）各自的优势和局限，指出没有一种方法能够在所有NLP任务上表现优异。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和归纳的逻辑，逐一指出三类主流预训练模型的固有缺陷：自回归模型在NLU任务中受限于单向注意力机制，自动编码模型虽适合NLU但无法直接用于生成，编码-解码模型参数需求大且在性能上不具备全面优势。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先整体介绍GLM的核心思想——基于自回归填空的统一预训练框架，并说明其如何将NLU任务转化为可生成回答的填空问题。随后，分条列举模型架构的具体改进，包括层归一化与残差连接顺序调整、输出层简化、激活函数替换等，突出每一项设计的动机和作用。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略。首先介绍预训练设置和下游任务评测，选用GLUE和SQuAD两个主流NLP基准数据集，分别覆盖单句、句对、抽取式问答等典型任务。实验重点在于与BERT等主流模型的直接对比，突出GLM在参数规模相同情况下的性能优势。\n\n示例 3：《CogTaskonomy: Cognitively Inspired Task Taxonomy Is Beneficial to Transfer Learning in NLP》\n  • 问题定位：论文从学术gap出发引出问题。开篇先指出迁移学习在自然语言处理中的多种形式和广泛关注，进而提出一个高层次的核心问题：不同任务之间的关系结构尚不明确，现有研究缺乏对NLP任务之间结构性关联的系统刻画。\n  • 现有研究缺口：论文通过对比视觉领域已有的Taskonomy体系，指出NLP领域在任务结构建模方面的不足。具体批评逻辑为：现有NLP任务分类体系缺乏、未能充分利用认知神经科学数据来指导任务结构的构建。\n  • 核心方法：方法部分采用分模块介绍的策略。首先整体介绍了CogTaskonomy框架的设计理念和目标，然后细分为两个主要的认知启发模块：Cognitive Representation Analytics（CRA）和Cognitive-Neural Mapping（CNM）。\n  • 实验设计：实验部分采用主实验+多数据集验证的策略。首先在广泛使用的NLP基准数据集和认知数据上评估CogTaskonomy的有效性，核心实验为任务迁移实验（task transferring），通过源任务到目标任务的迁移性能来度量任务相似性，并以此构建oracle任务排序。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 4 次，占比 28.6%）\n   类型：writing-level\n   应用：从问题提出、现有方法分析、创新点介绍到实验设计和结果分析，层层递进，逻辑清晰。\n\n2. 引用权威工作建立背景（使用频率 3 次，占比 21.4%）\n   类型：writing-level\n   应用：通过引用多篇相关领域权威文献，强调模型与人类注意力对齐的重要性，并为后续工作奠定理论基础。\n\n3. 创新点突出（使用频率 2 次，占比 14.3%）\n   类型：method-level\n   应用：提出GLM框架，结合autoregressive和autoencoding思想，采用autoregressive blank infilling，并在方法部分具体描述两项架构改进。\n\n4. 问题驱动式引入（使用频率 2 次，占比 14.3%）\n   类型：writing-level\n   应用：通过提出跨任务迁移学习中的核心问题（任务之间的关系），引导读者关注任务结构和任务分类的重要性。\n\n5. 实验细节透明化（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：详细说明训练轮数、学习率、模型参数规模、解码方式等实验实现细节。\n\n6. 与现有方法直接对比（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：将本方法与已有的预训练模型（如GPT2）在同一数据集上的表现进行直接对比，强调性能提升。\n\n7. 详细实验设置说明（使用频率 2 次，占比 14.3%）\n   类型：experiment-level\n   应用：详细描述数据规模、训练参数、优化器、硬件环境等关键细节，确保实验充分。\n\n8. 引用权威基准和前沿模型（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：通过引用BERT、GPT等主流PLM及GLUE/SuperGLUE等权威基准，强调研究对象的广泛影响力和当前主流模型的性能。\n\n9. 列举已知缺陷并引用相关工作（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：系统性地罗列PLM在句序、数字理解、语义理解等方面的缺陷，并广泛引用相关文献，说明问题并非孤立。\n\n10. 引入核心理论属性（LNP）（使用频率 1 次，占比 7.1%）\n   类型：writing-level\n   应用：明确提出LNP（逻辑否定属性）作为评判标准，并说明其在语言理解任务中的重要性。\n",
    "cluster_size": 14,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_304",
      "ARR_2022_39",
      "ARR_2022_242",
      "ARR_2022_167",
      "ARR_2022_69",
      "ARR_2022_160",
      "ARR_2022_99",
      "ARR_2022_158",
      "ARR_2022_235",
      "ARR_2022_117",
      "ARR_2022_24",
      "ARR_2022_306",
      "ARR_2022_57",
      "COLING_2020_24"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 4,
        "percentage": "28.6%"
      },
      {
        "name": "引用权威工作建立背景",
        "frequency": 3,
        "percentage": "21.4%"
      },
      {
        "name": "创新点突出",
        "frequency": 2,
        "percentage": "14.3%"
      },
      {
        "name": "问题驱动式引入",
        "frequency": 2,
        "percentage": "14.3%"
      },
      {
        "name": "实验细节透明化",
        "frequency": 2,
        "percentage": "14.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_24",
    "name": "神经机器翻译术语约束与质量评估",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决神经机器翻译中的术语约束和质量评估问题，采用新颖的训练方法和多任务框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过对比现有方法指出gap，方法部分采用先整体后局部的叙述策略，实验设计多采用多数据集验证和多指标评估。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确术语翻译和高质量自动评估的多语种神经机器翻译任务，预期提升翻译质量和评估准确性。",
    "writing_guide": "写作模板：神经机器翻译术语约束与质量评估\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决神经机器翻译中的术语约束和质量评估问题，采用新颖的训练方法和多任务框架。\n第2段（60字）：关键技术组合与写作策略 - skeleton通常以实际痛点开篇，通过对比现有方法指出gap，方法部分采用先整体后局部的叙述策略，实验设计多采用多数据集验证和多指标评估。\n第3段（60字）：适用场景与预期效果 - 适用于需要精确术语翻译和高质量自动评估的多语种神经机器翻译任务，预期提升翻译质量和评估准确性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Neighbors Are Not Strangers: Improving Non-Autoregressive Translation under Low-Frequency Lexical Constraints》\n  • 问题定位：论文首先从实际应用需求出发，指出神经机器翻译（NMT）虽然取得了成功，但在真实应用中往往需要对特定术语进行精确翻译。作者以应用痛点为切入点，强调词典和术语约束在领域自适应、交互式翻译等场景中的重要性，并指出现有方法在术语约束方面存在不足，特别是在处理低频词时存在问题。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和归纳的逻辑。首先总结现有方法主要基于自回归模型，在推断或训练阶段施加约束，但这些方法要么推断耗时、难以满足实时需求，要么不能保证约束词一定出现在输出中。对于非自回归模型，作者指出相关研究较少，且现有编辑式NAT方法在遇到低频词约束时表现脆弱。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先提出整体解决思路——Aligned Constrained Training (ACT)，并明确两大核心思想：1）约束训练以弥合训练与推断不一致，2）对齐提示以增强模型对约束词上下文的理解。\n  • 实验设计：实验部分采用多数据集验证和主实验+消融的策略。首先介绍数据集设置，包括主流通用领域（WMT14、WMT17）和实际应用相关的领域数据（OPUS医疗、法律），并详细说明约束词的提取方式和频率统计。评价指标包括BLEU和Term Usage Rate，兼顾翻译质量和约束词覆盖率。\n\n示例 2：《Why don’t people use character-level machine translation?》\n  • 问题定位：论文通过从学术gap出发引出问题。开篇先回顾了深度学习在自然语言处理领域推动的端到端学习趋势，指出输入数据的假设逐渐被弱化，但在机器翻译和NLP中，基于语言学的输入分割仍然被广泛采用。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出虽然有文献宣称字符级方法与子词模型表现相当，但字符级方法很少作为强基线，暗示其可能存在未被充分讨论的缺点。此外，批评以往研究多在小数据集上进行，且仅关注定量翻译质量，缺乏深入分析。\n  • 核心方法：方法部分采用分模块介绍和从简单到复杂的叙述策略。首先，作者概述字符级序列处理的主要挑战（如序列长度和信息密度），然后依次介绍四种架构：直接字符嵌入、Lee-style卷积编码、CANINE局部自注意力编码、Charformer平均池化编码。\n  • 实验设计：实验部分采用多数据集验证和主实验+扩展实验的叙述策略。首先，作者在中小规模IWSLT 2017数据集上对所有方法进行对比实验，详细说明数据预处理、模型实现和参数设置。\n\n示例 3：《Translation Error Detection as Rationale Extraction》\n  • 问题定位：论文通过结合实际应用需求和学术研究现状来引出问题。开篇首先介绍了质量评估（QE）在机器翻译中的重要性，强调在没有人工参考译文时预测翻译质量的实际痛点，如决定译文是否可直接发布、定位关键错误等。随后指出当前方法在句子级表现优异，但单词级预测准确率仍有提升空间，部分原因是单词级标注昂贵且耗时。\n  • 现有研究缺口：论文批评现有方法时，采用了对比和局限性分析的逻辑。首先指出当前主流方法在句子级QE上表现优异，但单词级预测准确率不足，归因于训练数据有限。进一步分析现有无监督或半监督方法的不足，如需要访问MT模型或依赖合成数据，未能完全摆脱单词级监督需求。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先用形式化定义描述任务和输入输出，然后介绍特征归因方法的基本原理和分类（简化、梯度、扰动等），再具体说明本研究选用的三种主流归因方法及其选择理由。最后补充说明LIME方法作为对比，强调本研究关注的是无须单词级监督的归因方法，而非归因方法的全面对比。\n  • 实验设计：实验部分采用了主实验+多指标验证的策略。首先明确实验目标是评估归因分数与人工标注错误的对应关系，针对归因方法输出连续分数而非二元标签的特点，选用AUC、平均精度、Top-K召回率、Top-1准确率等多种指标进行评估。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 10.0%）\n   类型：writing-level\n   应用：从领域现状和问题切入，逐步引出研究目标、方法设计、实验验证和结论，层层递进。\n\n2. 多指标评估（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：采用BLEU和Term Usage Rate等多种指标评估翻译质量和约束词覆盖率，确保结果可靠全面。\n\n3. 多数据集验证（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：在不同类型数据集（通用领域和专业领域）上进行实验，覆盖新闻、医疗、法律等多场景。\n\n4. 方法创新点突出（使用频率 2 次，占比 6.7%）\n   类型：method-level\n   应用：明确提出首次在MT中系统比较最新字符处理结构，并提出了新的两步解码器架构，解决字符序列过长导致的解码效率问题。\n\n5. 引用权威工作（使用频率 2 次，占比 6.7%）\n   类型：writing-level\n   应用：多次引用领域内权威论文和竞赛结果，证明现有方法的不足和新方法的必要性。\n\n6. 实验细节透明披露（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：详细描述数据预处理、模型参数、优化器设置、学习率调度等实验细节，便于他人复现。\n\n7. 问题导向开篇（使用频率 2 次，占比 6.7%）\n   类型：writing-level\n   应用：作者通过提出领域内的核心矛盾（高质量合成数据未必带来最佳性能），引出研究的根本问题，激发读者关注。\n\n8. 对比实验设计（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：作者设置多组对比，包括beam、sampling、beam*、gamma方法等，系统比较不同生成策略的效果。\n\n9. 创新点明确命名（使用频率 2 次，占比 6.7%）\n   类型：method-level\n   应用：作者提出Weighted Label Smoothing (WLS)和Masked Label Smoothing (MLS)，并给出简要定义。\n\n10. 参数敏感性分析（使用频率 2 次，占比 6.7%）\n   类型：experiment-level\n   应用：对关键超参数进行分步调优和分析，展示不同设置下的性能变化。\n",
    "cluster_size": 30,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_276",
      "ARR_2022_343",
      "ARR_2022_177",
      "ARR_2022_105",
      "ARR_2022_212",
      "ARR_2022_54",
      "ARR_2022_338",
      "ARR_2022_226",
      "ARR_2022_179",
      "ARR_2022_173",
      "ARR_2022_51",
      "ARR_2022_200",
      "ARR_2022_183",
      "ARR_2022_322",
      "ARR_2022_310",
      "ARR_2022_123",
      "ARR_2022_107",
      "ARR_2022_108",
      "ACL_2017_369",
      "ACL_2017_676",
      "ACL_2017_779",
      "ACL_2017_496",
      "ACL_2017_564",
      "ACL_2017_49",
      "ACL_2017_150",
      "COLING_2020_0",
      "COLING_2020_43",
      "COLING_2020_72",
      "COLING_2020_63",
      "COLING_2020_47"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "10.0%"
      },
      {
        "name": "多指标评估",
        "frequency": 2,
        "percentage": "6.7%"
      },
      {
        "name": "多数据集验证",
        "frequency": 2,
        "percentage": "6.7%"
      },
      {
        "name": "方法创新点突出",
        "frequency": 2,
        "percentage": "6.7%"
      },
      {
        "name": "引用权威工作",
        "frequency": 2,
        "percentage": "6.7%"
      }
    ]
  },
  {
    "pattern_id": "pattern_25",
    "name": "对话系统评估与迁移学习",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决对话系统评估、迁移学习和连贯性评价问题，采用形式化任务定义和多基线对比实验验证方法。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过批评现有方法指出gap，采用逻辑递进的叙事结构，结合引用权威文献和多数据集覆盖增强说服力。\n\n第3段（60字）：适用场景与预期效果 - 适用于对话系统评估、多语言迁移和连贯性评价任务，预期提升模型在真实场景和多语言环境下的表现。",
    "writing_guide": "写作模板：对话系统评估与迁移学习\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决对话系统评估、迁移学习和连贯性评价问题，采用形式化任务定义和多基线对比实验验证方法。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton通常从实际痛点出发，通过批评现有方法指出gap，采用逻辑递进的叙事结构，结合引用权威文献和多数据集覆盖增强说服力。\n\n第3段（60字）：适用场景与预期效果 - 适用于对话系统评估、多语言迁移和连贯性评价任务，预期提升模型在真实场景和多语言环境下的表现。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Ditch the Gold Standard: Re-evaluating Conversational Question Answering》\n  • 问题定位：论文从应用需求和实际痛点出发引入问题，强调对话式问答（CQA）有潜力革新人机交互的信息获取方式。通过指出当前评估方式（基于预收集的对话和金标准历史）与真实应用场景之间的差距，提出了对现有评估方法有效性的质疑，并以此作为研究动机。\n  • 现有研究缺口：论文批评现有方法时，采用了“现有方法忽视了实际应用场景的需求”和“现有方法在真实人机对话中失效”的逻辑。\n  • 核心方法：方法部分采用了先整体后局部、从简单到复杂的叙述策略。首先介绍了用于人类评估的四个代表性CQA模型，从最基础的BERT模型开始，逐步介绍更复杂的GraphFlow、HAM和ExCorD模型，并简要说明每个模型的核心机制和创新点。\n  • 实验设计：实验部分采用了主实验对比分析的策略。首先详细描述了CQA任务的设定和评估流程，接着进行大规模人类评估，与现有自动评估（Auto-Gold）进行对比，分析排名和模型间差距的变化。\n\n示例 2：《Show, Don’t Tell: Demonstrations Outperform Descriptions for Schema-Guided Task-Oriented Dialogue》\n  • 问题定位：论文从实际应用需求出发引出问题，强调随着任务型对话系统（TOD）的广泛应用，系统需要支持越来越多样化的服务/API，但许多服务开发者缺乏标注数据和机器学习专业知识，因此对未见服务的零样本/少样本迁移变得至关重要。\n  • 现有研究缺口：论文批评现有方法时，首先指出主流方法依赖于大语言模型和基于描述的schema建模，但自然语言描述的编写仍需人工投入且难以精确，同时对未见服务的监督作用有限。此外，引用Lee等（2021b）的实证结果，指出现有模型对schema描述的变化不够鲁棒，准确率显著下降。\n  • 核心方法：方法部分采用先整体后局部的叙述策略，先提出核心思想——用单一对话示例替代schema描述（即Show, Don’t Tell, SDT），再具体介绍在不同T5模型规模上的应用和两种SDT变体（SDT-seq与SDT-ind）的对比。\n  • 实验设计：实验部分采用多数据集验证和主实验+对比实验的叙述策略。首先在两个主流DST数据集（SGD和MultiWOZ 2.1）上进行主实验，分别说明数据集设置和prompt构建方式。其次，详细描述与多种基线方法的对比，并对不同prompt版本做平均以保证结果稳健。\n\n示例 3：《GlobalWoZ: Globalizing MultiWoZ to Develop Multilingual Task-Oriented Dialogue Systems》\n  • 问题定位：论文通过结合实际应用需求与学术痛点来引出问题。首先强调人工智能领域实现自然语言交流的重要目标，并指出任务型对话系统（ToD）的广泛应用和实际价值，如酒店预订、天气查询等。随后，作者转向现实挑战，即现有系统主要服务于英语用户，限制了全球用户的可用性，核心原因是高质量多语言数据集的匮乏。\n  • 现有研究缺口：论文对现有方法的批评采用了‘现有方法忽视了实际场景需求’和‘现有方法在跨语言、本地实体检索场景下失效’的逻辑。\n  • 核心方法：方法部分采用‘整体流程先行，分步骤详细展开’的叙述策略。先整体介绍将英文ToD数据集全球化的四步流程：模板抽取、翻译与后编辑、本地本体收集、模板实体替换。每一步骤都在后文有独立小节详细说明，强调流程的系统性和可复用性。\n  • 实验设计：实验部分采用‘主实验+多设置对比’的策略，围绕零样本（zero-shot）和小样本（few-shot）跨语言迁移两个核心实验设置展开。每个设置都明确实验假设和数据来源，分别评估模型在无目标语言标注数据和有限标注数据下的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进的叙事结构（使用频率 5 次，占比 21.7%）\n   类型：writing-level\n   应用：先引入问题和现有方法不足，再提出新方法，最后通过系统实验验证，结构清晰递进。\n\n2. 逻辑递进式叙事结构（使用频率 5 次，占比 21.7%）\n   类型：writing-level\n   应用：按照‘问题-方法-实验’的经典结构组织全文，层层递进，前后呼应\n\n3. 创新点突出（使用频率 4 次，占比 17.4%）\n   类型：method-level\n   应用：提出基于AMR的语义级扰动生成负样本，并强调其能捕捉更细致的连贯性错误\n\n4. 消融实验设计（使用频率 4 次，占比 17.4%）\n   类型：experiment-level\n   应用：系统移除方法中的关键组件，展示每个部分对整体性能的影响，证明方法设计的合理性。\n\n5. 定量与定性结果结合（使用频率 3 次，占比 13.0%）\n   类型：experiment-level\n   应用：同时报告任务成功率、语言质量指标（如BLEU、perplexity），并分析不同方法的表现差异。\n\n6. 多维度评价指标（使用频率 3 次，占比 13.0%）\n   类型：experiment-level\n   应用：采用PPL、F1、Distinct、BLEU、METEOR、ROUGE等多种自动评价指标，覆盖生成质量和多样性。\n\n7. 形式化任务定义（使用频率 2 次，占比 8.7%）\n   类型：writing-level\n   应用：对对话问答流程进行形式化定义，明确每一步的输入输出，帮助读者理解实验流程和评测标准。\n\n8. 多基线对比实验（使用频率 2 次，占比 8.7%）\n   类型：experiment-level\n   应用：在多个数据集上与多种现有方法（如SGP-DST、T5-seq等）系统对比，展示SDT的性能提升。\n\n9. 引用权威文献（使用频率 2 次，占比 8.7%）\n   类型：writing-level\n   应用：广泛引用相关领域的经典和最新文献，说明ToD系统的现状和挑战\n\n10. 多数据集覆盖（使用频率 2 次，占比 8.7%）\n   类型：experiment-level\n   应用：在多个公开数据集（如FED、DSTC9、Ubuntu、DailyDialog等）上进行训练和评测\n",
    "cluster_size": 23,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_227",
      "ARR_2022_199",
      "ARR_2022_42",
      "ARR_2022_254",
      "ARR_2022_269",
      "ARR_2022_115",
      "ARR_2022_152",
      "ARR_2022_40",
      "ARR_2022_207",
      "ARR_2022_157",
      "ARR_2022_324",
      "ARR_2022_335",
      "ARR_2022_247",
      "ARR_2022_63",
      "ARR_2022_282",
      "ARR_2022_309",
      "ARR_2022_318",
      "ACL_2017_128",
      "ACL_2017_769",
      "ACL_2017_627",
      "ACL_2017_26",
      "COLING_2020_1",
      "COLING_2020_65"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进的叙事结构",
        "frequency": 5,
        "percentage": "21.7%"
      },
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 5,
        "percentage": "21.7%"
      },
      {
        "name": "创新点突出",
        "frequency": 4,
        "percentage": "17.4%"
      },
      {
        "name": "消融实验设计",
        "frequency": 4,
        "percentage": "17.4%"
      },
      {
        "name": "定量与定性结果结合",
        "frequency": 3,
        "percentage": "13.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_26",
    "name": "时间推理问答模块设计",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决时间推理问题，采用时序知识图谱编码与问答模块设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点和学术gap引出问题，常用tricks包括挑战分层、模块化框架、联合训练和多基线对比实验。\n第3段（60字）：适用场景与预期效果 - 适用于涉及时间推理的问答任务，数据集需包含时间信息，预期提升模型在复杂时间关系上的理解能力。",
    "writing_guide": "写作模板：时间推理问答模块设计\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决时间推理问题，采用时序知识图谱编码与问答模块设计。\n第2段（60字）：关键技术组合与写作策略 - skeleton以实际痛点和学术gap引出问题，常用tricks包括挑战分层、模块化框架、联合训练和多基线对比实验。\n第3段（60字）：适用场景与预期效果 - 适用于涉及时间推理的问答任务，数据集需包含时间信息，预期提升模型在复杂时间关系上的理解能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Improving Time Sensitivity for Question Answering over Temporal Knowledge Graphs》\n  • 问题定位：论文通过介绍时序知识图谱（Temporal Knowledge Graph, TKG）在处理涉及时间推理问题上的独特价值切入，强调其在回答涉及事件发生时间及其时序关系问题上的重要性。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法未考虑/难以处理X’和‘现有方法在Y场景下存在不足’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部，分模块介绍’的叙述策略。首先给出问题定义和整体框架，明确任务输入输出和核心挑战。随后介绍整体架构，包括两个主要模块：1）时序感知的KG编码器（time-aware TKG encoder），2）时序敏感的问答模块（time-sensitive QA module）。\n  • 实验设计：实验部分采用‘主实验+多类型问题分组+与SOTA对比’的叙述策略。首先介绍实验数据集（CRONQUESTIONS），详细说明数据集规模、问题类型（实体类与时间类）、推理复杂度分组（简单推理与复杂推理）等。接着说明评测指标（Hits@1, Hits@10）、超参数设置和实现细节。\n\n示例 2：《Challenging America: Modeling language in longer time scales》\n  • 问题定位：论文首先从当前NLP主流方法的实际应用痛点出发，指出大规模预训练语言模型（如GPT-2、RoBERTa、T5）及其在标准基准（如GLUE、SuperGLUE）上的评测已成为常态。\n  • 现有研究缺口：论文批评现有方法主要采用‘现有方法忽视了X’和‘现有资源存在Y局限’的逻辑。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了大规模历史语料的构建过程，包括数据来源、数据规模、数据清洗（去除垃圾和噪声）、时间标注（精确到日）等核心特征。随后，方法部分会进一步细化，介绍如何基于该语料进行预训练，以及如何设计下游任务和基准测试，逐步展开每个模块的具体实现细节。\n  • 实验设计：实验部分的叙述策略以‘主实验+多角度分析’为主。首先会在新构建的历史文本基准上进行主实验，验证预训练模型在历史文本上的表现。其次，可能包含与现有模型（如现代语料预训练模型）的对比实验，突出新方法的优势。\n\n示例 3：《Good Night at 4 pm?! Time Expressions in Different Cultures》\n  • 问题定位：论文开篇从自然语言理解的实际需求出发，强调将语言表达（如颜色、空间、形容词等）映射到现实世界物理属性的重要性，继而聚焦到时间表达的落地（temporal grounding）问题。\n  • 现有研究缺口：论文批评现有方法主要采用了'现有方法忽视了文化差异'和'现有方法在多语言、多文化场景下表现有限'的逻辑。具体通过引用相关研究，指出以往方法未充分考虑不同文化、语言背景下时间表达的多样性，且现有模型在处理跨文化常识推理时存在不足。\n  • 核心方法：方法部分首先对任务进行明确定义（整体介绍），随后提出三种不同的解决方法，并按照数据来源（语料库/语言模型）和推断方式（直接/间接）两个维度进行分类。具体先介绍基于语料库的分布估计方法，再介绍基于语言模型的两种方法，并详细描述每种方法的实现细节和优化目标。\n  • 实验设计：实验部分采用了'主实验+多数据集验证+定量评估+可视化'的叙述策略。首先通过图表展示不同方法在多语言（多国家）下的预测结果与金标准的对比，随后定义细粒度的minute-level accuracy作为主要评价指标，量化各方法的表现。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题具体化与场景举例（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过举例（如罗斯福担任总统的时间）和图示（Figure 1），具体化问题场景，突出时间推理的重要性和挑战。\n\n2. 挑战分层与归纳（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：系统归纳并分层描述三大核心挑战（时间点识别、时间关系表达、时间嵌入方式），为后续方法创新做铺垫。\n\n3. 与前沿工作的对比引用（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：引用并简述前沿方法（如Saxena et al., 2021），并指出其在复杂推理上的不足，为新方法的必要性提供论据。\n\n4. 问题定义与符号化（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：用数学符号和集合定义问题（如G = (V, E, R, T)），明确输入、输出和知识图谱结构。\n\n5. 模块化方法框架描述（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将方法分为“时间感知编码器”和“时间敏感问答”两大模块，并逐步详细介绍各自功能。\n\n6. 辅助任务设计（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：在时间感知编码器中引入辅助时间顺序学习任务，强调对时间序列的建模创新。\n\n7. 联合训练与对比学习（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：在问答模块中采用联合训练和时间敏感对比学习，提升模型对时间表达的理解能力。\n\n8. 多维度数据集与任务划分（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：详细介绍数据集规模、类型、问题分类（实体/时间、简单/复杂），确保实验覆盖多样性。\n\n9. 标准化评估指标使用（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：采用Hits@1和Hits@10等标准指标，确保结果具有可比性和可信度。\n\n10. 多基线对比实验（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：选取EmbedKGQA、T-EaE-add/replacement、CronKGQA等多种基线，系统对比各类问题的表现。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_38",
      "ARR_2022_229",
      "ARR_2022_198",
      "ARR_2022_301",
      "ACL_2017_12"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "问题具体化与场景举例",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "挑战分层与归纳",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "与前沿工作的对比引用",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "问题定义与符号化",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "模块化方法框架描述",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_27",
    "name": "无监督学习文本摘要",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决文本摘要中的效率、质量与泛化性问题，采用无监督学习、知识蒸馏、层次结构建模等方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton开篇强调实际痛点，对比现有方法不足，方法部分采用分模块介绍与逐步递进，实验设计多数据集验证与主实验对比。\n第3段（60字）：适用场景与预期效果 - 适用于长文本摘要、对话摘要、社交媒体摘要等场景，预期提升摘要质量、效率与泛化能力，适合需要高效生成摘要的应用。",
    "writing_guide": "写作模板：无监督学习文本摘要\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决文本摘要中的效率、质量与泛化性问题，采用无监督学习、知识蒸馏、层次结构建模等方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton开篇强调实际痛点，对比现有方法不足，方法部分采用分模块介绍与逐步递进，实验设计多数据集验证与主实验对比。\n第3段（60字）：适用场景与预期效果 - 适用于长文本摘要、对话摘要、社交媒体摘要等场景，预期提升摘要质量、效率与泛化能力，适合需要高效生成摘要的应用。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning Non-Autoregressive Models from Search for Unsupervised Sentence Summarization》\n  • 问题定位：论文首先从实际应用需求出发，强调文本摘要在自然语言处理中的重要性及其广泛应用场景（如新闻标题生成），随后指出主流方法依赖大规模标注数据，导致在冷门领域和小语种难以应用，进一步引出无监督方法的研究价值。整体开篇策略是结合实际痛点和学术gap，逐步聚焦到无监督文本摘要的挑战和需求。\n  • 现有研究缺口：论文批评现有方法时，采用了'现有方法在实际应用中存在局限'和'现有方法忽视了效率和生成质量'的逻辑。具体表现为：指出基于循环一致性的方法训练困难且效率低下，编辑式方法虽然质量较高但推理速度慢且生成受限，容易陷入局部最优。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先总体介绍了方法框架：先用离散搜索获得目标摘要，再训练非自回归模型学习搜索结果。随后分模块详细介绍每一步，包括目标函数、非自回归模型架构（Transformer细节）、训练策略和长度控制算法。每个模块都从动机出发，逐步展开技术细节，逻辑清晰递进。\n  • 实验设计：实验部分以主实验为核心，先在主流数据集（Gigaword headline test set）与现有方法进行系统对比，分组展示不同摘要长度下的性能。\n\n示例 2：《Attention Temperature Matters in Abstractive Summarization Distillation》\n  • 问题定位：论文开篇首先介绍了自动文档摘要的任务及其两大主流方法（抽取式和生成式），随后聚焦于生成式摘要，强调其在效果和简洁性上的优势。接着指出当前最优性能依赖于大规模预训练Transformer模型，但这些模型在实际生产环境中推理速度慢，难以部署。\n  • 现有研究缺口：论文批评现有方法时，首先指出当前知识蒸馏主要用于分类任务，缺乏对序列生成任务（如摘要）的序列级知识利用。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先介绍了知识蒸馏的基本原理及其在序列到序列任务中的应用（如伪标签法），随后聚焦于教师模型注意力分布过于尖锐导致伪标签质量下降的问题，进一步分析并定义了copy bias和leading bias。\n  • 实验设计：实验部分采用了主实验+多数据集验证+人工评测的综合策略。首先在主流数据集（CNNDM和XSum）上进行ROUGE指标的主实验，涵盖不同模型和蒸馏方法的对比。其次，采用人工评测，从流畅性、忠实性和覆盖度三个维度对生成摘要进行主观评价，并通过排名方式综合评定摘要质量。\n\n示例 3：《Other Roles Matter! Enhancing Role-Oriented Dialogue Summarization via Role Interactions》\n  • 问题定位：论文从实际应用需求出发引出问题。开篇强调了对话内容日益增长导致信息过载，阅读完整对话耗时，因而对话摘要技术具有实际价值。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的句式。具体指出，现有方法要么分别为每个角色独立生成摘要，要么采用序列标注方式，但都‘忽视了不同角色摘要之间的强相关性’，未能利用其他角色的信息来增强摘要质量。通过举例说明其他角色信息如何提升摘要的完整性和判别力，进一步强调现有方法的不足。\n  • 核心方法：方法部分采用‘先整体后细节’和‘分模块介绍’的叙述策略。\n  • 实验设计：实验部分采用‘多数据集+多评价维度’的叙述策略。首先介绍了实验所用的模型、数据集和输入处理方式，然后详细说明了自动评价指标（如ROUGE、BLEU、BERTScore、MoverScore）和人工评价维度（信息性、非冗余性、流畅性），并给出评价流程。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 逻辑递进式叙事结构（使用频率 3 次，占比 33.3%）\n   类型：writing-level\n   应用：从问题引入、现有方法分析、创新方法提出、实验验证到结论呼应，层层递进组织全文结构。\n\n2. 多数据集验证（使用频率 2 次，占比 22.2%）\n   类型：experiment-level\n   应用：在Gigaword和DUC2004两个数据集上实验，验证方法的通用性和稳定性。\n\n3. 现有方法局限性强调（使用频率 2 次，占比 22.2%）\n   类型：writing-level\n   应用：作者强调当前大模型虽然效果好但推理速度慢，难以实际部署，为提出小模型蒸馏方法做铺垫。\n\n4. 多数据集覆盖（使用频率 2 次，占比 22.2%）\n   类型：experiment-level\n   应用：在会议、电视剧、政府报告等多个领域数据集上进行实验，展示SUMMN的跨领域泛化能力和鲁棒性。\n\n5. 现实应用场景举例（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：在引言开头通过举例（如新闻标题生成）说明文本摘要的广泛应用，强调研究意义。\n\n6. 现有方法局限性对比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：详细分析并点出当前主流方法（如有监督方法、循环一致性方法、编辑式方法）的缺陷，为新方法的提出铺垫。\n\n7. 创新点列表化（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：用项目符号列出NAUS的三大优势（速度、结构对应、长度控制），直接展示创新点。\n\n8. 师生模型类比（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：将非自回归模型比作学生，从搜索型教师模型中学习，形象说明模型设计思路。\n\n9. 逐步分节讲解方法（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：方法部分分为目标函数、模型结构、训练策略和长度控制等小节，层层递进讲解。\n\n10. 与主流模型结构对比（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：强调所用的encoder-only结构与传统encoder-decoder的不同，并分析其优势。\n",
    "cluster_size": 9,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_339",
      "ARR_2022_260",
      "ARR_2022_268",
      "ARR_2022_191",
      "ARR_2022_32",
      "ARR_2022_206",
      "ACL_2017_333",
      "COLING_2020_13",
      "COLING_2020_50"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "逻辑递进式叙事结构",
        "frequency": 3,
        "percentage": "33.3%"
      },
      {
        "name": "多数据集验证",
        "frequency": 2,
        "percentage": "22.2%"
      },
      {
        "name": "现有方法局限性强调",
        "frequency": 2,
        "percentage": "22.2%"
      },
      {
        "name": "多数据集覆盖",
        "frequency": 2,
        "percentage": "22.2%"
      },
      {
        "name": "现实应用场景举例",
        "frequency": 1,
        "percentage": "11.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_28",
    "name": "端到端实体-关系联合抽取",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦实体和关系联合抽取的挑战，采用端到端建模和新颖视角，覆盖文档级和联合抽取任务。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法局限性对比开篇，常用tricks包括新颖视角命名、方法流程分步阐述、图示辅助理解等。\n第3段（60字）：适用场景与预期效果 - 适用于实体和关系联合抽取任务，多场景实验验证方法的有效性和泛化能力，预期提升F1分数。",
    "writing_guide": "写作模板：端到端实体-关系联合抽取\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文聚焦实体和关系联合抽取的挑战，采用端到端建模和新颖视角，覆盖文档级和联合抽取任务。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法局限性对比开篇，常用tricks包括新颖视角命名、方法流程分步阐述、图示辅助理解等。\n第3段（60字）：适用场景与预期效果 - 适用于实体和关系联合抽取任务，多场景实验验证方法的有效性和泛化能力，预期提升F1分数。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《EmRel: Joint Representation of Entities and Embedded Relations for Multi-triple Extraction》\n  • 问题定位：论文通过强调关系抽取在构建知识库及其下游应用（如搜索引擎、问答系统）中的重要性，从实际应用需求出发引出问题。随后指出，尽管已有大量研究，但在多实体多关系的复杂场景（如文档级关系抽取和联合实体关系抽取）下仍面临挑战，进一步聚焦于现有方法的局限性，形成学术gap。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法主要从实体视角出发，忽略了关系与实体及上下文之间的丰富交互’的逻辑。具体句式包括‘现有方法大多关注实体间的交互’，‘关系被当作原子标签或独立搜索’，‘关系层面的互信息被忽略’，并通过举例说明在特定场景下（如多三元组抽取）现有方法难以充分建模三元组间的相关性。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略，首先提出整体创新视角（joint triple perspective），再逐步细化方法流程：先显式构造关系嵌入表示，接着通过注意力融合模块细化关系与实体的表示，最后在联合空间中通过新颖的对齐函数（Tucker分解）实现三元组抽取。\n  • 实验设计：实验部分采用‘多数据集验证+主流对比’的策略，分别在文档级关系抽取和联合实体关系抽取两个任务场景下，选用三大主流数据集（DocRED、NYT、WebNLG）进行全面实验。实验内容包括与强基线方法的直接对比，并报告在各数据集上的性能提升，同时补充与多种已有方法的横向比较，突出方法的普适性和优越性。\n\n示例 2：《Enhanced Multi-Channel Graph Convolutional Network for Aspect Sentiment Triplet Extraction》\n  • 问题定位：论文通过结合学术gap和实际任务挑战来引出问题。首先介绍了ASTE任务的定义及其重要性，随后指出当前方法在处理三元组元素之间的关联性和利用语言学特征方面存在不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：批评pipeline方法独立提取三元组元素，忽略了它们之间的相互作用，导致错误传播和额外成本；指出MRC和end-to-end方法虽然有所改进，但仍未充分利用词间多样关系和语言学特征。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了EMC-GCN模型的框架和设计思路，随后依次详细说明输入与编码层、biaffine attention模块、multi-channel GCN模块等关键组成部分。\n  • 实验设计：实验部分采用‘主实验+多数据集验证’的策略。首先在主实验中对比了EMC-GCN与pipeline、end-to-end和MRC-based方法的性能，突出模型在F1指标上的优势。实验结果涵盖不同数据集（D1和D2），并分析了BERT与BiLSTM编码器的性能差异。\n\n示例 3：《PARE: A Simple and Strong Baseline for Monolingual and Multilingual Distantly Supervised Relation Extraction》\n  • 问题定位：论文从学术gap出发引出问题。开篇首先介绍了关系抽取任务的基本定义和主流的远程监督方法，随后指出主流神经网络方法普遍采用了将每个句子独立编码的设计选择。作者明确提出这一设计可能导致对数据利用不充分，并假设如果能让句子间信息交互，编码效果会更好，从而引出本文的研究动机和核心问题。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体地，作者指出主流方法都将每个句子独立编码，未能充分利用同一实体对相关句子间的信息。通过‘我们认为这种选择导致了对可用数据的次优利用’等表达，强调了现有方法的局限性。\n  • 核心方法：方法部分采用了‘先整体后局部’的叙述策略。首先整体介绍了PARE模型的核心思想——将所有相关句子拼接为一个长文本整体编码，随后详细说明了具体实现流程，包括如何利用BERT编码、如何引入关系查询向量、如何通过注意力机制生成关系感知的摘要并进行预测。\n  • 实验设计：实验部分采用了‘多数据集验证+主实验+消融分析+细致对比’的策略。首先在四个主流数据集（包括英文和多语言）上与多种现有方法进行系统对比，验证主方法的有效性。其次，实验包含消融分析和注意力机制的进一步分析，以探究模型性能的原因和细节。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 举例说明问题（使用频率 2 次，占比 22.2%）\n   类型：writing-level\n   应用：通过具体例子（如basin country为unseen relation）说明零样本关系分类的实际困难，使问题更具象、易于理解。\n\n2. 借鉴跨领域方法（使用频率 2 次，占比 22.2%）\n   类型：method-level\n   应用：受计算机视觉领域零样本学习的启发，提出将输入样本特征空间映射到语义空间的思路，拓展了自然语言处理的解决方案。\n\n3. 场景驱动的问题引入（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：通过强调多实体多关系场景下的挑战，引出现有方法的不足，铺垫新方法的必要性\n\n4. 现有方法局限性对比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：详细描述现有方法仅关注实体视角，忽略关系与实体、上下文的交互，为提出新视角做铺垫\n\n5. 新颖视角命名与强调（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：明确提出“joint triple perspective”并与传统“entity perspective”对比，突出方法的新颖性\n\n6. 方法流程分步阐述（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：简要分步介绍EmRel的三个阶段：创建关系表示、联合建模、对齐推断\n\n7. 图示辅助理解（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：提及Figure 1对方法的直观展示，降低理解门槛\n\n8. 与知识图谱类比（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：将三元组视角比作小型上下文相关知识图谱，便于读者理解方法的本质\n\n9. 创新性技术点突出（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：提出基于Tucker分解的对齐函数，作为方法创新的核心技术点\n\n10. 多场景实验覆盖（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：在引言和实验部分均强调覆盖文档级和联合抽取两大场景，使用多个主流数据集\n",
    "cluster_size": 9,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_237",
      "ARR_2022_323",
      "ARR_2022_49",
      "ACL_2017_376",
      "ACL_2017_222",
      "ACL_2017_557",
      "ACL_2017_562",
      "COLING_2020_4",
      "COLING_2020_51"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "举例说明问题",
        "frequency": 2,
        "percentage": "22.2%"
      },
      {
        "name": "借鉴跨领域方法",
        "frequency": 2,
        "percentage": "22.2%"
      },
      {
        "name": "场景驱动的问题引入",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "现有方法局限性对比",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "新颖视角命名与强调",
        "frequency": 1,
        "percentage": "11.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_29",
    "name": "低频词表示端到端神经网络",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低频词表示与上下文建模问题，采用端到端神经网络设计和视觉信息融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以文献综述引入研究背景，常用tricks包括层次结构模型对比、基线模型设定、参数共享机制和端到端反向传播训练。\n第3段（60字）：适用场景与预期效果 - 适用于字符级和词级建模任务，特别是处理罕见词和低频词，预期提升模型对罕见词和形态丰富语言的表示能力。",
    "writing_guide": "写作模板：低频词表示端到端神经网络\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决低频词表示与上下文建模问题，采用端到端神经网络设计和视觉信息融合技术。\n第2段（60字）：关键技术组合与写作策略 - skeleton以文献综述引入研究背景，常用tricks包括层次结构模型对比、基线模型设定、参数共享机制和端到端反向传播训练。\n第3段（60字）：适用场景与预期效果 - 适用于字符级和词级建模任务，特别是处理罕见词和低频词，预期提升模型对罕见词和形态丰富语言的表示能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning Character-level Compositionality with Visual Features》\n  • 问题定位：论文通过定义组合性（compositionality）为自然语言的核心特征，并回顾神经模型在句子表征中的应用，强调了理解词以下层级的组合对于语言理解的重要性。引言以理论基础和技术进展为铺垫，逐步引出研究问题。\n  • 现有研究缺口：作者指出现有模型多依赖于词级或字符级的查找式嵌入，忽视了字符视觉特征的潜力。通过回顾相关文献，强调需要探索基于字符视觉信息的表征方法，从而填补现有方法在低频字符处理上的不足。\n  • 核心方法：方法部分采用对比叙述策略，先介绍基线Lookup模型的传统字符嵌入方式，再引出创新的Visual模型，强调其通过CNN从字符视觉外观学习表征。整体流程清晰，便于突出新旧方法的差异。\n  • 实验设计：实验部分按递进逻辑展开，先验证新模型的基本有效性，再针对低频字符优势进行对比，最后探讨多模型融合效果。每步实验目标明确，参数设置详尽，突出实验设计的系统性和针对性。\n\n示例 2：《Semi-supervised sequence tagging with bidirectional language models》\n  • 问题定位：论文在引言部分采用了现有技术回顾与实际需求结合的策略，先强调预训练词嵌入在NLP中的普遍性及有效性，并引用权威文献支持其语义和句法信息捕获能力，随后通过具体例子指出词嵌入在上下文表达上的局限，引出对上下文敏感表示的需求。\n  • 现有研究缺口：作者通过对比词嵌入的优势与实际任务需求，批评了其在处理上下文相关信息上的不足，强调现有方法无法区分同一词在不同语境下的角色，进而提出当前序列标注模型需更好地编码上下文，明确了研究的创新空间。\n  • 核心方法：方法部分采用结构化分层叙述，先整体介绍模型架构并与近期相关工作对齐，随后详细分解每个模块的输入、处理方式和参数化细节，通过公式和引用说明字符级与词级信息融合，突出模型对形态和语义的联合建模能力。\n  • 实验设计：实验部分以标准任务为切入点，选用广泛认可的基准数据集和评价指标，严格遵循前人工作设定（如标签方案和预处理），通过分任务描述和细节复现，确保结果的可比性和方法有效性，突出实验设计的规范性和透明度。\n\n示例 3：《Rare Entity Prediction: Language Understanding with External Knowledge using Hierarchical LSTMs》\n  • 问题定位：论文通过强调自然语言处理领域中模型获取世界知识的核心难题引入研究主题，明确提出模型可通过非结构化文本和结构化知识库两种方式获取知识，并以阅读理解作为检验模型能力的自然场景，聚焦于模型知识获取能力的评估。\n  • 现有研究缺口：作者批评现有阅读理解任务（如Daily Mail/CNN数据集）主要依赖基础语言建模，缺乏对推理能力的考察，指出当前任务在知识获取和推理层面存在不足，从而为新任务和方法的提出奠定基础。\n  • 核心方法：方法部分采用先介绍模型整体思路，再细致说明核心技术（RNN与LSTM），通过解释其结构和优势，突出模型对顺序数据和语言问题的适用性，为后续实验验证提供理论支撑。\n  • 实验设计：实验部分详细描述数据集划分、上下文与定义的具体设置，并报告对不同参数配置的尝试及其效果，采用逐步试错和对比分析的方法，突出实验设计的系统性和结果的客观性。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 文献综述引入法（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过引用大量相关工作（如Szabó, 2010; Iyyer et al., 2015等），介绍组合性在自然语言处理中的重要性和当前主流模型方法，为后续研究动机做铺垫。\n\n2. 层次结构模型对比（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：对比从简单到复杂的模型（如Bag-of-Words、RNN、树结构、CNN），展示方法发展脉络，并引出自身模型的独特性。\n\n3. 子词级别建模（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：强调组合性不仅在词之间存在，也在词内部，通过字符级、形态级建模提升对罕见词的表示能力。\n\n4. 基线模型设定（使用频率 1 次，占比 14.3%）\n   类型：experiment-level\n   应用：明确设置Lookup模型作为基线，用字符嵌入查找表实现字符表示，为后续新方法提供对比。\n\n5. 端到端神经网络设计（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：采用端到端结构：字符表示—RNN—句子表示—softmax分类，体现现代神经网络的整体设计理念。\n\n6. 视觉信息融合（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：创新地将字符转为图片，利用CNN提取视觉特征，生成字符嵌入，提升对低频及形近字符的参数共享能力。\n\n7. 参数共享机制（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：通过视觉特征映射，实现参数在形近字符间共享，提高模型对低频字符的学习效果。\n\n8. 图示辅助说明（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过图示（如Fig. 3）直观展示模型结构和流程，帮助读者理解复杂方法。\n\n9. 端到端反向传播训练（使用频率 1 次，占比 14.3%）\n   类型：method-level\n   应用：整个模型参数，包括CNN部分，通过分类损失端到端反向传播优化，保证特征与任务紧密结合。\n\n10. 引用前人工作建立背景（使用频率 1 次，占比 14.3%）\n   类型：writing-level\n   应用：通过引用多篇前人工作（如Mikolov et al., 2013; Pennington et al., 2014），阐述预训练词嵌入在NLP中的广泛应用和有效性，从而自然引出当前研究的动机。\n",
    "cluster_size": 7,
    "coherence_score": 0.75,
    "paper_ids": [
      "ACL_2017_543",
      "ACL_2017_561",
      "ACL_2017_588",
      "ACL_2017_554",
      "ACL_2017_760",
      "ACL_2017_371",
      "ACL_2017_792"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "文献综述引入法",
        "frequency": 1,
        "percentage": "14.3%"
      },
      {
        "name": "层次结构模型对比",
        "frequency": 1,
        "percentage": "14.3%"
      },
      {
        "name": "子词级别建模",
        "frequency": 1,
        "percentage": "14.3%"
      },
      {
        "name": "基线模型设定",
        "frequency": 1,
        "percentage": "14.3%"
      },
      {
        "name": "端到端神经网络设计",
        "frequency": 1,
        "percentage": "14.3%"
      }
    ]
  },
  {
    "pattern_id": "pattern_30",
    "name": "多目标训练长文本模型",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决长文本理解与生成问题，采用多目标训练和参数共享策略提升模型长距离依赖能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以学术gap开篇，通过理论与实际对比解释方法必要性，常用tricks包括参数敏感性分析和分任务实验设计。\n第3段（60字）：适用场景与预期效果 - 适用于长文档理解、问答、文本生成等任务，预期提升模型在长距离依赖上的表现和泛化能力。",
    "writing_guide": "写作模板：多目标训练长文本模型\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决长文本理解与生成问题，采用多目标训练和参数共享策略提升模型长距离依赖能力。\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以学术gap开篇，通过理论与实际对比解释方法必要性，常用tricks包括参数敏感性分析和分任务实验设计。\n第3段（60字）：适用场景与预期效果 - 适用于长文档理解、问答、文本生成等任务，预期提升模型在长距离依赖上的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Boosting coherence of language models》\n  • 问题定位：论文从学术gap出发引出问题，强调当前语言模型虽然在生成、排序和分类任务上表现良好，但由于训练数据可能违反语用规范，以及模型训练目标与实际推断时的上下文条件不一致，导致长距离语义连贯性不足。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出传统的n-gram和早期神经语言模型虽然尝试平衡短距离统计约束与长距离结构，但仍然对远距离内容或语法不敏感，并容易受到近期上下文的偏见影响。\n  • 核心方法：方法部分采用‘先整体后局部’的叙述策略。首先介绍多目标训练的整体框架，解释模型如何同时拟合不同长度上下文的预测器，并分析训练与推断时上下文分布的差异。\n  • 实验设计：实验部分采用‘多数据集验证+主实验+横向对比’的策略。首先在LAMBADA数据集上进行主实验，验证方法在长距离依赖预测上的有效性，并通过参数搜索展示模型表现的提升。\n\n示例 2：《QuALITY: Question Answering with Long Input Texts, Yes!》\n  • 问题定位：论文从实际痛点和应用需求出发引出问题。开篇强调当前自然语言理解模型受限于只能处理几百个词，无法应对需要整体理解长篇文本的任务，这限制了在新闻理解、摘要和问答等实际应用中的能力。作者进一步指出，突破这一限制将带来新的应用可能，并认为建立新的基准数据集是解决该问题的关键路径。\n  • 现有研究缺口：论文通过学术gap的逻辑批评现有方法。首先指出现有数据集大多只包含人类几分钟可读的短文本，无法支持长文档整体理解。其次，虽然有部分开放域问答数据集涉及长文本，但通常只需检索短片段即可回答问题，未能真正考验长文档理解能力。\n  • 核心方法：方法部分采用分模块介绍和先整体后局部的叙述策略。首先介绍了长文本输入的模型（Longformer及其变体），再介绍了基于检索的抽取式方法，包括三种不同的句子相关性评分方法。\n  • 实验设计：实验部分采用主实验+多基线+难度分组的策略。首先展示各模型在主测试集上的表现，并与人类表现进行对比，突出模型与人类的差距。其次，分析不同训练数据（QuALITY、RACE、RACE→QuALITY）对模型性能的影响。\n\n示例 3：《LongT5: Efficient Text-To-Text Transformer for Long Sequences》\n  • 问题定位：论文采用了从学术gap出发的开篇策略。首先回顾了Transformer模型（如BERT、T5等）在NLP任务中的优异表现，并指出近期长输入Transformer的进展表明扩大输入长度和模型规模能带来性能提升。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下受限’的逻辑。\n  • 核心方法：方法部分采用了‘先整体后局部’和‘分模块介绍’的叙述策略。首先整体介绍了LongT5的设计思想，即在T5架构基础上同时扩展输入长度和模型规模。\n  • 实验设计：实验部分采用了‘多数据集验证+主实验’的策略。首先在多种摘要任务（涵盖不同输入长度）上与主流方法进行对比，使用ROUGE等标准指标评估，突出LongT5在长输入场景下的优势。其次在问答任务（NQ和TriviaQA）上验证模型的长上下文理解能力，采用EM和F1指标。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 实验细节透明披露（使用频率 2 次，占比 40.0%）\n   类型：experiment-level\n   应用：作者详细说明实验设置、参数选择、数据处理和代码开放，确保读者可以复现结果。\n\n2. 问题引入与动机铺垫（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：作者首先指出现有语言模型在长距离连贯性上的失败，并用具体模型（GPT-2/3）和数据分布偏差举例，强调问题的普遍性和重要性。\n\n3. 创新方法简明预告（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：作者在引言末尾直接提出了coherence boosting方法，并简要说明其原理和优势，为后文详细展开做铺垫。\n\n4. 理论与实际场景对比（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：作者详细分析了训练时多目标优化与推理时单目标分布的区别，指出现有训练方式导致长距离依赖建模不足，为新方法的必要性提供理论基础。\n\n5. 参数共享与优化困境阐释（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：通过阐述参数共享和长短上下文损失的权衡，解释模型在长距离依赖建模上的天然劣势。\n\n6. 分任务实验设计（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：作者将实验分为五大类任务（完形填空、问答、文本分类、自然语言推断、知识检索），覆盖15个数据集，确保方法在多种场景下都有效。\n\n7. 与主流模型直接对比（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：在LAMBADA等任务上，作者将coherence boosting后的模型与原始GPT-2/3进行准确率对比，展示显著提升，甚至小模型超过大模型。\n\n8. 参数敏感性分析（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过对混合参数的网格搜索和分析，作者揭示最佳参数随模型规模变化的规律，解释大模型对长距离依赖的天然优势。\n\n9. 自然场景与基准任务结合（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：作者在通用文本生成和对话任务中评估方法，展示生成文本中长距离依赖词的分布接近自然文本。\n\n10. 逻辑递进式叙事结构（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：全文结构从问题引入、理论分析、方法提出到分层实验验证，层层递进，逻辑清晰。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_312",
      "ARR_2022_142",
      "ARR_2022_29",
      "ARR_2022_349",
      "ARR_2022_346"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "实验细节透明披露",
        "frequency": 2,
        "percentage": "40.0%"
      },
      {
        "name": "问题引入与动机铺垫",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "创新方法简明预告",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "理论与实际场景对比",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "参数共享与优化困境阐释",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_31",
    "name": "神经序列模型与预训练嵌入",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义解析和自然语言理解中的表达能力和特征工程难题，采用神经序列模型直接生成目标语言，结合在线学习和预训练嵌入提升性能。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和研究缺口开篇，方法部分采用分步叙述和公式补充，常用tricks包括在线部署、预训练嵌入拼接、全局注意力机制等，实验设计注重对比验证和实际应用。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要将自然语言转换为目标语言的任务，如SQL生成、程序构建等，预期提升模型的表达能力和泛化性能，减少特征工程成本。",
    "writing_guide": "写作模板：神经序列模型与预训练嵌入\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决语义解析和自然语言理解中的表达能力和特征工程难题，采用神经序列模型直接生成目标语言，结合在线学习和预训练嵌入提升性能。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和研究缺口开篇，方法部分采用分步叙述和公式补充，常用tricks包括在线部署、预训练嵌入拼接、全局注意力机制等，实验设计注重对比验证和实际应用。\n\n第3段（60字）：适用场景与预期效果 - 适用于需要将自然语言转换为目标语言的任务，如SQL生成、程序构建等，预期提升模型的表达能力和泛化性能，减少特征工程成本。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Learning a Neural Semantic Parser from User Feedback》\n  • 问题定位：论文通过对现有语义解析方法的局限性进行概述，突出自然语言接口构建中的两大难题：中间表示的表达能力不足和特征工程的高成本。作者以实际应用部署难度为切入点，强调亟需更高效、易用的解决方案。\n  • 现有研究缺口：作者采用对比批评策略，指出现有方法要么牺牲查询语言的表达力，要么依赖繁琐的特征工程，导致难以迁移和扩展。通过明确现有工作的不足，为提出新方法奠定理论基础和实际需求。\n  • 核心方法：方法部分采用分步叙述，先总体介绍神经序列模型如何直接映射自然语言到SQL，随后详细说明模型架构、输入处理和解码机制，并用公式补充技术细节，突出创新点和实现路径。\n  • 实验设计：实验部分以对比验证为主线，先展示模型在标准数据集上的表现，强调直接生成SQL的难度和突破。通过与前人工作的结果对比，突出新方法无需特征工程即可达到同等性能，强化方法有效性和实用价值。\n\n示例 2：《Probabilistic Regular Graph Languages》\n  • 问题定位：论文通过指出当前NLP系统在处理机器翻译、摘要和复述等任务时，常因仅以词袋或语法树建模语言而无法保持句子和文档的组合语义，从而引出语义保留的重要性，强调语义建模的必要性。\n  • 现有研究缺口：作者批评现有方法忽视了语言的组合语义，仅依赖表层结构，导致语义丢失。通过列举已有语义标注数据集，提出现有数据虽丰富，但缺乏有效的概率图模型来充分利用这些资源。\n  • 核心方法：方法部分以需求为驱动，明确提出为利用配对语义图的数据集，必须开发概率图模型。此策略将方法的提出与前述语义保留需求紧密关联，形成逻辑递进。\n  • 实验设计：实验部分通常围绕验证所提概率图模型的有效性展开，通过与现有方法或基线进行对比，展示模型在语义保留和下游任务上的优势，结构上强调方法与实际应用之间的联系。\n\n示例 3：《Robust Incremental Neural Semantic Graph Parsing》\n  • 问题定位：论文通过强调自然语言理解（NLU）中将句子解析为结构化、可解释语义表示的重要性，引出研究主题。作者指出这些结构对于查询执行、推理等任务至关重要，并以当前端到端模型在浅层解析任务中的优势为切入点，逐步聚焦到深层语义解析的挑战。\n  • 现有研究缺口：作者批评现有方法多局限于浅层解析（如双词依存），缺乏对深层语义结构的有效处理。通过对比传统管道方法和最新端到端模型，指出当前研究在解析深层语义表示（如MRS）方面存在不足，明确了论文的创新空间和研究价值。\n  • 核心方法：方法部分采用递进式叙述，先介绍对硬注意力模型的扩展，再详细说明如何结合过渡系统堆栈特征，并引用相关工作以增强方法的合理性。通过具体公式和结构描述，突出方法的创新点和与前人工作的联系与区别。\n  • 实验设计：实验部分以评价指标为核心，先介绍EDM指标的定义和适用性，再通过与Smatch等其他指标的对比，突出所选指标对MRS解析的针对性。实验设计注重细节，如对标注误差的容忍度，体现了对实际应用场景的考虑。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. Bypassing Intermediate Representations（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用神经序列模型将自然语言直接映射到SQL查询，避免使用中间语义表示，从而可以充分利用SQL的查询能力并减少特定领域的特征工程。\n\n2. Online Deployment for Interactive Learning（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：将模型立即部署到线上，收集用户的问题和对结果的反馈，利用真实交互数据进行模型优化，并减少SQL标注工作量。\n\n3. Crowdsourcing SQL Annotations（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：通过技能型众包市场获取SQL标注，这些标注既能直接用于模型训练，也比传统的逻辑语义标注更容易获得和更经济。\n\n4. Encoder-Decoder with Global Attention（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用带有全局注意力机制的编码-解码结构，编码端使用双向LSTM，解码端直接输出SQL查询token，通过注意力机制动态聚焦输入的不同部分。\n\n5. Combining Pre-trained and Learned Embeddings（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将预训练的word2vec词向量与在训练数据上学习到的源词嵌入进行拼接，丰富词语表达，提升模型性能。\n\n6. Conditional Token Prediction in Decoder（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：解码器在生成下一个SQL token时，基于之前生成的token、编码器隐藏状态的注意力以及前一时刻的注意力信号，计算条件概率分布，从而实现上下文相关的生成。\n\n7. Formal Mathematical Description of Model Components（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：用数学公式详细描述解码器分布、上下文向量和注意力权重的计算方法，使模型实现过程清晰、规范，便于他人复现。\n\n8. Rapid Domain Adaptation via Short-term Deployment（使用频率 1 次，占比 20.0%）\n   类型：experiment-level\n   应用：通过仅三天的在线部署，在学术领域成功训练出语义解析器，展示了方法在新领域的高效部署和学习能力。\n\n9. Comparative Reference to Related Work（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：将本方法与直接生成程序、基于众包获取释义等相关技术进行对比，强调本方法的优势和创新之处。\n\n10. 指出现有方法的局限性（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过批判现有方法（如bag-of-words和句法树）未能保留组合语义，引出对语义建模的需求，为后续研究铺垫背景。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ACL_2017_726",
      "ACL_2017_503",
      "ACL_2017_578",
      "ACL_2017_706",
      "ACL_2017_606"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "Bypassing Intermediate Representations",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "Online Deployment for Interactive Learning",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "Crowdsourcing SQL Annotations",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "Encoder-Decoder with Global Attention",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "Combining Pre-trained and Learned Embeddings",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  },
  {
    "pattern_id": "pattern_32",
    "name": "文本分类与情感分析模型验证",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨文本分类与情感分析中的简单模型有效性，通过系统性文献回顾和对比性实验设计验证假设。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以问题引入和任务演进铺垫，常用tricks包括系统性文献回顾、方法家族归纳、对比性实验设计和多数据集验证。\n\n第3段（60字）：适用场景与预期效果 - 适用于文本分类、情感分析等NLP任务，特别是需要验证简单模型有效性的场景，预期提升模型的泛化能力和解释性。",
    "writing_guide": "写作模板：文本分类与情感分析模型验证\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要探讨文本分类与情感分析中的简单模型有效性，通过系统性文献回顾和对比性实验设计验证假设。\n\n第2段（60字）：关键技术组合与写作策略 - skeleton特点以问题引入和任务演进铺垫，常用tricks包括系统性文献回顾、方法家族归纳、对比性实验设计和多数据集验证。\n\n第3段（60字）：适用场景与预期效果 - 适用于文本分类、情感分析等NLP任务，特别是需要验证简单模型有效性的场景，预期提升模型的泛化能力和解释性。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP》\n  • 问题定位：论文通过强调文本分类领域方法众多、研究活跃这一现实切入，展示了当前方法的多样性和复杂性，进而引出自身的研究问题。开篇采用了从学术现状和方法繁多的实际痛点出发的策略，指出尽管有许多复杂模型，但是否简单的BoW模型也能很好完成任务仍值得探究。\n  • 现有研究缺口：论文通过对现有方法的系统梳理，指出当前主流方法分为BoW、图模型和序列模型三大类，并分别描述其代表性方法和特点。隐含批评在于：尽管有大量复杂模型（如图模型、Transformer等），但简单的BoW模型是否被低估了其有效性尚未被充分研究。\n  • 核心方法：方法部分采用了‘先整体后局部’的策略，首先将所有方法划分为三大类（BoW、图模型、序列模型），再通过表格总结各自关键属性，突出不同方法的本质区别。整体介绍后，逐一细化每类方法的代表性实现和核心机制。\n  • 实验设计：实验部分采用‘多方法、多数据集对比’的策略，既有从文献中汇报的结果，也有作者自行复现的实验。对16种方法在5个数据集上进行系统性对比，突出主实验的全面性，强调横向对比和结果的代表性。\n\n示例 2：《A Robustly Optimized BMRC for Aspect Sentiment Triplet Extraction》\n  • 问题定位：论文首先从领域重要性和实际需求出发，介绍了细粒度情感分析（ABSA）作为自然语言处理中的重要研究方向，强调其在挖掘特定方面意见和情感上的价值。随后通过回顾ABSA的三个基本子任务及其发展，逐步引出当前研究热点——方面情感三元组抽取（ASTE），并明确指出这是本文的研究目标。\n  • 现有研究缺口：论文通过对现有方法（如BMRC）进行评价，指出其存在的具体问题：例如共享分类器可能导致查询冲突，影响模型性能；忽略了词分割、span匹配和概率生成等重要策略。批评逻辑以“现有方法在特定结构下存在缺陷”以及“忽视关键策略”两种句式展开，强调了方法在实际应用中的不足和改进空间。\n  • 核心方法：方法部分采用了先整体后局部的叙述顺序。首先简要回顾了BMRC的基本原理，作为背景铺垫，然后逐项详细介绍了本文提出的四项改进，包括专属分类器设计、词分割、span匹配优化和概率生成优化。每项改进都紧扣前述gap，突出针对性和创新性，整体结构清晰、层层递进。\n  • 实验设计：实验部分采用了多数据集验证和多类型实验的策略。首先介绍了实验所用的数据集、评价指标和对比基线，确保实验的公平性和权威性。主实验对比了改进前后的模型性能，并在多个公开数据集上验证了方法的有效性。随后通过消融实验（如F1分数提升分析）进一步证明各项改进的贡献。\n\n示例 3：《Learning Cognitive Features from Gaze Data for Sentiment and Sarcasm Classification using Convolutional Neural Network》\n  • 问题定位：论文通过强调情感与讽刺检测在社交媒体分析、推荐和对话系统中的核心地位，直接切入研究主题。引言中结合实际应用场景，突出了该问题的现实意义和研究价值，吸引读者关注。\n  • 现有研究缺口：作者通过回顾已有文献，指出传统方法虽能处理词汇和句法层面的问题，但在语义和语用层面存在显著不足，尤其难以捕捉复杂的语境和讽刺表达，从而明确提出研究空白和挑战。\n  • 核心方法：方法部分采用分步叙述策略，先简要介绍整体技术路线，再细化为不同的模型变体，并通过引用相关章节（如4.1）提示后文详细说明，层层递进，增强逻辑性和可读性。\n  • 实验设计：实验部分以“逐项列举”的方式展开，先介绍数据集来源、规模及其独特性（如眼动数据），再依次说明实验设置和模型变体，条理清晰，便于读者快速把握实验设计的全貌。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 系统性文献回顾（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：作者详细回顾了领域内主流方法及其代表性文献，梳理了BoW、图模型和序列模型三大类方法，为自己的研究定位提供了坚实背景。\n\n2. 方法家族归纳（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：将现有方法归纳为BoW-based、graph-based和sequence-based三大类，并在方法部分用表格对比其关键属性。\n\n3. 对比性实验设计（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：明确指出将16种方法分为三大类进行系统对比，并结合文献结果和自有实验，确保对比的广度和深度。\n\n4. 多数据集验证（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：在5个公开文本分类数据集上进行实验，覆盖不同任务场景，提升实验的完备性。\n\n5. 自设假设驱动（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：明确提出“简单但有效的BoW模型可以很好地完成文本分类”这一假设，为全文实验和讨论定下主线。\n\n6. 属性对比表格（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过表格形式对比三类模型在图结构、词序、文本长度、归纳能力等维度的差异。\n\n7. 文献实验结果引用与自有实验结合（使用频率 1 次，占比 16.7%）\n   类型：experiment-level\n   应用：部分方法直接引用文献中的实验结果，部分方法由作者自行复现，兼顾实验的广度与深度。\n\n8. 逻辑递进式叙事（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：先提出领域问题和主流方法，再归纳方法类别，最后引出自己的研究假设和实验设计。\n\n9. 任务演进铺垫（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：通过梳理ABSA领域的任务演进，从基础子任务到复杂任务（如ASTE），逐步引出本文关注的研究目标，显示问题的重要性和研究的自然延伸。\n\n10. 引用权威与前沿工作（使用频率 1 次，占比 16.7%）\n   类型：writing-level\n   应用：大量引用领域内权威和最新文献，说明该方向受到广泛关注，并明确自己的工作与前人工作的关系。\n",
    "cluster_size": 6,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_230",
      "ARR_2022_351",
      "ACL_2017_387",
      "ACL_2017_33",
      "COLING_2020_76",
      "COLING_2020_73"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "系统性文献回顾",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "方法家族归纳",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "对比性实验设计",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "多数据集验证",
        "frequency": 1,
        "percentage": "16.7%"
      },
      {
        "name": "自设假设驱动",
        "frequency": 1,
        "percentage": "16.7%"
      }
    ]
  },
  {
    "pattern_id": "pattern_33",
    "name": "多Span阅读理解技术",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多span阅读理解问题，采用模块化方法设计和多指标评估体系。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法梳理为基础，常用tricks包括问题空白强调、数据集创新展示和多指标评估体系。\n第3段（60字）：适用场景与预期效果 - 适用于多span阅读理解任务，数据集多样，目标是提升模型在复杂场景下的表现和泛化能力。",
    "writing_guide": "写作模板：多Span阅读理解技术\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决多span阅读理解问题，采用模块化方法设计和多指标评估体系。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题引入和现有方法梳理为基础，常用tricks包括问题空白强调、数据集创新展示和多指标评估体系。\n第3段（60字）：适用场景与预期效果 - 适用于多span阅读理解任务，数据集多样，目标是提升模型在复杂场景下的表现和泛化能力。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《MultiSpanQA: A Dataset for Multi-Span Question Answering》\n  • 问题定位：论文首先从学术进展和实际需求出发，引入阅读理解任务的最新发展，指出现有系统已在主流数据集上接近甚至超越人类表现。随后，作者强调实际应用中答案常常由多个部分组成，而现有研究几乎全部局限于单一可抽取或计算的答案片段。\n  • 现有研究缺口：论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体地，指出现有数据集和方法都假定答案为单一片段，忽略了多片段答案的普遍性和复杂性。通过举例说明实际问题，并强调缺乏相关数据集和系统性研究，进一步论证现有方法的局限性。\n  • 核心方法：方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先回顾相关工作，梳理多片段预测的主流技术路径及其缺陷。随后，正式定义多片段QA任务，提出自己的方法框架。\n  • 实验设计：实验部分采用‘主实验+多基线对比’的策略，聚焦于新数据集MultiSpanQA的性能验证。首先详细说明实验设置，包括模型结构、训练参数和评价指标。随后，分组报告不同模型（单片段、序列标注、联合预测等）在基础数据集和扩展数据集（含不可回答和单片段问题）上的表现。\n\n示例 2：《Answer Uncertainty and Unanswerability in Multiple-Choice Machine Reading Comprehension》\n  • 问题定位：论文首先从实际应用需求出发，指出机器阅读理解（MRC）系统在自然语言处理中的重要性，并强调当前主流系统在公开数据集上已超越人类表现。但作者进一步提出，在实际部署中，MRC系统并不总是需要回答所有问题，特别是在存在答案不确定性或问题无解的情况下。\n  • 现有研究缺口：论文批评现有工作的逻辑主要体现在两个方面：一方面，指出已有大量工作关注span-based MRC中的无解性，但在多项选择题MRC中对此关注有限；另一方面，强调大部分相关研究仅专注于提升默认任务的性能，而忽视了对无解性和答案不确定性的系统性研究。\n  • 核心方法：方法部分采用先整体后局部的叙述策略。首先介绍了所用数据集（ReClor）及其默认配置，然后详细说明了为研究答案不确定性和无解性而设计的数据集变体（如TRN-mixed, TRN-ans, DEV-mixed），以及各自的构成比例。\n  • 实验设计：实验部分主要采用主实验+对比实验的叙述策略。首先基于不同的数据集配置（如默认、混合、仅可答）进行实验，系统地分析了ELECTRA模型在不同设置下的表现，并与其他主流预训练语言模型（PrLMs）及代表性系统（如DAGN、FocalReasoner）进行对比。\n\n示例 3：《Evaluation Metrics for Reading Comprehension: Prerequisite Skills and Readability》\n  • 问题定位：论文引言通过强调自然语言处理（NLP）目标——让智能体理解自然语言——引入研究问题，并以阅读理解（RC）任务为测试手段，突出RC能力的复杂性和多步骤特性，凸显其研究价值和挑战性。\n  • 现有研究缺口：作者批评当前RC数据集主要以表层类别（如问题类型）进行分类，忽视了对系统实际能力的细致刻画，指出仅用简单准确率衡量系统不足，强调需要更丰富的评测维度以推动RC系统发展。\n  • 核心方法：方法部分采用逐一说明数据集选择与样本筛选过程，详细列举所用RC数据集（QA4MRE、MCTest、SQuAD）及其抽样策略，突出实验设计的代表性和覆盖性，为后续分析奠定基础。\n  • 实验设计：实验部分以理论为依据，明确提出两大评价维度（前提技能与可读性），并结合前人工作细化技能分类，强调评价指标的科学性和系统性，展示实验设计的理论支撑和创新点。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 问题空白强调（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：作者指出现有阅读理解数据集几乎都只关注单一span答案，忽略了实际中常见的多span问题，强调了研究空白。\n\n2. 数据集创新展示（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：作者详细介绍了MultiSpanQA数据集的构建过程和规模，强调其是首个高质量多span阅读理解数据集。\n\n3. 多维度贡献总结（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：通过列举数据集、标签体系、模型和指标等多方面贡献，系统性地总结工作亮点。\n\n4. 现有方法梳理与不足分析（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：作者系统回顾了多span相关方法，指出它们在捕获全局信息、结构预测等方面的不足。\n\n5. 模块化方法设计（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：将模型分为编码器、序列标注器、span数预测器、结构预测器和调整模块等，清晰分解任务流程。\n\n6. 公式推导与逐步说明（使用频率 1 次，占比 11.1%）\n   类型：method-level\n   应用：通过逐步列出公式和模块输入输出，详细解释每一步的原理和实现方式。\n\n7. 多指标评估体系（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：采用精确匹配、部分匹配、F1、结构预测准确率等多种指标，全面评估模型性能。\n\n8. 多种基线对比（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：与单span模型、序列标注模型等多种基线进行对比，展示新方法的性能提升。\n\n9. 分组难度分析（使用频率 1 次，占比 11.1%）\n   类型：experiment-level\n   应用：按答案类型和span数量分组报告结果，分析模型在不同类别上的表现和难点。\n\n10. 逻辑递进式叙事结构（使用频率 1 次，占比 11.1%）\n   类型：writing-level\n   应用：从问题引入、现有方法梳理、创新方法提出、实验验证到结论呼应，层层递进组织全文。\n",
    "cluster_size": 9,
    "coherence_score": 0.75,
    "paper_ids": [
      "ARR_2022_130",
      "ARR_2022_330",
      "ACL_2017_148",
      "ACL_2017_684",
      "ACL_2017_117",
      "ACL_2017_18",
      "ACL_2017_335",
      "COLING_2020_83",
      "COLING_2020_57"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "问题空白强调",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "数据集创新展示",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "多维度贡献总结",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "现有方法梳理与不足分析",
        "frequency": 1,
        "percentage": "11.1%"
      },
      {
        "name": "模块化方法设计",
        "frequency": 1,
        "percentage": "11.1%"
      }
    ]
  },
  {
    "pattern_id": "pattern_34",
    "name": "神经网络多任务学习分词",
    "summary": "第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决中文分词任务中的多语料兼容性和标注成本问题，采用神经网络模型和多任务学习方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和文献综述开篇，常用tricks包括举例说明分歧、强调特征工程的最小化和文献综述引入研究背景。\n第3段（60字）：适用场景与预期效果 - 适用于需要处理多语料和大规模标注数据的中文分词任务，预期提升模型的泛化能力和标注效率。",
    "writing_guide": "写作模板：神经网络多任务学习分词\n\n【模板聚焦】\n第1段（60字）：核心研究问题与技术路线 - 这类论文主要解决中文分词任务中的多语料兼容性和标注成本问题，采用神经网络模型和多任务学习方法。\n第2段（60字）：关键技术组合与写作策略 - skeleton以问题定位和文献综述开篇，常用tricks包括举例说明分歧、强调特征工程的最小化和文献综述引入研究背景。\n第3段（60字）：适用场景与预期效果 - 适用于需要处理多语料和大规模标注数据的中文分词任务，预期提升模型的泛化能力和标注效率。\n\n【代表性论文骨架示例】\n该套路包含 3 个代表性论文的骨架示例，可直观体现该模式的论文撰写框架：\n\n示例 1：《Adversarial Multi-Criteria Learning for Chinese Word Segmentation》\n  • 问题定位：论文通过强调中文分词在自然语言处理中的基础性和重要性，引入当前主流方法依赖大规模人工标注语料库的高成本问题，突出任务的现实意义和挑战性，为后续研究动机做铺垫。\n  • 现有研究缺口：作者指出已有分词语料库虽取得进展，但因分词标准不一致导致资源难以充分利用，批评现有方法在多语料兼容性上的不足，强调资源浪费和研究空白，明确提出需要更好利用多语料库的需求。\n  • 核心方法：方法部分采用由浅入深的叙述策略，先介绍分词任务的主流建模方式（序列标注），再列举传统与神经网络方法，突出神经网络在特征工程上的优势，并具体说明任务的标签体系和输入输出形式，逻辑清晰递进。\n  • 实验设计：实验部分详细说明参数设置和数据预处理策略，针对不同数据集规模调整批次大小，描述dropout和参数初始化方法，统一字符嵌入矩阵以保证跨语料一致性，并与前人工作对齐，突出实验设计的规范性和可复现性。\n\n示例 2：《Neural Word Segmentation with Rich Pretraining》\n  • 问题定位：论文通过回顾分词领域从统计方法到深度学习的研究转向，强调神经网络模型在特征组合和非稀疏表示上的优势，引出当前神经分词器已达到或超过传统方法的准确率，顺势引入自身工作的研究背景和意义。\n  • 现有研究缺口：作者指出，尽管神经分词器表现优异，但现有方法主要依赖字符嵌入以减少n-gram稀疏性，暗示当前模型在特征利用和结构设计上仍有改进空间，为后续提出新方法埋下伏笔。\n  • 核心方法：方法部分采用逐步递进的叙述策略，先整体描述分词器的增量式处理流程，再形式化定义状态和转移操作，结合图示说明，帮助读者直观理解模型的工作机制和创新点。\n  • 实验设计：实验部分详细说明数据集选择与分割，既遵循前人工作以保证可比性，又引入多样测试集验证模型鲁棒性，并具体描述预训练过程，突出实验设计的全面性和严谨性。\n\n示例 3：《None》\n  • 问题定位：论文通过强调词素切分在多个NLP任务中的核心作用引入研究问题，引用相关领域（如信息检索、语音识别、机器翻译）的文献，凸显该任务的基础性和广泛应用价值，增强问题的重要性和现实意义。\n  • 现有研究缺口：作者批评以往研究过度依赖正字法特征，忽视了语义信息，导致词语被过度切分。通过具体例子说明表层形式变化并不总能准确反映形态变化，从而指出现有方法的局限性和改进空间。\n  • 核心方法：方法部分采用对比叙述策略，首先介绍自身系统MORSE的性能评估方式，并明确与主流工具Morfessor的对比。通过多语言测试和数据集创新，突出方法的普适性和创新性，强调语义信息的引入。\n  • 实验设计：实验部分结构清晰，先进行本体性能评估，再跨三种形态复杂度不同的语言测试算法通用性，随后批判现有基准数据集并提出新数据集，最后通过特定词汇集比较语义信息对切分效果的影响，层层递进展示方法优势。\n\n【高频研究技巧】\n该模式下有以下 15 个高频使用的研究技巧：\n\n1. 引入研究背景和痛点（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过介绍中文分词任务的重要性、现有方法的局限（如高昂的标注语料成本和语料不兼容问题），有效引出研究动机和本文工作的意义。\n\n2. 举例说明分歧（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过具体句子“姚明进入总决赛”在不同语料库的切分结果，直观展示分词标准不统一的问题，增强问题的现实感。\n\n3. 文献综述与现有方法评述（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：简要回顾已有利用异构标注数据的方法，分析其采用的技术（如stacking或多任务架构）及存在的不足（如共享特征空间设计复杂），为后文提出新方法做铺垫。\n\n4. 问题形式化建模（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将中文分词任务形式化为基于字符的序列标注问题，明确每个字符的标签集合（B, M, E, S），并给出数学表达式，提升表达的科学性和严谨性。\n\n5. 通用神经网络架构分层描述（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：将神经网络分为字符嵌入层、特征提取层和标签推断层三个部分，分别说明各层作用，使读者对整体架构有清晰把握。\n\n6. 采用先进模型结构（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：采用双向长短时记忆网络（Bi-LSTM）结合条件随机场（CRF）作为标签推断层，引用最新研究，说明所用架构为当前最优方法之一。\n\n7. 强调特征工程的最小化（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：指出神经网络能自动学习特征，减少人工特征工程工作，突出方法的实用性和先进性。\n\n8. 充分利用异构语料资源（使用频率 1 次，占比 20.0%）\n   类型：method-level\n   应用：提出利用多种分词标准的异构语料，通过多任务学习等方式，解决语料不兼容和资源浪费的问题。\n\n9. 文献综述引入研究背景（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：通过回顾统计方法到深度学习的研究转变，引用多个相关文献，突出当前深度学习在分词任务中的重要性和主流地位。\n\n10. 强调神经网络的非稀疏表示能力（使用频率 1 次，占比 20.0%）\n   类型：writing-level\n   应用：强调神经网络在表示学习和特征组合上的非稀疏性和非线性能力，为后文介绍embedding和网络结构做理论基础。\n",
    "cluster_size": 5,
    "coherence_score": 0.75,
    "paper_ids": [
      "ACL_2017_326",
      "ACL_2017_343",
      "ACL_2017_723",
      "COLING_2020_8",
      "COLING_2020_79"
    ],
    "skeleton_count": 3,
    "trick_count": 15,
    "top_tricks": [
      {
        "name": "引入研究背景和痛点",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "举例说明分歧",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "文献综述与现有方法评述",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "问题形式化建模",
        "frequency": 1,
        "percentage": "20.0%"
      },
      {
        "name": "通用神经网络架构分层描述",
        "frequency": 1,
        "percentage": "20.0%"
      }
    ]
  }
]