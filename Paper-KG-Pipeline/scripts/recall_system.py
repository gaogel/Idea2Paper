"""
ä¸‰è·¯å¬å›ç³»ç»Ÿ Demo - Idea2Pattern

åŸºäºçŸ¥è¯†å›¾è°±çš„ä¸‰è·¯å¬å›ç­–ç•¥ï¼š
  è·¯å¾„1: Idea â†’ Idea â†’ Pattern (ç›¸ä¼¼Ideaå¬å›)
  è·¯å¾„2: Idea â†’ Domain â†’ Pattern (é¢†åŸŸç›¸å…³æ€§å¬å›)
  è·¯å¾„3: Idea â†’ Paper â†’ Pattern (ç›¸ä¼¼Paperå¬å›)
"""

import json
import pickle
from collections import defaultdict
from pathlib import Path
from typing import Dict, List, Tuple

import numpy as np

# ===================== é…ç½® =====================
SCRIPT_DIR = Path(__file__).parent
PROJECT_ROOT = SCRIPT_DIR.parent
OUTPUT_DIR = PROJECT_ROOT / "output"

# è¾“å…¥æ–‡ä»¶
NODES_IDEA = OUTPUT_DIR / "nodes_idea.json"
NODES_PATTERN = OUTPUT_DIR / "nodes_pattern.json"
NODES_DOMAIN = OUTPUT_DIR / "nodes_domain.json"
NODES_PAPER = OUTPUT_DIR / "nodes_paper.json"
EDGES_FILE = OUTPUT_DIR / "edges.json"
GRAPH_FILE = OUTPUT_DIR / "knowledge_graph_v2.gpickle"


# ===================== å¬å›å‚æ•°é…ç½® =====================
class RecallConfig:
    """å¬å›ç³»ç»Ÿé…ç½®"""
    # æ¯è·¯å¬å›çš„Top-K
    PATH1_TOP_K_IDEAS = 10       # è·¯å¾„1: å¬å›å‰Kä¸ªæœ€ç›¸ä¼¼çš„Idea
    PATH1_TOP_K_PATTERNS = 5     # è·¯å¾„1: æ¯ä¸ªIdeaæœ€å¤šä¿ç•™Kä¸ªPattern

    PATH2_TOP_K_DOMAINS = 5      # è·¯å¾„2: å¬å›å‰Kä¸ªæœ€ç›¸å…³çš„Domain
    PATH2_TOP_K_PATTERNS = 10    # è·¯å¾„2: æ¯ä¸ªDomainæœ€å¤šä¿ç•™Kä¸ªPattern

    PATH3_TOP_K_PAPERS = 20      # è·¯å¾„3: å¬å›å‰Kä¸ªæœ€ç›¸ä¼¼çš„Paper
    PATH3_TOP_K_PATTERNS = 8     # è·¯å¾„3: æ¯ä¸ªPaperæœ€å¤šä¿ç•™Kä¸ªPattern

    # å„è·¯å¬å›çš„æƒé‡
    PATH1_WEIGHT = 0.4  # è·¯å¾„1æƒé‡
    PATH2_WEIGHT = 0.3  # è·¯å¾„2æƒé‡
    PATH3_WEIGHT = 0.3  # è·¯å¾„3æƒé‡

    # æœ€ç»ˆå¬å›çš„Top-K
    FINAL_TOP_K = 10


# ===================== å¬å›ç³»ç»Ÿ =====================
class RecallSystem:
    """ä¸‰è·¯å¬å›ç³»ç»Ÿ"""

    def __init__(self):
        print("ğŸš€ åˆå§‹åŒ–å¬å›ç³»ç»Ÿ...")

        # åŠ è½½æ•°æ®
        self.ideas = self._load_json(NODES_IDEA)
        self.patterns = self._load_json(NODES_PATTERN)
        self.domains = self._load_json(NODES_DOMAIN)
        self.papers = self._load_json(NODES_PAPER)

        # åŠ è½½å›¾è°±
        with open(GRAPH_FILE, 'rb') as f:
            self.G = pickle.load(f)

        # æ„å»ºç´¢å¼•
        self.idea_id_to_idea = {i['idea_id']: i for i in self.ideas}
        self.pattern_id_to_pattern = {p['pattern_id']: p for p in self.patterns}
        self.domain_id_to_domain = {d['domain_id']: d for d in self.domains}
        self.paper_id_to_paper = {p['paper_id']: p for p in self.papers}

        print(f"  âœ“ åŠ è½½ {len(self.ideas)} ä¸ªIdea")
        print(f"  âœ“ åŠ è½½ {len(self.patterns)} ä¸ªPattern")
        print(f"  âœ“ åŠ è½½ {len(self.domains)} ä¸ªDomain")
        print(f"  âœ“ åŠ è½½ {len(self.papers)} ä¸ªPaper")
        print(f"  âœ“ å›¾è°±èŠ‚ç‚¹: {self.G.number_of_nodes()}, è¾¹: {self.G.number_of_edges()}")
        print()

    def _load_json(self, filepath: Path) -> List[Dict]:
        """åŠ è½½JSONæ–‡ä»¶"""
        with open(filepath, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _compute_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆJaccardï¼‰"""
        tokens1 = set(text1.lower().split())
        tokens2 = set(text2.lower().split())

        if not tokens1 or not tokens2:
            return 0.0

        intersection = tokens1 & tokens2
        union = tokens1 | tokens2

        return len(intersection) / len(union)

    # ===================== è·¯å¾„1: Idea â†’ Idea â†’ Pattern =====================

    def _recall_path1_similar_ideas(self, user_idea: str) -> Dict[str, float]:
        """è·¯å¾„1: é€šè¿‡ç›¸ä¼¼Ideaå¬å›Pattern

        æµç¨‹:
          1. è®¡ç®—ç”¨æˆ·Ideaä¸å›¾è°±ä¸­æ‰€æœ‰Ideaçš„ç›¸ä¼¼åº¦
          2. é€‰æ‹©Top-Kæœ€ç›¸ä¼¼çš„Idea
          3. æ”¶é›†è¿™äº›Ideaå…³è”çš„Pattern
          4. æŒ‰ç›¸ä¼¼åº¦åŠ æƒè®¡ç®—Patternå¾—åˆ†

        è¿”å›: {pattern_id: score}
        """
        print("\nğŸ” [è·¯å¾„1] ç›¸ä¼¼Ideaå¬å›...")

        # Step 1: è®¡ç®—ä¸æ‰€æœ‰Ideaçš„ç›¸ä¼¼åº¦
        similarities = []
        for idea in self.ideas:
            sim = self._compute_text_similarity(user_idea, idea['description'])
            if sim > 0:
                similarities.append((idea['idea_id'], sim))

        # Step 2: æ’åºå¹¶é€‰æ‹©Top-K
        similarities.sort(key=lambda x: x[1], reverse=True)
        top_ideas = similarities[:RecallConfig.PATH1_TOP_K_IDEAS]

        print(f"  æ‰¾åˆ° {len(similarities)} ä¸ªç›¸ä¼¼Ideaï¼Œé€‰æ‹©Top-{RecallConfig.PATH1_TOP_K_IDEAS}")

        # Step 3: æ”¶é›†Patternå¹¶è®¡ç®—å¾—åˆ†
        pattern_scores = defaultdict(float)

        for idea_id, similarity in top_ideas:
            idea = self.idea_id_to_idea[idea_id]
            pattern_ids = idea.get('pattern_ids', [])

            print(f"  - {idea_id} (ç›¸ä¼¼åº¦={similarity:.3f}): {len(pattern_ids)} ä¸ªPattern")

            # ä»å›¾è°±ä¸­æ‰¾åˆ°è¿™ä¸ªIdeaçš„æ‰€æœ‰Patternï¼ˆé€šè¿‡Paperä¸­è½¬ï¼‰
            for paper_id in idea.get('source_paper_ids', []):
                if not self.G.has_node(paper_id):
                    continue

                # æ‰¾åˆ°Paperä½¿ç”¨çš„Pattern
                for successor in self.G.successors(paper_id):
                    edge_data = self.G[paper_id][successor]
                    if edge_data.get('relation') == 'uses_pattern':
                        pattern_id = successor
                        quality = edge_data.get('quality', 0.5)

                        # å¾—åˆ† = ç›¸ä¼¼åº¦ Ã— Paperè´¨é‡
                        score = similarity * quality
                        pattern_scores[pattern_id] += score

        print(f"  âœ“ å¬å› {len(pattern_scores)} ä¸ªPattern")
        return dict(pattern_scores)

    # ===================== è·¯å¾„2: Idea â†’ Domain â†’ Pattern =====================

    def _recall_path2_domain_patterns(self, user_idea: str) -> Dict[str, float]:
        """è·¯å¾„2: é€šè¿‡é¢†åŸŸç›¸å…³æ€§å¬å›Pattern

        æµç¨‹:
          1. æ‰¾åˆ°ä¸ç”¨æˆ·Ideaæœ€ç›¸å…³çš„Domainï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
          2. åœ¨è¿™äº›Domainä¸­æ‰¾åˆ°è¡¨ç°å¥½çš„Pattern
          3. æŒ‰Domainç›¸å…³æ€§å’ŒPatternæ•ˆæœåŠ æƒè®¡ç®—å¾—åˆ†

        è¿”å›: {pattern_id: score}
        """
        print("\nğŸŒ [è·¯å¾„2] é¢†åŸŸç›¸å…³æ€§å¬å›...")

        # Step 1: æ‰¾åˆ°ç›¸å…³Domainï¼ˆåŸºäºå…³é”®è¯åŒ¹é…ï¼‰
        domain_scores = []
        user_tokens = set(user_idea.lower().split())

        for domain in self.domains:
            domain_name = domain['name']
            domain_tokens = set(domain_name.lower().split())

            # ç®€å•çš„å…³é”®è¯åŒ¹é…
            match_score = len(user_tokens & domain_tokens) / max(len(user_tokens), 1)

            if match_score > 0:
                domain_scores.append((domain['domain_id'], match_score))

        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„Domainï¼Œä½¿ç”¨æœ€ç›¸ä¼¼Ideaçš„Domain
        if not domain_scores:
            print("  æœªæ‰¾åˆ°ç›´æ¥åŒ¹é…çš„Domainï¼Œä½¿ç”¨ç›¸ä¼¼Ideaçš„Domain...")
            similarities = []
            for idea in self.ideas:
                sim = self._compute_text_similarity(user_idea, idea['description'])
                if sim > 0:
                    similarities.append((idea, sim))

            similarities.sort(key=lambda x: x[1], reverse=True)
            top_idea = similarities[0][0] if similarities else None

            if top_idea:
                # é€šè¿‡å›¾è°±æ‰¾åˆ°Ideaçš„Domain
                for successor in self.G.successors(top_idea['idea_id']):
                    edge_data = self.G[top_idea['idea_id']][successor]
                    if edge_data.get('relation') == 'belongs_to':
                        domain_id = successor
                        weight = edge_data.get('weight', 0.5)
                        domain_scores.append((domain_id, weight))

        # Step 2: æ’åºå¹¶é€‰æ‹©Top-K Domain
        domain_scores.sort(key=lambda x: x[1], reverse=True)
        top_domains = domain_scores[:RecallConfig.PATH2_TOP_K_DOMAINS]

        print(f"  æ‰¾åˆ° {len(domain_scores)} ä¸ªç›¸å…³Domainï¼Œé€‰æ‹©Top-{RecallConfig.PATH2_TOP_K_DOMAINS}")

        # Step 3: ä»è¿™äº›Domainä¸­æ‰¾Pattern
        pattern_scores = defaultdict(float)

        for domain_id, domain_weight in top_domains:
            domain = self.domain_id_to_domain.get(domain_id)
            if not domain:
                continue

            print(f"  - {domain_id} ({domain['name']}, ç›¸å…³åº¦={domain_weight:.3f})")

            # æ‰¾åˆ°åœ¨è¯¥Domainä¸­è¡¨ç°å¥½çš„Pattern
            for predecessor in self.G.predecessors(domain_id):
                edge_data = self.G[predecessor][domain_id]
                if edge_data.get('relation') == 'works_well_in':
                    pattern_id = predecessor
                    effectiveness = edge_data.get('effectiveness', 0.0)
                    confidence = edge_data.get('confidence', 0.0)

                    # å¾—åˆ† = Domainç›¸å…³åº¦ Ã— æ•ˆæœ Ã— ç½®ä¿¡åº¦
                    score = domain_weight * max(effectiveness, 0.1) * confidence
                    pattern_scores[pattern_id] += score

        print(f"  âœ“ å¬å› {len(pattern_scores)} ä¸ªPattern")
        return dict(pattern_scores)

    # ===================== è·¯å¾„3: Idea â†’ Paper â†’ Pattern =====================

    def _recall_path3_similar_papers(self, user_idea: str) -> Dict[str, float]:
        """è·¯å¾„3: é€šè¿‡ç›¸ä¼¼Paperå¬å›Pattern

        æµç¨‹:
          1. æ‰¾åˆ°ä¸ç”¨æˆ·Ideaæœ€ç›¸ä¼¼çš„Paperï¼ˆåŸºäºcore_ideaï¼‰
          2. æ”¶é›†è¿™äº›Paperä½¿ç”¨çš„Pattern
          3. æŒ‰Paperç›¸ä¼¼åº¦å’Œè´¨é‡åŠ æƒè®¡ç®—å¾—åˆ†

        è¿”å›: {pattern_id: score}
        """
        print("\nğŸ“„ [è·¯å¾„3] ç›¸ä¼¼Paperå¬å›...")

        # Step 1: è®¡ç®—ä¸æ‰€æœ‰Paperçš„ç›¸ä¼¼åº¦
        similarities = []

        for paper in self.papers:
            paper_idea = paper.get('idea', {}).get('core_idea', '')
            if not paper_idea:
                continue

            sim = self._compute_text_similarity(user_idea, paper_idea)
            if sim > 0.1:  # è¿‡æ»¤ä½ç›¸ä¼¼åº¦
                # ä»å›¾è°±ä¸­è·å–Paperè´¨é‡
                if self.G.has_node(paper['paper_id']):
                    # è®¡ç®—è´¨é‡ï¼ˆåŸºäºReviewè¯„åˆ†ï¼‰
                    reviews = paper.get('reviews', [])
                    if reviews:
                        scores = [r.get('rating', 5) for r in reviews]
                        avg_score = np.mean(scores)
                        quality = (avg_score - 1) / 9  # å½’ä¸€åŒ–åˆ°[0,1]
                    else:
                        quality = 0.5

                    combined_weight = sim * quality
                    similarities.append((paper['paper_id'], sim, quality, combined_weight))

        # Step 2: æ’åºå¹¶é€‰æ‹©Top-K
        similarities.sort(key=lambda x: x[3], reverse=True)
        top_papers = similarities[:RecallConfig.PATH3_TOP_K_PAPERS]

        print(f"  æ‰¾åˆ° {len(similarities)} ä¸ªç›¸ä¼¼Paperï¼Œé€‰æ‹©Top-{RecallConfig.PATH3_TOP_K_PAPERS}")

        # Step 3: æ”¶é›†Pattern
        pattern_scores = defaultdict(float)

        for paper_id, similarity, quality, combined_weight in top_papers:
            print(f"  - {paper_id} (ç›¸ä¼¼åº¦={similarity:.3f}, è´¨é‡={quality:.3f})")

            # ä»å›¾è°±ä¸­æ‰¾åˆ°Paperä½¿ç”¨çš„Pattern
            if not self.G.has_node(paper_id):
                continue

            for successor in self.G.successors(paper_id):
                edge_data = self.G[paper_id][successor]
                if edge_data.get('relation') == 'uses_pattern':
                    pattern_id = successor
                    pattern_quality = edge_data.get('quality', 0.5)

                    # å¾—åˆ† = Paperç›¸ä¼¼åº¦ Ã— Paperè´¨é‡ Ã— Patternè´¨é‡
                    score = combined_weight * pattern_quality
                    pattern_scores[pattern_id] += score

        print(f"  âœ“ å¬å› {len(pattern_scores)} ä¸ªPattern")
        return dict(pattern_scores)

    # ===================== å¤šè·¯èåˆ =====================

    def recall(self, user_idea: str, verbose: bool = True) -> List[Tuple[str, Dict, float]]:
        """ä¸‰è·¯å¬å›èåˆ

        Args:
            user_idea: ç”¨æˆ·è¾“å…¥çš„Ideaæè¿°
            verbose: æ˜¯å¦æ‰“å°è¯¦ç»†ä¿¡æ¯

        Returns:
            [(pattern_id, pattern_info, score), ...] æŒ‰å¾—åˆ†æ’åº
        """
        print("=" * 80)
        print("ğŸ¯ å¼€å§‹ä¸‰è·¯å¬å›")
        print("=" * 80)
        print(f"\nã€ç”¨æˆ·Ideaã€‘\n{user_idea}\n")

        # è·¯å¾„1: ç›¸ä¼¼Ideaå¬å›
        path1_scores = self._recall_path1_similar_ideas(user_idea)

        # è·¯å¾„2: é¢†åŸŸç›¸å…³æ€§å¬å›
        path2_scores = self._recall_path2_domain_patterns(user_idea)

        # è·¯å¾„3: ç›¸ä¼¼Paperå¬å›
        path3_scores = self._recall_path3_similar_papers(user_idea)

        # èåˆä¸‰è·¯å¾—åˆ†
        print("\nğŸ”— èåˆä¸‰è·¯å¬å›ç»“æœ...")
        all_patterns = set(path1_scores.keys()) | set(path2_scores.keys()) | set(path3_scores.keys())

        final_scores = {}
        for pattern_id in all_patterns:
            score1 = path1_scores.get(pattern_id, 0.0) * RecallConfig.PATH1_WEIGHT
            score2 = path2_scores.get(pattern_id, 0.0) * RecallConfig.PATH2_WEIGHT
            score3 = path3_scores.get(pattern_id, 0.0) * RecallConfig.PATH3_WEIGHT

            final_scores[pattern_id] = score1 + score2 + score3

        # æ’åºå¹¶è¿”å›Top-K
        ranked = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)
        top_k = ranked[:RecallConfig.FINAL_TOP_K]

        # æ„å»ºè¿”å›ç»“æœ
        results = []
        for pattern_id, score in top_k:
            pattern_info = self.pattern_id_to_pattern.get(pattern_id, {})
            results.append((pattern_id, pattern_info, score))

        # æ‰“å°ç»“æœ
        if verbose:
            self._print_results(results, path1_scores, path2_scores, path3_scores)

        return results

    def _print_results(self, results: List[Tuple[str, Dict, float]],
                      path1_scores: Dict, path2_scores: Dict, path3_scores: Dict):
        """æ‰“å°å¬å›ç»“æœ"""
        print("\n" + "=" * 80)
        print(f"ğŸ“Š å¬å›ç»“æœ Top-{RecallConfig.FINAL_TOP_K}")
        print("=" * 80)

        for rank, (pattern_id, pattern_info, final_score) in enumerate(results, 1):
            print(f"\nã€Rank {rank}ã€‘ {pattern_id}")
            print(f"  åç§°: {pattern_info.get('name', 'N/A')}")
            print(f"  æœ€ç»ˆå¾—åˆ†: {final_score:.4f}")

            # æ˜¾ç¤ºå„è·¯å¾—åˆ†
            score1 = path1_scores.get(pattern_id, 0.0) * RecallConfig.PATH1_WEIGHT
            score2 = path2_scores.get(pattern_id, 0.0) * RecallConfig.PATH2_WEIGHT
            score3 = path3_scores.get(pattern_id, 0.0) * RecallConfig.PATH3_WEIGHT

            print(f"  - è·¯å¾„1 (ç›¸ä¼¼Idea):   {score1:.4f} (å æ¯” {score1/final_score*100:.1f}%)")
            print(f"  - è·¯å¾„2 (é¢†åŸŸç›¸å…³):   {score2:.4f} (å æ¯” {score2/final_score*100:.1f}%)")
            print(f"  - è·¯å¾„3 (ç›¸ä¼¼Paper):  {score3:.4f} (å æ¯” {score3/final_score*100:.1f}%)")

            print(f"  èšç±»å¤§å°: {pattern_info.get('cluster_size', 0)} ç¯‡è®ºæ–‡")
            print(f"  æ‘˜è¦: {pattern_info.get('summary', 'N/A')[:100]}...")

        print("\n" + "=" * 80)


# ===================== Demo æµ‹è¯•ç”¨ä¾‹ =====================
def demo():
    """è¿è¡ŒDemo"""

    # åˆå§‹åŒ–å¬å›ç³»ç»Ÿ
    system = RecallSystem()

    # æµ‹è¯•ç”¨ä¾‹
    test_ideas = [
        "ä½¿ç”¨Transformeræ¨¡å‹è¿›è¡Œæ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼Œåœ¨å¤šä¸ªæ•°æ®é›†ä¸ŠéªŒè¯æ•ˆæœ",
        "æå‡ºä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶æ”¹è¿›ç¥ç»æœºå™¨ç¿»è¯‘çš„å¯¹é½è´¨é‡",
        "é€šè¿‡å¯¹æŠ—è®­ç»ƒæå‡æ¨¡å‹åœ¨å¯¹è¯ç³»ç»Ÿä¸­çš„é²æ£’æ€§",
        "åˆ©ç”¨çŸ¥è¯†å›¾è°±å¢å¼ºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„è¯­ä¹‰ç†è§£èƒ½åŠ›",
    ]

    for i, user_idea in enumerate(test_ideas, 1):
        print("\n\n")
        print("ğŸ¬" * 40)
        print(f"æµ‹è¯•ç”¨ä¾‹ {i}/{len(test_ideas)}")
        print("ğŸ¬" * 40)

        results = system.recall(user_idea, verbose=True)

        # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹ç»“æœ
        if i < len(test_ideas):
            input("\næŒ‰Enterç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹...")


if __name__ == '__main__':
    demo()

