{
  "paper_id": "ARR_2022_225",
  "title": "IDPG: An Instance-Dependent Prompt Generation Method",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，主要关注于针对具体实例生成提示（prompt），以提升自然语言处理模型的性能。",
    "core_technique": "基于提示学习（Prompt Learning）的方法，提出了实例依赖的提示生成（Instance-Dependent Prompt Generation）机制，可能结合了预训练语言模型如Transformer架构。",
    "application": "可应用于文本分类、自然语言理解、问答系统等多种自然语言处理任务。",
    "domains": [
      "自然语言处理",
      "提示学习"
    ]
  },
  "ideal": {
    "core_idea": "提出实例依赖的自动生成prompt方法，实现高效迁移学习并缓解领域差异。",
    "tech_stack": [
      "Transformer",
      "Prompt Tuning",
      "Prefix Tuning",
      "Adapter",
      "Compacter",
      "PHM Layer",
      "DNN Generator"
    ],
    "input_type": "下游自然语言处理任务的输入文本",
    "output_type": "针对输入实例生成的自适应prompt及下游任务预测结果"
  },
  "skeleton": {
    "problem_framing": "论文从当前主流的NLP迁移学习范式（即大规模预训练模型+下游微调）切入，指出随着模型参数量激增，全面微调和存储所有参数在实际中变得昂贵且困难。这种从实际痛点和工程瓶颈出发的开篇策略，直接引发了对参数高效迁移学习方法的需求，并自然引出核心研究问题：能否只调整少量参数实现知识迁移？",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法存在局限’的逻辑。具体表现为：一方面，adapter类方法虽然参数高效，但每个任务都需插入和训练额外模块，仍需为每个任务存储不同参数；另一方面，prompt-tuning等方法虽然进一步减少了可训练参数，但都依赖于任务特定的prompt，导致与传统语言模型目标不兼容，且统一prompt可能扰乱模型预测，影响性能。整体上，批评句式多为‘现有方法仅关注X，导致Y问题’、‘这些方法依赖于Z，带来W困难’等。",
    "method_story": "方法部分采用了‘分模块、分方法详细介绍’的策略。首先，作者列举并量化了各类主流参数高效微调方法（如Compacter、Adapter、Prompt-tuning等）的参数量，逐一说明其实现细节和参数计算方式。随后，分别介绍了作者提出的多种IDPG（Instance-Dependent Prompt Generation）方法，包括单层/多层、不同生成器结构（DNN/PHM）及输入编码方式（如GloVe），每种方法都详细给出参数配置和计算过程。整体叙述顺序为：先罗列对比方法，再分模块、分版本介绍自家方法，突出创新点和实现细节。",
    "experiments_story": "实验部分采用了‘多数据集+多方法对比’的策略。首先，选取了10个标准NLU数据集（包括GLUE子任务和经典情感/主观性数据集），确保方法的广泛适用性。其次，系统对比了Transformer微调、prompt-tuning、adapter等多种主流方法，并对作者提出的不同IDPG变体进行了详细实验。实验还包括参数量匹配的公平对比和不同学习率下的性能调优。整体上，实验叙述以主实验（多数据集、多方法横向对比）为主，兼顾参数消融和调优细节，突出方法的有效性和参数效率。"
  },
  "tricks": [
    {
      "name": "问题驱动式引入",
      "type": "writing-level",
      "purpose": "激发读者兴趣并明确研究动机",
      "location": "introduction",
      "description": "作者通过提出当前主流方法的局限性（如参数量大、微调成本高）和自然的问题（是否能只微调少量参数），引导读者关注本文的研究方向。"
    },
    {
      "name": "多线索文献综述",
      "type": "writing-level",
      "purpose": "展示对领域现状的全面把握，凸显新方法的定位",
      "location": "introduction",
      "description": "作者系统梳理了参数高效微调和提示学习两大研究方向，并点出各自的不足，为新方法铺垫合理性。"
    },
    {
      "name": "创新点明确提出",
      "type": "writing-level",
      "purpose": "突出工作的新颖性和独特贡献",
      "location": "introduction",
      "description": "在介绍现有方法不足后，作者直接提出“instance-dependent prompt generation”作为创新点，强调其区别于以往任务特定提示。"
    },
    {
      "name": "细致参数量对比",
      "type": "experiment-level",
      "purpose": "量化方法的高效性，增强说服力",
      "location": "method",
      "description": "作者详细列举每种方法的参数量计算过程，突出新方法在参数量上的优势。"
    },
    {
      "name": "公式与结构分解",
      "type": "method-level",
      "purpose": "提升方法的可解释性，帮助读者理解原理",
      "location": "method",
      "description": "通过分步描述各模块的参数计算和结构设计，让读者清晰掌握方法实现细节。"
    },
    {
      "name": "广泛基线对比",
      "type": "experiment-level",
      "purpose": "证明方法有效性和优越性",
      "location": "experiments",
      "description": "作者在十个标准NLU任务上与多种主流方法（微调、提示、适配器等）进行系统对比，增强结果的说服力。"
    },
    {
      "name": "公平实验设置",
      "type": "experiment-level",
      "purpose": "消除外部变量影响，确保结论可靠",
      "location": "experiments",
      "description": "所有方法均基于相同的预训练模型和统一的调参范围，强调对比的公平性。"
    },
    {
      "name": "细致实验参数披露",
      "type": "experiment-level",
      "purpose": "提升实验的可复现性和透明度",
      "location": "method / experiments",
      "description": "作者详列每种方法的超参数和调参策略，并在附录补充训练细节，便于他人复现。"
    },
    {
      "name": "多版本方法探索",
      "type": "method-level",
      "purpose": "展示方法的灵活性和适用性",
      "location": "method / experiments",
      "description": "作者不仅提出单层和多层两种生成方式，还探索不同生成器和编码器，体现方法的扩展性。"
    },
    {
      "name": "逻辑递进式叙事",
      "type": "writing-level",
      "purpose": "提升论文整体可读性和逻辑性",
      "location": "introduction / method / experiments",
      "description": "全文按照“问题-现状-不足-创新方法-实验验证”顺序展开，层层递进，逻辑清晰。"
    },
    {
      "name": "实验细节与主结论呼应",
      "type": "writing-level",
      "purpose": "增强结论的可信度和完整性",
      "location": "experiments",
      "description": "实验部分不仅展示结果，还解释参数设置与性能之间的关系，呼应方法设计初衷。"
    }
  ]
}