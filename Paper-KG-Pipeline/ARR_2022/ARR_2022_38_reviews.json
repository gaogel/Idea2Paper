[
  {
    "review_id": "d0adbc683b192055",
    "paper_id": "ARR_2022_38",
    "reviewer": "Ritam Dutt",
    "paper_summary": "The paper advances research in Temporal KGQA through a unified time-sensitive question answering framework (TSQA). The framework involves a time-sensitive approach to learn temporal KG embeddings, and contrastive losses to improve answer retrieval, and enhance the model's ability in capturing temporal signals. The proposed architecture significantly outperforms state of the art models on the CronQuestions dataset. ",
    "strengths": "1. The paper is well written and presents the simple yet subtle techniques to incorporate time-sensitive information while learning temporal KG embeddings and model training for T-KGQA. \n2. The paper performs a thorough qualitative analysis and ablation studies highlighting the efficacy of the proposed design choices on temporal KGQA. ",
    "weaknesses": "No visible weakness. One research question I hoped to see was the amount of data required to ensure the TSQA framework could be applied to other datasets. The gains in performance comes from learning the TKGE embeddings and the inclusion of the contrastive losses. It would be interesting to observe whether the gains would remain as steep if trained on a fraction of the original dataset. ",
    "comments": "",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "d35b383d873b104b",
    "paper_id": "ARR_2022_38",
    "reviewer": null,
    "paper_summary": "This paper describes a framework to inculcate temporal order into question answering over knowledge bases. They add a time estimation module to the temporal KGQA. They also add an auxiliary contrastive loss to improve time sensitivity of the encoder, particularly for answer prediction and time estimation for questions that differ only by a time relation word (e.g., before/after). They also add one to improve time-order classification between timestamp embedding pairs. Their framework also has a narrower search space for faster training and inference. This model achieves state-of-the-art performance on CronQuestions dataset. ",
    "strengths": "The paper proposes a framework that pushes the state-of-the-art on the CronQuestions dataset significantly. The authors clearly outline the shortcomings of previous work and propose solutions to each of them. Apart from performance improvements, they also improve training and inference speeds by finding a way to narrow the search space. ",
    "weaknesses": "1. All the baselines that have been compared against look like incremental work built on top of each other. It is possible that other models have not been built on CronQuestions, so it would be better if authors had repurposed other work for this dataset. ",
    "comments": "Please update the citation for CronQuestions dataset to include the ACL 2021 paper link. The arXiv link misled me initially. ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]