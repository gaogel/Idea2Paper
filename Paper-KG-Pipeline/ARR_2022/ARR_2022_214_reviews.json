[
  {
    "review_id": "ce03d3f5478b63fb",
    "paper_id": "ARR_2022_214",
    "reviewer": "Chao Shang",
    "paper_summary": "This paper proposes a simple and new random intermediate layer knowledge distillation approach (RAIL-KD). The main point is to select the intermediate layers from the teacher model randomly which are distilled to the corresponding student layers. Here all layers are taken into the training without any additional parameters. So it could avoid skip and search problem and reduce the computational cost of intermediate layer distillation. The whole idea is interesting and straightforward. It is great to have many analyses in the experiments. However, I have some concerns about the performance. ",
    "strengths": "1.This paper presents a new intermediate layer knowledge distillation approach with performance improvement and low computational cost.  2.This paper adds some comparisons of the current ILD methods about the efficiency and performance. The proposed RAIL-KD has a less computational overhead.  3.In the experiments, authors compare different distillation methods under many challenge datasets. ",
    "weaknesses": "1.Adding the random selection is not a new idea. The randomness of the layer selection could cause the unstable of performance. It is better to show more results such as the convergence analysis. Random selection might not be the best option here.\n2.The performance is not convincing. The improvements under some settings are not significant.  3.The new approach could not find the best subset (subset mapping) since the proposed model just selects m layers randomly. But it is not clear if we should ignore it or solve it later. From my opinion, the attention-based approaches with best mapping search may achieve better performance. ",
    "comments": "The whole approach lacks the evidences to prove the usefulness. Comparing to ALP-KD, the improvement is not significant. ",
    "overall_score": "2.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]