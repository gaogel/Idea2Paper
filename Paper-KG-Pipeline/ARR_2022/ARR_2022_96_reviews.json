[
  {
    "review_id": "42ae5ac0b6ebf8db",
    "paper_id": "ARR_2022_96",
    "reviewer": null,
    "paper_summary": "This paper investigates the effectiveness of an early stopping method that is designed to be effective in scenarios where there is a limited amount of labelled data where the prediction accuracy fluctuates highly during training. The early stopping method being presented is based on two considerations: the probabilities of the predicted class label, and the similarity of the output class distribution to the true class distribution.\nExperiments are presented involving 5  document classification datasets that show the extent to which the method being proposed is effective. Three of the datasets concern sentiment analysis and the other two involve classification on the basis of topic. ",
    "strengths": "The scenario that this paper applies to (i.e. a situation where there is a limited quantity of labelled data) is an important one that arises frequently in many practical applications of NLP.\nThe overall method being proposed is sensible and the method is instantiated in a way that addresses a number of the complexities that arise.\nTwo types of document classification are considered: classification based on sentiment, and classification based on topic.\nThe paper is generally well written. ",
    "weaknesses": "The major weakness of this paper is the fact that the proposed method does not appear to out-perform pre-existing methods by a particularly significant margin. Indeed, there is no discussion of the statistical significance of the differences that are observed. ",
    "comments": "Some of the LaTeX could be improved in the mathematical formulas. In particular, situations where the names of functions involve multiple characters. ",
    "overall_score": "3.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]