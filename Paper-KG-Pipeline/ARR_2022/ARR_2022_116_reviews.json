[
  {
    "review_id": "a3834a569f77482c",
    "paper_id": "ARR_2022_116",
    "reviewer": null,
    "paper_summary": "Authors present  a novel finetuning method, BitFit, where instead of finetuning the entire model the authors finetune only the `biasâ€™ terms and the final task-specific classification layer. The authors compare BitFit to other parameter-efficient finetuning methods such as adapters and sparse params and report that BitFit performs better than previous approaches and even better than full finetuning on certain tasks. Additional analysis on the change in values of layer wise bias terms reveals that finetuning a specific subset of bias terms can also lead to marginally lower performance as compared to finetuning all bias terms. For low to medium data regimes, BitFit performs better than full finetuning. ",
    "strengths": "1. Simple and effective method of finetuning that performs better than competitive baselines. For low to medium data, BitFit has better performance than fine-tuning the entire transformer model. \n2. Author perform additional analysis on the change of bias terms and find that tuning a subset of bias terms also lead to marginally lower performance than finetuning all bias terms. ",
    "weaknesses": "1. Sensitivity of results to random seeds is not clear. Would be helpful to report variance for finetuning under different random seed settings. \n2. The actual strengths or limitations of BitFit are unclear. To elaborate, in addition to reporting empirical numbers on multiple tasks an analysis of the kind of examples where BitFit performs well should be added. It would be helpful for the community to understand if there is a certain type of tasks/nature of examples,  where BitFit performs better or is comparable to full fine-tuning. ",
    "comments": "Minor typo: Line 69: hard reason --> hard to reason ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "63e6907546809c29",
    "paper_id": "ARR_2022_116",
    "reviewer": null,
    "paper_summary": "The paper proposes a simple and efficient method, BitFit, for fine-tuning language models on tasks with small-or-low training data. BitFit fine-tunes only the bias-terms of the language model and shows comparable performance to full fine-tuning on some tasks in GLUE.  The bias terms constitute very few parameters of a pre-trained LM and so BitFit is more efficient than DiffPrune and Adapters in terms of the number of parameters fine-tuned. ",
    "strengths": "- The paper introduces a simple technique for fine-tuning language models and comparisons with other techniques show that the method is parameter efficient on the GLUE benchmark. ",
    "weaknesses": "- The paper provides some unsubstantiated conjectures about the \"fine-tuning as exposure of existing capabilities in LMs\". Without adequate reasoning or references, it is hard to comprehend what the author(s) refer to in this case.\n- Generalization gap: No reference to a graph or table that the Generalization gap talks about. However, I did understand later that the generalization gap referred to here is from validation to test in Table 1. The difference between full fine-tuning validation and test also seems to be within 3% from this table and given that experiments haven't been run over multiple seeds, the conclusion about the lower generalization gap is unformed. On QQP, both full fine-tuning and BitFit suffer very similar drops. \n    - Have the author(s) run the codes for multiple seeds and reported the mean? \n    - If not run for multiple seeds, is the <1% difference a significant result?\nOverall, while this paper proposes an interesting empirical result, it makes some unsubstantiated claims and some of the conclusions from the experiments are not adequately justified. The paper could benefit from a more substantial discussion of fewer results in the main paper with a more detailed discussion deferred to the Appendix for other experiments. ",
    "comments": "- Perhaps this point is not explicitly mentioned, but it seems like BitFit also has the added advantage of *not* introducing any new parameters to the model. This would have been a nice positive to stress on.\n- Is there any reason why the paper stresses on Masked Language Models in particular? Did experiments not work out with an autoregressive LM? ",
    "overall_score": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "44e7ab41a54cab53",
    "paper_id": "ARR_2022_116",
    "reviewer": null,
    "paper_summary": "This paper presents an interesting finding, i.e., fine-tuning only the bias terms of pre-trained language models is competitive with fine-tuning the entire model. The authors compared the proposed method Bias-terms Fine-tuning (BitFit) with other parameter-efficient fine-tuning methods (e.g., Adapters, Diff-Pruning). The experimental results on GLUE benchmark show that BitFit can achieve strong performance with less trainable parameters. ",
    "strengths": "- The paper is well written and easy to understand.\n- The proposed method (BitFit) is neat and novel.\n- The authors show strong empirical results on GLUE benchmark. ",
    "weaknesses": "I do not have any concerns about this paper. ",
    "comments": "It would be helpful to compare BitFit with Adapter and Diff-Pruning base on other language models (e.g.,RoBERTa, T5). But current version is good enough for a short paper. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]