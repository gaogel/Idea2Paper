[
  {
    "review_id": "1b46053fcca83345",
    "paper_id": "ARR_2022_221",
    "reviewer": null,
    "paper_summary": "In an effort to advance research for question answering and natural language generation on tables, the authors introduce a new dataset HiTab (Hierarchical Tables), a collection of 3,597 complex tables (w/ several levels of headers for either rows or columns) from 25+ domains with manually-derived fine-grained annotations of quantity and entity alignments between the table cells and the natural language text descriptions that accompany the tables (in their original reports). Entity alignments map entities mentioned in text to corresponding row/column headers/subheaders and quantities are mapped to with single-cell quantities or to multiple cell via an operator that should be applied to the multiple cell values (e.g., average, difference, etc.). Moreover, QA pairs are created from these source declarative sentences and are included in the dataset. ",
    "strengths": "- the dataset is compared to similar datasets - in addition to creating the dataset, baseline performance is established using existing models as-is or adapted for the new dataset; along with some error analysis.\n- for Table QA, the means of representing the table's header hierarchy in a logical-form is novel.\n- data and software made available to the research community ",
    "weaknesses": "- while this dataset format/type is not mainstream, it is relevant for Table QA and NLG tasks ",
    "comments": "The paper is well-written. I like the use of the initial example throughout the paper. The order of the Tables/Figures shown in the Appendices is somewhat confusing, having to jump back and forth across pages (although this may be due to their size and latex's automatic layout). Appendix B.3 is not referenced in the main paper.\nPlease revisit the following sentences for readability: line 137, 301, 498, 550 For Table 1, where examples are shown, why is the % not aligned as well for the 1st example (to E3/G3) while is is aligned for the 3rd (where proportion aligns to E3, shouldn't this be G3)? ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "bc6b2a09a1aa8ae1",
    "paper_id": "ARR_2022_221",
    "reviewer": null,
    "paper_summary": "This paper presents a new dataset namely HiTab with 3,597 hierarchical tables and 10,686 questions. They construct this dataset by collecting a wealth of statistical reports and Wikipedia pages, and then asking human annotators to convert sentence descriptions into question-answer pairs. Nearly all tables in the dataset are hierarchical, with fine-grained annotations of quantity and entity alignment. They evaluate two tasks on this dataset: table QA and natural language generation. They show that complex hierarchical structures increase the difficulty of both table QA and text generation. ",
    "strengths": "In general, I think there are some unique features to make this HiTab dataset valuable to the NLP community, including 1) this is the first dataset that focuses on hierarchical tables, 2) it contains a detailed annotation of entity and quantity alignment for each table-question pair, and 3) instead of crowd-sourcing, HiTab obtain the questions from real sentence descriptions of each table. This avoids annotation artifacts and bias to some extent.  There are some other strengths as follows:  - Good efforts are spent to build this dataset, with 18 annotators and 2400 working hours. Besides the hierarchical tables,  - Automatic Evaluation (Section 2.4) and Human Inspections (Section 2.5) are conducted in the dataset construction process to ensure the data quality.  - The details of dataset construction are well-presented in the paper and the Appendix. The authors also provide a good comparison with existing Table QA datasets.  - The dataset and codes are provided alongside with the paper. I randomly checked some data samples, and they are in high quality. ",
    "weaknesses": "It is still not quite obvious to me what additional challenges are posed by the hierarchical table structure in table QA. Although the authors mentioned three challenges in the introduction, it seems that they are not well-reflected in the experiments. I think Appendix B.4 is a good example to empirically show hierarchical structures indeed increases the difficulty of table QA. I suggest the authors put this part into the main paper, and I expect to see more results and analysis towards this direction to reveal how SOTA QA models fail in facing with complex hierarchical structures. ",
    "comments": "I am not an expert of table QA. But to me, the authors seem to miss a straightforward baseline, that is to firstly flat the table into a text sequence like Figure 7 and then train a text-based QA model on it. For example, we can fine-tune the pretrained QA models like SpanBERT for table QA after flatting the table into a text sequence. In this case, we might be able to learn the hierarchical information through the self-attention mechanism built in Transformers. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]