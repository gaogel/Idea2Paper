[
  {
    "review_id": "20e43a0613cdb728",
    "paper_id": "ARR_2022_341",
    "reviewer": null,
    "paper_summary": "The paper proposes a neural model computing local coherence on the basis of entities, by constraining the input to noun phrases and proper names. This allows modeling the notion of focus. This approach is presented as more linguistically sound, it outperforms previous models in applications and leads to better explainability. ",
    "strengths": "The paper introduces a new model for computing local coherence that outperforms previous models on three applications. The approach is well-motivated and the authors provide a clear picture of how the paper relates to previous work. The methodology appears sound and is described in detail.  Besides the overall results in the end tasks, through further analyses, the authors show 1) that their method leads to more interpretable explanations about model behavior, and 2) patterns underlying the model's behavior. ",
    "weaknesses": "In the introduction, the authors say that computing coherence on the basis of words or subwords is incorrect from a linguistic perspective and that their approach is more sound. However, they do not directly state why this is the case. One way of achieving this would be, for instance, by commenting on an example, which would also serve as an introduction to the concept of discourse coherence. This would improve the readability of the paper, especially for a reader that is not so familiar with the research area. ",
    "comments": "The font in Figure 1 is very small. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]