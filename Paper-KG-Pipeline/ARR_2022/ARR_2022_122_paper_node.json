{
  "paper_id": "ARR_2022_122",
  "title": "Locally Aggregated Feature Attribution on Natural Language Understanding",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，主要关注自然语言理解任务中的特征归因问题。",
    "core_technique": "特征归因方法，可能结合了现有的解释性技术，对自然语言处理模型（如Transformer等）进行本地特征聚合归因分析。",
    "application": "自然语言理解相关场景，如文本分类、问答系统、情感分析等任务中的模型可解释性和决策分析。",
    "domains": [
      "自然语言处理",
      "可解释人工智能"
    ]
  },
  "ideal": {
    "core_idea": "提出了一种基于句子级嵌入空间的局部聚合梯度特征归因方法（LAFA），用于提升NLP模型解释性。",
    "tech_stack": [
      "梯度归因",
      "句子级嵌入",
      "相似文本聚合",
      "深度学习模型解释"
    ],
    "input_type": "自然语言文本输入及其对应的深度学习模型",
    "output_type": "输入文本中各特征（如词语、短语）的归因分数"
  },
  "skeleton": {
    "problem_framing": "论文从实际应用痛点出发引出问题，强调随着深度学习模型的流行，模型可解释性和理解变得越来越重要。通过举例说明模型理解在特征发现、模型调试和决策信任等方面的关键作用，进一步指出在NLP领域，尽管深度模型表现优异，但其内部机制难以理解，亟需更好的解释方法。整体采用了‘应用需求驱动+现有挑战’的开篇策略。",
    "gap_pattern": "论文通过对现有方法的系统梳理，指出了两类主流方法的不足：一是模型无关方法（如Shapley值、LIME）虽通用但在高维和复杂模型下计算效率低下；二是模型特定的梯度法虽然高效，但梯度本身噪声大且难以解释，尤其在NLP中由于输入为离散token且参考token难以定义，直接应用存在困难。批评逻辑为‘现有方法虽有优点，但在实际NLP场景下存在效率或适用性问题’。",
    "method_story": "方法部分采用‘先整体后细节’的叙述顺序，首先概述提出的LAFA方法的三大步骤（邻居查找、梯度计算、梯度聚合），随后对每一步进行详细分解说明，包括如何在嵌入空间中查找相似文本、如何计算和聚合梯度，并结合动机示例说明每一步的必要性。整体结构清晰，分模块介绍，逻辑递进。",
    "experiments_story": "实验部分采用‘主实验+分析实验’的叙述策略。首先在无标签和有标签两种场景下，系统比较所提方法与主流基线（Simple Gradient, Smooth Gradient等）的性能，分析不同邻居数和不同编码层的影响，并通过表格展示结果。实验类型涵盖主实验（与基线方法对比）、参数敏感性分析（邻居数、编码层选择）、以及对有无额外标签场景的适用性分析，体现了多角度验证和细致分析。"
  },
  "tricks": [
    {
      "name": "多重动机论证",
      "type": "writing-level",
      "purpose": "增强说服力，强调模型可解释性的重要性和多方面价值",
      "location": "introduction",
      "description": "通过列举模型可解释性的多重应用场景（特征发现、模型审计、建立信任）和具体案例，强调理解模型的必要性。"
    },
    {
      "name": "现实案例引入",
      "type": "writing-level",
      "purpose": "增强说服力和可读性，让读者直观理解问题背景",
      "location": "introduction",
      "description": "通过引用知名文献中的具体案例（如狼与哈士奇的分类错误），形象展示模型可解释性的实际意义。"
    },
    {
      "name": "方法分流对比",
      "type": "writing-level",
      "purpose": "突出创新点，明确自身方法的定位",
      "location": "introduction",
      "description": "将现有方法分为模型无关和模型特定两类，指出各自优缺点，为新方法的提出做铺垫。"
    },
    {
      "name": "挑战点突出",
      "type": "writing-level",
      "purpose": "展示新方法的必要性和创新性",
      "location": "introduction",
      "description": "强调现有梯度归因方法在NLP领域的局限（如离散输入、参考难定义），为后续方法创新埋下伏笔。"
    },
    {
      "name": "分步法流程展示",
      "type": "method-level",
      "purpose": "提升可解释性，让方法结构清晰易懂",
      "location": "method",
      "description": "将方法分为三个明确步骤（邻居搜索、梯度计算、归纳聚合），并配合流程图说明。"
    },
    {
      "name": "动机示例驱动",
      "type": "writing-level",
      "purpose": "帮助理解方法原理，降低理解门槛",
      "location": "method",
      "description": "通过具体的计算机描述示例，说明简单梯度方法的不足和新方法的优势。"
    },
    {
      "name": "数学公式严密推导",
      "type": "method-level",
      "purpose": "增强方法的科学性和说服力",
      "location": "method",
      "description": "用数学公式详细定义每一步操作，包括邻居选择、梯度聚合和核函数加权。"
    },
    {
      "name": "参数敏感性讨论",
      "type": "experiment-level",
      "purpose": "展示实验的完备性和方法的鲁棒性",
      "location": "experiments",
      "description": "讨论邻居数量M对平滑效果的影响，分析过小和过大可能带来的问题。"
    },
    {
      "name": "分层编码器选择",
      "type": "experiment-level",
      "purpose": "提升方法的适应性和科学性",
      "location": "experiments",
      "description": "通过实验比较不同BERT层作为编码器的效果，结合有无标签两种场景，选择最优层。"
    },
    {
      "name": "多基线对比实验",
      "type": "experiment-level",
      "purpose": "突出方法的有效性和优越性",
      "location": "experiments",
      "description": "与Simple Gradient、Smooth Gradient等主流方法进行定量对比，展示LAFA的改进效果。"
    },
    {
      "name": "指标多样化",
      "type": "experiment-level",
      "purpose": "增强实验的说服力和结论的可靠性",
      "location": "experiments",
      "description": "采用不同的评估指标（如精度、不同层次的归因分数）来全面评价方法表现。"
    },
    {
      "name": "实验场景区分",
      "type": "experiment-level",
      "purpose": "增强实验的完备性和适用性说明",
      "location": "experiments",
      "description": "分别设计无标签和有标签两种实验场景，覆盖更广泛的实际应用需求。"
    },
    {
      "name": "逐层呼应结构",
      "type": "writing-level",
      "purpose": "保证叙事流畅，逻辑清晰",
      "location": "introduction / method / experiments",
      "description": "从引言提出问题、方法分步解决、实验逐步验证，层层递进，前后呼应。"
    }
  ]
}