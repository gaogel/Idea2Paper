{
  "paper_id": "ARR_2022_303",
  "title": "CORWA: A Citation-Oriented Related Work Annotation Dataset",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究学术论文中的相关工作部分的文本数据，聚焦于论文引用关系及其在相关工作撰写中的注释和标注问题。",
    "core_technique": "论文涉及自然语言处理技术，特别是文本标注、信息抽取和可能的深度学习方法（如Transformer等）用于分析和处理相关工作中的引用文本。",
    "application": "成果可应用于学术论文自动生成、学术写作辅助工具、文献综述自动化、学术搜索与推荐系统等场景。",
    "domains": [
      "自然语言处理",
      "学术文献分析",
      "信息检索"
    ]
  },
  "ideal": {
    "core_idea": "提出并标注了面向引文的相关工作生成数据集CORWA，并联合多任务模型区分异质文本片段。",
    "tech_stack": [
      "Transformer编码器",
      "多任务学习",
      "段落级句子标注",
      "联合标签解码"
    ],
    "input_type": "NLP论文的相关工作章节文本及其句子、引文标注信息",
    "output_type": "带有引文范围、引文类型和话语标签的相关工作章节标注"
  },
  "skeleton": {
    "problem_framing": "论文从学术gap出发引出问题，强调学术研究的前沿性和创新性，指出每篇论文都需要在相关工作部分与前人工作进行比较。作者进一步指出，相关工作部分在同一领域内内容和格式高度相似，因此有自动生成相关工作部分的实际需求。通过批判现有相关工作生成方法仅将其视为一般的摘要任务，忽略了相关工作部分的异质性和复杂写作风格，明确提出需要更细致的自动生成方法。",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’的逻辑。具体指出以往方法将相关工作生成简化为句子级摘要任务，未能区分不同信息来源的异质文本片段和多样化写作风格。此外，批评现有数据集多为自动抽取，缺乏细致人工标注，未能支持更复杂的生成任务。句式上常用‘mostly ignore’、‘neglecting’、‘not been previously used’等表达，突出现有方法的不足。",
    "method_story": "方法部分采用先整体后局部的叙述策略。首先介绍整体模型架构（联合相关工作标注器），说明采用Transformer编码器对段落独立编码，并联合训练三项任务。随后分别介绍各子任务的标签方式和机制，强调多任务学习和编码器共享。整体先给出框架，再细化到各模块和任务的具体实现。",
    "experiments_story": "实验部分先介绍主实验流程，包括五折交叉验证和模型性能评估。接着描述如何利用自动标注扩展数据集，并用扩展数据进一步提升模型性能。随后介绍基于LED的大规模生成基线实验，涵盖预训练、输入结构、训练细节等。实验类型包括主任务性能评估、远程监督数据扩展、预训练与基线模型对比，体现多数据集和多任务验证，突出模型泛化和实际应用能力。"
  },
  "tricks": [
    {
      "name": "问题动机铺垫",
      "type": "writing-level",
      "purpose": "引导读者关注领域痛点，凸显研究意义",
      "location": "introduction",
      "description": "作者首先指出相关工作部分的同质化和自动生成的需求，强调现有方法的局限性，为提出新方法埋下伏笔。"
    },
    {
      "name": "现有方法批判",
      "type": "writing-level",
      "purpose": "突出自身工作的创新性和必要性",
      "location": "introduction",
      "description": "通过批判以往将相关工作生成简化为一般摘要任务的做法，强调忽视了相关工作片段的异质性，凸显自身方法的独特视角。"
    },
    {
      "name": "多维度创新点展示",
      "type": "writing-level",
      "purpose": "系统性地展示方法的新颖性",
      "location": "introduction",
      "description": "作者不仅提出对异质片段的区分，还引入文献综述风格的细粒度标签，展示方法在信息源和写作风格上的创新。"
    },
    {
      "name": "任务分解与多任务学习",
      "type": "method-level",
      "purpose": "提升方法可解释性和科学性",
      "location": "method",
      "description": "将相关工作生成任务拆解为多个子任务（片段检测、类型识别、话语标签），并用多任务学习联合训练，便于读者理解模型结构和优势。"
    },
    {
      "name": "模型结构可视化",
      "type": "method-level",
      "purpose": "帮助读者直观理解方法原理",
      "location": "method",
      "description": "通过图示（如Figure 4）展示模型架构，明确各部分功能和信息流，增强方法的可解释性。"
    },
    {
      "name": "与主流模型对比",
      "type": "experiment-level",
      "purpose": "证明方法的有效性和先进性",
      "location": "experiments",
      "description": "在实验部分详细介绍与主流Transformer模型的对比，说明自身方法如何突破输入长度限制，提升性能。"
    },
    {
      "name": "多指标量化评估",
      "type": "experiment-level",
      "purpose": "增强实验结果的说服力和完备性",
      "location": "experiments",
      "description": "采用F1分数、ROUGE等多项指标对模型进行量化评估，全面展示方法性能。"
    },
    {
      "name": "远程监督数据扩充",
      "type": "experiment-level",
      "purpose": "证明方法具有可扩展性和实用价值",
      "location": "experiments",
      "description": "利用自动标签器对大规模未标注数据进行标注，扩充训练集，提升模型泛化能力，显示方法的实际应用潜力。"
    },
    {
      "name": "严格的数据划分与交叉验证",
      "type": "experiment-level",
      "purpose": "确保实验结论的可靠性和科学性",
      "location": "experiments",
      "description": "采用五折交叉验证调整超参数，并严格排除测试集文本，保证实验结果的公正性。"
    },
    {
      "name": "人类主观评价补充",
      "type": "experiment-level",
      "purpose": "从多角度验证模型输出质量",
      "location": "experiments",
      "description": "引入人工评价环节，邀请多位NLP专业学生对生成文本的流畅性等方面进行打分，补充自动指标的不足。"
    },
    {
      "name": "任务与评价目标区分",
      "type": "writing-level",
      "purpose": "避免实验结果被误解，提升论文严谨性",
      "location": "experiments",
      "description": "明确区分span-level和sentence-level生成任务及其评价目标，强调不同任务间分数不可直接比较，防止读者误读。"
    },
    {
      "name": "逐层递进叙事结构",
      "type": "writing-level",
      "purpose": "增强论文逻辑性和可读性",
      "location": "introduction / method / experiments",
      "description": "全文采用先提出问题、分析现有不足、提出新方法、详细描述实现、再通过实验验证的递进结构，逻辑清晰，易于跟进。"
    }
  ]
}