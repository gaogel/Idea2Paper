{
  "paper_id": "ARR_2022_11",
  "title": "A Feasibility Study of Answer-Unaware Question Generation for Education",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，特别是教材等教育类文本内容，用于自动生成问题。",
    "core_technique": "自动化问题生成（Question Generation, QG）模型，重点研究无需人工选定答案片段的answer-unaware QG方法，并探索利用人工或自动生成的摘要提升生成质量。",
    "application": "教育场景中的自动化试题生成、快速制作测验题、辅助学生复习等，如自动生成测验题目和复习卡片。",
    "domains": [
      "自然语言处理",
      "教育技术"
    ]
  },
  "ideal": {
    "core_idea": "提出并验证了无需手动选择答案片段的自动问题生成方法，提升教育场景下问题生成效率。",
    "tech_stack": [
      "T5语言模型",
      "SQuAD数据集微调",
      "多任务学习（问答、问题生成、答案抽取）",
      "自动摘要生成"
    ],
    "input_type": "原始文本、人工或自动生成的文本摘要",
    "output_type": "自动生成的相关性高的问题"
  },
  "skeleton": {
    "problem_framing": "论文从实际应用需求出发引出问题，强调编写高质量、针对性强的问题（如测验题）既困难又耗时，自动化问题生成（QG）可以显著减少人工负担。通过描述教育场景下教师和学生的具体痛点（如教师出题慢、学生复习效率低），自然引出对自动化、无需人工标注答案的QG系统的需求。",
    "gap_pattern": "论文批评现有方法时，采用了'现有方法依赖于人工选择答案片段'、'在缺乏明确关键术语列表时不适用'等逻辑，指出主流的answer-aware QG模型需要人工高亮答案span，增加了使用门槛和负担，并在某些实际教育场景下不适用。句式上多用'Previous work has focused primarily on...'、'This adds significant overhead...'等表达，突出方法局限和实际应用中的不足。",
    "method_story": "方法部分采用了'先整体后细节'的叙述顺序。首先介绍了整体思路：借鉴多任务微调（QA+QG+答案抽取）提升模型能力，选择T5模型并说明其任务分离优势。随后分步骤详细描述了三种微调任务的具体实现方式、输入输出格式、数据处理细节（如文本分块、句子边界处理、答案抽取策略等），最后说明了如何利用该模型在answer-unaware场景下生成问题。",
    "experiments_story": "实验部分采用了'多场景对比验证'的策略，设计了三类输入（原始教材文本、人写摘要、自动摘要）下的主实验，分别评估模型在不同输入条件下的表现。每类实验都详细描述了数据来源、处理方式和生成的QA对数量。评测采用人工标注，设置了多维度评价标准（可用性、语法、可解释性、相关性、答案正确性），并对比分析了不同输入下的表现差异，突出方法有效性和适用性。"
  },
  "tricks": [
    {
      "name": "问题动机引入",
      "type": "writing-level",
      "purpose": "引发读者兴趣，强调研究问题的重要性和实际价值",
      "location": "introduction",
      "description": "通过强调手工编写高质量问题的困难和自动生成问题对师生的潜在巨大帮助，突出研究的实际意义。"
    },
    {
      "name": "现有方法局限对比",
      "type": "writing-level",
      "purpose": "突出自身工作的创新点和必要性",
      "location": "introduction",
      "description": "指出以往QG方法依赖于人工选择答案片段，带来额外负担，强调本工作无需此步骤的优势。"
    },
    {
      "name": "贡献点列举",
      "type": "writing-level",
      "purpose": "明确展示工作的创新性和主要成果",
      "location": "introduction",
      "description": "以条目化方式清晰列出三大贡献，便于读者快速把握创新点。"
    },
    {
      "name": "失败分析",
      "type": "experiment-level",
      "purpose": "增强说服力，通过展示模型失败的主要原因，体现分析的深度和科学性",
      "location": "introduction / experiments",
      "description": "明确指出answer-unaware QG模型主要失败在于生成无关或难以理解的问题，显示对方法局限的自省。"
    },
    {
      "name": "多条件对比实验设计",
      "type": "experiment-level",
      "purpose": "增强实验完备性和对比性，验证方法在不同输入条件下的表现",
      "location": "experiments",
      "description": "分别在原始文本、人写摘要和自动摘要三种条件下进行实验，系统比较方法效果。"
    },
    {
      "name": "定量指标与主观评价结合",
      "type": "experiment-level",
      "purpose": "提升实验结果的说服力和可靠性",
      "location": "experiments",
      "description": "采用专家人工标注，结合多维度（可接受性、语法、可解释性、相关性、正确性）评价生成问题。"
    },
    {
      "name": "具体数据与提升幅度展示",
      "type": "writing-level",
      "purpose": "用具体数字增强说服力，量化方法改进效果",
      "location": "introduction / experiments",
      "description": "用百分比（如33%->83%）直观展示方法改进带来的显著提升。"
    },
    {
      "name": "方法原理可解释化",
      "type": "method-level",
      "purpose": "帮助读者理解模型训练和推理流程",
      "location": "method",
      "description": "详细说明T5模型的多任务微调过程，解释每个任务的输入输出和建模目标。"
    },
    {
      "name": "技术细节透明化",
      "type": "method-level",
      "purpose": "增强方法的可复现性和可信度",
      "location": "method",
      "description": "详细描述输入分段、句子边界处理、答案抽取策略等实现细节。"
    },
    {
      "name": "与已有工作对齐",
      "type": "writing-level",
      "purpose": "显示方法的合理性和理论基础",
      "location": "method",
      "description": "引用并借鉴已有文献（如Dong et al., Bao et al.）的多任务训练思想，说明方法设计的依据。"
    },
    {
      "name": "一致性与可靠性分析",
      "type": "experiment-level",
      "purpose": "证明实验结论的可靠性和一致性",
      "location": "experiments",
      "description": "报告不同章节、不同标注者间的一致性和分布，分析分歧原因。"
    },
    {
      "name": "分步叙事结构",
      "type": "writing-level",
      "purpose": "清晰组织全文逻辑，便于读者逐步理解",
      "location": "introduction / method / experiments",
      "description": "先引入问题和动机，再介绍方法细节，最后系统实验验证，层层递进。"
    }
  ]
}