[
  {
    "review_id": "f2b2affe077eb681",
    "paper_id": "ARR_2022_119",
    "reviewer": null,
    "paper_summary": "This paper proposes a text-to-SQL parser that can better utilize given alignments between text and SQL queries. Empirically, the proposed parser achieves the new state-of-the-art performance on the SQUALL dataset. ",
    "strengths": "The usage of alignments as contexts is creative and coupled well with BERT-based encoding. The training method of noisy alignment augmentation is also interesting, and the way I view this is that it's an efficient way of \"marginalizing\" over all possible noisy alignments. ",
    "weaknesses": "My main complaints are 1) the presentation of this work is a bit misleading to me, 2) I'm not convinced by the main arguments of this work.\nFor 1), it's not completely clear from early sections that this work focus on the setting where the gold alignments are given. I don't think this setting is the default text-to-SQL in the current literature, so it'd be better to clarify this as early as possible.  For 2), the main arguments of the proposed system are that attention cannot capture alignments well because it's at the token level. But isn't the sequence tagging model used is also at the token level?  The second argument is that attention is prone to overfitting. I'm not convinced that we should attribute the overfitting of current parsers to attention mechanisms, and this paper does not provide any justification.  Maybe the authors should emphasize their way of incorporating alignments (alignments as context, and alignment augmentation), which I think are the main contribution of this work. ",
    "comments": "The two-stage process is very related to [1]. In general, the paper perhaps should also mention the line of work that treat alignments as latent variables, e.g., [2, 3] - [1] Compositional Generalization via Semantic Tagging - [2] Span-based semantic parsing for compositional generalization - [3] Learning semantic parsers from denotations with latent structured alignments and abstract programs ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]