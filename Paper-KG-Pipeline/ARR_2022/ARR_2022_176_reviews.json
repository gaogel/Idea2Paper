[
  {
    "review_id": "43d85d8b36e1f938",
    "paper_id": "ARR_2022_176",
    "reviewer": null,
    "paper_summary": "The paper presents a novel way of using annotator rationales. The main novelty lies in introducing the rationales though a ranking constraint. The newly introduced model is empirically compared with several others from prior work. The new model outperforms those baselines when little data is available. ",
    "strengths": "The idea of a ranking constraint is very interesting and as far as I'm aware is novel. The comparison with other work is sensible as is the choice of baseline tasks.  The paper is easy to read. ",
    "weaknesses": "The experimental setup is a bit weak in my view. The choice of baselines covers related work, but it doesn't cover possible variations of the model, such as a non-BERT ranking baseline. The SVM and LR baselines both use the \"old\" style of using representations. I would honestly expect this kind of investigation from a paper that emphasizes the role of the ranking constraint and even puts it in the title.  In addition, the presentation of the main results makes it difficult to see the strengths of each model. The graphs are cut off at around 250 training documents even though some datasets contain much more. It appears as if the rivaling models start to converge after a while. Yet the analysis in table 1 suggest that the new model indeed promises overall improvements that the others cannot achieve (for example 85% accuracy on ASRS). ",
    "comments": "It would be helpful for me to address my two concerns above. This would strengthen the results vastly. ",
    "overall_score": "2.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "f787fa8cde25eef9",
    "paper_id": "ARR_2022_176",
    "reviewer": "Rong Xiang",
    "paper_summary": "This paper proposes a novel approach that jointly utilizes annotator information, that labels and elicited rationales are used to speed up the training of deep learning models with limited training data. The ranking constraint is the most important mechanism introduced. Performance evaluation shows that the proposed method achieves state-of-the-art performance with higher efficiency and lower demand for data. ",
    "strengths": "1. The proposed approach is well-designed and novel. This paper derives the constraint formulas in a rigorous logical flow. \n2. This paper contributes a new text classification dataset with rationales and makes it publicly available. \n3. The experiments are sufficiently and reasonably conducted to verify the effectiveness of this method. ",
    "weaknesses": "1. Experimental part is less convincing. The LR and SVM based baselines are too weak compared with deep learning approaches. \n2. Figure 2 does not show complete trends w.r.t the training documents. It seems that LwR-RC might be outperformed with RB-WAVG or even Lw/oR-BERT. Moreover, analysis of this trend is insufficiently discussed. ",
    "comments": "1. Please provide some statistics of three benchmarks as truncation has been used in both sentence length and sentence number for each instance. \n2. Please reorganize the section of performance evaluation to highlight the strengths of the proposed methods. ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]