[
  {
    "review_id": "e30201431866f3b1",
    "paper_id": "ARR_2022_254",
    "reviewer": null,
    "paper_summary": "Automated evaluation of coherence in a conversation is a longstanding challenge in conversational models. Recent models address the task using contrastive learning where the goal is to learn a classifier to distinguish between a coherent conversation and an incoherent one. However, the problem of existing models lies in heuristic manipulations that result in unrealistic and too easy negative examples.\nThe paper presents a method, namely DEAM, to overcome the problem of constructing more realistic negative examples. To this end, the proposed method (a) converts an utterance to an AMR graph, a semantic representation that abstracts away from syntax, (b) injects inconsistency to AMR, (c) translates the manipulated AMR back to text. The effectiveness of DEAM rests on determining ways to manipulate AMRs—i.e., step (b). This is done via four logical flaws that dialogue models mainly suffer from: contradiction, coreference inconsistency, irrelevancy, and engagement decline.\nDEAM is compared against other seemingly trivial baselines that shuffle utterances, shuffle one speaker’s utterances, or insert random utterances. Under the same setting, DEAM outperforms all existing baselines in terms of correlation with human judgment. Also, via an ablation study, decreased engagement and irrelevancy are shown to be the most impactful issues. ",
    "strengths": "- Evaluating conversational models automatically is notoriously cumbersome. The proposed method in the paper aims at gauging coherence in conversations, which is important in building natural-sounding dialogue systems.\n- The proposed perturbations in AMR seem to be easy for the community to use for their own datasets.  - The analysis of the proposed paper is convincing; especially the correlation with the human judgment that is shown to be consistently the highest among the three baselines.\nOverall, I think the paper is a nice contribution and can be of interest to the community. ",
    "weaknesses": "- The four logical flaws in dialogue systems are derived from “the observation of interactions between advanced dialogue systems and humans” (L272-273). More information about these observations is helpful. For instance, in which dialogue models these observations were made? How often do they occur? Are there other flaws too? The last question can be important for future research.\n- The paper can also benefit from an error analysis. What are the circumstances that DEAM fails? To what extent does failure in AMR parsing cause an issue in DEAM?\n- The AMR abstraction from syntax may attribute to inadvertent inconsistencies. In Figure 4 top-right, I can see that the verb tense is changed from past to present. In this particular example, this may not be much of an issue, but for some cases, this can lead to unintended inconsistency. For example, if the conversation is about a deceased person, past tense is presumably used frequently and only a tense change to present can make the conversation flawed. ",
    "comments": "- L85: FED dataset -> the FED dataset - L307: AMR-to-Text model -> the AMR-to-Text model - L346: “apparently” weakens the point. I suggest removing it - L350: The sentence about question-type utterances sounds detached from the paragraph.\n- L407: PersonaChat dataset -> the PersonaChat dataset - L462: \\citet should be used - In Figure 4 bottom-left, the first sentence should remain the same (i.e., it should start with “He was” rather than “They are”) ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]