[
  {
    "review_id": "6b76cb35bc2bd130",
    "paper_id": "ARR_2022_297",
    "reviewer": null,
    "paper_summary": "The paper creates a corpus of verbal negations and adapts QA-SRL to collect questions and answers regarding the arguments of the affirmative counterpart of a negated predicate, and manipulate them to generate the affirmative interpretation. They use the curated dataset to pose two challenges - classifying entailment and neutral relationship between the negation and its affirmative counterpart, and generating the affirmative interpretation directly. Experiments show that current models are unable to perform reasonably on the generation task, which is the more realistic setting. ",
    "strengths": "The authors adapt a question answering approach to create an annotation scheme to create a corpus of verbal negations and their affirmative interpretations. The paper describes the full annotation process clearly, and the authors are careful to manually verify significant random samples of the corpus. The annotation process is designed to guide annotators to fill in template questions before answering them factually. These answers are used to create the affirmative interpretations. Further, they only retain the records where annotators are confident about their judgment. The authors perform well-designed experiments to establish benchmarks for the tasks they propose on their corpus. These experiments show that standard models are unable to perform the generation task as well as humans do. ",
    "weaknesses": "1. While it is fair to say that two annotators might have different answers to the same question and both might be correct, it would be better to verify that the answers provided are all valid. The authors manually validate a small subset of the dataset but, for a high quality dataset, it would be better to validate all of it. \n2. The paper should include automatic metrics for the generation task. While the metrics have their own problems, it would be a good way to compare systems without expensive human evaluation. ",
    "comments": "1. It would be good if you expand on the importance of the order of wh-words used for question generation. \n2. Line 112: Consider the ‘second’ example actually refers to the first example in Figure 1. \n3. I agree with the authors about the framing of the classification task, that it isn’t a realistic one. Maybe the paper would be better without it. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]