{
  "paper_id": "ARR_2022_218",
  "title": "An Empirical Study on Explanations in Out-of-Domain Settings",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究解释性方法在跨领域（out-of-domain）环境下的表现，涉及的研究对象通常为文本数据或结构化数据，因为解释性研究多聚焦于模型对输入数据（如文本、表格等）的解释能力。",
    "core_technique": "论文关注于解释性技术（如特征重要性、可解释模型等）在分布外数据上的适用性和鲁棒性，可能涉及对现有解释方法的实证评估和改进。",
    "application": "成果可应用于需要模型解释的实际场景，如医疗诊断、金融风控、法律判决等对解释性要求较高的领域，尤其是在模型需要泛化到新领域或新数据分布时。",
    "domains": [
      "可解释人工智能",
      "机器学习泛化",
      "实证机器学习"
    ]
  },
  "ideal": {
    "core_idea": "首次系统评估解释方法在跨领域场景下的忠实性与泛化能力。",
    "tech_stack": [
      "特征归因方法",
      "select-then-predict模型",
      "HardKuma",
      "FRESH",
      "BERT",
      "bi-LSTM"
    ],
    "input_type": "文本分类任务中的输入文本数据，包含跨领域数据集对。",
    "output_type": "模型预测结果及其对应的解释（如重要性标注、rationale mask）"
  },
  "skeleton": {
    "problem_framing": "论文首先通过强调模型解释性的重要性切入，指出在实际应用（如临床文本分类、自动事实核查）中，忠实的解释对于理解模型行为和辅助人类决策至关重要。接着，论文介绍了两类主流的解释方法（特征归因和select-then-predict模型），并指出当前这些方法主要在同分布（in-domain）数据上进行评估。最后，作者提出实际部署时常会遇到分布外（out-of-domain）数据，现有解释方法在这种情况下的表现尚未被系统研究，由此引出本文的研究问题。整体采用了“从应用需求出发，结合学术gap”的开篇策略。",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法在特定场景下未被充分研究’的逻辑。具体句式包括：‘目前这些解释方法大多只在同分布数据上评估’，‘我们尚不清楚分布外情况下post-hoc解释的忠实性如何’，‘同样地，我们也不了解select-then-predict模型在分布外的泛化能力’。这种批评方式强调了现有工作的局限性和未覆盖的研究空白。",
    "method_story": "方法部分采用‘分模块介绍’的策略，先整体说明选用的两类select-then-predict模型（HardKuma和FRESH），随后分别详细介绍每个模型的结构、训练方式和实现细节。对于FRESH，还进一步区分了两种rationale抽取方式（TOPK和CONTIGUOUS），并说明了各自的实现细节和所用的基础模型（BERT或bi-LSTM）。整体上，叙述顺序为‘方法类别→具体模型→模型细节→实现差异’。",
    "experiments_story": "实验部分采用‘多数据集验证+对比分析’的策略。首先，主实验聚焦于HardKuma和FRESH在in-domain与out-of-domain数据上的表现对比，评估其预测性能和rationale长度等指标。其次，通过跨数据集（如AmazDigiMu与AmazPantry、SST与Yelp等）验证模型的泛化能力。此外，还将模型与全文本训练的基线进行对比，分析不同训练集来源对rationale长度和模型表现的影响。整体实验设计突出‘跨领域泛化’和‘多角度指标评估’。"
  },
  "tricks": [
    {
      "name": "引用权威文献建立背景",
      "type": "writing-level",
      "purpose": "增强说服力，让读者相信所研究问题的重要性和相关性",
      "location": "introduction",
      "description": "通过引用Adebayo et al., 2020; Chakrabarty et al., 2019; Popat et al., 2018等权威文献，说明解释性方法在实际应用中的重要性和研究现状。"
    },
    {
      "name": "问题空白陈述",
      "type": "writing-level",
      "purpose": "突出新颖性，强调当前领域尚未解决的问题",
      "location": "introduction",
      "description": "明确指出‘how faithful out-of-domain post-hoc explanations are has yet to be explored’，强调本工作填补了研究空白。"
    },
    {
      "name": "方法分类对比引入",
      "type": "writing-level",
      "purpose": "帮助读者理解方法原理和背景，增强可解释性",
      "location": "introduction",
      "description": "将主流解释方法分为feature attribution和select-then-predict两类，并用图示（Figure 1）进行直观展示。"
    },
    {
      "name": "假设明确提出",
      "type": "writing-level",
      "purpose": "增强叙事结构和说服力，引导读者关注核心科学问题",
      "location": "introduction",
      "description": "明确提出‘我们假设post-hoc explanation faithfulness reduces in out-of-domain settings’，为后续实验和分析埋下伏笔。"
    },
    {
      "name": "贡献点列表化",
      "type": "writing-level",
      "purpose": "突出新颖性和完备性，让读者快速抓住论文创新点",
      "location": "introduction",
      "description": "以条目形式罗列论文贡献，强调‘to the best of our knowledge, we are the first to...’等表述。"
    },
    {
      "name": "详细方法实现细节披露",
      "type": "method-level",
      "purpose": "增强可复现性和可解释性，降低方法理解门槛",
      "location": "method",
      "description": "详细描述HardKuma和FRESH的实现细节，包括模型结构、训练方式、参数选择等。"
    },
    {
      "name": "与现有工作直接对比",
      "type": "method-level",
      "purpose": "增强对比性，突出自身方法的优势和改进",
      "location": "method",
      "description": "将HardKuma与BERT、bi-LSTM等主流模型进行对比，说明选择bi-LSTM的原因和性能表现。"
    },
    {
      "name": "多数据集广泛实验设计",
      "type": "experiment-level",
      "purpose": "增强完备性，证明实验结果具有普适性和可靠性",
      "location": "experiments",
      "description": "在六组数据集对上进行实验，展示方法在多种场景下的表现。"
    },
    {
      "name": "定量结果与统计检验",
      "type": "experiment-level",
      "purpose": "增强说服力和结论可靠性",
      "location": "experiments",
      "description": "通过F1-macro分数、标准差、t-test等统计检验，量化方法性能并验证显著性。"
    },
    {
      "name": "案例分析与现象解释",
      "type": "experiment-level",
      "purpose": "增强可解释性，帮助读者理解实验结果背后的原因",
      "location": "experiments",
      "description": "对HardKuma模型在不同数据集上的表现进行现象分析，解释为何有些模型泛化能力较强。"
    },
    {
      "name": "叙事递进结构",
      "type": "writing-level",
      "purpose": "优化逻辑流，逐步引导读者理解问题、方法和结论",
      "location": "introduction / method / experiments",
      "description": "从问题背景、方法介绍、实验设计到结果分析，层层递进，逻辑清晰。"
    },
    {
      "name": "术语统一与澄清",
      "type": "writing-level",
      "purpose": "提升可解释性，避免术语混淆",
      "location": "introduction",
      "description": "对rationale extractor与rationale generator等术语进行澄清，确保读者理解一致。"
    }
  ]
}