[
  {
    "review_id": "43983cb662197434",
    "paper_id": "ARR_2022_213",
    "reviewer": null,
    "paper_summary": "This paper proposes an in-depth study of the impact of translationese on machine translation performance from a causal point-of-view, i.e. how the alignment of direction (from originally authored to translated text and vice-versa) of the model and data involved in the translation process influences BLEU scores. This differs from previous work which mostly focused on the alignment direction between the translation model and the test set.\nThe authors built an annotated corpus based on Europarl to control for variables such as original or translationese, content in terms of topics, and sentence length, and extracted comparable sub-corpora of aligned and unaligned directions to empirically show the following: aligned training and test directions perform best, alignment direction is also relevant when producing synthetic data with supervised training and back-translation, but the impact of data and model alignment varies among language pairs and translations when considering other factors.  The evaluation is conducted on five language pairs in ten translation directions with a test set sampled from the corpus built by the authors, as well as on the newstest2014 from WMT in two language pairs with four translation directions. ",
    "strengths": "Emerging from the presence of various directions (mixed set) in WMT test sets, recent studies on the impact of translationese on machine translation were mostly limited to the test-to-model alignment impact.  The authors of this paper, however, aim at providing a deeper understanding of previously observed results, due to the fact that the relation between training and test directions alignment as measured by automatic metrics is still unclear. This is especially true with the large amount of synthetic data produced and used in machine translation nowadays.  An additional contribution, backed by further experiments, is the exploration of causal and anticausal learning and their impact on translation performances (based on an automatic metric) when various data directions are used, which appears to be positive or negative depending on the translation direction and language pair.  Finally, the claims made by the authors throughout the paper are supported by a solid set of experiments conducted on various translation directions, the paper is very well written and straightforward to follow. ",
    "weaknesses": "Due to the difficulty to build a corpus as employed in this study, the amount of data used to train the machine translation systems is relatively small when compared to publicly available corpora used for the same language pairs by the research community. Thus, the conclusions drawn by the authors might be limited to low or average data settings.\nAlso, a popular method usually employed to mitigate the alignment mismatch between train and test directions is to add a tag per sample specifying the direction. Commonly used when adding back-translations to the training data, this method could contrast with the current set of experiments and provide an interesting comparison point. The question would be, is the machine translation system able to model the direction and potentially abstract from train-test or data-model alignment mismatch. ",
    "comments": "Because speakers at the European Parliament might not be native speakers of the language in which the transcription are written in, wouldn’t the Europarl corpus contain text annotated as originals but from non-native speakers?\nThe information about the passive voice checker in English is missing.\nDark colors in tables tend to make the numbers difficult to read. ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "3805bb3c1bb62fde",
    "paper_id": "ARR_2022_213",
    "reviewer": null,
    "paper_summary": "This paper studies translationese effects (differences between original and translations in the same language) in machine translation. Since one cannot have parallel corpora with originals in the 2 languages simultaneously, the authors analyse which is the best configuration in data and model alignments for maximising machine translation quality. Recent literature has studied the effect that translationese has in the test sets for the evaluation, but training data and models have been less explored. For this work, the authors first compile a corpus tagged for translationese in five language pairs (causalMT) and then run several experiments on different combinations of the data to see the effect on BLEU scores. ",
    "strengths": "- The number of experiments is comprehensive - The conclusions might help MT researchers in designing their systems. This is true for language pairs where translationese information is available, but also in general when one uses back-translation or self-training ",
    "weaknesses": "- Given the nature of the work, evaluation is important. Authors argue that they cannot perform human evaluation, but at least the combination of other metrics would be relevant. COMET for instance correlates better with human judgements than BLEU [1] and goes further string matching - A couple of relevant references are missing and it would be nice to see them included in the revised version and emphasize your contributions after their works: [2] which create a similar corpus from Europarl with the addition of information about the possibility of pivot translation (which might translationese effects) and [3] which also studied the relevance of the train-test alignment in SMT translation quality (see the references in the Comments section) ",
    "comments": "- Section 4, lines 404-411. \nI don't understand this part, I'm not able to reproduce you Corr column in Table 4 from the numbers in Table 2. Table 4's caption helps a bit, but I think the explanation here is not clear enough. Also, the term correlation is confusing (at least to me). I understand your point in the definition but, still, when I read \"correlation\" I expect something between -1 and 1 that shows me how much two variables relate to each other.\n- Still in Table 4, the 3r column shouldn't be named ATE? If I understood properly Corr is also Cau-Ant.\n- Causal effect results. How does (1) and the last part of (2) match? \n\"The data-model alignment is a clear cause for MT performance.\" vs \"For other language pairs, the data-model alignment can sometimes have a distinct positive impact and can also sometimes have a negative impact.\"\n- Related to the previous point: it makes a lot of sense to me that data-model alignment affects MT performance. The fact that it does not always happen couldn't be the effect of more \"others\" in Eq.3 besides length and content?\n- I think it would be good to include some of the appendices in the main text. Some parts of the main text are duplicated (Section 6 is already found in pieces in previous sections) on the other hand some relevant information is ignored here. \nFor instance, I found Appendix E1 especially interesting as the performance quality of method used to find topic and length equivalents might affect the final quality of the generated corpora.\nReferences [1] Tom Kocmi, Christian Federmann, Roman Grundkiewicz, Marcin Junczys-Dowmunt, Hitokazu Matsushita, Arul Menezes. To Ship or Not to Ship: An Extensive Evaluation of Automatic Metrics for Machine Translation. WMT@EMNLP 2021: 478-494 [2] Kwabena Amponsah-Kaakyire, Daria Pylypenko, Cristina España-Bonet and Josef van Genabith. Do not Rely on Relay Translations: Multilingual Parallel Direct Europarl. Proceedings of the Workshop on Modelling Translation: Translatology in the Digital Age (MoTra21), pages 1-7, Iceland (online), May 2021.\n[3] Sylwia Ozdowska, and Andy Way. Optimal Bilingual Data for French-English PB-SMT. Annual Conference of the European Association for Machine Translation EAMT (2009). ",
    "overall_score": "3 = Good: This paper makes a reasonable contribution, and might be of interest for some (broad or narrow) sub-communities, possibly with minor revisions.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]