[
  {
    "review_id": "90f1a911459b14b0",
    "paper_id": "ARR_2022_88",
    "reviewer": null,
    "paper_summary": "The paper presents a transformer based model for generating paraphrases for an input sentence with an added constraint of following a specific syntactic template. The proposed architecture consists of a normal transformer encoder to encode the source sentence, a tree-based transformer encoder to encode the syntax of the template, and finally a decoder which utilizes both sentence and syntax embeddings to generate the paraphrase. An additional attention regularization term is added to the cross entropy loss to explicitly align the decoder-syntax encoder cross-attention map to the paraphrase-template alignment known at training time. A template retriever is also proposed which can retrieve the appropriate templates for the input sentence, as for a given sentence not all syntactic templates would be compatible. Through the experiments, authors show that their method can outperform the existing baselines by a good margin, in terms of semantic and semantic similarity with the reference, as well as on the ability to generate diverse paraphrases. ",
    "strengths": "- Selecting appropriate syntactic templates for generating paraphrases is an important but overlooked aspect in controlled text generation, but it is addressed in the paper with the use of Syntactic Template Retriver.\n- The proposed method obtains impressive improvements over the baselines for the most part.\n- The evaluation setup looks comprehensive, with the methods compared over a wide variety of automatic metrics as well as with human evaluation. To the authors' credit they have added comparisons with other methods and experiments on QQPos dataset in the both syntactic and diverse paraphrase generation experiments as suggested by the reviewers. ",
    "weaknesses": "- While the authors have now edited the paper to motivate the syntactic paraphrasing task much better, my comments on a lack of motivation for architectural and modeling choices as well in deriving insights from the results still hold.  - The newly added results for the SGCP baseline look very different from the numbers reported in Kumar et al., 2020. The metrics reported in this paper for SGCP are significantly worse than even the copy baselines which makes me a bit doubtful about validity of the results reproduced by the authors.\nOverall, through the revision the authors seem to have partially addressed my major issues with the first version but a significant portion is still unaddressed as pointed out above. I request the authors to try to rectify these in their final submission, especially the second point on the performance metrics for the SGCP baseline. ",
    "comments": "1. In section 4.1 how is template encoder different from parse-tree encoder? Templates are also constituency parse trees right? \n2. It would have been useful if in Table 5, examples of the templates would have also been given. ",
    "overall_score": "3 = Good: This paper makes a reasonable contribution, and might be of interest for some (broad or narrow) sub-communities, possibly with minor revisions.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "6d82987300bc0425",
    "paper_id": "ARR_2022_88",
    "reviewer": null,
    "paper_summary": "This is the second time for this paper to be submitted. Compared with the previous version, it has a significant improvement in organization and experiments. This paper mainly belongs to controlled text generation domain. Utilizing the syntax to control generation process, this paper proposes a novel model to encode the syntax information and retrieval similar templates. In order to improve generation diversification, a template retriever is designed in practice. Two encoders are used for extracting related syntactic information to direct the generation process.  Experimental results show that this work achieves substantial improvements over previous baselines. ",
    "strengths": "Compared with the first submitted version, at this time, this paper has a more clear organization. Some missing experiments are supplemented. Furthermore, a number of baselines are taken into consideration and improve the robustness of results. ",
    "weaknesses": "The whole architecture of this proposed method may be a little complicated. So I am very curious about the training and inference speed. Can you provide more information about the amount of parameters and inference speed towards other baselines？ ",
    "comments": "None ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "80f0f27bae63d383",
    "paper_id": "ARR_2022_88",
    "reviewer": null,
    "paper_summary": "In this paper, the authors proposed Structural Information-augmented Syntax Controlled Paraphrasing (Si_SCP) which is a syntax-controlled paraphrase generation technique. They tackled two problems of such generation (a) encoding the structural information -- by using a tree transformer to capture parent-child and sibling relationships and (b) retrieving syntactic structure to guide the generation - by introducing a synthetic template retriever. ",
    "strengths": "(a) The paper is well written and easy to follow. \n(b) Various experiments and ablation studies are done to establish the effectiveness of the proposed mechanism. \n(c) The authors worked on the previous weaknesses thoroughly. ",
    "weaknesses": "Though the paper is detailed, I recommend the following areas to be addressed (a) Retrieval of the similar templates: The authors should clarify on why the query text and the whole query parse is important to retrieve templates? Is  it always the case that given a query, we can retrieve templates other than the own query template? Are all top K retrieved templates meaningful concerning the query or some thresholding on similarity is needed? \n(b) Human evaluation needs some more elaboration. The author should report the inter-annotator agreement along with the results.   (c) Syntactic evaluation: At the time of evaluating TED, did the authors use the top most retrieved template? They should elaborate on the process (d) Table 1: The performance of (Si_SCP) is slightly better than guiG in ParaNMT-small where as for QQP-OS the gains are higher. Is there any specific reasons or observation regarding the same? \n(e) Though the paper is focused on syntax guided paraphrase generation, it would be nice if the authors can discuss Si_SCP’s gain in comparison to unsupervised paraphrase generations [Krishna, Kalpesh, John Wieting, and Mohit Iyyer. \" Reformulating Unsupervised Style Transfer as Paraphrase Generation.\" Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2020.] ",
    "comments": "While I can see a detailed work in the paper, I would recommend the authors to address the points mentioned in the weaknesses. ",
    "overall_score": "3 = Good: This paper makes a reasonable contribution, and might be of interest for some (broad or narrow) sub-communities, possibly with minor revisions.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]