[
  {
    "review_id": "2ea1d4c58dad5df2",
    "paper_id": "ARR_2022_77",
    "reviewer": null,
    "paper_summary": "This paper presents the residue detection approach, which is specific to NLP adversarial attacks. The method leverages a linear classifier operating on the residue of sentence embedding to detect the adversary.\nIn the empirical evaluation, they detect substitution attacks on four classification datasets, and a targeted universal concatenation attack on a regression dataset. Results show the proposed method can outperform state-of-the-art detection approaches, such as FGWS, on most datasets. ",
    "strengths": "The proposed residue detection method is novel, which leverages the residue of sentence embeddings and feeds the residue into a linear classifier to identify adversarial attacks.  The study proposes two hypotheses of the residue properties in NLP adversarial samples. It further provides the rationale analysis and empirical evaluations to validate these properties.\nThe evaluations cover two types of adversarial attacks on five datasets. Besides, they conducted experiments on both NLP and image tasks. ",
    "weaknesses": "In section 3, some contents are basically introducing previous work, such as PGD, which are not closely related to the proposed method. I would suggest putting these parts into related work section.  Figure2 provides insightful findings on the residue properties. However, they are evaluated only on one dataset. It would be great to apply it to more datasets. ",
    "comments": "Please see the suggestions and comments in the summary of weaknesses. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]