[
  {
    "review_id": "ae97f0c9dfb463df",
    "paper_id": "ARR_2022_148",
    "reviewer": null,
    "paper_summary": "This paper works on personalized language modeling in case that there is limited data for the target user (i.e. a new user). The authors propose that leveraging the data from similar users extracted from the corpus to enhance the personalized language modeling for a new user. They first introduce three methods to calculate the similarity between a target user and the selected anchor users, and then either leverage the data of similar anchor users to fine-tune the language model or interpolate the anchor user models based on the similarity. The experiments show that their methods can improve the perplexity and accuracy, and more analysis explores the trade-off between the amount of available data from similar users. ",
    "strengths": "1. The paper explores an interesting topic of personalized language modeling. \n2. The proposed methods are easy to implement. ",
    "weaknesses": "The overall writing is poor. The whole paper lacks logic when organizing their content and is poorly structured, making it difficult to read, especially when they describe their experimental results. It is hard to learn something useful because of the writing. ",
    "comments": "Suggestions: 1. Add more figures to clarify the ideas. \n2. Leave the training details (like how many hours it takes to train) in a single section like \"implementation details\". \n3. Organize the results in a more reasonable way, e.g., highlight what we can learn from each result. ",
    "overall_score": "2.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]