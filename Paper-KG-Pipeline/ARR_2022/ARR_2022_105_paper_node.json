{
  "paper_id": "ARR_2022_105",
  "title": "UniTE: Unified Translation Evaluation",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究文本数据，聚焦于翻译文本的自动评价问题。",
    "core_technique": "论文采用或改进了统一的评价框架，可能涉及深度学习模型如Transformer及相关自然语言处理技术，用于提升翻译评价的一致性和泛化能力。",
    "application": "成果可应用于机器翻译系统的自动评价、翻译质量评估、辅助人工翻译审核等实际场景。",
    "domains": [
      "自然语言处理",
      "机器翻译",
      "自动评价"
    ]
  },
  "ideal": {
    "core_idea": "提出了一种统一模型UniTE，实现对REF、SRC和SRC+REF三类机器翻译评价任务的统一评估。",
    "tech_stack": [
      "多语言预训练语言模型（PLM）",
      "层级协调（layerwise coordination）",
      "单调区域注意力（Monotonic Regional Attention, MRA）",
      "多任务学习",
      "基于排序的数据标注策略"
    ],
    "input_type": "包含假设译文、源语言文本和参考译文的文本序列",
    "output_type": "翻译质量的自动化评估分数"
  },
  "skeleton": {
    "problem_framing": "论文以机器翻译质量自动评估的重要性为切入点，强调该任务在衡量MT模型性能中的核心作用。开篇通过梳理翻译评估的三大主流任务（REF、SRC、SRC+REF），结合近期文献，指出现有方法各自为政，难以统一，实际应用中存在不便和局限，属于从学术gap和应用需求双重角度出发，突出统一模型的必要性和潜在优势。",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法仅针对单一任务，无法兼容多种评估场景’的逻辑，并指出‘各方法核心均为依赖特定输入片段，忽略了任务间知识迁移的可能’，强调了方法的局限性和割裂性。句式上多用‘只能用于...，无法支持...’、‘这些方法忽视了...’等表达，突出统一模型的价值。",
    "method_story": "方法部分先整体后局部，先介绍统一模型UniTE的设计理念和输入格式如何适配三大任务，再分步骤详细阐述模型架构：输入拼接、PLM表示、层级协调、区域注意力机制、池化与预测。每一步都结合与现有方法的对比，突出创新点。最后针对PLM预训练与任务输入不匹配的问题，提出多任务预训练和数据标注策略，形成完整闭环。",
    "experiments_story": "实验部分按任务类型依次展开，先介绍REF任务的主流方法及其局限，再讲SRC任务的典型方法和应用场景，最后介绍SRC+REF任务的最新进展和优势。整体上采用主实验+对比分析的策略，涵盖统计方法、模型方法、特征组合等多种类型，突出模型在多任务统一评估中的性能和泛化能力。"
  },
  "tricks": [
    {
      "name": "任务分类梳理",
      "type": "writing-level",
      "purpose": "帮助读者理解领域背景和任务划分，突出统一模型的必要性",
      "location": "introduction",
      "description": "作者将机器翻译评测方法分为REF、SRC和SRC+REF三类，清晰梳理现有方法的局限，为提出统一模型做铺垫。"
    },
    {
      "name": "引用权威工作",
      "type": "writing-level",
      "purpose": "增强说服力，显示方法建立在已有工作的基础之上并解决其不足",
      "location": "introduction / method / experiments",
      "description": "多次引用领域内权威论文和竞赛结果，证明现有方法的不足和新方法的必要性。"
    },
    {
      "name": "问题递进式引入",
      "type": "writing-level",
      "purpose": "引导读者关注核心科学问题，增强叙事逻辑性",
      "location": "introduction",
      "description": "作者先指出现有方法的局限，再提出统一模型的需求，最后明确列出两个关键挑战。"
    },
    {
      "name": "创新点显式总结",
      "type": "writing-level",
      "purpose": "突出新颖性，帮助读者快速把握论文贡献",
      "location": "introduction",
      "description": "明确提出UniTE模型，并用小标题方式列举创新点（如Monotonic Regional Attention和多任务预训练）。"
    },
    {
      "name": "统一输入格式设计",
      "type": "method-level",
      "purpose": "展示方法的通用性和简洁性，降低模型复杂度",
      "location": "method",
      "description": "通过拼接不同输入段落（hypothesis, source, reference），实现三类任务统一输入格式，便于模型处理。"
    },
    {
      "name": "层级语义交互机制",
      "type": "method-level",
      "purpose": "提升模型表达能力，突出方法创新性",
      "location": "method",
      "description": "强调模型在每一层实现语义交互，利用PLM的多层特性，区别于只用顶层表示的传统方法。"
    },
    {
      "name": "专门针对挑战的策略设计",
      "type": "method-level",
      "purpose": "增强方法的针对性和可解释性，回应引言提出的科学问题",
      "location": "method",
      "description": "针对统一输入和PLM适配两大挑战，分别提出Monotonic Regional Attention和统一预训练策略。"
    },
    {
      "name": "与现有方法的系统对比",
      "type": "experiment-level",
      "purpose": "证明方法有效性和先进性，增强说服力",
      "location": "experiments",
      "description": "在多个任务和数据集上与主流方法（如BLEU, COMET, TransQuest等）进行对比实验。"
    },
    {
      "name": "多任务多场景实验设计",
      "type": "experiment-level",
      "purpose": "验证方法的广泛适用性和稳健性，提升完备性",
      "location": "experiments",
      "description": "分别在REF、SRC、SRC+REF三类任务和不同年份的WMT数据集上进行评测。"
    },
    {
      "name": "采用权威评价指标",
      "type": "experiment-level",
      "purpose": "增强实验结果的权威性和可比性",
      "location": "experiments",
      "description": "采用Kendall’s Tau等WMT官方评价指标，保证实验结果具有公信力。"
    },
    {
      "name": "方法原理可解释化",
      "type": "writing-level",
      "purpose": "帮助读者理解模型内部机制，提升可解释性",
      "location": "method",
      "description": "详细描述输入拼接、层级表示、注意力机制等设计，并用公式和示意图辅助说明。"
    },
    {
      "name": "实验与方法呼应",
      "type": "writing-level",
      "purpose": "形成闭环，增强论文整体逻辑性",
      "location": "experiments",
      "description": "实验部分紧扣引言和方法提出的挑战，验证所提策略的有效性。"
    }
  ]
}