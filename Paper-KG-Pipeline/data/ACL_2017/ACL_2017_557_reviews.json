[
  {
    "review_id": "b15d119443464ad6",
    "paper_id": "ACL_2017_557",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "- The paper is clearly written and well-structured.   - The system newly applied several techniques including global optimization to end-to-end neural relation extraction, and the direct incorporation of the parser representation is interesting.\n - The proposed system has achieved the state-of-the-art performance on both ACE05 and CONLL04 data sets.\n - The authors include several analyses.",
    "weaknesses": "- The approach is incremental and seems like just a combination of existing methods.    - The improvements on the performance (1.2 percent points on dev) are relatively small, and no significance test results are provided.",
    "comments": "- Major comments:  - The model employed a recent parser and glove word embeddings. How did they affect the relation extraction performance?\n - In prediction, how did the authors deal with illegal predictions?\n- Minor comments:  - Local optimization is not completely \"local\". It \"considers structural correspondences between incremental decisions,\" so this explanation in the introduction is misleading.\n - Points in Figures 6 and 7 should be connected with straight lines, not curves.\n - How are entities represented in \"-segment\"?\n - Some citations are incomplete. Kingma et al. (2014) is accepted to ICLR, and Li et al. (2014) misses pages.",
    "overall_score": "4",
    "confidence": "5"
  }
]