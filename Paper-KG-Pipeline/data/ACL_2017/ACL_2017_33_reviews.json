[
  {
    "review_id": "16c2d45af5bd9401",
    "paper_id": "ACL_2017_33",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "- Innovative idea: sentiment through regularization - Experiments appear to be done well from a technical point of view - Useful in-depth analysis of the model",
    "weaknesses": "- Very close to distant supervision - Mostly poorly informed baselines",
    "comments": "",
    "overall_score": "3",
    "confidence": "4"
  },
  {
    "review_id": "ffd1a2e08cddcfff",
    "paper_id": "ACL_2017_33",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "This paper proposes a nice way to combine the neural model (LSTM) with linguistic knowledge (sentiment lexicon, negation and intensity). The method is simple yet effective. It achieves the state-of-the-art performance on Movie Review dataset and is competitive against the best models on SST dataset.",
    "weaknesses": "Similar idea has also been used in (Teng et al., 2016). Though this work is  more elegant in the framework design and mathematical representation, the experimental comparison with (Teng et al., 2016) is not as convincing as the comparisons with the rest methods. The authors only reported the re-implementation results on the sentence level experiment of SST and did not report their own phrase-level results.\nSome details are not well explained, see discussions below.",
    "comments": "The reviewer has the following questions/suggestions about this work, 1. Since the SST dataset has phrase-level annotations, it is better to show the statistics of the times that negation or intensity words actually take effect. \nFor example, how many times the word \"nothing\" appears and how many times it changes the polarity of the context.\n2. In section 4.5, the bi-LSTM is used for the regularizers. Is bi-LSTM used to predict the sentiment label?\n3. The authors claimed that \"we only use the sentence-level annotation since one of our goals is to avoid expensive phrase-level annotation\". However, the reviewer still suggest to add the results. Please report them in the rebuttal phase if possible.\n4. \" s_c is a parameter to be optimized but could also be set fixed with prior knowledge.\"  The reviewer didn't find the specific definition of s_c in the experiment section, is it learned or set fixed?  What is the learned or fixed value?\n5. In section 5.4 and 5.5, it is suggested to conduct an additional experiment with part of the SST dataset where only phrases with negation/intensity words are included. Report the results on this sub-dataset with and without the corresponding regularizer can be more convincing.",
    "overall_score": "4",
    "confidence": "5"
  }
]