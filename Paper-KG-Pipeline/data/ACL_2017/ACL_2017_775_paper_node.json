{
  "paper_id": "ACL_2017_775",
  "title": "A Geometric Contextual Model for Identifying Unseen Metaphors",
  "conference": "ACL",
  "domain": {
    "research_object": "针对未见隐喻的自动识别，提升自然语言理解中的隐喻检测能力。",
    "core_technique": "提出几何上下文模型，通过空间表示和上下文信息识别隐喻表达。",
    "application": "用于文本分析、智能问答、机器翻译等自然语言处理任务中的隐喻识别。",
    "domains": [
      "自然语言处理",
      "计算语言学"
    ]
  },
  "ideal": {
    "core_idea": "利用几何上下文模型识别未见隐喻表达",
    "tech_stack": [
      "几何表示学习",
      "上下文建模",
      "隐喻识别算法"
    ],
    "input_type": "文本语料，隐喻候选短语",
    "output_type": "隐喻识别结果（是否为隐喻）"
  },
  "skeleton": {
    "problem_framing": "论文通过回顾隐喻计算建模的主流理论，强调隐喻作为概念域映射的观点，并梳理了符号和统计方法在识别、解释和生成隐喻方面的丰富成果，从而引出当前主流方法的局限性及其发展脉络。",
    "gap_pattern": "作者批评现有方法忽视语境在隐喻生成中的作用，指出理论与计算模型之间存在明显裂痕，强调需要将语境纳入隐喻识别与建模过程，以弥补现有模型的不足。",
    "method_story": "方法部分首先明确三项设计原则，突出语境选择、独立于主观标注以及几何可解释性。随后，作者借鉴前人分布式语义空间模型，利用大规模语料的PMI统计，系统阐述模型的理论基础与实现路径。",
    "experiments_story": "实验部分围绕前述模型展开，选用已有标注数据集，详细说明数据构成及标注方式，并结合具体技术流程，将形容词-名词对投射到语境化子空间，以检验模型在隐喻识别任务中的有效性和表现。"
  },
  "tricks": [
    {
      "name": "理论背景引入",
      "type": "writing-level",
      "purpose": "为研究方法奠定理论基础，增强论文可信度",
      "location": "开头段落",
      "description": "通过介绍隐喻的概念域映射理论和相关领域的研究进展，为后续方法的提出提供理论支撑。"
    },
    {
      "name": "文献对比与创新点突出",
      "type": "writing-level",
      "purpose": "突出自己的方法区别于现有方法，明确创新点",
      "location": "第二、三段",
      "description": "对比传统符号方法和统计方法，指出现有方法的不足，并明确本研究采用分布式语义方法并引入动态语境建模。"
    },
    {
      "name": "提出模型三大设计原则",
      "type": "writing-level",
      "purpose": "明确模型设计目标，指导后续方法论描述",
      "location": "模型介绍段落",
      "description": "用条列方式提出三个模型设计原则（语境选择性、独立于先验隐喻性评级、几何可解释性），为方法论框架设定清晰目标。"
    },
    {
      "name": "基于分布式语义的向量空间建模",
      "type": "method-level",
      "purpose": "实现对隐喻语境的动态建模与识别",
      "location": "方法描述段落",
      "description": "采用标准分布式向量空间模型，将词表示为向量，通过统计词在大规模语料中的共现关系，生成可用于语境分析的词空间。"
    },
    {
      "name": "上下文窗口设定",
      "type": "method-level",
      "purpose": "捕捉词语在不同语境下的分布特征",
      "location": "方法细节段落",
      "description": "定义上下文窗口大小n，统计目标词两侧n个词的共现情况，作为词向量构建的基础。"
    },
    {
      "name": "正点互信息（PMI）计算",
      "type": "method-level",
      "purpose": "提升词共现统计的区分度，减少高频词干扰",
      "location": "公式部分",
      "description": "采用正点互信息（PMI）公式对词共现进行加权，结合平滑参数a，提升语义空间的有效性和鲁棒性。"
    },
    {
      "name": "大规模语料训练",
      "type": "experiment-level",
      "purpose": "确保词向量空间的代表性和泛化能力",
      "location": "方法描述段落",
      "description": "在英文维基百科2014年12月快照上训练模型，选取20万高频词作为词汇表，提升模型的覆盖率和实用性。"
    },
    {
      "name": "动态生成隐喻子空间",
      "type": "method-level",
      "purpose": "针对每个候选隐喻在线生成专属语义空间，提高识别的灵活性和准确性",
      "location": "模型创新点描述",
      "description": "借鉴McGregor等人（2015）的方法，为每个候选隐喻上下文动态生成新的语义子空间，实现语境化分析。"
    },
    {
      "name": "与语用学理论结合",
      "type": "writing-level",
      "purpose": "弥补计算方法与语用学理论的断层，提升方法解释力",
      "location": "方法理论部分",
      "description": "强调方法不仅依赖统计建模，还结合语用学理论，关注语境对隐喻生成和识别的重要作用。"
    },
    {
      "name": "独立于先验隐喻性标签的空间生成",
      "type": "method-level",
      "purpose": "避免人工标签偏见，提升模型的客观性和泛化能力",
      "location": "模型设计原则部分",
      "description": "空间生成过程不依赖于预先设定的隐喻/字面性标签，而是完全由语料和上下文驱动。"
    }
  ]
}