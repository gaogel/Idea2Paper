[
  {
    "review_id": "047958c21b32c605",
    "paper_id": "ACL_2017_483",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "This is the first neural network-based approach to argumentation mining. The proposed method used a Pointer Network (PN) model with multi-task learning and outperformed previous methods in the experiments on two datasets.",
    "weaknesses": "This is basically an application of PN to argumentation mining. Although the combination of PN and multi-task learning for this task is novel, its novelty is not enough for ACL long publication. The lack of qualitative analysis and error analysis is also a major concern.",
    "comments": "Besides the weaknesses mentioned above, the use of PN is not well-motivated. Although three characteristics of PN were described in l.138-143, these are not a strong motivation against the use of bi-directional LSTMs and the attention mechanism. The authors should describe what problems are solved by PN and discuss in the experiments how much these problems are solved.\nFigures 2 and 3 are difficult to understand. What are the self link to D1 and the links from D2 to E1 and D3/D4 to E2? These are just the outputs from the decoder and not links. The decoder LSTM does not have an input from e_j in these figures, but it does in Equation (3). Also, in Figure 3, the abbreviation \"FC\" is not defined.\nEquation (8) is strange. To calculate the probability of each component type, the probability of E_i is calculated.\nIn the experiments, I did not understand why only \"PN\", which is not a joint model, was performed for the microtext corpus.\nIt is not clear whether the BLSTM model is trained with the joint-task objective.\nThere are some studies on discourse parsing using the attention mechanism. The authors should describe the differences from these studies.\nMinor issues: l.128: should related -> should be related l.215: (2015) is floating l.706: it able -> it is able I raised my recommendation score after reading the convincing author responses. \nI strongly recommend that the authors should discuss improved examples by PN as well as the details of feature ablation.",
    "overall_score": "3",
    "confidence": "5"
  },
  {
    "review_id": "c83379c74ba6e328",
    "paper_id": "ACL_2017_483",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "- Thorough review of prior art in the specific formulation of argument mining handled in this paper.\n- Simple and effective modification of an existing model to make it suitable for the task. The model is mostly explained clearly.\n- Strong results as compared to prior art in this task.",
    "weaknesses": "- 071: This formulation of argumentation mining is just one of several proposed subtask divisions, and this should be mentioned. For example, in [1], claims are detected and classified before any supporting evidence is detected. \nFurthermore, [2] applied neural networks to this task, so it is inaccurate to say (as is claimed in the abstract of this paper) that this work is the first NN-based approach to argumentation mining.\n- Two things must be improved in the presentation of the model: (1) What is the pooling method used for embedding features (line 397)? and (2) Equation (7) in line 472 is not clear enough: is E_i the random variable representing the *type* of AC i, or its *identity*? Both are supposedly modeled (the latter by feature representation), and need to be defined. Furthermore, it seems like the LHS of equation (7) should be a conditional probability.\n- There are several unclear things about Table 2: first, why are the three first baselines evaluated only by macro f1 and the individual f1 scores are missing? \nThis is not explained in the text. Second, why is only the \"PN\" model presented? Is this the same PN as in Table 1, or actually the Joint Model? What about the other three?\n- It is not mentioned which dataset the experiment described in Table 4 was performed on.",
    "comments": "",
    "overall_score": "4",
    "confidence": "3"
  }
]