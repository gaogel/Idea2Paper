{
  "paper_id": "COLING_2020_52",
  "title": "Multi-Word Lexical Simplification",
  "conference": "COLING",
  "domain": {
    "research_object": "针对多词表达的词汇简化方法，提升文本可读性和理解性。",
    "core_technique": "采用自然语言处理技术，自动替换复杂多词表达为更简单的等价表达。",
    "application": "辅助语言学习、阅读障碍者、自动文本简化和信息获取等场景。",
    "domains": [
      "自然语言处理",
      "计算语言学"
    ]
  },
  "ideal": {
    "core_idea": "提出多词表达的词汇简化方法，提升文本易读性",
    "tech_stack": [
      "自然语言处理",
      "词汇替换算法",
      "语义保持模型"
    ],
    "input_type": "包含复杂词汇的自然语言文本",
    "output_type": "用更易懂多词表达替换后的简化文本"
  },
  "skeleton": {
    "problem_framing": "论文通过定义文本简化任务及其多样化应用场景，强调该任务对不同用户群体（如二语学习者、科学文本读者等）的重要性。引言以任务定义为起点，逐步引出文本简化的实际需求和挑战，建立研究背景。",
    "gap_pattern": "作者批评了以往仅关注单词替换的简化方法，指出这种方法过于简单，未能覆盖人类实际简化行为的复杂性。通过引用最新研究和数据集，强调现有方法在处理多词替换和句子级操作时的不足，明确研究空白。",
    "method_story": "方法部分以现有单词级无监督简化方法为基础，介绍了自身方法Plainifier的创新点。通过逐步说明候选生成、递归过程及模型训练，突出方法对多词替换复杂性的适应，并以章节分明的方式组织技术细节。",
    "experiments_story": "实验部分通过与人工众包结果对比，验证方法有效性。明确实验数据的选取与划分标准，突出方法无需训练数据但可调优的特点，体现实验设计的科学性和公正性，便于后续结果的量化评估。"
  },
  "tricks": [
    {
      "name": "引入任务背景与应用场景",
      "type": "writing-level",
      "purpose": "阐明研究的重要性与应用价值",
      "location": "论文开头",
      "description": "通过介绍文本简化任务的定义及其广泛应用场景（如二语学习者、普通读者、脑卒中患者等），增强论文的现实意义和吸引力。"
    },
    {
      "name": "阐述现有方法的局限性",
      "type": "writing-level",
      "purpose": "突出研究创新点和必要性",
      "location": "背景介绍后",
      "description": "指出单词替换方法过于简单，不能覆盖人类简化句子的多样操作，如替换、删除、添加和拆分，为提出新任务和方法做铺垫。"
    },
    {
      "name": "提出新任务MWLS",
      "type": "writing-level",
      "purpose": "展示研究创新点",
      "location": "方法介绍前",
      "description": "定义Multi-Word Lexical Simplification（MWLS）任务，强调其区别于传统LS，关注短语级片段替换以提升句子可理解性。"
    },
    {
      "name": "构建并公开新数据集",
      "type": "experiment-level",
      "purpose": "为任务研究提供数据基础",
      "location": "方法部分",
      "description": "通过众包收集1462句、7059条简化数据，保证研究的可复现性和数据丰富性。"
    },
    {
      "name": "扩展已有方法",
      "type": "method-level",
      "purpose": "提升模型适应新任务的能力",
      "location": "方法设计",
      "description": "在Qiang等人（2020）单词简化无监督方法基础上，扩展为可处理多词片段替换的Plainifier方法。"
    },
    {
      "name": "利用BERT生成候选片段",
      "type": "method-level",
      "purpose": "提升候选生成的多样性和上下文相关性",
      "location": "方法细节",
      "description": "采用特定训练的BERT模型，根据上下文递归生成多词候选片段，适应片段长度和结构变化。"
    },
    {
      "name": "多维度候选排序",
      "type": "method-level",
      "purpose": "保证简化片段的质量",
      "location": "方法细节",
      "description": "综合语言模型概率、简易度和语义相似性等指标，对生成的候选片段进行排序，确保输出兼顾简化与语义保持。"
    },
    {
      "name": "针对不同长度片段的比较方法",
      "type": "method-level",
      "purpose": "解决候选片段长度不一致带来的评价难题",
      "location": "方法细节",
      "description": "在候选排序阶段，设计机制比较不同长度的候选片段，保证评估的公平性和有效性。"
    },
    {
      "name": "严格的数据分割与调参",
      "type": "experiment-level",
      "purpose": "保证评估的客观性和泛化能力",
      "location": "实验设计",
      "description": "随机选取100句用于调参，剩余1177句用于评价，避免过拟合并确保结果的可靠性。"
    },
    {
      "name": "与人工结果对比评估",
      "type": "experiment-level",
      "purpose": "验证方法有效性",
      "location": "实验部分",
      "description": "将Plainifier输出与众包人工简化结果对比，采用多参考标准，提升评估的权威性和说服力。"
    }
  ]
}