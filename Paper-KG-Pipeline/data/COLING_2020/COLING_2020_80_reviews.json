[
  {
    "review_id": "82a668a23172852c",
    "paper_id": "COLING_2020_80",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "which if addressed would lead to an even stronger camera-ready version: - The paper does not discuss linguistic aspects in detail. In particular, I'd appreciate some more discussion on why decisions on transcripts should lead to improved translations. This paper gives empirical evidence, and justifies the approach from an engineer's perspective only. To make this suggestion more precise: In the intro, please consider elaborating further on this sentence: \"We believe that these are two edge design choices and that a tighter coupling of ASR and MT is desirable for future end-to-end ST applications.\"\n- The focus seems to be on improving translations only (and probably lead to the choice of alpha=0.3 for the training objective). This is a reasonable choice, but should be stated more explicitly, given that one could also target improvements in both BLEU score *and* WER. In fact, the proposed model seems to experience a trade-off between translation accuracy and transcription accuracy, which in itself is a very interesting observation. It might be worth citing a highly relevant, concurrent work that goes the other direction, assuming that both translation and transcript are of equal importance: https://arxiv.org/pdf/2007.12741.pdf  . Another related work to cite might be https://ieeexplore.ieee.org/document/5947637 who have reported on BLEU/WER tradeoff quite a few years ago.\n- On \"chained decoders\": are these conceptually related / identical to http://arxiv.org/abs/1802.06655 ?\n- Evaluation: please do not say \"significant\" unless you have actually formally verified statistical significance, in which case it would be necessary to report the details of the stat. significance check. Also, the standard nowadays is to use sacreBLEU to compute comparable BLEU scores (please see https://www.aclweb.org/anthology/W18-6319/ on why it is impossible to compare BLEU scores when the tokenization details are not known or not consistent).\n- typo: \"weekly tight\" -> \"weakly tied\"",
    "comments": "",
    "overall_score": "5",
    "confidence": "5"
  }
]