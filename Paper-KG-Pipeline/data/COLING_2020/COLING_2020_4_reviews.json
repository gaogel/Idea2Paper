[
  {
    "review_id": "57516f820c5446c8",
    "paper_id": "COLING_2020_4",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "The paper consider the relation classification problem in the presence of unseen (novel) relations in a zero-shot setting. Compared with existing approach leveraging external artificial descriptive information, the proposed approach considers external knowledge graph embedding and further the logical rule mining to improve relation representation. The approach is novel, and extensive ablation studies show the effectiveness of proposed approach.\nThe idea of leveraging knowledge is novel. The paper reads good, however it might be difficult for readers new to zero shot learning.   Comments, - Zero-shot as the backbone of the approach is not clearly described. Despite the description of related works in Sec. 2. and math equations in Eq. (2) and Eq. (3), it is still hard to get the essence and motivation of zero-shot learning given the current manuscript. As a consequence, I am unsure about what is needed for zero shot learning and what is learnt  and what is the training objective function given Eq.(2) or Eq.(3) during the training phase.\n- It might be better to provide comparison with the existing approaches (Levy et al 2017 and Obamuyide and Vlachos, 2018) leveraging different external materials given the same training set.\nSome typos, - Fig. 1 is squeezed - There is no space between ‘(’ and the preceding letter in Sec. 3.2 - Some symbols above Eq.(5) is not in math environment.",
    "overall_score": "3",
    "confidence": "3"
  },
  {
    "review_id": "19b3da4ecaf8f422",
    "paper_id": "COLING_2020_4",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "This submission proposes to address the relation classification task in a zero-shot manner, i.e., for relations unseen during training time. The proposed method relies on word, graph, and rule embeddings, and their combinations. The results show that combining rule and graph embeddings yields best performance. The analysis shows that while this holds for most relations that benefit from the graph structure, it does not hold for relations that are sparse in the graph.\nStrong points: (S1) This paper tackles a timely challenge, of classifying relations without training data.\n(S2) The method is intuitive and well-described.  (S3) The paper is overall well-structured and understandable.\n(S4) The results clearly show the superiority over the compared baselines.\n(S5) The additional analysis and discussion gives welcome insights into where the method works better and where not.\nWeak points: (S1) My primary concern is that while indeed the 'unseen' relations are  not given during training, they can be assumed to be present in Wikipedia and in Wikidata, making them very accessible to all embedding methods. In addition, the data selection is biased towards the most populous 100 relations, the bottom 30 of which are considered 'unseen'. While that is true, it is also the case that they would be covered well in the background resources.\nWhile this strong dependency/assumption of the completeness of the underlying resource does not need to be problematic, in this case I find it to be a problem, in particular because its role in the results is not discussed/acknowledged in the paper.\n(W2) The related work on zero-shot RC seems quite sparse. Is this meant to be exhaustive? I'd suggest adding more recent work here, e.g. by Qin et al. (2020) on \"Generative Adversarial Zero-Shot Relational Learning for Knowledge Graphs\".\n(W3) The paper does not give an impression about the relevance/size of the zero-shot relation classification. How many of the relations are 'unseen' in a real use case? Would this be a long tail of many infrequent relation? Even if there is no exhaustive study on this, it would help the reader understand the significance of this work.\n(W4) Some important decisions should be motivated better. For instance, \"We drop relations from the cluster where all relations’ instance number is less than 500 with the assumption that there is no support from related seen labels.\" - why is this a good/reasonable assumption? Please elaborate Other comments: - in the introduction, what are 'traditional' methods?\n- In multiple occasions, the paper uses unsupported claims. For instance, the introduction states at least three times that various decisions of the approach are 'natural', but it is not clear why that is: this should be defended more clearly. Similarly, in section 3.2 \"PCNNs has been proven to be effective in RC.\" needs support/citation.\n- in section 3: what does this mean: \"Meanwhile, connections of relations are harvested.\"\n- In 3.1 - I think you mean \"relation instances\" (or \"occurrences\") - as a single relation might occur multiple times in the corpus - The citation style is not always correct. For instance, \"(Norouzi et al., 2013) proposes\" should become \"Norouzi et al., (2013) propose\" - Wikidata 2020 has much more than 594 relations - which version is used in the paper?\n- The reason why 'mother' is better captured in Wikipedia is probably because this information is mostly stated inline and as such is not extracted into Wikidata. So it is reasonable that the word embeddings can capture it better.",
    "overall_score": "4",
    "confidence": "3"
  }
]