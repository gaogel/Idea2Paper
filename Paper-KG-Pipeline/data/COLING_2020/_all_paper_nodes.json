[
  {
    "paper_id": "COLING_2020_0",
    "title": "PheMT: A Phenomenon-wise Dataset for Machine Translation Robustness on User-Generated Contents",
    "conference": "COLING",
    "domain": {
      "research_object": "面向用户生成内容的机器翻译鲁棒性现象级数据集",
      "core_technique": "构建和分析针对多种语言现象的机器翻译鲁棒性数据集",
      "application": "提升机器翻译系统在真实用户生成内容上的表现和稳定性",
      "domains": [
        "自然语言处理",
        "机器翻译"
      ]
    },
    "ideal": {
      "core_idea": "提出面向UGC的机器翻译鲁棒性现象级数据集PheMT",
      "tech_stack": [
        "神经机器翻译",
        "数据集构建",
        "鲁棒性评估"
      ],
      "input_type": "用户生成内容文本",
      "output_type": "现象级标注的翻译数据集与鲁棒性评测结果"
    },
    "skeleton": {
      "problem_framing": "论文引言通过对NMT在新闻等干净文本领域取得的突破进行肯定，随后指出其在用户生成内容（UGC）上的局限，强调UGC在现实交流中的普遍性，巧妙地将研究问题定位为提升机器翻译在UGC领域的适用性，突出其现实意义和挑战性。",
      "gap_pattern": "作者采用“成就-不足”式gap批评策略，先列举NMT在人类水平翻译等方面的成就，再指出其在UGC处理上的明显短板，并引用相关文献支持，强调现有研究未能充分解决UGC带来的挑战，从而为后续研究铺垫必要性。",
      "method_story": "方法部分通过回顾已有日语文本规范化和形态分析的规则，结合前人工作定义了两类语言现象，并扩展为四种标签，明确创新点在于将这些现象用于下游任务如机器翻译的影响分析，突出方法的理论依据和实际操作流程。",
      "experiments_story": "实验部分以现有NMT系统为对象，设计对比原始与规范化句子的翻译表现，通过BLEU分数和准确率量化现象对模型性能的影响，强调数据集的针对性和实验设计的科学性，确保结果能直接反映现象对翻译质量的作用。"
    },
    "tricks": [
      {
        "name": "引言中引用前沿成果",
        "type": "writing-level",
        "purpose": "建立研究背景和重要性",
        "location": "论文开头",
        "description": "通过引用领域内的最新成果和权威论文（如Sutskever et al., 2014; Hassan et al., 2018），突出NMT在某些领域的进步，并引出研究的不足之处，为后续研究设定背景。"
      },
      {
        "name": "问题陈述与现实意义结合",
        "type": "writing-level",
        "purpose": "增强研究话题的现实相关性",
        "location": "引言段落",
        "description": "将技术问题（NMT对UGC的适应性有限）与实际生活中的普遍现象（UGC在真实交流中的普及）结合，强调研究的现实意义和紧迫性。"
      },
      {
        "name": "指出现有评估方法的局限性",
        "type": "writing-level",
        "purpose": "为提出新方法做铺垫",
        "location": "引言后半段",
        "description": "批判性分析现有MT评估方法（仅给出整体分数），指出其无法揭示性能差距的具体原因，从而为提出细粒度评估方法做铺垫。"
      },
      {
        "name": "提出细粒度评估需求",
        "type": "writing-level",
        "purpose": "引出创新点",
        "location": "引言结尾",
        "description": "明确提出需要更详细的错误分析和细粒度评估，为后续方法创新奠定理论基础。"
      },
      {
        "name": "参考领域文献定义标签",
        "type": "method-level",
        "purpose": "确保标签定义的科学性和可复现性",
        "location": "方法部分 (i) Definition of phenomena labels",
        "description": "通过参考相关领域的文献（如Sasano et al., 2013; Ikeda et al., 2016），结合已有规则，定义现象标签，保证方法的科学性和可复现性。"
      },
      {
        "name": "扩展标签以覆盖实际数据",
        "type": "method-level",
        "purpose": "提高数据集的适用性和代表性",
        "location": "方法部分 (i)",
        "description": "在已有标签基础上，结合UGC常见现象，扩展标签体系，使其更适合实际数据分析。"
      },
      {
        "name": "众包多标注者投票机制",
        "type": "method-level",
        "purpose": "保证数据标注质量和一致性",
        "location": "方法部分 (i)",
        "description": "每句分配五名众包标注者，仅当多数一致时才采纳标签，有效保证标注数据的质量和一致性。"
      },
      {
        "name": "分离现象表达的抽取与标准化",
        "type": "method-level",
        "purpose": "便于后续分析和模型训练",
        "location": "方法部分 (ii)",
        "description": "在标签分类后，进一步让众包工人抽取并标准化相关表达，为后续分析和实验提供结构化数据。"
      },
      {
        "name": "数据集现象分组设计",
        "type": "experiment-level",
        "purpose": "实现现象级评估与对比",
        "location": "整体方法设计",
        "description": "按照不同语言现象对数据集进行分组，便于针对每种现象进行细粒度评估和对比分析。"
      },
      {
        "name": "附录详细实验设置",
        "type": "writing-level",
        "purpose": "提升论文可复现性和透明度",
        "location": "文末（Appendix A）",
        "description": "将详细实验设置放在附录，既保证正文简洁，又便于他人复现实验，提高论文的科学性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_10",
    "title": "Referring to what you know and do not know: Making Referring Expression Generation Models Generalize To Unseen Entities",
    "conference": "COLING",
    "domain": {
      "research_object": "提升指代表达生成模型在未见实体上的泛化能力，增强模型理解与表达能力。",
      "core_technique": "采用知识推理与不确定性建模方法改进指代表达生成模型的泛化性能。",
      "application": "用于自然语言生成任务中的自动指代表达生成，提升对新实体的描述能力。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "提升指称表达生成模型对未见实体的泛化能力",
      "tech_stack": [
        "数据到文本生成",
        "指称表达生成",
        "泛化建模"
      ],
      "input_type": "结构化非语言数据及实体信息",
      "output_type": "针对实体的自然语言指称短语"
    },
    "skeleton": {
      "problem_framing": "论文通过定义数据到文本自然语言生成（NLG）及其子任务指称表达生成（REG），将研究置于自动化文本生成的背景下。引言部分以具体例子说明REG的重要性和应用场景，帮助读者理解任务的实际意义和研究价值。",
      "gap_pattern": "作者通过回顾传统REG系统的两步流程，指出现有方法在指称表达生成时的局限性，尤其是在实体表示和上下文利用方面。通过引用前人工作，明确提出当前方法在处理复杂实体描述和上下文建模上的不足，为后续方法创新埋下伏笔。",
      "method_story": "方法部分采用对比叙述策略，先简述前人NeuralREG的做法，再突出自身改进点：将目标实体由单一token扩展为多token描述，并引入实体类型和性别特征。通过分步说明输入、输出及建模方式，突出方法的创新性和针对性。",
      "experiments_story": "实验部分采用定量对比和案例分析相结合的策略。先通过表格展示与多个基线模型在不同指标下的全面对比，突出自身方法的优越性；再通过具体文本案例，直观展示生成效果，增强实验说服力和可读性。"
    },
    "tricks": [
      {
        "name": "分步阐述传统方法",
        "type": "writing-level",
        "purpose": "清晰介绍领域背景和传统流程",
        "location": "论文开头对REG系统的描述",
        "description": "将传统REG系统的流程分为两个明确步骤：首先选择指称形式（如代词、专有名、描述），然后根据语境实现具体文本表达。通过分步说明，有助于读者理解后续创新点。"
      },
      {
        "name": "对比传统与现代方法",
        "type": "writing-level",
        "purpose": "突出方法创新性和发展趋势",
        "location": "介绍数据驱动系统前后",
        "description": "先描述传统规则驱动的模块化架构，再说明数据驱动的端到端系统如何改变了REG系统架构，突出技术演进。"
      },
      {
        "name": "详细定义输入输出结构",
        "type": "method-level",
        "purpose": "明确任务建模及实现细节",
        "location": "方法部分对输入输出的描述",
        "description": "将输入（pre-context、post-context、实体描述、类型、性别）和输出（指称表达的token序列）用数学符号和集合明确定义，为模型设计和复现提供清晰基础。"
      },
      {
        "name": "引入实体多维特征",
        "type": "method-level",
        "purpose": "丰富实体表示，提升生成质量",
        "location": "方法部分描述实体表示",
        "description": "不仅用单一token表示实体，还引入实体的标识符token序列、类型和性别等多维特征，增强模型对实体的理解与区分能力。"
      },
      {
        "name": "采用Encoder-Attention-Decoder架构",
        "type": "method-level",
        "purpose": "利用神经网络捕捉上下文信息，实现端到端生成",
        "location": "模型架构说明",
        "description": "使用编码器-注意力-解码器结构，结合copy机制，提升模型对上下文和实体信息的融合能力，适应数据驱动的任务需求。"
      },
      {
        "name": "共享输入词嵌入矩阵",
        "type": "method-level",
        "purpose": "参数共享，提升训练效率与泛化能力",
        "location": "模型架构说明",
        "description": "模型各部分共享同一输入词嵌入矩阵，减少参数量，提高各输入源之间的语义一致性。"
      },
      {
        "name": "详细列出模型训练参数",
        "type": "experiment-level",
        "purpose": "方便复现与对比实验",
        "location": "模型训练参数说明",
        "description": "详细给出epoch数、dropout率、early stopping、beam size、最大输出长度、batch/state/attention size以及词嵌入维度等关键训练参数，增强实验可复现性。"
      },
      {
        "name": "分实体类别展示实验结果",
        "type": "experiment-level",
        "purpose": "更细致地分析模型表现",
        "location": "实验结果展示部分",
        "description": "不仅展示全部实体的实验结果，还分别展示已见和未见实体的结果，便于分析模型在不同泛化场景下的性能。"
      },
      {
        "name": "引用并对比前人方法",
        "type": "writing-level",
        "purpose": "突出自身改进点及贡献",
        "location": "方法介绍与相关工作引用",
        "description": "明确引用前人工作（如NeuralREG），并指出自身在实体表示等方面的改进，突出创新点。"
      },
      {
        "name": "适当使用数学符号和公式",
        "type": "writing-level",
        "purpose": "增强技术表达的严谨性与清晰度",
        "location": "方法建模与输入输出定义",
        "description": "用集合和符号（如X(pre), X(post), X(wiki), y）表示输入输出结构，使方法描述更规范易懂。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_11",
    "title": "An Anchor-Based Automatic Evaluation Metric for Document Summarization",
    "conference": "COLING",
    "domain": {
      "research_object": "针对文档摘要自动评价方法的研究，旨在提升评价的准确性和自动化水平。",
      "core_technique": "基于锚点的自动评价指标，通过识别关键内容对摘要进行质量评估。",
      "application": "用于自动化评估生成的文档摘要质量，辅助摘要系统开发与优化。",
      "domains": [
        "自然语言处理",
        "文本挖掘"
      ]
    },
    "ideal": {
      "core_idea": "提出基于锚点的自动文档摘要评价指标，提升评价准确性。",
      "tech_stack": [
        "锚点检测",
        "自动评价算法",
        "文本相似度计算"
      ],
      "input_type": "系统生成摘要与原始文档",
      "output_type": "摘要质量自动评分"
    },
    "skeleton": {
      "problem_framing": "论文通过强调自动评价指标在文档摘要任务中的核心作用，引入评价系统性能的必要性，并指出现有指标在理想设计上仍面临挑战，凸显该领域的重要性和现实需求。",
      "gap_pattern": "作者批评现有主流指标（如ROUGE）依赖参考摘要，指出无参考指标尚不成熟，尤其在人类评价相关性和多文档摘要场景下表现不足，从而明确提出研究空白和改进空间。",
      "method_story": "方法部分首先界定研究对象为多文档摘要，并选择具有代表性的公开数据集，强调任务难度和评测多样性，合理铺垫后续对多种评价指标的系统性检验。",
      "experiments_story": "实验设计围绕两个权威多文档摘要数据集展开，详细说明数据规模、参考摘要数量和选取标准，突出实验的严谨性和可复现性，为后续指标对比和鲁棒性测试奠定基础。"
    },
    "tricks": [
      {
        "name": "指出现有方法的不足并引出创新点",
        "type": "writing-level",
        "purpose": "明确研究意义并突出自身创新",
        "location": "开头段落",
        "description": "通过综述现有自动评价指标的不足（如reference-free方法不成熟、参考文献支持），自然引出本文提出的新协议，增强论文的创新性和研究价值。"
      },
      {
        "name": "引用权威文献支持论点",
        "type": "writing-level",
        "purpose": "增强论据的说服力和权威性",
        "location": "开头及方法论相关段落",
        "description": "在介绍现有评价方法和问题时，广泛引用权威文献（如Schluter, 2017; Kryscinski et al., 2019），显示作者对领域现状的把握并为观点提供支撑。"
      },
      {
        "name": "重新审视被忽视的要素",
        "type": "writing-level",
        "purpose": "提出新颖视角，丰富评价指标设计",
        "location": "方法创新提出部分",
        "description": "通过‘重新思考源文档的角色’，发掘前人忽略的要素（源文档），为评价协议引入新的信息维度，提升创新性。"
      },
      {
        "name": "对比多种评价指标",
        "type": "experiment-level",
        "purpose": "全面验证新方法的有效性",
        "location": "实验设计部分",
        "description": "将新提出的方法与多种主流评价指标（如ROUGE, ROUGE-WE, BERTScore）进行对比，增强实验的说服力和结果的普适性。"
      },
      {
        "name": "选择具有挑战性的数据集",
        "type": "experiment-level",
        "purpose": "凸显方法在复杂场景下的优势",
        "location": "数据集选择部分",
        "description": "选用多文档摘要（MDS）数据集（TAC 2008/2009），因其比单文档更具挑战性，有助于突出方法的实际价值和区分度。"
      },
      {
        "name": "多参考摘要和鲁棒性测试",
        "type": "experiment-level",
        "purpose": "检验方法的稳健性和泛化能力",
        "location": "数据集描述部分",
        "description": "利用具有多参考摘要的数据集，进行鲁棒性测试，确保新指标在不同参考下表现一致，增强结果的可靠性。"
      },
      {
        "name": "采用人工评价作为对比基准",
        "type": "experiment-level",
        "purpose": "验证自动指标与人工评价的一致性",
        "location": "实验设计部分",
        "description": "使用Pyramid分数作为人工评价基准，测试自动评价指标与人工打分的相关性，提升实验的科学性。"
      },
      {
        "name": "参数调优使用独立验证集",
        "type": "method-level",
        "purpose": "防止过拟合，确保参数选择合理",
        "location": "数据集描述部分",
        "description": "参数（如锚点集大小k）调优时，单独使用另一数据集（DUC 2007），保证参数选择不受测试集影响，提高实验规范性。"
      },
      {
        "name": "细致描述评价指标的计算方法",
        "type": "method-level",
        "purpose": "确保方法可复现与易于理解",
        "location": "方法介绍部分",
        "description": "详细说明各评价指标（如ROUGE-1, ROUGE-2, ROUGE-WE, BERTScore）的计算方式和参数设定，便于他人复现和比较。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_12",
    "title": "Exploring the Value of Personalized Word Embeddings",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象为个性化词嵌入模型，旨在提升词向量的个体差异表达能力。",
      "core_technique": "核心技术是根据用户或上下文信息定制词嵌入方法，实现个性化语义表示。",
      "application": "应用场景包括个性化推荐、用户建模和自然语言处理中的定制化任务。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "探索个性化词嵌入对提升个体文本理解的价值",
      "tech_stack": [
        "词嵌入",
        "自然语言处理",
        "个性化建模"
      ],
      "input_type": "多作者或个人文本语料",
      "output_type": "针对个体优化的词嵌入表示"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过介绍词嵌入在自然语言处理中的广泛应用切入，指出现有词嵌入通常基于大规模多源语料训练，强调其对语言的普遍性捕捉，进而引出个体差异对词语理解的影响，提出个性化词嵌入的需求。",
      "gap_pattern": "作者批评现有多源语料训练的词嵌入虽然数据量大，但未必能为个体提供理想的语义表示。通过具体词语（如“hometown”）的多样联想，揭示当前方法在个性化表达上的不足，明确提出研究空白。",
      "method_story": "方法部分采用以实际任务（语言建模）为切入点，说明如何将个性化词嵌入应用于下游任务。通过选用已有的强基线模型，并解释选择理由（代码可用性、运行效率），体现方法选择的合理性与可复现性。",
      "experiments_story": "实验部分以标准化流程展开，首先在语言建模任务中测试所提方法，详细说明实验设置（如参数选择、模型调整），并通过与主流基线对比，突出新方法的有效性和改进点，确保实验严谨性和说服力。"
    },
    "tricks": [
      {
        "name": "引入问题背景",
        "type": "writing-level",
        "purpose": "为研究设定背景，突出现有方法的局限性",
        "location": "论文开头",
        "description": "通过介绍词嵌入在NLP中的广泛应用，以及多源语料导致个体表示不理想的问题，明确研究动机。"
      },
      {
        "name": "举例说明个性化需求",
        "type": "writing-level",
        "purpose": "具体化抽象问题，使读者易于理解个性化词嵌入的必要性",
        "location": "第一段",
        "description": "用‘hometown’一词在不同个人的语义联想上的差异，具体展示个性化词嵌入的意义。"
      },
      {
        "name": "提出创新方法",
        "type": "writing-level",
        "purpose": "突出论文贡献",
        "location": "第一段结尾",
        "description": "明确提出‘个性化词嵌入’的概念，并说明与通用嵌入的不同。"
      },
      {
        "name": "应用场景设定",
        "type": "writing-level",
        "purpose": "展示方法的实际价值和潜在应用",
        "location": "第一段末尾",
        "description": "提出个性化文本生成、对话系统等实际应用场景，增强方法的吸引力。"
      },
      {
        "name": "合理选择实验基线",
        "type": "experiment-level",
        "purpose": "保证实验可复现性和公平性",
        "location": "第二段",
        "description": "选择Merity等人的语言模型作为基线，理由包括代码可用性和运行效率，体现实验选择的合理性。"
      },
      {
        "name": "模型架构微调",
        "type": "method-level",
        "purpose": "提升模型性能",
        "location": "第二段",
        "description": "在原有模型基础上解耦编码器和解码器权重，通过初步实验发现性能提升。"
      },
      {
        "name": "嵌入层拼接策略",
        "type": "method-level",
        "purpose": "融合个性化与通用信息",
        "location": "第二段",
        "description": "将个性化用户嵌入和通用嵌入拼接作为词输入，兼顾个性化表达和通用语义。"
      },
      {
        "name": "一致的数据分割",
        "type": "experiment-level",
        "purpose": "保证实验对比的公平性",
        "location": "第二段",
        "description": "对个性化和通用模型使用相同的训练、验证和测试数据划分，仅嵌入层不同，确保结果可比。"
      },
      {
        "name": "数据子采样",
        "type": "experiment-level",
        "purpose": "控制计算资源消耗，保证实验可行性",
        "location": "第二段",
        "description": "从大规模数据集中为每个用户采样1000条帖子，降低计算负担。"
      },
      {
        "name": "多指标评估",
        "type": "method-level",
        "purpose": "全面评估模型性能",
        "location": "第二段结尾",
        "description": "采用平均倒数排名等多个指标衡量模型预测下一个词的能力，保证评估结果的全面性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_13",
    "title": "TWEETSUM: Event oriented Social Summarization Dataset",
    "conference": "COLING",
    "domain": {
      "research_object": "面向事件的社交媒体推文摘要数据集，关注事件相关信息的提取与总结。",
      "core_technique": "利用自然语言处理和文本摘要技术，对社交媒体内容进行事件导向的自动摘要。",
      "application": "用于社交媒体事件追踪、信息聚合、舆情分析等自动化信息处理场景。",
      "domains": [
        "自然语言处理",
        "社交媒体分析"
      ]
    },
    "ideal": {
      "core_idea": "构建面向事件的社交媒体推文摘要数据集TWEETSUM",
      "tech_stack": [
        "数据集构建",
        "社交媒体分析",
        "事件驱动摘要"
      ],
      "input_type": "社交媒体推文及事件相关信息",
      "output_type": "事件导向的推文摘要数据集"
    },
    "skeleton": {
      "problem_framing": "论文通过引用权威数据（Pew Research Center调查）突出社交媒体在突发事件中作为新闻信息源的重要性，强调Twitter的主导地位，并指出用户面临的信息过载问题，从而自然引出社交媒体内容摘要的紧迫需求。",
      "gap_pattern": "作者批评现有方法难以应对推文高频高量的特点，暗示传统新闻摘要方法不适用于社交媒体，明确提出在突发事件下高效获取代表性信息的技术缺口，强调社交关系等新特征的重要性。",
      "method_story": "方法部分采用标准评价指标ROUGE，简要介绍其原理及变体，并说明本研究选用的具体ROUGE指标，突出方法的客观性和与前人工作的衔接，为后续实验结果的比较奠定基础。",
      "experiments_story": "实验部分通过表格展示多种模型在数据集上的表现，重点突出SNSR模型的显著优势，并分析原因，进一步对比其他模型的不足，结合模型设计与数据特点，层层递进地阐释实验结果的合理性和创新点。"
    },
    "tricks": [
      {
        "name": "引用权威数据增强论据",
        "type": "writing-level",
        "purpose": "增强论文论据的说服力和权威性",
        "location": "第一段引用Pew Research Center数据",
        "description": "通过引用Pew Research Center等权威机构的最新调查数据，突出社交媒体作为新闻源的重要性，为研究背景提供有力支撑。"
      },
      {
        "name": "对比现有数据集揭示研究空白",
        "type": "writing-level",
        "purpose": "突出自己工作的创新点和必要性",
        "location": "第一段末到第二段，比较已有数据集与社交媒体文本的不同",
        "description": "对比主流的文档摘要数据集（如NYT、Gigaword、NEWSROOM、CNN/DAILYMAIL）与社交媒体文本的差异，指出主流数据集不适用于推特等社交媒体，突出当前研究的独特价值。"
      },
      {
        "name": "详细列举研究对象特性",
        "type": "writing-level",
        "purpose": "帮助读者理解研究对象的特殊性",
        "location": "第二段，列举社交媒体文本的三个特性",
        "description": "系统梳理社交媒体文本（如推特）的短小、非正式、含社交信号等特性，强调其与传统文档的不同，为后续方法设计和实验分析做铺垫。"
      },
      {
        "name": "采用主流评价指标以便对比",
        "type": "method-level",
        "purpose": "确保实验结果具有可比性和权威性",
        "location": "第三段，介绍ROUGE指标",
        "description": "选用ROUGE-1、ROUGE-2、ROUGE-L、ROUGE-SU*等被广泛认可的自动摘要评价指标，对比不同模型性能，便于与相关工作进行横向对比。"
      },
      {
        "name": "设置随机基线作为对照",
        "type": "experiment-level",
        "purpose": "检验模型有效性，突出模型优势",
        "location": "表2及相关描述，对比各模型与Random基线",
        "description": "在实验中设置随机选择摘要(Random)作为基线，并与各方法进行性能对比，突出改进模型（如SNSR）相较于随机选取的显著提升。"
      },
      {
        "name": "消融实验验证组件有效性",
        "type": "experiment-level",
        "purpose": "分析模型各部分的贡献",
        "location": "最后一段，移除社交关系组件的实验",
        "description": "通过移除SNSR模型中的社交关系组件（-social），进行消融实验，定量验证社交关系对模型性能的影响，增强实验结论的说服力。"
      },
      {
        "name": "错误分析探讨模型不足",
        "type": "writing-level",
        "purpose": "客观评价方法，指明未来改进方向",
        "location": "对BERT模型表现的分析",
        "description": "分析BERT模型表现不佳的原因，从推文短小噪声大、只考虑文本内容、摘要选择策略简单三个方面进行探讨，体现对实验现象的深入理解。"
      },
      {
        "name": "多模型对比分析",
        "type": "experiment-level",
        "purpose": "全面评估方法优劣",
        "location": "表2及相关描述，对比多种模型",
        "description": "采用多种现有模型（如BERT、SNSR等）在同一数据集上进行对比，全面展示各方法在推特摘要任务上的表现，突出新方法的优势。"
      },
      {
        "name": "分项列举改进点",
        "type": "writing-level",
        "purpose": "结构化表达模型不足或未来方向",
        "location": "BERT模型不足的三点分析",
        "description": "以条列式分点方式，清晰列出模型存在的问题或改进空间，使读者易于理解并为后续研究指明方向。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_14",
    "title": "Would you describe a leopard as yellow? Evaluating crowd-annotations with justified and informative disagreement",
    "conference": "COLING",
    "domain": {
      "research_object": "分析众包标注者在图像描述任务中的分歧及其合理性和信息性。",
      "core_technique": "采用定性与定量方法评估标注分歧，提出新的分歧分析框架。",
      "application": "提升数据标注质量，优化机器学习训练数据的收集与评估流程。",
      "domains": [
        "人工智能",
        "计算机视觉"
      ]
    },
    "ideal": {
      "core_idea": "提出用带理由的众包标注来衡量语义歧义和分歧信息。",
      "tech_stack": [
        "众包标注",
        "语义分析",
        "分歧建模"
      ],
      "input_type": "文本语义标注任务及标注者意见",
      "output_type": "包含分歧理由的多样化标注数据"
    },
    "skeleton": {
      "problem_framing": "论文通过提出‘豹是否是黄色’这一日常但模糊的问题，引出词汇语义中的模糊性现象，并用‘红酒’的例子对比清晰与模糊表达，强调语义判断的主观性和多样性。这种策略使读者迅速理解语义标注任务中面临的核心难题。",
      "gap_pattern": "作者指出现有语义标注任务常常包含模糊、歧义和主观性强的例子，强调仅采用单一判断会忽视表达本身的模糊性，暗示当前方法在捕捉多样语义解释方面存在不足。这种批评为后续方法创新和改进提供了理论空间。",
      "method_story": "方法部分强调诊断性实验的必要性，并引用Sommerauer等人提出的细粒度语义标注数据集，说明实验设计需能揭示词向量是否编码了具体语义属性。通过具体例子（如‘会飞’属性）展示方法的适用性和科学性。",
      "experiments_story": "实验部分通过正负例（如‘海鸥’vs‘企鹅’）来测试词向量对语义属性的区分能力，不仅验证模型是否编码了特定属性，还进一步探索哪些因素影响属性在分布式表示中的体现，体现实验设计的系统性和探索性。"
    },
    "tricks": [
      {
        "name": "引入模糊性现象",
        "type": "writing-level",
        "purpose": "引发读者思考并引入研究主题",
        "location": "开头段落",
        "description": "通过提出‘豹子是不是黄色’这样有争议的问题，展示语义表达的模糊性，引导读者关注词汇语义学中的模糊现象。这种写作方式能够有效吸引读者并自然过渡到研究主题。"
      },
      {
        "name": "对比典型与非典型例子",
        "type": "writing-level",
        "purpose": "突出语义判断的复杂性",
        "location": "开头段落",
        "description": "通过对比‘wine is red’（公认）和‘leopards are yellow’（有争议），展示语义判断的复杂性和多样性，为后续讨论数据标注中的歧义和模糊性做铺垫。"
      },
      {
        "name": "强调众包标注的多样性价值",
        "type": "writing-level",
        "purpose": "为多标注视角合理性提供理论基础",
        "location": "第二段",
        "description": "指出众包标注能捕捉不同解释和概念化视角，强调多样性数据对语义研究的意义，为后续方法论提供理论支持。"
      },
      {
        "name": "批判现有方法依赖一致性",
        "type": "writing-level",
        "purpose": "突出问题和研究创新点",
        "location": "第二段",
        "description": "批判现有标注评估和标签提取方法过度依赖标注者一致性，忽视了标注单元的难度和歧义，从而为新方法的提出创造空间。"
      },
      {
        "name": "引入诊断实验方法",
        "type": "method-level",
        "purpose": "分析模型内部表示",
        "location": "第三段",
        "description": "介绍‘诊断实验’（diagnostic experiments）作为分析深度学习模型语义能力的方法，强调实验结论依赖于高质量、有信息量的数据集。"
      },
      {
        "name": "细粒度语义标注",
        "type": "method-level",
        "purpose": "提升分析分辨率和数据集价值",
        "location": "第四段",
        "description": "通过对属性-概念对进行细粒度语义判断标注，提升数据集的分析分辨率，使得实验能更精确地探查模型对语义属性的编码能力。"
      },
      {
        "name": "正负例对比设计",
        "type": "experiment-level",
        "purpose": "验证模型对语义属性的区分能力",
        "location": "第四段",
        "description": "通过选取正例（如seagull, airplane, bee）和负例（如penguin, train, ant），设计对比实验，检验模型是否能仅凭embedding区分属性。"
      },
      {
        "name": "多语义关系注释",
        "type": "method-level",
        "purpose": "揭示属性反映机制的多样性",
        "location": "第五段",
        "description": "为每对属性-概念注释多种语义关系（如典型性、变异性等），便于探查哪些语义因素影响属性在分布式表示中的反映。"
      },
      {
        "name": "分组语义关系以支持实验设计",
        "type": "method-level",
        "purpose": "支持多类型实验与分析",
        "location": "第五段",
        "description": "将语义关系按属性适用的概念实例子集（大多数、部分、极少）分组，便于设计多种类型的诊断实验和结果分析。"
      },
      {
        "name": "突出数据集的歧义性与难度",
        "type": "writing-level",
        "purpose": "强调研究挑战与数据集价值",
        "location": "结尾段落",
        "description": "强调该标注任务包含大量歧义和难度高的例子，突显数据集在分析模型语义能力时的独特价值和挑战性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_15",
    "title": "Semantic Role Labeling with Heterogeneous Syntactic Knowledge",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象为语义角色标注任务，旨在理解句子中各成分的语义角色。",
      "core_technique": "核心技术是融合异构句法知识以提升语义角色标注的准确性。",
      "application": "应用场景包括自然语言理解、信息抽取和自动问答等领域。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "融合多种异构句法知识提升语义角色标注性能",
      "tech_stack": [
        "深度学习",
        "句法分析",
        "特征融合"
      ],
      "input_type": "文本句子或语段",
      "output_type": "谓词-论元结构及语义角色标签"
    },
    "skeleton": {
      "problem_framing": "论文通过定义语义角色标注（SRL）任务及其在自然语言处理中的基础地位，结合具体例子（如图1），直观引入研究问题，并通过“谁做了什么”等通俗表达降低理解门槛，帮助读者迅速把握研究主题。",
      "gap_pattern": "作者梳理现有SRL研究，按照是否利用句法知识将方法分为syntax-aware和syntax-agnostic两类，指出大多数无句法模型依赖深层神经网络编码上下文，但未直接提出不足，而是通过分类和引用文献隐含现有方法的局限，为后文改进做铺垫。",
      "method_story": "方法部分采用“承接-复用-细化”策略，先表明沿用He et al. (2018a)的任务设定和模型框架，随后形式化定义输入输出，分模块简要介绍整体结构，突出方法的系统性和与前人工作的联系，为创新点留出空间。",
      "experiments_story": "实验部分采用“标准数据集+多语言+细致评测”策略，选用中英文权威数据集，详细说明依存树库和解析器配置，报告自动依存树的性能指标，强调实验的规范性和可复现性，为后续结果分析和对比提供坚实基础。"
    },
    "tricks": [
      {
        "name": "任务定义与示例引入",
        "type": "writing-level",
        "purpose": "帮助读者快速理解研究任务",
        "location": "论文开头",
        "description": "在论文开头清晰地定义语义角色标注（SRL）任务，并通过‘Who did what to whom, when and where’等具体问题以及图示（如Figure 1）举例，直观展示任务内容。"
      },
      {
        "name": "方法分类与相关工作梳理",
        "type": "writing-level",
        "purpose": "厘清研究现状，突出自身创新点",
        "location": "相关工作部分",
        "description": "将现有SRL方法分为syntax-aware和syntax-agnostic两大类，分别列举代表性工作，便于突出本文所采用的方法及其创新之处。"
      },
      {
        "name": "基线模型复现与模块分解",
        "type": "method-level",
        "purpose": "为新方法提供对比基础，确保实验公正",
        "location": "方法介绍部分",
        "description": "详细介绍所采用的基线模型（如He et al., 2018a），并将其分解为输入层、编码器层、表示层和打分器层等模块，便于后续改进与分析。"
      },
      {
        "name": "输入特征多样化（词+字）",
        "type": "method-level",
        "purpose": "提升模型对词形和语义细粒度的捕捉能力",
        "location": "输入层描述部分",
        "description": "将每个词的输入表示为词向量和字符级表示的拼接，字符表示通过CNN获取，增强模型对未登录词和形态变化的鲁棒性。"
      },
      {
        "name": "深层BiLSTM编码器与高层连接",
        "type": "method-level",
        "purpose": "增强模型的上下文建模能力，防止梯度消失",
        "location": "编码器层介绍部分",
        "description": "采用三层BiLSTM作为主编码器，并引入highway connections以促进信息流动，提升深层网络的训练效果。"
      },
      {
        "name": "统一三元组建模",
        "type": "method-level",
        "purpose": "简化任务流程，便于整体优化",
        "location": "任务建模部分",
        "description": "将SRL任务统一为谓词-论元-语义角色三元组的识别问题，直接预测三元组集合，而非逐步标注，提高建模效率和灵活性。"
      },
      {
        "name": "借鉴并对比不同语法信息注入方式",
        "type": "method-level",
        "purpose": "探究语法信息对SRL的影响，优化集成方式",
        "location": "相关工作与方法部分",
        "description": "对比不同语法知识注入方式（如依存树嵌入、k阶修剪等），为后续改进模型集成语法提供理论与方法参考。"
      },
      {
        "name": "形式化符号定义",
        "type": "writing-level",
        "purpose": "提升方法描述的严谨性和可复现性",
        "location": "任务建模与方法部分",
        "description": "使用数学符号系统地定义输入、输出和中间变量（如S, P, A, R, Y等），使方法流程清晰、易于复现。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_16",
    "title": "Multi-label classification with pre-trained language models",
    "conference": "COLING",
    "domain": {
      "research_object": "多标签分类任务中文本数据的自动标注方法",
      "core_technique": "利用预训练语言模型提升多标签分类的准确性和效率",
      "application": "文本内容的自动标签分配，如新闻、评论等多标签场景",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "利用预训练语言模型提升多标签文本分类性能",
      "tech_stack": [
        "预训练语言模型",
        "多标签分类",
        "迁移学习"
      ],
      "input_type": "文本数据，含多个可能标签",
      "output_type": "每条文本对应的多个预测标签"
    },
    "skeleton": {
      "problem_framing": "论文通过强调机器学习领域中使用基准数据集评估新方法的“准标准”做法，引入了自然语言处理中的迁移学习和基准集合的重要性，突出其在研究者中的广泛应用和规范性，为后续研究设定了背景和必要性。",
      "gap_pattern": "作者指出现有基准数据集虽然在文档化和评估标准上表现突出，但隐含地暗示了在特定任务（如开放式问答自动编码）上仍存在自动化和评估方法上的不足，借此为后续方法创新和实验设计铺垫理论空白。",
      "method_story": "方法部分以数据集来源和前人工作的启发为线索，强调数据集的权威性和相关性，并通过描述数据预处理和统计分析的流程，逐步引入具体的基线方法，为后续实验对比和创新提供清晰的技术路径。",
      "experiments_story": "实验部分首先指出传统分类评估指标在多标签学习中的局限性，随后引用权威综述提出更适用的多标签评估标准，明确实验评价维度，并通过延续前述符号体系，保证实验设计的逻辑连贯和科学性。"
    },
    "tricks": [
      {
        "name": "使用基准数据集进行性能评估",
        "type": "method-level",
        "purpose": "保证模型评估具有可比性和权威性",
        "location": "开头部分",
        "description": "采用公开的基准数据集对新提出的方法进行性能评估，这样可以方便与已有方法进行横向对比，确保评测结果的公正性和权威性。"
      },
      {
        "name": "固定训练-测试划分和评估指标",
        "type": "method-level",
        "purpose": "确保实验结果的可复现性和公平性",
        "location": "开头部分",
        "description": "所用的基准数据集都明确规定了训练集和测试集的划分方式，以及统一的评估指标，避免了因数据划分不同带来的评测偏差。"
      },
      {
        "name": "公开排行榜统一展示结果",
        "type": "writing-level",
        "purpose": "提高方法影响力和透明度",
        "location": "开头部分",
        "description": "通过在公开排行榜上展示模型的评测结果，便于同行及时了解最新进展，也促进了模型性能的透明对比。"
      },
      {
        "name": "引入未被充分利用的数据集进行新领域评估",
        "type": "method-level",
        "purpose": "拓展模型评估的适用范围，填补研究空白",
        "location": "中部",
        "description": "注意到极端多标签数据集在社会科学调查研究中的应用较少，主动引入此类数据集进行模型评估，拓展了研究视角。"
      },
      {
        "name": "致敬和借鉴已有工作的思路",
        "type": "writing-level",
        "purpose": "体现研究的延续性和创新点",
        "location": "中部",
        "description": "明确说明本研究的数据集选择和问题定义受到前人工作的启发，体现学术传承并突出自身创新点。"
      },
      {
        "name": "详细描述数据集准备和预处理流程",
        "type": "writing-level",
        "purpose": "保证实验可复现性",
        "location": "中部",
        "description": "在实验部分详细说明数据集的获取、预处理、统计信息等，便于他人复现实验过程。"
      },
      {
        "name": "设定简单基线模型作为对比",
        "type": "experiment-level",
        "purpose": "评估新方法的有效性",
        "location": "后部",
        "description": "使用标准的逻辑回归分类器（无正则化）作为简单基线，便于衡量新方法的改进幅度。"
      },
      {
        "name": "采用one-vs-rest多标签分类策略",
        "type": "method-level",
        "purpose": "应对多标签分类任务",
        "location": "后部",
        "description": "针对每个标签分别训练一个二分类器，实现多标签分类需求，适用于标签数量较多的场景。"
      },
      {
        "name": "使用预训练词向量进行特征表示",
        "type": "method-level",
        "purpose": "提升文本表示能力",
        "location": "后部",
        "description": "将原始文本通过fasttext生成的词向量进行平均，作为模型输入特征，提升文本语义表达能力。"
      },
      {
        "name": "结合多种工具包实现数据预处理和建模",
        "type": "experiment-level",
        "purpose": "提高实验效率和易用性",
        "location": "后部",
        "description": "结合nltk进行文本预处理，gensim处理fasttext向量，scikit-learn实现逻辑回归，提升了实验流程的模块化和复用性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_17",
    "title": "Humans Meet Models on Object Naming: A New Dataset and Analysis",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象为人类与人工智能模型在物体命名任务中的表现与差异。",
      "core_technique": "核心技术包括构建新的物体命名数据集及对比分析方法。",
      "application": "应用场景涉及计算机视觉、认知科学和人机交互中的物体识别与命名。",
      "domains": [
        "计算机视觉",
        "认知科学"
      ]
    },
    "ideal": {
      "core_idea": "构建并分析人类与模型物体命名行为的新数据集",
      "tech_stack": [
        "数据集收集",
        "语言分析",
        "模型对比"
      ],
      "input_type": "物体图片及命名数据",
      "output_type": "命名多样性分析与人机命名一致性评估"
    },
    "skeleton": {
      "problem_framing": "引言通过回顾已有文献，强调了客观命名研究中对自然、可靠数据的需求，并指出语言变异和命名一致性的重要性。通过对比人类与模型的命名行为，突出命名数据采集的挑战，设定了研究的核心问题和背景。",
      "gap_pattern": "作者批评现有L&V领域的数据采集方法虽然兼顾自然性和控制性，但未充分解决命名变异与一致性之间的平衡。此外，现有主流模型尚未针对命名表现进行系统性评估，存在研究空白。",
      "method_story": "方法部分以“引入新诊断性评估方法”为主线，强调该方法依托MN v2数据，能够细致区分模型输出的名称类型，并检测模型是否受人类类似的不确定性影响。通过选取具有代表性的模型（Bottom-Up）进行案例分析，增强方法的适用性和创新性。",
      "experiments_story": "实验部分通过图表和统计数据，清晰展示了人类命名数据的充分性和分布特征，区分主流名称与替代名称的评判结果。通过量化分析和可视化，突出实验设计的严谨性和结论的说服力，为后续模型评估奠定基础。"
    },
    "tricks": [
      {
        "name": "结合自然性与可控性的数据收集方法",
        "type": "method-level",
        "purpose": "获取既自然又可控的人类命名数据",
        "location": "第二段开头",
        "description": "通过让说话者自由地描述或指称图片中的目标对象，兼顾数据的自然性和实验的可控性，为后续分析提供高质量的命名数据。"
      },
      {
        "name": "利用图片和边界框作为语言使用情境的代理",
        "type": "method-level",
        "purpose": "大规模高效地收集命名数据",
        "location": "第二段中部",
        "description": "采用图片和简单的bounding box标注目标对象，既降低了数据收集的难度，又利用了现有的计算机视觉数据集资源，支持大规模实验。"
      },
      {
        "name": "关注命名变异性和一致性",
        "type": "writing-level",
        "purpose": "强调研究的科学性和数据的可靠性",
        "location": "第一段中部",
        "description": "明确指出需要兼顾语言变异性（同一对象可被多种名称指称）和人类对命名达成一致的需求，为后续分析提供理论基础。"
      },
      {
        "name": "诊断性评估方法的引入",
        "type": "method-level",
        "purpose": "细致分析模型命名表现及其与人类的异同",
        "location": "第三段开头",
        "description": "设计诊断性评估方法，可以检测模型输出是否为最常见的人类答案、次常见答案或错误答案，并分析模型是否受人类同样的不确定性影响。"
      },
      {
        "name": "与人类上界进行对比分析",
        "type": "experiment-level",
        "purpose": "评估模型性能的合理上限",
        "location": "第三段中部",
        "description": "利用人工注释数据估算人类命名表现的上界，将模型表现与之对比，体现模型评估的科学性和严谨性。"
      },
      {
        "name": "关注视觉与指称不确定性对模型和人类的共同影响",
        "type": "experiment-level",
        "purpose": "分析模型和人类在不确定性条件下的表现异同",
        "location": "第三段",
        "description": "不仅评估模型的准确率，还考察其在视觉难辨或指称不明确时的表现，突出方法的全面性。"
      },
      {
        "name": "提出具体研究问题并聚焦分析",
        "type": "writing-level",
        "purpose": "明确研究目标，提升论文逻辑性",
        "location": "第三段末尾",
        "description": "在分析前提出两个核心研究问题，有助于聚焦实验设计和结果讨论，增强论证的针对性。"
      },
      {
        "name": "利用已有数据集扩展与创新",
        "type": "method-level",
        "purpose": "在已有资源基础上创新数据集和方法",
        "location": "第二段后部",
        "description": "如ManyNames数据集是在Visual Genome的注释基础上扩展而来，体现对现有资源的高效利用和创新。"
      },
      {
        "name": "模型与人类表现的细粒度对比",
        "type": "experiment-level",
        "purpose": "细致揭示模型与人类命名行为的异同",
        "location": "第三段及末尾",
        "description": "不仅仅关注整体准确率，还分析模型是否能捕捉到不同领域、不同对象特征下的人类命名规律。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_18",
    "title": "Normalizing Compositional Structures Across Graphbanks",
    "conference": "COLING",
    "domain": {
      "research_object": "不同图结构库中的组合结构标准化方法，提升语义表示一致性。",
      "core_technique": "提出统一的标准化框架，比较和转换多种图结构语义表示。",
      "application": "用于自然语言处理中的语义分析、跨资源语义信息整合。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "统一不同语义图库的结构以便比较和集成",
      "tech_stack": [
        "语义图表示",
        "结构归一化",
        "跨库映射算法"
      ],
      "input_type": "多种语义图库中的句子语义图",
      "output_type": "结构归一化后的统一语义图表示"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍基于图的句子语义表示，强调其在自然语言语义建模中的表现力和灵活性。随后引用多个已有图库，指出不同图库在设计原则上的差异，借此引出对比和统一不同语义图表示的研究必要性。",
      "gap_pattern": "作者通过展示不同图库在基本策略上的显著差异，尤其是在边标签、方向和动词结构处理等方面，明确指出现有方法缺乏统一和兼容性，形成了研究语义依存图归一化和跨图库学习的现实需求。",
      "method_story": "方法部分强调利用多任务学习（MTL）来跨图库共享模型权重，提升低资源图库的预测能力。通过说明图库间的相似性，合理化MTL的选择，并结合具体的预处理步骤，展现方法的系统性与创新性。",
      "experiments_story": "实验设计聚焦于归一化依存树的质量评估，采用跨形式相似性和解析适用性作为指标，紧扣2015年共享任务数据集。通过具体的预处理和多任务学习设置，展示实验如何验证所提方法的有效性和泛化能力。"
    },
    "tricks": [
      {
        "name": "Graph-based Representation Comparison",
        "type": "writing-level",
        "purpose": "Highlight differences and motivate normalization",
        "location": "Introduction, Figure 1",
        "description": "Explicitly illustrate and discuss differences between various graphbanks using concrete examples (e.g., edge labels, directions, verb constructions, coordination) to motivate the need for normalization and unified analysis."
      },
      {
        "name": "Methodology Development for Cross-Graphbank Analysis",
        "type": "method-level",
        "purpose": "Systematically understand and normalize graphbank differences",
        "location": "Introduction, Section 2",
        "description": "Develop a methodology to analyze the nature of differences across graphbanks and normalize their annotations at the compositional structure level, enabling comparative and unified studies."
      },
      {
        "name": "Use of AM Dependency Trees for Compositional Structure",
        "type": "method-level",
        "purpose": "Provide a common representation for meaning comparisons",
        "location": "Section 2",
        "description": "Employ AM dependency trees to represent the compositional structure of graph-based meaning representations, building upon previous work to facilitate cross-formalism comparison and normalization."
      },
      {
        "name": "Evaluation via Cross-Formalism Similarity and Parsing Suitability",
        "type": "experiment-level",
        "purpose": "Assess the quality of normalization and representation",
        "location": "Section 2",
        "description": "Evaluate normalized AM dependency trees by measuring their similarity across different formalisms and their suitability for parsing tasks on shared corpora, providing empirical validation of the normalization approach."
      },
      {
        "name": "Preprocessing Coordination Structures",
        "type": "method-level",
        "purpose": "Improve normalization consistency",
        "location": "Section 2",
        "description": "Apply specialized preprocessing steps (e.g., L19’s coordination handling for PSD) to address structural variations and improve consistency in normalized representations."
      },
      {
        "name": "Motivation for Multi-Task Learning (MTL)",
        "type": "writing-level",
        "purpose": "Justify unified modeling across graphbanks",
        "location": "Introduction, Conclusion",
        "description": "Argue for the use of multi-task learning due to similarities among graphbanks, enabling shared model weights and transfer of training data benefits across different annotation schemes."
      },
      {
        "name": "Data Scarcity Mitigation via MTL",
        "type": "experiment-level",
        "purpose": "Enhance performance for low-resource graphbanks",
        "location": "Introduction",
        "description": "Leverage multi-task learning to allow models trained on larger datasets from some graphbanks to improve predictions on graphbanks with limited data, addressing resource imbalance."
      },
      {
        "name": "Identification of Linguistically Meaningful Differences",
        "type": "method-level",
        "purpose": "Guide future corpus design",
        "location": "Introduction, Discussion",
        "description": "Systematically identify which graphbank design differences are linguistically meaningful and important, providing insights for the development of future semantic corpora."
      },
      {
        "name": "Unified Structural Approaches for Facilitation of MTL",
        "type": "method-level",
        "purpose": "Enable more effective multi-task learning",
        "location": "Introduction, Discussion",
        "description": "Propose and identify more unified approaches to certain structures within graphbanks to facilitate multi-task learning and cross-formalism generalization."
      },
      {
        "name": "Building on Prior Work",
        "type": "writing-level",
        "purpose": "Establish context and credibility",
        "location": "Section 2",
        "description": "Explicitly reference and build upon previous studies (e.g., Lindemann et al., 2019) to situate the current methodology within existing research and demonstrate continuity and advancement."
      }
    ]
  },
  {
    "paper_id": "COLING_2020_19",
    "title": "Second-Order Unsupervised Neural Dependency Parsing",
    "conference": "COLING",
    "domain": {
      "research_object": "无监督神经网络方法进行二阶句法依存分析，提升句法结构解析效果。",
      "core_technique": "采用神经网络模型结合二阶特征，实现无监督依存句法分析。",
      "application": "可用于自然语言处理中的自动句法结构分析，如机器翻译和信息抽取。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "提出二阶无监督神经依存句法分析方法，提升解析准确率",
      "tech_stack": [
        "神经网络",
        "无监督学习",
        "二阶依存关系建模"
      ],
      "input_type": "未标注的自然语言句子",
      "output_type": "依存句法树结构"
    },
    "skeleton": {
      "problem_framing": "论文通过强调依存句法分析在自然语言处理中的基础性作用及其对下游任务的意义，引入研究主题。作者先介绍有监督方法的高准确率，随后指出其依赖昂贵的人工标注树库，进而自然转向无监督方法的必要性和挑战，清晰设定研究背景和动机。",
      "gap_pattern": "作者采用对比批评策略，指出当前无监督依存句法分析准确率远低于有监督方法，且现有方法存在性能瓶颈。通过引用前人工作和具体数据，突出无监督方法的不足，明确论文旨在填补这一性能差距。",
      "method_story": "方法部分采用递进式叙述，先介绍经典的DMV模型及其生成机制，详细说明模型的三类规则及参数设置。通过逐步解释模型如何生成句子及依存树，帮助读者理解后续改进的理论基础和创新点。",
      "experiments_story": "实验部分以对比表格为核心，系统展示新方法与现有方法在标准数据集上的性能差异。作者突出新模型的提升，并分析不同结构信息对性能的影响，结合定量结果和现象讨论，层层递进，最后提出未来研究方向，增强论文的开放性和深度。"
    },
    "tricks": [
      {
        "name": "引入任务背景",
        "type": "writing-level",
        "purpose": "帮助读者快速了解研究领域和任务的重要性",
        "location": "开头第一段",
        "description": "论文开头简要介绍了依存句法分析在自然语言处理中的地位及其对下游任务的作用，为读者提供研究背景。"
      },
      {
        "name": "对比监督与无监督方法",
        "type": "writing-level",
        "purpose": "突出研究问题的意义和挑战",
        "location": "第一段中部",
        "description": "通过对比监督方法和无监督方法的准确率及数据需求，强调无监督方法的研究价值和面临的困难。"
      },
      {
        "name": "聚焦研究对象",
        "type": "writing-level",
        "purpose": "明确论文关注点，聚焦讨论范围",
        "location": "第一段末尾",
        "description": "明确指出论文关注无监督依存句法分析，限定讨论范围，避免主题发散。"
      },
      {
        "name": "文献回顾与模型介绍",
        "type": "writing-level",
        "purpose": "展示已有方法基础，铺垫创新点",
        "location": "第二段开头",
        "description": "简要回顾了主流无监督依存句法分析方法（如DMV），为后续方法改进做铺垫。"
      },
      {
        "name": "模型局限性分析",
        "type": "writing-level",
        "purpose": "为提出改进方法做理论依据",
        "location": "第二段中部",
        "description": "指出DMV模型及其扩展缺乏表达能力，分析其只依赖有限上下文，忽略更丰富的上下文信息。"
      },
      {
        "name": "引出判别方法",
        "type": "writing-level",
        "purpose": "引导至更具表现力的改进方向",
        "location": "第二段末尾",
        "description": "通过分析生成模型的不足，自然引出判别方法能利用更多上下文信息的优势。"
      },
      {
        "name": "详细分步描述模型生成过程",
        "type": "method-level",
        "purpose": "帮助读者理解模型机制",
        "location": "第三段",
        "description": "详细介绍DMV模型的ROOT、CHILD、DECISION三类规则及其参数含义，并逐步描述生成句子和依存树的过程。"
      },
      {
        "name": "引入公式与符号说明",
        "type": "method-level",
        "purpose": "提升模型描述的严谨性和可复现性",
        "location": "第三段",
        "description": "用数学符号（如PROOT(c), PCHILD(c|p, dir, val)等）明确模型参数与生成过程，便于后续公式推导和实现。"
      },
      {
        "name": "模型联合概率分解",
        "type": "method-level",
        "purpose": "为后续优化目标函数或算法实现做准备",
        "location": "第三段末尾",
        "description": "说明如何通过各步生成概率的乘积计算句子与依存树的联合概率，为模型训练和推断提供理论基础。"
      },
      {
        "name": "指出模型扩展方向",
        "type": "writing-level",
        "purpose": "为创新方法做铺垫",
        "location": "最后一段开头",
        "description": "指出DMV模型未考虑token间相关性，并引出后续神经网络方法（如Neural DMV），为创新点埋下伏笔。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_1",
    "title": "CHIME: Cross-passage Hierarchical Memory Network for Generative Review Question Answering",
    "conference": "COLING",
    "domain": {
      "research_object": "针对生成型评论问答任务，提升跨段落信息整合与答案生成能力的模型。",
      "core_technique": "提出跨段落分层记忆网络（CHIME），用于高效捕捉和融合多段评论内容。",
      "application": "用于电商平台或社交媒体中自动生成评论问答，提升用户体验。",
      "domains": [
        "自然语言处理",
        "信息检索"
      ]
    },
    "ideal": {
      "core_idea": "跨段落分层记忆网络提升生成式评论问答效果",
      "tech_stack": [
        "分层记忆网络",
        "跨段落信息融合",
        "生成式问答模型"
      ],
      "input_type": "多段评论文本与问题",
      "output_type": "针对问题的生成式答案"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾大规模预训练语言模型（如BERT、XLNet、T5）在问答任务上的突破性进展，引出当前问答系统的主流能力和成就，强调其在标准数据集上已超越人类表现，为后续问题设定背景。",
      "gap_pattern": "作者指出现有问答系统主要处理事实型问题，并假设了简化的任务场景，如多项选择和文本片段检索，批评其忽视了现实中更具描述性和复杂性的用户提问，明确提出当前方法的局限性和研究空白。",
      "method_story": "方法部分采用结构化叙述，先介绍所用数据集、对比基线和评测指标，再逐步展开对新方法的设计理念和优势的说明，突出新方法在处理多段、矛盾信息时的创新点和资源效率。",
      "experiments_story": "实验部分按照标准流程展开，先介绍实验设置（数据集、基线、指标），再展示结果表格，最后结合定量和定性分析，突出新方法在多维度评测上的优越性，并补充内存消耗等实际应用价值，增强说服力。"
    },
    "tricks": [
      {
        "name": "背景与现有工作综述",
        "type": "writing-level",
        "purpose": "为研究设定背景，突出问题和创新点",
        "location": "论文开头",
        "description": "通过回顾大型预训练语言模型和现有QA系统的进展，指出当前系统主要处理factoid问题，忽略了现实场景中更复杂的描述性问题，从而自然引出本文的研究目标和意义。"
      },
      {
        "name": "问题定义与挑战阐述",
        "type": "writing-level",
        "purpose": "明确研究对象和难点，突出创新需求",
        "location": "引言部分",
        "description": "详细描述e-shopping社区中review QA的特殊性，强调与传统factoid QA的区别，列举跨文档证据整合、自由文本生成等挑战，为后续方法设计做铺垫。"
      },
      {
        "name": "系统对比与消融实验设计",
        "type": "experiment-level",
        "purpose": "验证方法有效性，分析组件作用",
        "location": "实验部分",
        "description": "设计基线模型及多种消融版本（如CHIME-c、CHIME-a），通过逐步移除或修改模型组件，分析各部分对最终性能的贡献，并突出新方法的优势。"
      },
      {
        "name": "多维度评价指标",
        "type": "method-level",
        "purpose": "全面评估生成答案的质量",
        "location": "实验部分",
        "description": "采用词汇、语义和复合评价指标（如BLEU、BERTScore、BLEURT），从不同角度对模型输出进行量化，确保评价结果的客观性和全面性。"
      },
      {
        "name": "结果可视化与样例展示",
        "type": "writing-level",
        "purpose": "增强说服力，便于读者理解模型表现",
        "location": "实验结果与分析部分",
        "description": "通过表格和具体生成样例展示不同方法的效果，结合定量和定性分析，使实验结果更具说服力和可解释性。"
      },
      {
        "name": "内存消耗对比分析",
        "type": "experiment-level",
        "purpose": "展示新方法在资源利用上的优势",
        "location": "实验结果部分",
        "description": "对比CHIME与XLNet在处理同等规模数据时的内存消耗，突出新方法在效率和可扩展性上的改进。"
      },
      {
        "name": "模型结构创新：上下文与答案记忆融合",
        "type": "method-level",
        "purpose": "提升跨文档证据整合与生成能力",
        "location": "方法部分",
        "description": "提出结合上下文记忆与答案记忆的模型结构，通过交互式证据收集和信息融合，提高生成答案的连贯性和准确性，尤其在处理多文档、意见不一致时效果更佳。"
      },
      {
        "name": "消融实验分析组件重要性",
        "type": "experiment-level",
        "purpose": "科学验证模型设计合理性",
        "location": "实验部分",
        "description": "通过对比完整模型与各消融版本的表现，验证如跨段证据收集、记忆融合等模块的关键作用，为模型设计提供理论支持。"
      },
      {
        "name": "公开代码与工具链接",
        "type": "writing-level",
        "purpose": "提升研究透明度与可复现性",
        "location": "脚注/实验设置部分",
        "description": "在文中提供相关代码库和评测工具的链接，方便其他研究者复现和扩展工作，增强论文影响力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_20",
    "title": "A Linguistic Perspective on Reference: Choosing a Feature Set for Generating Referring Expressions in Context",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象是在特定语境下生成指称表达式所需的特征集合选择问题。",
      "core_technique": "核心技术是基于语言学视角分析和选择用于生成指称表达的特征集合。",
      "application": "应用场景包括自然语言生成、对话系统和人机交互中的自动生成指称表达。",
      "domains": [
        "计算语言学",
        "自然语言处理"
      ]
    },
    "ideal": {
      "core_idea": "根据语境中指称对象的显著性选择合适的指称表达特征集。",
      "tech_stack": [
        "语料库分析",
        "特征选择",
        "自然语言处理"
      ],
      "input_type": "文本语境与指称对象信息",
      "output_type": "生成的最优指称表达特征集"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过回顾理论与实证研究，强调指称表达选择受多种因素影响，突出‘显著性’与指称形式的直接关系。通过引用前人研究，建立研究背景，并引出本文关注的核心变量和理论传统。",
      "gap_pattern": "作者通过总结现有文献，指出虽然‘显著性’的影响因素已被广泛讨论，但具体变量如何影响指称表达的选择仍需进一步实证检验，隐含当前研究在变量重要性量化与模型验证方面存在不足。",
      "method_story": "方法部分采用先介绍整体算法（Random Forests），再说明其特性（变量重要性评估），并结合具体实验（特征选择），层层递进，突出方法的科学性与创新性，为后续实验设计和分析奠定基础。",
      "experiments_story": "实验部分按逻辑顺序展开，先简述所用算法和特征选择方法，再详细介绍分类模型的训练过程，随后分步进行特征重要性评估和特征子集实验，强调实验的系统性和结果的可比性，逐步推进研究发现。"
    },
    "tricks": [
      {
        "name": "文献回顾构建理论基础",
        "type": "writing-level",
        "purpose": "为研究提供理论支持和背景",
        "location": "开头段落",
        "description": "通过回顾相关理论和实证研究，梳理前人关于指称表达选择的主要观点和影响因素，为后续实验设计和方法选择提供理论基础。"
      },
      {
        "name": "界定核心任务术语",
        "type": "writing-level",
        "purpose": "统一术语，明确研究范围",
        "location": "中段",
        "description": "将‘Referring Expression Generation’中的具体子任务命名为‘Selection of Referential Form (SRF)’，并在后文统一使用该术语，避免歧义。"
      },
      {
        "name": "多因素特征分析",
        "type": "method-level",
        "purpose": "全面考虑影响指称表达选择的变量",
        "location": "理论综述与方法部分",
        "description": "归纳并说明包括提及时距、频率、语法功能、生命性、距离和竞争等多个变量对指称表达选择的影响，为后续特征工程提供依据。"
      },
      {
        "name": "采用集成学习算法Random Forests",
        "type": "method-level",
        "purpose": "提升分类任务的准确性和稳健性",
        "location": "方法部分",
        "description": "选用Random Forests作为主要分类器，通过集成多个决策树进行分类，增强模型的泛化能力，并利用其内置的特征重要性评估方法。"
      },
      {
        "name": "内嵌特征选择方法（RFI）",
        "type": "experiment-level",
        "purpose": "自动评估和排序特征重要性",
        "location": "实验部分",
        "description": "利用Random Forests自带的特征重要性评估机制（Rank Features by Importance, RFI），在训练模型过程中自动计算并排序各特征的重要性。"
      },
      {
        "name": "递进式特征选择（FFS）",
        "type": "experiment-level",
        "purpose": "优化特征子集，提高模型性能",
        "location": "实验部分",
        "description": "采用Forward Feature Selection方法，从单一特征开始逐步添加特征，每次选择能提升模型性能的特征，直至性能不再提升，得到最优特征组合。"
      },
      {
        "name": "对比多种特征选择方法",
        "type": "experiment-level",
        "purpose": "验证特征选择的有效性和稳定性",
        "location": "实验设计部分",
        "description": "将内嵌特征选择（RFI）与递进式特征选择（FFS）相结合，通过对比分析两种方法所得特征重要性，增强结果的说服力。"
      },
      {
        "name": "工具选择与实现细节说明",
        "type": "method-level",
        "purpose": "提升实验可复现性",
        "location": "方法部分",
        "description": "明确指出采用ranger包在R语言中实现Random Forests算法，并说明变量重要性度量标准（Permutation Importance），便于他人复现实验。"
      },
      {
        "name": "变量重要性度量标准说明",
        "type": "experiment-level",
        "purpose": "确保特征评估方法的透明性",
        "location": "方法细节部分",
        "description": "说明变量重要性度量采用Permutation Importance（Mean Decrease in Accuracy），为特征选择结果提供理论和技术支撑。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_21",
    "title": null,
    "conference": "COLING",
    "domain": {
      "research_object": "播客音频及其自动语音识别转录文本，包含多样风格和体裁。",
      "core_technique": "自动语音识别（ASR）、自然语言处理（NLP）、信息检索（IR）等方法。",
      "application": "用于语音处理、文本分析、语言学研究及信息检索等任务。",
      "domains": [
        "自然语言处理",
        "语音处理"
      ]
    },
    "ideal": {
      "core_idea": "构建播客语音数据集，促进语音与语言技术研究",
      "tech_stack": [
        "自动语音识别",
        "语料库构建",
        "语音处理"
      ],
      "input_type": "播客音频数据",
      "output_type": "转录文本及相关语料库"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍播客的多样性和流行度，强调其在新闻、对话、虚构与非虚构等多种形式上的广泛应用，提出播客作为研究对象在语言技术、信息检索等领域具有丰富潜力，从而引出对播客研究的必要性。",
      "gap_pattern": "作者指出尽管播客日益流行，但相关学术研究却相对较少，现有转录语音数据集规模有限，缺乏对播客多样性和结构的系统性分析，明确提出当前研究领域存在的数据和方法上的空白。",
      "method_story": "方法部分采用标准化的信息检索主题设定，参考TREC的做法，明确区分不同类型的信息需求，并详细说明如何构建评价标准和检索流程，突出方法的规范性和可复现性。",
      "experiments_story": "实验设计以具体任务驱动，先定义检索主题，再通过BM25模型进行初步检索，并结合人工调整以提升覆盖率，最后通过人工判定相关性，展现实验流程的系统性和严谨性。"
    },
    "tricks": [
      {
        "name": "结构化贡献列表",
        "type": "writing-level",
        "purpose": "清晰展示论文贡献",
        "location": "Our contributions are four-fold: • The largest corpus... • A set of labeled data... • Benchmarking results... • An analysis of the data...",
        "description": "通过项目符号（bullet points）方式将主要贡献分条列出，便于读者快速把握论文核心成果。"
      },
      {
        "name": "对比数据集规模",
        "type": "writing-level",
        "purpose": "突出数据集的创新性和重要性",
        "location": "This is orders of magnitude larger than previous transcribed speech datasets...",
        "description": "通过与已有数据集的对比，强调所构建数据集在规模和多样性上的优势。"
      },
      {
        "name": "引用权威基准与先前工作",
        "type": "writing-level",
        "purpose": "增强方法的权威性和可复现性",
        "location": "following those used by the Text REtrieval Conference (TREC) (Voorhees et al., 2005)",
        "description": "在实验设计时，采用权威会议或文献中已有的标准流程或定义，提升研究的规范性和可对比性。"
      },
      {
        "name": "多类型任务定义",
        "type": "method-level",
        "purpose": "覆盖多样化的信息需求，提升任务适用性",
        "location": "Topics can be one of three types: topical, re-finding, and known item...",
        "description": "根据实际应用场景，将检索任务细分为不同类型，更全面地评估系统性能。"
      },
      {
        "name": "人工与众包结合标注",
        "type": "experiment-level",
        "purpose": "提高标注数据的质量与规模",
        "location": "We started with expert annotation... then added 1060 crowdsourced labels...",
        "description": "先由专家进行初步标注，确保质量，再通过众包扩展数据量，实现效率与质量的平衡。"
      },
      {
        "name": "多元辅助资源支持标注",
        "type": "method-level",
        "purpose": "提升标注准确性",
        "location": "They could use the metadata, the full transcript, the audio, and any other resources...",
        "description": "允许标注者参考多种信息源（元数据、文本、音频等），以便做出更准确的判断。"
      },
      {
        "name": "分级相关性评判标准",
        "type": "method-level",
        "purpose": "细致区分检索结果的相关程度",
        "location": "They used a standard graded scale of Excellent/Good/Fair/Bad, along with a Perfect grade...",
        "description": "采用分级标准对检索相关性进行细致标注，使评测结果更具区分度。"
      },
      {
        "name": "详细标注指南提供",
        "type": "writing-level",
        "purpose": "保证标注一致性和可复现性",
        "location": "Table A1 in Appendix C shows the guidelines we provided the human assessors.",
        "description": "在附录中公布标注指南，确保标注过程标准化，有助于后续复现和扩展。"
      },
      {
        "name": "标准基线模型对比",
        "type": "experiment-level",
        "purpose": "客观评估任务难度和数据集价值",
        "location": "Benchmarking results for retrieval and summarization tasks using standard baselines",
        "description": "采用标准基线模型进行任务基准测试，为后续研究提供参考点。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_22",
    "title": "A Two-Level Interpretation of Modality in Human-Robot Dialogue",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象为人机对话中模态表达的双层解释机制，旨在提升交流理解。",
      "core_technique": "采用语义分析与对话建模方法，对人类与机器人交流中的模态进行分层解释。",
      "application": "应用于智能机器人与人类的自然语言交互系统，提高对话的准确性与自然度。",
      "domains": [
        "人工智能",
        "人机交互"
      ]
    },
    "ideal": {
      "core_idea": "提出人机对话中模态表达的双层解释框架",
      "tech_stack": [
        "语义解析",
        "模态推理",
        "人机交互建模"
      ],
      "input_type": "自然语言对话文本",
      "output_type": "模态表达的语义解释与环境对齐"
    },
    "skeleton": {
      "problem_framing": "论文通过强调模态表达在实现人机对话中的核心作用切入，指出其对信息交换和协作的意义。通过具体场景（如机器人在远程任务中的对话）举例，增强问题的现实紧迫感和应用价值，吸引读者关注。",
      "gap_pattern": "作者隐含地指出现有系统在自动理解和使用模态表达方面存在不足，强调学习模态表达的必要性。通过对实际对话需求的描绘，突出了当前方法在处理复杂表达时的局限，形成研究动机。",
      "method_story": "方法部分采用标准的注释协议，详细描述了数据标注流程，包括多标注者一致性评估和金标准数据集的构建，突出方法的系统性和科学性，为后续实验和分析奠定基础。",
      "experiments_story": "实验部分以数据统计和一致性分析为主，先报告注释一致性指标（如Cohen's kappa），再介绍注释数据的分布和类型。通过表格和具体数值，清晰展示实验设计和数据特征，便于读者理解研究的有效性。"
    },
    "tricks": [
      {
        "name": "引入具体场景举例",
        "type": "writing-level",
        "purpose": "帮助读者理解研究背景和问题的重要性",
        "location": "论文开头，提出人机对话中的模态表达场景",
        "description": "通过描述机器人在远程任务中的对话示例（如“Tell me what you see”），具体展示模态表达在信息交流中的作用，使问题具象化，增强论文的现实意义。"
      },
      {
        "name": "提出研究悖论",
        "type": "writing-level",
        "purpose": "突出研究难点，激发读者兴趣",
        "location": "介绍模态表达学习的悖论段落",
        "description": "指出模态表达虽然用于交流和知识对齐，却难以在共享环境中进行显式的“grounding”，与可指示的物体或动作形成对比，强调研究挑战。"
      },
      {
        "name": "数据注释一致性分析",
        "type": "method-level",
        "purpose": "验证注释数据的可靠性和质量",
        "location": "注释一致性统计部分",
        "description": "通过统计注释者间的目标一致率（87.65%）、字符串重叠率（83.31%-91.59%）以及Cohen’s kappa等指标，量化数据标注的可靠性。"
      },
      {
        "name": "构建金标准数据集",
        "type": "method-level",
        "purpose": "为后续模型训练和评估提供高质量参考数据",
        "location": "IAA计算后，合并注释部分",
        "description": "对共享转录本进行仲裁，结合单人注释数据，形成高质量的金标准数据集，确保后续研究有坚实的数据基础。"
      },
      {
        "name": "多维度统计和分类",
        "type": "method-level",
        "purpose": "全面分析模态表达的分布特征",
        "location": "结果统计与表格部分",
        "description": "统计模态表达、否定、量词等在数据中的分布，并按说话者、取值、解释和时间索引等维度分类，展现数据的多样性和细致性。"
      },
      {
        "name": "使用附录补充细节",
        "type": "writing-level",
        "purpose": "主文简洁，细节充分，便于查阅",
        "location": "提及Appendix B",
        "description": "将模态表达的详细分类结果放入附录，正文仅给出主要统计，保证论文结构清晰且信息完整。"
      },
      {
        "name": "使用具体统计指标展示数据",
        "type": "writing-level",
        "purpose": "增强结果的说服力和可复现性",
        "location": "表格和统计描述部分",
        "description": "用具体数字（如注释数、注释平均数、分布比例等）和表格（如Table 5, Table 6）清晰展示数据结果，提升论文的科学性。"
      },
      {
        "name": "对比“grounded learning”与语言信号",
        "type": "writing-level",
        "purpose": "突出模态表达的特殊性",
        "location": "模态表达无法通过环境指示进行grounding的段落",
        "description": "将模态表达与可指示的物体、动作进行对比，强调其只能通过语言信号进行学习，突出研究的理论价值。"
      },
      {
        "name": "提出应用前景",
        "type": "writing-level",
        "purpose": "说明研究意义和价值",
        "location": "模态表达理解对非人类代理的意义说明",
        "description": "阐述理解模态表达将帮助机器人更好地推理物体用途和评估行为影响，强调研究对实际任务的促进作用。"
      },
      {
        "name": "层次化数据处理流程",
        "type": "method-level",
        "purpose": "确保数据处理的系统性和可追溯性",
        "location": "注释、仲裁、合并、统计的流程描述",
        "description": "先双人注释，再一致性评估、仲裁，最后合并为金标准，流程清晰，便于后续复现和优化。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_23",
    "title": "BioMedBERT: A Pre-trained Biomedical Language Model for QA and IR",
    "conference": "COLING",
    "domain": {
      "research_object": "针对生物医学领域文本，提升问答和信息检索任务的语言理解能力。",
      "core_technique": "采用预训练语言模型BERT，并针对生物医学语料进行微调优化。",
      "application": "用于生物医学文献的自动问答系统和信息检索工具。",
      "domains": [
        "人工智能",
        "生物医学信息学"
      ]
    },
    "ideal": {
      "core_idea": "预训练生物医学语言模型提升问答与信息检索效果",
      "tech_stack": [
        "BERT",
        "预训练模型",
        "自然语言处理"
      ],
      "input_type": "生物医学领域文本数据",
      "output_type": "高质量问答结果或相关文献检索结果"
    },
    "skeleton": {
      "problem_framing": "论文通过COVID-19疫情的紧迫性和生物医学文献激增作为切入点，强调研究者在信息筛选和新药发现上的需求，巧妙地将现实问题与技术需求结合，增强研究的现实意义和紧迫感。",
      "gap_pattern": "作者批评现有工具无法高效处理海量、快速增长的生物医学文献，尤其在疫情期间更显不足，突出缺乏能够自动提取关键信息的语言理解工具，从而明确提出研究空白。",
      "method_story": "方法部分采用递进式叙述，先介绍BERT架构及其优势，再说明如何结合预训练和微调提升模型性能，强调技术选型的合理性与创新性，增强方法的科学性和可复现性。",
      "experiments_story": "实验部分按时间和决策过程展开，先描述初步尝试及遇到的问题，再说明如何调整策略（如迁移学习），突出实验设计的探索性和实用性，并通过具体任务验证方法有效性，逻辑清晰，层层递进。"
    },
    "tricks": [
      {
        "name": "引入背景和研究动机",
        "type": "writing-level",
        "purpose": "突出研究的重要性和紧迫性",
        "location": "开头段落",
        "description": "通过引用COVID-19大流行和文献增长速度，强调现有工具不足，突显研究的现实意义和必要性。"
      },
      {
        "name": "使用权威数据和文献支持论点",
        "type": "writing-level",
        "purpose": "增强论文说服力和可信度",
        "location": "开头段落",
        "description": "引用PubMed数据和具体文献，展示生物医学文献的激增，并用数据说明问题的严重性。"
      },
      {
        "name": "对比传统方法与新方法",
        "type": "writing-level",
        "purpose": "突出所提方法的优势和创新点",
        "location": "中段",
        "description": "将传统的Lucene-based Elasticsearch与基于BERT的模型进行对比，指出传统方法在语境检索上的不足，引出新方法的必要性。"
      },
      {
        "name": "分层方法（Hierarchical Approach）",
        "type": "method-level",
        "purpose": "系统化地提取文本和上下文信息",
        "location": "方法部分",
        "description": "采用分层的信息检索策略，先提取文本信息再结合上下文信息，提高信息提取的准确性和全面性。"
      },
      {
        "name": "利用预训练和微调（Pre-training and Fine-tuning）",
        "type": "method-level",
        "purpose": "提升模型的准确性和鲁棒性",
        "location": "BERT模型描述部分",
        "description": "结合BERT模型的预训练和微调阶段，增强模型对生物医学文本的理解能力。"
      },
      {
        "name": "详细介绍模型架构及原理",
        "type": "writing-level",
        "purpose": "让读者理解模型的技术基础",
        "location": "BERT模型描述部分",
        "description": "详细说明BERT的transformer结构、多头注意力机制、堆叠编码器等关键技术细节，帮助读者理解模型优势。"
      },
      {
        "name": "分解损失函数并公式化展示",
        "type": "method-level",
        "purpose": "清晰传达模型训练目标和优化方式",
        "location": "损失函数描述部分",
        "description": "将总损失函数分解为MaskedLM损失和NSP损失，并以公式形式详细展示，有助于读者理解训练过程。"
      },
      {
        "name": "引用经典任务和先前研究",
        "type": "writing-level",
        "purpose": "展现研究的理论基础和创新点",
        "location": "BERT任务描述部分",
        "description": "介绍MLM和NSP任务，并引用相关经典文献，说明模型设计的理论依据和科学性。"
      },
      {
        "name": "专用领域预训练（BioMedBERT）",
        "type": "method-level",
        "purpose": "提升模型对领域文本的理解能力",
        "location": "模型架构部分",
        "description": "在BERT基础上对生物医学文本进行再训练，形成BioMedBERT，专注于提升对生物医学文献的检索和理解。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_24",
    "title": "Specializing Unsupervised Pretraining Models for Word-Level Semantic Similarity",
    "conference": "COLING",
    "domain": {
      "research_object": "针对词级语义相似性任务，研究无监督预训练模型的专门化方法。",
      "core_technique": "采用无监督预训练模型，通过专门化技术提升词语语义相似性计算能力。",
      "application": "可应用于自然语言处理中的词义消歧、信息检索及文本理解等场景。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "针对词级语义相似性任务对无监督预训练模型进行专门化优化",
      "tech_stack": [
        "无监督预训练模型",
        "BERT",
        "语言建模"
      ],
      "input_type": "大规模文本语料或词对",
      "output_type": "词对的语义相似度分数"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过列举主流无监督预训练模型（如GPT、ELMo、BERT）在自然语言处理任务中的卓越表现，强调它们依赖于语言建模目标，并以BERT为代表，具体说明其预训练目标，从而自然引出对模型能力的关注。",
      "gap_pattern": "作者批评现有模型主要依赖分布式知识，导致词义关系混淆和缺乏世界知识，引用相关研究指出BERT等模型难以从原始文本中恢复知识库三元组，并总结已有工作多聚焦于结构化知识注入，明确提出研究空白。",
      "method_story": "方法部分先分析无监督预训练模型的局限性，随后归纳已有缓解策略，并将关注点聚焦于更高层级语言单元的masking，逻辑上由问题到解决方案递进，突出自身方法与前人工作的联系与创新点。",
      "experiments_story": "实验部分通过对比基线BERT与改进模型LIBERT，明确控制变量以突出方法效果，首先在GLUE任务上验证语义知识注入的有效性，随后扩展至词汇简化任务，采用分阶段展示结果，强调方法的广泛适用性。"
    },
    "tricks": [
      {
        "name": "引用最新相关工作以建立研究背景",
        "type": "writing-level",
        "purpose": "展示领域进展和研究现状",
        "location": "开头段落",
        "description": "通过列举和引用GPT、ELMo、BERT等主流模型及其文献，快速梳理领域发展脉络，为后续问题引入和创新点提出打下基础。"
      },
      {
        "name": "分解复杂任务目标为多个子任务",
        "type": "method-level",
        "purpose": "清晰表达模型预训练目标及其结构",
        "location": "介绍BERT预训练目标时",
        "description": "将BERT的预训练目标细分为Masked Language Modeling (MLM)和Next Sentence Prediction (NSP)两部分，使方法描述条理清晰，便于理解。"
      },
      {
        "name": "对比分析现有方法的局限性",
        "type": "writing-level",
        "purpose": "突出研究问题的重要性和创新空间",
        "location": "论述BERT及相关模型局限性时",
        "description": "分析当前预训练模型（如BERT）在语义关系区分和世界知识获取上的不足，为后续方法改进提供理论依据。"
      },
      {
        "name": "引用并归纳现有改进技术的类别",
        "type": "writing-level",
        "purpose": "系统展示领域内已有改进方向",
        "location": "介绍注入外部知识的相关工作时",
        "description": "将已有方法按技术路线分为：掩码高阶语言单元、引入辅助任务、文本与图结构混合等类别，梳理研究现状。"
      },
      {
        "name": "方法创新点的类别化和实例化",
        "type": "method-level",
        "purpose": "便于读者把握技术创新的多样性",
        "location": "描述注入知识的三类方法时",
        "description": "分别举例说明三种主要的知识注入方法，每类方法都配合具体文献与技术细节，增强说服力和可操作性。"
      },
      {
        "name": "结合任务与模型结构描述技术细节",
        "type": "method-level",
        "purpose": "提高方法复现性和可理解性",
        "location": "介绍Liu et al. (2020)和Peters et al. (2019)方法时",
        "description": "详细描述如特殊注意力掩码、软位置编码、端到端实体链接等具体技术实现，突出方法细节。"
      },
      {
        "name": "强调分布式语义模型的固有限制",
        "type": "writing-level",
        "purpose": "为后续改进或新模型做理论铺垫",
        "location": "分析分布式模型缺陷时",
        "description": "指出无监督预训练模型仍会混淆语义相似性与主题相关性，且难以恢复知识库三元组，突出研究动机。"
      },
      {
        "name": "结合多任务学习提升模型能力",
        "type": "method-level",
        "purpose": "增强模型对世界知识和语言现象的捕捉能力",
        "location": "介绍辅助任务和连续学习框架时",
        "description": "如引入实体对齐的去噪自编码、大小写预测、句子重排等辅助任务，提升模型泛化和推理能力。"
      },
      {
        "name": "多文献并列式引用展示研究广度",
        "type": "writing-level",
        "purpose": "体现研究视野开阔，增强论据可信度",
        "location": "多处列举相关文献时",
        "description": "将多篇相关论文并列引用，展示领域内多条研究线索，增强论文的学术权威性和说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_25",
    "title": "Exploring Question-Specific Rewards for Generating Deep Questions",
    "conference": "COLING",
    "domain": {
      "research_object": "针对自动生成深层次问题的奖励机制进行探索和优化。",
      "core_technique": "采用问题特定的奖励函数来提升深度问题生成模型的性能。",
      "application": "用于教育、智能问答系统和辅助学习等场景中的深度问题自动生成。",
      "domains": [
        "自然语言处理",
        "教育技术"
      ]
    },
    "ideal": {
      "core_idea": "提出问题特定奖励机制提升自动深度问题生成质量",
      "tech_stack": [
        "深度学习",
        "强化学习",
        "自然语言处理"
      ],
      "input_type": "文本或文档内容",
      "output_type": "针对输入内容生成的高质量深度问题"
    },
    "skeleton": {
      "problem_framing": "论文通过定义Question Generation（QG）的目标和实际应用场景（如教育、对话系统、FAQ等）来引入研究问题，强调其现实意义和广泛用途。引用大量前人工作，展示QG领域的研究基础和发展脉络，帮助读者快速理解问题的重要性。",
      "gap_pattern": "作者通过回顾现有方法，指出当前主流方法多采用Seq2Seq模型，并简要提及其局限性，如生成高质量问题的挑战。通过对比前人工作，暗示现有方法在生成相关、流畅且可回答问题方面仍有提升空间，从而引出自身研究的必要性。",
      "method_story": "方法部分采用自上而下的叙述策略，先从任务定义和数学建模切入，明确目标函数。随后介绍整体框架及其组成部分，结合图示结构，逐步细化到具体机制（如attention、copying、coverage），并通过引用相关文献表明方法的合理性和创新点。",
      "experiments_story": "实验部分以数据集选择和任务难度为切入点，突出实验的挑战性和代表性。详细说明数据预处理和分割方式，确保实验可复现。接着介绍模型配置和实现细节，引用相关工作，保证实验的严谨性和与前人工作的可比性。"
    },
    "tricks": [
      {
        "name": "文献综述和应用场景引入",
        "type": "writing-level",
        "purpose": "展示研究背景和实际意义，增强论文说服力",
        "location": "开头段落",
        "description": "通过引用多篇相关文献，介绍Question Generation（QG）的实际应用场景，如教育、对话系统、FAQ和数据集构建，明确研究的重要性和实用性。"
      },
      {
        "name": "现有方法梳理与问题指出",
        "type": "writing-level",
        "purpose": "明确现有主流方法和存在的核心问题，引出创新点",
        "location": "背景介绍与方法动机部分",
        "description": "对比现有Seq2Seq+Attention方法，并指出其训练目标仅基于似然函数，存在exposure bias，无法覆盖所有等价问题表达。"
      },
      {
        "name": "问题公式化",
        "type": "method-level",
        "purpose": "将任务数学化，便于后续模型设计和优化目标明确",
        "location": "方法介绍部分",
        "description": "将QG任务形式化为条件概率最大化问题，给出公式Ŷ = argmax_Y P(Y|D)，并详细说明序列生成的概率分解方式。"
      },
      {
        "name": "模块化模型结构设计",
        "type": "method-level",
        "purpose": "结构清晰，便于突出创新点和模型扩展",
        "location": "模型框架介绍部分",
        "description": "将模型分为Question Generator和QG-specific Rewards两大模块，分别负责问题生成和奖励优化，结构层次分明。"
      },
      {
        "name": "多机制集成提升生成质量",
        "type": "method-level",
        "purpose": "提升生成文本的多样性和准确性",
        "location": "Question Generator细节描述部分",
        "description": "在Seq2Seq基础上，集成Attention、Copying和Coverage机制，结合前沿NQG工作，增强模型对输入的理解和信息覆盖能力。"
      },
      {
        "name": "奖励函数设计",
        "type": "method-level",
        "purpose": "针对目标任务设计专属优化目标，弥补传统损失函数的不足",
        "location": "QG-specific Rewards部分",
        "description": "设计三个QG特定奖励函数，分别评价生成问题的流畅性、相关性和可回答性，更贴合任务需求，引导模型生成高质量问题。"
      },
      {
        "name": "强化学习优化与自批判训练",
        "type": "method-level",
        "purpose": "解决暴露偏差问题，提升生成序列的多样性和实用性",
        "location": "模型训练策略部分",
        "description": "采用自批判序列训练（SCST）算法，在预训练基础上用强化学习优化奖励函数，提升模型泛化能力和生成质量。"
      },
      {
        "name": "预训练-微调范式",
        "type": "experiment-level",
        "purpose": "提升模型性能，利用已有知识加速收敛",
        "location": "训练流程描述部分",
        "description": "先用最大似然训练进行预训练，再用强化学习和奖励函数微调，借鉴语言生成领域主流实践，确保模型训练稳定和效果优异。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_26",
    "title": "Studying Taxonomy Enrichment on Diachronic WordNet Versions",
    "conference": "COLING",
    "domain": {
      "research_object": "对不同版本的WordNet进行分类体系扩展与丰富，提升其结构和内容。",
      "core_technique": "提出多种适用于多语言环境的分类体系扩展方法，解决资源匮乏问题。",
      "application": "用于自然语言处理任务中的词汇资源维护、更新和增强。",
      "domains": [
        "自然语言处理",
        "知识工程"
      ]
    },
    "ideal": {
      "core_idea": "研究如何自动丰富和维护不同版本的WordNet词汇分类体系。",
      "tech_stack": [
        "本体构建",
        "分类体系比较",
        "自动化丰富算法"
      ],
      "input_type": "不同时间版本的WordNet词汇数据库",
      "output_type": "增强和更新后的WordNet分类体系"
    },
    "skeleton": {
      "problem_framing": "论文通过强调词汇资源（如WordNet和Wiktionary）在NLP任务中的核心作用，引入了构建和维护这些资源的重要性。作者结合实际应用场景，突出了词汇资源在多项NLP任务中的广泛应用，增强了问题的现实紧迫感和学术价值。",
      "gap_pattern": "作者指出现有资源的手工注释过程成本高昂，需专家参与，而自动化方法的质量又难以匹配手工标注，明确揭示了当前领域在效率与质量之间的矛盾。这种gap批评策略清晰地界定了研究的必要性和创新空间。",
      "method_story": "方法部分以已有基线模型为出发点，说明在此基础上进行了扩展，包括对同义词集候选项的排序和多源信息的融合。作者简明扼要地描述了方法创新点，突出了与前人工作的关联和改进。",
      "experiments_story": "实验部分将任务形式化为soft ranking问题，采用业界认可的MAP指标进行评估，并详细解释了指标的计算方式及其适用性。作者还批判性地指出数据集设计与评价指标之间的矛盾，展现了对实验设计的反思和严谨态度。"
    },
    "tricks": [
      {
        "name": "明确研究动机和背景",
        "type": "writing-level",
        "purpose": "阐明研究的必要性和现实意义",
        "location": "论文开头",
        "description": "通过介绍词汇资源在NLP中的重要性和手工标注的高成本，突出自动化方法的价值，为后续研究方法的提出做铺垫。"
      },
      {
        "name": "定义任务目标与术语",
        "type": "writing-level",
        "purpose": "让读者清楚理解研究任务和关键概念",
        "location": "任务描述部分",
        "description": "对Taxonomy Enrichment任务进行形式化定义，并解释如“orphan words”、“hypernyms”等核心术语，便于读者准确把握研究内容。"
      },
      {
        "name": "举例说明任务",
        "type": "writing-level",
        "purpose": "通过实例提升任务的可理解性",
        "location": "任务目标说明处",
        "description": "用‘duck’为例，说明如何为孤立词找到合适的上位词，帮助读者直观理解任务要求。"
      },
      {
        "name": "借鉴和扩展已有方法",
        "type": "method-level",
        "purpose": "在前人工作的基础上创新，提高方法有效性",
        "location": "方法介绍部分",
        "description": "以RUSSE-2020基线模型为基础，结合候选同义词集排序及维基词典、多种嵌入信息，增强模型能力。"
      },
      {
        "name": "将任务建模为软排序问题",
        "type": "method-level",
        "purpose": "更合理地反映实际应用中的多答案和排序需求",
        "location": "方法描述部分",
        "description": "将Taxonomy Enrichment任务视为soft ranking问题，允许每个词有多个可能的上位词，并考虑候选答案的排序。"
      },
      {
        "name": "采用标准评价指标MAP",
        "type": "experiment-level",
        "purpose": "保证实验结果具有可比性和权威性",
        "location": "评价方法介绍处",
        "description": "使用Mean Average Precision (MAP)作为主要评估指标，并详细给出公式，方便复现和与相关任务（如Hypernym Discovery）对比。"
      },
      {
        "name": "分析评价指标与数据集设计的适配性",
        "type": "writing-level",
        "purpose": "揭示潜在问题，体现研究的严谨性",
        "location": "评价方法分析部分",
        "description": "讨论MAP指标与数据集（含二阶上位词扩展）的不一致，指出强制要求模型找到所有标准答案可能违背初衷，体现对实验设计的深入思考。"
      },
      {
        "name": "引用相关领域权威任务和数据集",
        "type": "writing-level",
        "purpose": "增强研究的学术关联性和影响力",
        "location": "任务与方法介绍处",
        "description": "引用如WordNet、SemEval-2016、RUSSE-2020等权威资源和任务，增强方法的可信度和学科内的对接。"
      },
      {
        "name": "结合多种信息源提升模型性能",
        "type": "method-level",
        "purpose": "丰富特征，提高模型泛化能力",
        "location": "方法介绍部分",
        "description": "融合Wiktionary等词典信息与多种词嵌入，扩展模型的知识覆盖面，提升预测准确性。"
      },
      {
        "name": "详细公式展示与变量说明",
        "type": "writing-level",
        "purpose": "增强方法透明度和可复现性",
        "location": "评价指标描述处",
        "description": "用数学公式详细说明MAP的计算过程，对各变量进行解释，便于他人理解和复现。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_27",
    "title": "The Indigenous Languages Technology project: An empowerment-oriented approach to developing language software",
    "conference": "COLING",
    "domain": {
      "research_object": "加拿大原住民社区语言保护与推广相关的软件开发项目",
      "core_technique": "以赋权为导向，结合社区协作开发多样化语言技术工具",
      "application": "支持原住民社区语言保存、教育及日常交流的技术应用",
      "domains": [
        "计算机辅助语言学",
        "社会信息学"
      ]
    },
    "ideal": {
      "core_idea": "以赋权为导向，协作开发支持加拿大原住民语言的软件。",
      "tech_stack": [
        "自然语言处理",
        "协作开发平台",
        "定制化软件工具"
      ],
      "input_type": "原住民社区语言需求与相关语言数据",
      "output_type": "支持语言保存与复兴的软件工具"
    },
    "skeleton": {
      "problem_framing": "论文通过强调服务加拿大原住民社区、支持其语言保护和复兴的目标来引入问题，将技术开发与社会需求紧密结合，突出项目的社会价值和实际应用场景，增强读者对研究意义的认同感。",
      "gap_pattern": "作者指出加拿大原住民语言缺乏丰富的文本和语音数据，除部分例外外，现有技术难以直接应用于这些语言，批评了数据驱动方法的局限性，为采用基于规则的方法提供了合理性和创新空间。",
      "method_story": "方法部分强调项目由多个子项目组成，以适应不同社区的多样化语言需求，突出协作和定制化策略，并解释为何采用以规则为主的技术路径，体现对实际条件和需求的敏感性。",
      "experiments_story": "实验部分预计将围绕各子项目的实际应用展开，可能采用案例分析或定性评估，突出技术在不同社区中的适应性和效果，强调与社区合作的过程和成果的社会影响。"
    },
    "tricks": [
      {
        "name": "项目分阶段描述",
        "type": "writing-level",
        "purpose": "清晰展示项目进展和结构",
        "location": "论文开头",
        "description": "将整个项目分为不同阶段（如Phase I和Phase II），分别描述每个阶段的时间范围、目标和资金等，有助于读者理解项目的整体框架和进展。"
      },
      {
        "name": "多机构协作",
        "type": "method-level",
        "purpose": "整合多方资源与专业知识",
        "location": "项目背景介绍",
        "description": "强调项目由多个研究机构合作完成，突出跨学科、跨组织协作方式，提升项目的影响力和资源整合能力。"
      },
      {
        "name": "根据社区需求定制子项目",
        "type": "method-level",
        "purpose": "提升研究的针对性和实际应用价值",
        "location": "项目设计部分",
        "description": "根据不同社区的语言需求，设计多样化的子项目，确保研究成果能够满足各社区的具体需求，增强项目的实用性和包容性。"
      },
      {
        "name": "采用规则驱动技术替代数据驱动方法",
        "type": "method-level",
        "purpose": "应对数据稀缺问题，提高技术适用性",
        "location": "技术方案介绍",
        "description": "针对原住民语言缺乏大量文本或语音数据的现状，采用规则驱动的方法而不是依赖机器学习，适应数据稀缺场景，保证技术的可实现性。"
      },
      {
        "name": "赋权型合作研究模式",
        "type": "method-level",
        "purpose": "促进社区参与，实现共同目标",
        "location": "研究方法论部分",
        "description": "采用“empowerment”研究模式，强调与社区成员平等合作，兼顾语言学家和社区的双重需求，提升研究的社会影响力和可持续性。"
      },
      {
        "name": "响应社区实际需求设定研究课题",
        "type": "method-level",
        "purpose": "确保研究成果切合实际，增强社区认可度",
        "location": "子项目举例部分",
        "description": "直接采纳社区成员（如教育者）提出的需求作为研究课题，例如开发动词变位器和自动朗读工具，使研究紧密结合实际应用场景。"
      },
      {
        "name": "设置顾问委员会指导项目",
        "type": "method-level",
        "purpose": "确保项目方向符合社区利益和需求",
        "location": "项目管理部分",
        "description": "设立由原住民成员组成的顾问委员会，为项目提供指导和反馈，保证研究过程和成果能够真正服务于目标社区。"
      },
      {
        "name": "文献回顾与方法对比",
        "type": "writing-level",
        "purpose": "展示研究方法的理论依据和创新性",
        "location": "方法论介绍部分",
        "description": "引用相关文献，梳理不同的原住民语言研究方法，并明确本项目采用的赋权型合作模式，突出方法选择的合理性和创新性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_28",
    "title": "A Straightforward Approach to Narratologically Grounded Character Identification",
    "conference": "COLING",
    "domain": {
      "research_object": "基于叙事学理论的角色识别方法，关注文本中角色的自动识别。",
      "core_technique": "结合叙事学知识与自然语言处理技术，实现角色识别的直接方法。",
      "application": "用于文学作品、故事文本中的角色自动识别与分析。",
      "domains": [
        "自然语言处理",
        "叙事学"
      ]
    },
    "ideal": {
      "core_idea": "提出一种基于叙事学的角色识别简单方法",
      "tech_stack": [
        "叙事学理论",
        "文本分析",
        "角色识别算法"
      ],
      "input_type": "叙事文本或故事文本",
      "output_type": "文本中角色的识别与标注结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调角色在叙事中的核心地位引入问题，引用权威定义（如Fludernik）突出角色识别对于自动化故事理解的重要性。通过理论阐述和现实需求相结合，明确角色识别是故事理解的关键步骤，为后续研究奠定基础。",
      "gap_pattern": "文中通过回顾已有自动角色识别方法，指出现有方法虽多，但仍需改进和完善，尤其是在自动化和准确性方面。通过对比和批评现有方法的不足，突显自身研究的创新点和必要性，形成研究空白（gap）。",
      "method_story": "方法部分采用分步叙述策略，先简要介绍整体流程（两步法），再详细说明每一步的实现细节，包括特征选择、模型训练和测试数据集。通过逐步展开，逻辑清晰地引导读者理解模型设计和实现过程。",
      "experiments_story": "实验部分以数据集为主线，先介绍数据预处理，再详细描述实验设置和评价指标。通过展示不同特征组合的实验结果，突出模型性能，并采用交叉验证等方法增强结果的可信度，逻辑递进地展示实验过程和结论。"
    },
    "tricks": [
      {
        "name": "引用权威定义强化论点",
        "type": "writing-level",
        "purpose": "通过引用权威学者的定义，增强自己观点的权威性和说服力",
        "location": "开头段落，引用Fludernik的叙事定义",
        "description": "作者在论文开头引用了Monika Fludernik关于叙事的定义，强调角色在叙事中的核心地位，为后续研究的必要性和重要性提供理论支撑。"
      },
      {
        "name": "综述现有研究方法",
        "type": "writing-level",
        "purpose": "展示对领域现状的了解，明确自身工作的创新点",
        "location": "第二段，综述已有的角色识别方法",
        "description": "作者梳理了领域内已有的角色识别方法，包括基于本体、案例推理、监督学习、启发式方法等，指出现有方法的不足，为提出新方法作铺垫。"
      },
      {
        "name": "分步描述模型流程",
        "type": "method-level",
        "purpose": "清晰展示模型的结构和处理流程，便于复现和理解",
        "location": "描述character detection model的部分",
        "description": "作者将角色检测模型分为两步：首先自动标记共指链的活体性，其次应用监督学习分类器进行角色识别，分步表述使流程更清晰。"
      },
      {
        "name": "特征工程与组合实验",
        "type": "experiment-level",
        "purpose": "通过不同特征组合实验，找到最优特征集提升模型性能",
        "location": "模型实验部分，描述特征组合测试",
        "description": "作者在扩展的ProppLearner语料库上探索了不同特征组合及其对模型表现的影响，最终选取表现最好的七个特征进行模型训练。"
      },
      {
        "name": "多数据集泛化测试",
        "type": "experiment-level",
        "purpose": "验证模型的泛化能力和鲁棒性",
        "location": "模型实验部分，跨数据集测试",
        "description": "作者不仅在训练语料库上测试模型，还将其应用于OntoNotes和Corpus of English Novels两个不同的数据集，检验模型在不同数据上的表现。"
      },
      {
        "name": "采用SVM及参数说明",
        "type": "method-level",
        "purpose": "明确模型实现细节，便于他人复现",
        "location": "实现说明部分",
        "description": "作者详细说明了模型采用SVM（支持向量机）并使用RBF核函数，给出实现的具体工具和参数，提升方法的透明度和可复现性。"
      },
      {
        "name": "十折交叉验证与宏平均报告",
        "type": "experiment-level",
        "purpose": "确保实验结果的稳健性和公平性",
        "location": "模型评估部分",
        "description": "作者采用十折交叉验证训练模型，并报告测试集的宏平均分，减少偶然性和样本分布偏差对结果的影响。"
      },
      {
        "name": "数据预处理与质量控制",
        "type": "method-level",
        "purpose": "提升训练数据质量，确保实验可靠性",
        "location": "ProppLearner语料库预处理部分",
        "description": "作者对语料库进行预处理，纠正共指链标注中的小错误，如去重、合并链头、合并代词等，提高数据质量，为模型训练打下基础。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_29",
    "title": "Lexical Semantic Analysis of Meaning Representation",
    "conference": "COLING",
    "domain": {
      "research_object": "论文研究词汇语义分析，聚焦于意义表达方式的建模与理解。",
      "core_technique": "采用语义表示理论与词汇分析方法，探讨词义的结构化表达。",
      "application": "可用于自然语言处理中的文本理解、机器翻译及信息检索等任务。",
      "domains": [
        "计算语言学",
        "自然语言处理"
      ]
    },
    "ideal": {
      "core_idea": "分析并比较多种符号化语义表示的词汇语义内容及其差异。",
      "tech_stack": [
        "语义表示分析",
        "语料库比较",
        "符号方法"
      ],
      "input_type": "文本及其语义标注",
      "output_type": "语义内容差异分析与对比结果"
    },
    "skeleton": {
      "problem_framing": "论文通过引用前人工作，指出多种符号意义表示（MRs）在文本注释中的广泛应用，但其编码的语义内容及相互关系尚不清晰。作者提出需要深入理解MRs的语言学基础，提出具体问题，如MRs与句法信息的关系及其对词汇语义的考虑。",
      "gap_pattern": "作者批评现有研究未能明确不同MRs所编码的语义内容及其相互比较，强调理论理解的缺口，并质疑MRs是否仅仅是句法信息的粗化或重组，提出对更简化或资源更丰富的语言表示的探索空间。",
      "method_story": "方法部分通过对比不同解析器的特征输入（如词形、词干、句法特征及词嵌入），设置实验条件，强调对比分析的严谨性。引用公开数据集和标准评估方法，确保方法的可复现性和科学性。",
      "experiments_story": "实验部分采用表格展示不同解析方法的性能，明确实验集和评估标准。通过与已有工作的结果对比，突出新方法的优势或局限，并详细说明特征来源和实验设置，保证实验的透明度和可比性。"
    },
    "tricks": [
      {
        "name": "明确提出研究问题",
        "type": "writing-level",
        "purpose": "清晰界定论文核心探讨内容，吸引读者关注",
        "location": "第一段",
        "description": "作者在开头提出尚未明确的问题——不同语义表示(MR)编码的语义内容及其相互关系，并用具体问题引导后续研究，如MR是否仅仅是语法信息的粗化和重组。"
      },
      {
        "name": "文献回顾与定位",
        "type": "writing-level",
        "purpose": "界定现有工作，突出本研究创新点",
        "location": "第一段及第二段",
        "description": "通过引用相关文献（Abend and Rappoport, 2017; Oepen et al., 2019; Hershcovich et al., 2018, 2019a），总结前人工作，说明目前研究的不足和本论文的切入点。"
      },
      {
        "name": "设立直观公式/问题驱动",
        "type": "writing-level",
        "purpose": "用简洁公式化表达研究假设，便于读者理解核心问题",
        "location": "第一段末",
        "description": "以“sentence-level meaning representation ?= syntax + lexical semantics”表达核心研究假设，使问题具体化、易于讨论。"
      },
      {
        "name": "对比实验设计",
        "type": "experiment-level",
        "purpose": "通过多种方法对比，突出新方法效果和局限性",
        "location": "第三段",
        "description": "展示多种解析方法的得分，包括使用不同特征（词、词形、语法特征、词嵌入等）的模型，并与前人方法进行对比，突出新方法的表现。"
      },
      {
        "name": "利用公开数据和工具",
        "type": "method-level",
        "purpose": "保证实验可复现性和方法通用性",
        "location": "第三段",
        "description": "采用公开数据集（EWT Reviews）和工具（如TUPA、HIT-SCIR parser），并给出相关链接，方便后续研究者复现和扩展。"
      },
      {
        "name": "规则与监督方法结合",
        "type": "method-level",
        "purpose": "分析不同方法之间的性能差异及互补性",
        "location": "第三段",
        "description": "将基于语法的转换器与监督学习方法（含词信息）进行对比，分析词汇语义规则能否弥合二者差距，体现方法创新和分析深度。"
      },
      {
        "name": "误差分析与混淆矩阵展示",
        "type": "method-level",
        "purpose": "深入分析模型错误类型，指导后续改进",
        "location": "第三段末",
        "description": "通过混淆矩阵展示规则方法与金标准的类别对比，分析模型错误分布，为进一步优化提供依据。"
      },
      {
        "name": "避免统计重复计数",
        "type": "method-level",
        "purpose": "保证数据分析的准确性和科学性",
        "location": "最后一段",
        "description": "对于有相同终端产出的UCCA单元，仅取顶层类别，避免双重计数，保证结果统计合理。"
      },
      {
        "name": "附录补充实验细节",
        "type": "writing-level",
        "purpose": "增加论文透明度和细节，方便深入理解",
        "location": "第三段末",
        "description": "将部分混淆矩阵和细节放在附录，正文突出核心结果，附录补充完整信息，兼顾精炼与详尽。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_2",
    "title": "Data Selection for Bilingual Lexicon Induction from Specialized Comparable Corpora",
    "conference": "COLING",
    "domain": {
      "research_object": "专用领域可比语料库中双语词汇归纳的数据选择方法",
      "core_technique": "利用数据选择策略提升双语词汇归纳的准确性和效率",
      "application": "用于自动构建专用领域的双语词典，支持跨语言信息检索和翻译",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "从专业可比语料中选择数据以提升双语词典归纳效果",
      "tech_stack": [
        "可比语料处理",
        "数据选择算法",
        "双语词典归纳"
      ],
      "input_type": "专业领域的可比语料文本",
      "output_type": "高质量的双语词汇对列表"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍自动化生成和扩展双语词典的研究背景，强调该任务在自然语言处理中的重要性。作者指出，最初的研究多依赖于平行语料，但由于可比语料的易获取性和广泛性，研究重心逐渐转向了可比语料的利用。",
      "gap_pattern": "作者批评了技术和科学领域可比语料规模有限的问题，暗示现有方法在专业领域应用时受到数据量的制约。这种gap批评策略通过对比一般领域和专业领域的数据资源，突出研究的现实挑战和改进空间。",
      "method_story": "方法部分采用分步叙述策略，先说明数据选择流程，再描述如何构建训练数据，并详细列举实验所用工具和数据来源。通过逐步展开，增强了方法的可复现性和逻辑清晰性。",
      "experiments_story": "实验部分先介绍数据和评价指标，随后系统展示不同数据选择方法在多种语料组合下的表现。通过对比实验结果和计算效率，突出各方法的优劣，逻辑上与方法部分紧密衔接，便于读者理解实验设计和结论。"
    },
    "tricks": [
      {
        "name": "利用可比语料库进行双语词典自动扩展",
        "type": "writing-level",
        "purpose": "强调研究创新点和现实意义",
        "location": "论文开头",
        "description": "在引言部分指出传统方法依赖平行语料，而可比语料因获取容易成为主流，突出本文方法的现实背景和应用价值。"
      },
      {
        "name": "多文献引用论证方法趋势",
        "type": "writing-level",
        "purpose": "展示方法的研究基础和领域认可度",
        "location": "相关工作背景介绍",
        "description": "通过引用大量相关文献，说明从平行语料到可比语料的转变是领域发展趋势，增强论文说服力。"
      },
      {
        "name": "结合领域语料与通用语料提升方法表现",
        "type": "method-level",
        "purpose": "缓解专业领域语料稀缺问题，提升词典自动生成效果",
        "location": "方法论部分",
        "description": "提出将小规模专业领域可比语料与大规模通用语料结合，通过数据融合提升分布式分析方法效果，解决领域语料稀缺问题。"
      },
      {
        "name": "数据选择与相似度排序采样",
        "type": "experiment-level",
        "purpose": "优化训练数据质量，分析数据选择对结果的影响",
        "location": "实验方法步骤1-2",
        "description": "根据专业语料，选取通用语料中最相似的句子/文档，按相似度分层采样（从最相似到最不相似，反向亦然），分析数据选择策略对实验结果的影响。"
      },
      {
        "name": "增量式数据融合实验设计",
        "type": "experiment-level",
        "purpose": "系统评估不同规模/相似度数据对模型表现的影响",
        "location": "实验方法步骤2",
        "description": "将通用语料分批（每次10%）加入专业语料，观察从最相似到最不相似数据的加入对模型的影响，实现可控变量分析。"
      },
      {
        "name": "使用fastText训练词向量",
        "type": "method-level",
        "purpose": "获得高质量词嵌入以支持跨语言词典生成",
        "location": "实验方法步骤3",
        "description": "采用fastText工具训练源语言和目标语言的词向量，详细列出参数设置（如skipgram, minCount, dim等），保证结果可复现。"
      },
      {
        "name": "词向量空间对齐",
        "type": "method-level",
        "purpose": "实现跨语言词语的空间映射，便于相似度计算",
        "location": "实验方法步骤4",
        "description": "利用VecMap工具将源语言和目标语言的词向量映射到同一空间，为后续的词语相似度计算和词典生成提供基础。"
      },
      {
        "name": "改进的相似度度量（Cross-domain Similarity Local Scaling）",
        "type": "method-level",
        "purpose": "提升跨语言词语匹配的准确率",
        "location": "实验方法步骤5",
        "description": "采用CDSLS方法代替传统余弦相似度，结合最近邻信息，提升目标词候选排序的准确性。"
      },
      {
        "name": "详细实验流程分步描述",
        "type": "writing-level",
        "purpose": "增强实验部分的可读性与可复现性",
        "location": "方法和实验部分",
        "description": "将整体实验流程拆分为若干具体操作步骤，每步简明扼要，便于他人复现和理解。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_30",
    "title": "A Corpus for Modelling Empathy in Student-Written Peer Reviews",
    "conference": "COLING",
    "domain": {
      "research_object": "学生撰写的同伴评审文本中共情表达的语料库",
      "core_technique": "自然语言处理方法用于分析和建模文本中的共情特征",
      "application": "提升教育环境中自动化同伴评审系统的情感理解能力",
      "domains": [
        "自然语言处理",
        "教育技术"
      ]
    },
    "ideal": {
      "core_idea": "构建用于建模学生互评中同理心的语料库",
      "tech_stack": [
        "语料库构建",
        "自然语言处理",
        "同理心标注"
      ],
      "input_type": "学生撰写的互评文本",
      "output_type": "带有同理心标签的语料库"
    },
    "skeleton": {
      "problem_framing": "论文以奥巴马关于同理心赤字的名言开篇，通过引用权威人物和现实社会问题，将同理心的重要性与社会、教育和职业发展紧密联系，增强问题的现实紧迫感和普遍意义，吸引读者关注。",
      "gap_pattern": "作者指出虽然同理心被广泛认为是基础能力，但在教育课程和专业沟通中的具体培养与应用仍存在不足，暗示当前研究和实践之间存在差距，为后续研究设定空间和必要性。",
      "method_story": "方法部分通常通过界定同理心的操作性定义，结合前人理论和测量工具，说明本研究如何具体评估和干预同理心能力，突出方法的科学性和创新性。",
      "experiments_story": "实验部分一般采用对比实验或干预设计，详细描述实验对象、流程和测量指标，强调实验的可重复性和数据的客观性，以验证同理心培养方法的有效性。"
    },
    "tricks": [
      {
        "name": "引用权威人物观点开篇",
        "type": "writing-level",
        "purpose": "增强论点的权威性和吸引力",
        "location": "开头引用奥巴马讲话",
        "description": "通过引用美国前总统奥巴马关于同理心的讲话，增强论文的现实意义和说服力，引发读者兴趣。"
      },
      {
        "name": "结合理论定义核心概念",
        "type": "writing-level",
        "purpose": "确保论述严谨，统一术语",
        "location": "对同理心的定义引用Davis（1983）",
        "description": "通过引用权威文献对‘同理心’进行明确定义，为后文论述提供理论基础，避免歧义。"
      },
      {
        "name": "结合现实与学术背景阐述研究意义",
        "type": "writing-level",
        "purpose": "突出研究的现实紧迫性和学术价值",
        "location": "联系社会需求和教育政策（OECD, 2018）",
        "description": "将社会实际问题（同理心赤字）与教育政策（如OECD学习框架）结合，强调研究的重要性和应用前景。"
      },
      {
        "name": "引用数据支持论点",
        "type": "method-level",
        "purpose": "用实证数据增强说服力",
        "location": "引用Konrath等（2011）关于同理心下降的数据",
        "description": "通过引用大样本、长时间跨度的实证研究数据，客观展示同理心能力的下降趋势，增强论文可信度。"
      },
      {
        "name": "多领域场景举例",
        "type": "writing-level",
        "purpose": "展示研究的广泛适用性",
        "location": "举例数字公司、敏捷工作环境等",
        "description": "通过举例同理心在数字公司、敏捷环境等多种实际场景中的重要性，说明研究成果的广泛应用和现实意义。"
      },
      {
        "name": "对比分析未来趋势",
        "type": "writing-level",
        "purpose": "突出研究前瞻性和独特价值",
        "location": "对比人类与人工智能的同理心能力",
        "description": "通过将同理心作为未来区分人类与人工智能的关键能力，突出同理心研究的前瞻性和不可替代性。"
      },
      {
        "name": "政策建议结合学术研究",
        "type": "writing-level",
        "purpose": "推动研究成果转化为社会实践",
        "location": "引用OECD提出教育改革建议",
        "description": "结合学术研究结果与国际组织政策建议，推动同理心训练纳入高等教育课程，体现研究的实际指导意义。"
      },
      {
        "name": "引用多篇权威文献支撑论述",
        "type": "method-level",
        "purpose": "增强论据的广度和深度",
        "location": "文中多次引用Davis, Luca and Tarricone, Poser and Bittner等文献",
        "description": "通过综合多篇权威文献，构建坚实的理论和实证支撑，提升论文的学术深度和说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_31",
    "title": "Combining Word Embeddings with Bilingual Orthography Embeddings for Bilingual Dictionary Induction",
    "conference": "COLING",
    "domain": {
      "research_object": "利用词嵌入和双语正字法嵌入提升双语词典自动生成效果",
      "core_technique": "结合分布式词表示与正字法特征进行双语词典归纳建模",
      "application": "自动构建和扩展不同语言之间的词典资源，促进跨语言处理",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "结合词嵌入与双语正字法嵌入提升词典归纳效果",
      "tech_stack": [
        "词嵌入",
        "双语正字法嵌入",
        "词典归纳算法"
      ],
      "input_type": "源语言词汇及少量种子词典",
      "output_type": "目标语言词汇翻译列表"
    },
    "skeleton": {
      "problem_framing": "论文通过定义双语词典归纳（BDI）任务，并强调其在机器翻译和词嵌入评估中的核心作用，结合引用权威文献，突出该任务的学术和应用价值，为后续研究奠定基础。",
      "gap_pattern": "作者通过回顾近期方法，指出现有技术虽能利用弱或无监督信号构建词嵌入，但在不同字母系统的语言对上仍存在局限，暗示传统距离度量（如Levenshtein距离）不适用，明确提出研究空白。",
      "method_story": "方法部分采用递进式叙述，先介绍融合词嵌入、字符级信息和人工特征的分类器框架，再说明候选翻译的生成与重排序流程，并强调针对不同字母系统语言对的创新设计，突出方法针对性和系统性。",
      "experiments_story": "实验部分详细描述数据集选择与处理流程，说明分频率分组实验设计，确保结果的全面性和可比性，同时通过具体分组和切分比例，展现实验的严谨性和针对性，增强结论的说服力。"
    },
    "tricks": [
      {
        "name": "定义任务背景和重要性",
        "type": "writing-level",
        "purpose": "明确研究任务并突出其在领域中的重要性",
        "location": "论文开头",
        "description": "在引言部分首先定义Bilingual Dictionary Induction（BDI）的任务，并阐述其在机器翻译和词嵌入评估中的核心作用，为后续方法和实验提供理论基础。"
      },
      {
        "name": "引用并总结相关工作",
        "type": "writing-level",
        "purpose": "展示现有方法与不足，突出创新点",
        "location": "相关工作描述段",
        "description": "通过引用多篇关键文献，简要总结现有的BWE方法及其局限性（如难以处理专有名词），为新方法的提出做铺垫。"
      },
      {
        "name": "多特征融合",
        "type": "method-level",
        "purpose": "提升翻译准确性，处理难翻译词汇",
        "location": "方法介绍段",
        "description": "将词嵌入（BWE）、字符级信息（BOE）、人工特征（如词频、长度等）融合到分类器中，通过多维度特征提升翻译判别能力。"
      },
      {
        "name": "候选生成与分组重排序",
        "type": "method-level",
        "purpose": "提高预测效果，优化最终输出",
        "location": "方法流程描述",
        "description": "分别用BWE和seq2seqTr模型生成候选翻译词，之后用分类系统对两个候选组进行重排序，最终选取得分最高的作为预测结果。"
      },
      {
        "name": "聚焦不同字母表语言对",
        "type": "experiment-level",
        "purpose": "验证方法在特殊场景下的有效性",
        "location": "实验设计说明",
        "description": "选择字母表不同的语言对作为实验对象，强调新方法在Levenshtein距离不可用场景下的适用性，突出研究应用价值。"
      },
      {
        "name": "提出无监督字符级序列到序列转写模型（seq2seqTr）",
        "type": "method-level",
        "purpose": "解决不同字母表和专有名词的翻译问题",
        "location": "方法创新部分",
        "description": "设计并采用无监督seq2seqTr模型进行字符级转写，利用双向GRU编码器和带注意力的单向解码器，专门处理不同字母表和低频词（如专有名词）的翻译。"
      },
      {
        "name": "无监督训练策略",
        "type": "method-level",
        "purpose": "降低对人工标注的依赖，提升模型泛化能力",
        "location": "方法描述",
        "description": "在seq2seqTr模型训练时，无需区分转写和非转写词对标签，采用无监督方式训练，提高数据利用率和方法的可迁移性。"
      },
      {
        "name": "详细模型结构说明",
        "type": "writing-level",
        "purpose": "便于复现与理解模型设计",
        "location": "模型细节描述段",
        "description": "详细描述seq2seqTr模型结构，包括编码器为双向GRU，解码器为单向带注意力机制，隐藏层单元数等参数，有助于他人复现。"
      },
      {
        "name": "针对专有名词等难翻译词的特殊处理",
        "type": "method-level",
        "purpose": "提升系统对特殊词汇的翻译能力",
        "location": "方法说明",
        "description": "指出BWE方法对专有名词等词汇表现不佳，采用字符级信息和转写模型进行补充处理，提升整体系统性能。"
      },
      {
        "name": "人工特征工程的集成",
        "type": "method-level",
        "purpose": "增强分类器判别能力",
        "location": "方法细节描述",
        "description": "将手工设计的特征（如词频、词长等）与自动化特征（如嵌入、字符级表示）结合，集成到分类器中，以提升翻译判断的精度。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_32",
    "title": "Incorporating Noisy Length Constraints into Transformer with Length-aware Positional Encodings",
    "conference": "COLING",
    "domain": {
      "research_object": "在Transformer模型中融入带噪声的长度约束以提升序列建模能力",
      "core_technique": "提出长度感知位置编码方法，使模型能处理不确定性长度信息",
      "application": "适用于需要长度控制的自然语言生成与序列预测任务",
      "domains": [
        "自然语言处理",
        "深度学习"
      ]
    },
    "ideal": {
      "core_idea": "将带噪声的长度约束融入Transformer的长度感知位置编码中",
      "tech_stack": [
        "Transformer",
        "长度感知位置编码",
        "神经机器翻译"
      ],
      "input_type": "源语言文本及长度约束",
      "output_type": "目标语言文本，满足长度约束"
    },
    "skeleton": {
      "problem_framing": "论文以神经机器翻译中解码器逐步生成输出、句子长度依赖终止预测为切入点，指出过早终止会导致信息遗漏（under-translation），并简要介绍Transformer的位置信息处理方式，为后续长度控制问题铺垫背景。",
      "gap_pattern": "作者通过回顾现有长度控制方法（如LRPE和LDPE），指出它们虽然能精确匹配长度，但在翻译任务中不总是适用，因为不同语言间长度差异普遍存在，强调现有方法在实际应用中的局限性，形成研究空白。",
      "method_story": "方法部分先阐述Transformer结合LRPE和LDPE的基本机制，随后提出通过在训练阶段引入随机噪声增强模型对长度变化的鲁棒性，并创新性地结合BERT进行输出长度预测，突出自身方法对长度预测误差的适应能力。",
      "experiments_story": "实验部分采用英日翻译任务，系统对比基线Transformer与引入不同长度控制及噪声策略的模型，利用BLEU、长度比和方差等指标量化效果，并通过统计检验验证改进方法的有效性，突出方法的实际表现与局限。"
    },
    "tricks": [
      {
        "name": "文献回顾与问题定位",
        "type": "writing-level",
        "purpose": "展示已有研究基础并明确自身工作的创新点",
        "location": "开头段落",
        "description": "通过回顾Transformer的基本结构及已有关于输出长度控制的研究（如LRPE和LDPE），指出现有方法在实际翻译中的局限性（如输入长度不能很好预测输出长度），为提出新方法铺垫背景。"
      },
      {
        "name": "方法创新与结合",
        "type": "method-level",
        "purpose": "提升模型对输出长度的预测和控制能力",
        "location": "方法提出部分",
        "description": "将BERT用于输出长度预测，并结合LRPE和LDPE两种长度感知位置编码，以实现更准确的输出长度控制，缓解下译问题。"
      },
      {
        "name": "噪声注入增强鲁棒性",
        "type": "method-level",
        "purpose": "提升模型对长度预测误差的鲁棒性",
        "location": "方法描述部分",
        "description": "在训练阶段对长度约束引入随机噪声（如在窗口[−2,2]或[−4,4]内采样），使模型在面对长度预测不准时也能保持性能。"
      },
      {
        "name": "多种推断策略对比",
        "type": "experiment-level",
        "purpose": "系统评价不同长度约束方法的效果",
        "location": "实验设计部分",
        "description": "在推断阶段分别采用BERT预测长度、输入长度、参考长度等多种长度约束策略，比较其对翻译性能的影响，验证所提方法的有效性。"
      },
      {
        "name": "消融实验设计",
        "type": "experiment-level",
        "purpose": "验证各组成部分的作用",
        "location": "实验部分",
        "description": "通过对比无噪声、不同噪声窗口和不同长度约束来源的实验，分析噪声注入和长度预测的实际贡献。"
      },
      {
        "name": "性能评估多指标呈现",
        "type": "experiment-level",
        "purpose": "全面评估模型性能",
        "location": "结果分析部分",
        "description": "采用BLEU分数、长度比、方差等多个指标，全面展示不同方法在翻译质量和长度控制上的表现。"
      },
      {
        "name": "基于开源工具实现",
        "type": "method-level",
        "purpose": "保证实验的可复现性和通用性",
        "location": "实验实现部分",
        "description": "实验基于OpenNMT实现，便于他人复现和进一步改进。"
      },
      {
        "name": "用真实任务验证方法有效性",
        "type": "experiment-level",
        "purpose": "确保方法在实际应用中的适用性",
        "location": "实验设置部分",
        "description": "选用英到日的机器翻译任务进行实验，验证所提方法在真实复杂语言对上的实际效果。"
      },
      {
        "name": "上界性能分析",
        "type": "experiment-level",
        "purpose": "评估方法理论最优表现",
        "location": "实验对比部分",
        "description": "通过使用参考长度作为约束，探索所提方法在理想长度预测情况下的性能上限。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_33",
    "title": "Evaluating Pretrained Transformer-based Models on the Task of Fine-Grained Named Entity Recognition",
    "conference": "COLING",
    "domain": {
      "research_object": "对预训练的Transformer模型在细粒度命名实体识别任务中的表现进行评估和比较。",
      "core_technique": "采用BERT等Transformer架构的预训练语言模型，分析其在FG-NER任务中的效果。",
      "application": "提升文本中细粒度实体识别能力，应用于信息抽取、智能问答等自然语言处理场景。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "评估预训练Transformer模型在细粒度命名实体识别任务中的表现",
      "tech_stack": [
        "预训练Transformer模型",
        "BERT",
        "命名实体识别"
      ],
      "input_type": "包含命名实体的自然语言文本",
      "output_type": "细粒度类别的命名实体及其边界"
    },
    "skeleton": {
      "problem_framing": "论文通过定义命名实体识别（NER）的基本任务和主要目标，详细介绍了NER的四大类别，并强调其在自然语言处理领域的重要性。通过引用主流工具和最新研究，作者将NER定位为活跃且技术不断进步的研究领域，为后续讨论奠定基础。",
      "gap_pattern": "作者在介绍现有NER方法时，指出传统的NER（即粗粒度NER）模型在区分实体类别方面存在局限，暗示当前方法虽性能优异但在细致分类或特定领域仍有不足。这种gap批评为提出新方法或改进现有模型提供了理论空间。",
      "method_story": "方法部分采用对比叙述策略，系统介绍了五种被研究的模型，并详细说明了各自的配置。通过提前揭示主要结果，突出transformer模型的优势，并以具体数据支持模型性能的比较，为实验部分的深入分析做铺垫。",
      "experiments_story": "实验部分围绕研究问题展开，先介绍数据集和对比模型，再通过表格展示各模型在不同领域的表现。采用micro-averaged F1分数应对类别不均衡，并用加粗方式突出最佳结果，增强结果的可读性和对比性，逻辑清晰地回应研究问题。"
    },
    "tricks": [
      {
        "name": "定义和分类任务背景",
        "type": "writing-level",
        "purpose": "为读者清晰介绍研究任务和背景",
        "location": "开头段落",
        "description": "在论文开头明确介绍命名实体识别（NER）的定义、主要任务及其实体分类方法，为后续研究提供背景和上下文。"
      },
      {
        "name": "结合实际应用场景说明研究意义",
        "type": "writing-level",
        "purpose": "增强研究的实际价值和应用导向",
        "location": "任务背景介绍后",
        "description": "通过举例说明NER在金融等行业中的具体应用场景，强调细粒度识别在工业界中的必要性，提升论文的实际意义。"
      },
      {
        "name": "对比现有方法与问题",
        "type": "writing-level",
        "purpose": "突出当前方法的局限性，引出研究动机",
        "location": "任务背景及相关工作中",
        "description": "在介绍现有NER模型（如spaCy、flair等）时，指出其分类粒度粗、实体类别有限等不足，为提出新方法或改进提供合理动机。"
      },
      {
        "name": "详细列举实验模型与配置",
        "type": "method-level",
        "purpose": "保证实验可复现性和对比的公平性",
        "location": "方法介绍部分",
        "description": "对比实验时，详细列出所用的五个模型及其配置参数，确保实验的透明性和可复现性。"
      },
      {
        "name": "多模型多领域对比实验",
        "type": "experiment-level",
        "purpose": "全面评估模型在不同领域下的性能表现",
        "location": "实验结果分析部分",
        "description": "在49个不同领域上对五种模型进行F1分数对比，确保实验结论的广泛适用性和说服力。"
      },
      {
        "name": "细致统计性能指标",
        "type": "experiment-level",
        "purpose": "量化模型表现，支持结论",
        "location": "实验结果部分",
        "description": "不仅报告平均F1分数，还统计各模型在不同领域下的最高分数、表现分布等，提供更加细致的性能分析。"
      },
      {
        "name": "可视化结果分布",
        "type": "experiment-level",
        "purpose": "直观展现模型性能及其稳定性",
        "location": "实验结果部分",
        "description": "通过箱线图（boxplot）展示F1分数在各领域的分布，便于读者直观理解模型的稳定性和表现波动。"
      },
      {
        "name": "分析模型稳定性",
        "type": "experiment-level",
        "purpose": "评估模型对领域变化的鲁棒性",
        "location": "实验结果分析部分",
        "description": "通过比较各模型F1分数的四分位距，分析transformer类模型在不同领域下表现更稳定、对领域选择不敏感。"
      },
      {
        "name": "关注极端情况表现",
        "type": "experiment-level",
        "purpose": "发现模型在小样本领域的不足",
        "location": "实验结果分析部分",
        "description": "特别指出如XLNet在样本最小的十个领域表现不如传统模型，揭示模型在极端数据分布下的局限性。"
      },
      {
        "name": "逐层递进式结构安排",
        "type": "writing-level",
        "purpose": "帮助读者层层深入理解研究内容",
        "location": "全文结构安排",
        "description": "从任务定义、应用场景、相关工作、方法介绍到实验对比，逐步深入，逻辑清晰，增强论述说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_34",
    "title": "Morphological disambiguation from stemming data",
    "conference": "COLING",
    "domain": {
      "research_object": "针对基尼亚卢旺达语的形态分析与消歧问题进行研究，提升自动处理能力。",
      "core_technique": "利用词干数据和有限状态工具进行形态分析，并设计消歧方法。",
      "application": "用于自然语言处理中的文本预处理，提升多形态语言的自动分析效果。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "利用词干数据实现形态学消歧，提升Kinyarwanda等语言的NLP处理能力。",
      "tech_stack": [
        "形态学分析",
        "词干提取",
        "消歧算法"
      ],
      "input_type": "词干化后的文本数据",
      "output_type": "消歧后的形态学分析结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调形态丰富语言在自然语言处理任务中的核心地位引入问题，指出形态分析和消歧对于信息抽取和机器翻译等下游任务至关重要。通过具体词例和语言特性，突出形态结构复杂性和处理需求。",
      "gap_pattern": "作者隐含批评现有工具难以应对多形态组合导致的词汇稀疏和分解困难，强调这些语言的形态规律性和语义特征未被充分利用，暗示现有方法在处理相关任务时存在不足。",
      "method_story": "方法部分采用技术性叙述，强调项目实现细节和技术选型（如C++11和Eigen库），并说明代码库的整体架构及其针对Kinyarwanda语言的专用性，突出系统性和可扩展性。",
      "experiments_story": "实验部分以流程化方式展开，先描述数据准备和注释方式，再详细说明分割、特征统计等步骤，突出实验的系统性和可复现性，同时通过表格展示结果组织数据，增强说服力。"
    },
    "tricks": [
      {
        "name": "背景与现状描述",
        "type": "writing-level",
        "purpose": "突出研究意义与空白",
        "location": "论文开头",
        "description": "通过介绍形态丰富语言在NLP中的重要性，以及现有工具的不足（如Kinyarwanda缺乏形态分析工具），明确研究的必要性和创新点。"
      },
      {
        "name": "案例引入法",
        "type": "writing-level",
        "purpose": "增强论述的具体性与可理解性",
        "location": "Figure 1说明",
        "description": "通过具体词语（如‘ntuzamwibeshyeho’）展示形态单位，帮助读者理解复杂语言现象，并为后续方法提供直观背景。"
      },
      {
        "name": "低资源语言数据利用策略",
        "type": "method-level",
        "purpose": "解决数据匮乏问题",
        "location": "方法部分",
        "description": "采用易于收集的stemming数据替代高质量人工标注数据，通过转换为形态消歧资源，有效缓解低资源语言数据获取难题。"
      },
      {
        "name": "领域专家数据增强",
        "type": "experiment-level",
        "purpose": "提升训练数据质量",
        "location": "实验部分",
        "description": "对具备扎实语言学知识的最佳标注者的数据进行4倍上采样，增强训练集质量，提高模型表现。"
      },
      {
        "name": "特征统计与表格构建",
        "type": "method-level",
        "purpose": "提取有效形态特征",
        "location": "方法部分",
        "description": "通过统计每个词干和特征的出现次数，分别构建chosen和proposed表格，并利用统计结果生成形态特征，为后续模型训练提供输入。"
      },
      {
        "name": "分层数据处理流程",
        "type": "method-level",
        "purpose": "保证实验可复现性与系统性",
        "location": "实验部分",
        "description": "依次进行数据分割、特征提取、训练集与验证集划分、基线模型训练等步骤，确保整个流程有序、清晰。"
      },
      {
        "name": "不确定性排序",
        "type": "method-level",
        "purpose": "优化词干预测与筛选",
        "location": "方法与实验部分",
        "description": "利用基线分类器对未标注词汇进行词干预测，并根据模型预测的不确定性进行排序，便于后续人工或自动筛选。"
      },
      {
        "name": "跨语言适用性声明",
        "type": "writing-level",
        "purpose": "提升方法通用性与影响力",
        "location": "方法介绍部分",
        "description": "明确指出所提方法不仅适用于Kinyarwanda，还可推广至其他形态丰富语言，增强论文贡献度。"
      },
      {
        "name": "代码复用与依赖最小化",
        "type": "experiment-level",
        "purpose": "提升工具开发效率与可移植性",
        "location": "实验实现部分",
        "description": "使用POSIX C和C++11开发，依赖仅有Eigen库，保证代码高效、轻量，便于在不同环境下部署和扩展。"
      },
      {
        "name": "与现有工具对比引入",
        "type": "writing-level",
        "purpose": "突出研究创新性",
        "location": "背景部分",
        "description": "通过对比土耳其语等已有成熟工具，突出Kinyarwanda在形态分析工具上的空白，强调本工作的重要性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_35",
    "title": "Tree Representations in Transition System for RST Parsing",
    "conference": "COLING",
    "domain": {
      "research_object": "该论文研究基于转移系统的树结构表示方法在修辞结构理论（RST）解析中的应用。",
      "core_technique": "采用转移系统结合树结构表示，实现对文本修辞结构的自动解析与建模。",
      "application": "主要应用于自动文本分析、信息抽取以及自然语言理解等任务。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "提出在转移系统中优化树结构表示以提升RST解析效果",
      "tech_stack": [
        "转移系统",
        "树结构表示",
        "RST解析"
      ],
      "input_type": "文本单元序列",
      "output_type": "文本的修辞结构树"
    },
    "skeleton": {
      "problem_framing": "论文通过强调文本单元间的逻辑连接及其在NLP下游任务中的重要性，引入文本级话语解析的问题。作者引用相关领域的研究，突出话语结构理论（RST）在解析文档层次结构中的核心作用，明确研究对象和理论基础。",
      "gap_pattern": "作者通过回顾现有的RST解析方法，隐含指出当前系统在处理新标签和结构时特征不足，尤其对训练样本较少的情况表现有限。此外，现有系统在核性和跨度识别方式上存在改进空间，形成研究切入点。",
      "method_story": "方法部分采用对比式叙述，介绍了两种树结构的构建及新核类型和动作的设计。为解决新标签训练样本少的问题，作者引入额外依赖特征，并比较两种分类器的识别策略，突出创新点和技术细节。",
      "experiments_story": "实验部分以标准数据集和主流评价指标为基础，明确实验设计和对比对象。作者聚焦于与现有最优系统的性能比较，通过表格和分项指标展示新方法的改进效果，突出方法有效性和贡献。"
    },
    "tricks": [
      {
        "name": "引入理论背景",
        "type": "writing-level",
        "purpose": "为研究提供理论基础和背景说明",
        "location": "论文开头",
        "description": "通过介绍Rhetorical Structure Theory (RST)及其在文本解析中的作用，明确研究所基于的理论框架，帮助读者理解后续方法和实验设计。"
      },
      {
        "name": "细致定义核心概念",
        "type": "writing-level",
        "purpose": "确保读者理解关键术语和概念",
        "location": "方法介绍部分",
        "description": "详细解释EDU、span、nuclearity、relation等核心概念，并区分不同核类型和关系类型，为后续方法描述和实验结果分析打下基础。"
      },
      {
        "name": "构建多种树结构以扩展模型能力",
        "type": "method-level",
        "purpose": "提升模型对不同结构的解析能力",
        "location": "方法部分",
        "description": "设计并实现了二叉树和多分支树结构，分别引入新的核类型和动作，增强模型对复杂文本结构的解析能力。"
      },
      {
        "name": "特征增强以解决标签稀疏问题",
        "type": "method-level",
        "purpose": "提高模型对少量训练样本标签的泛化能力",
        "location": "方法部分",
        "description": "针对新标签训练样本较少的问题，增加了由Bi-Affine模型生成的依赖特征，以及其他文献提取的特征，丰富模型输入，提升分类性能。"
      },
      {
        "name": "对比联合分类与分离分类策略",
        "type": "method-level",
        "purpose": "分析不同分类策略对模型性能的影响",
        "location": "方法与实验部分",
        "description": "在过渡系统中分别测试了同时用一个分类器识别span和nuclearity与分别用不同分类器识别两者的方法，通过实验对比，分析各自优缺点。"
      },
      {
        "name": "采用标准数据集进行实验",
        "type": "experiment-level",
        "purpose": "确保实验结果具有可比性和权威性",
        "location": "实验部分",
        "description": "选用Wall Street Journal (RST-DT)标准数据集，明确训练集与测试集划分，保证实验的规范性和结果的可复现性。"
      },
      {
        "name": "多维度评价指标",
        "type": "experiment-level",
        "purpose": "全面评估模型性能",
        "location": "实验部分",
        "description": "采用Micro-averaged F1分数和LAS（labelled attachment score）分别对span、nuclearity和relation进行评估，保证对模型性能的全面衡量。"
      },
      {
        "name": "与当前最优系统对比",
        "type": "experiment-level",
        "purpose": "突出新方法的有效性",
        "location": "实验结果部分",
        "description": "只与当前最优的过渡系统（Wang et al., 2017）进行结果对比，突出自身方法在各项指标上的改进。"
      },
      {
        "name": "分析失败原因",
        "type": "writing-level",
        "purpose": "为后续研究提供改进方向",
        "location": "实验结果分析部分",
        "description": "对分离分类策略性能较差的原因进行分析，指出联合shift-reduce与核类型动作更适合过渡系统，为模型优化提供理论依据。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_36",
    "title": "Deep Learning Framework for Measuring the Digital Strategy of Companies from Earnings Calls",
    "conference": "COLING",
    "domain": {
      "research_object": "基于公司财报电话会议文本，分析企业数字化战略的不同类型和实施情况。",
      "core_technique": "采用先进的自然语言处理和深度学习模型对非结构化文本数据进行聚类分析。",
      "application": "辅助企业和投资者评估公司数字化战略的效果与趋势，支持战略决策。",
      "domains": [
        "人工智能",
        "企业管理"
      ]
    },
    "ideal": {
      "core_idea": "利用深度学习NLP模型从财报电话中量化企业数字战略水平",
      "tech_stack": [
        "深度学习",
        "自然语言处理",
        "NLP模型"
      ],
      "input_type": "企业财报电话文本",
      "output_type": "企业数字战略测量结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调数字技术对现代经济和企业的深远影响，引出数字化转型的重要性。作者引用权威文献指出，数字技术既带来机遇也带来威胁，凸显企业在数字化进程中面临的双重挑战，从而自然引出对数字战略研究的需求。",
      "gap_pattern": "作者指出，尽管企业积极采用数字技术，但由于缺乏连贯的数字战略，提升业绩的成功率很低。通过引用行业报告，明确现有研究和实践之间的差距，强调对数字战略现状及其测量方法理解不足，形成研究切入点。",
      "method_story": "方法部分首先指出缺乏通用的公司绩效测量框架，进而提出通过分析数字战略各组成部分（即数字成熟度）进行测量。借鉴NLP领域的aspect-based sentiment analysis任务，创新性地提出Aspect-based Maturity Analysis（ABMA）方法，结合具体话题设定，增强方法的针对性和创新性。",
      "experiments_story": "实验部分以实际应用为导向，选取财富500强公司财报电话会议文本作为数据源，详细描述了数据预处理、文本分类、结果聚合等步骤。通过聚类分析不同公司的数字战略模式，结合标准化处理和特征选择，系统展示了ABMA方法的实用性和适用范围。"
    },
    "tricks": [
      {
        "name": "引用权威文献建立研究背景",
        "type": "writing-level",
        "purpose": "增强论文的可信度和学术基础",
        "location": "引言段落",
        "description": "通过引用权威文献（如Sebastian et al., 2017; World Economic Forum & Bain & Company, 2018）来说明数字技术对企业的影响和当前存在的问题，为研究动机和意义提供坚实的学术支撑。"
      },
      {
        "name": "明确研究对象和数据来源",
        "type": "method-level",
        "purpose": "提高研究的针对性和数据的可获取性",
        "location": "方法介绍部分",
        "description": "明确指出本研究以公司财报电话会议（earnings calls transcripts）为主要数据来源，突出其在揭示企业数字战略方面的信息价值。"
      },
      {
        "name": "构建分析框架并细分核心变量",
        "type": "method-level",
        "purpose": "系统化分析问题，便于后续量化和建模",
        "location": "方法介绍部分",
        "description": "将数字战略细分为三个核心组成部分（business value, strategy management, digital technology），并进一步细化为17个粗粒度主题（aspect），构建分析框架。"
      },
      {
        "name": "借鉴并改造现有NLP任务",
        "type": "method-level",
        "purpose": "利用成熟技术解决新问题，提高方法创新性",
        "location": "方法介绍部分",
        "description": "参考aspect-based sentiment analysis任务，将其改造为Aspect-based Maturity Analysis（ABMA），用于测量公司数字战略成熟度。"
      },
      {
        "name": "采用多标签与多分类结合的建模策略",
        "type": "method-level",
        "purpose": "适应复杂标签体系，实现更细致的文本分类",
        "location": "方法介绍部分",
        "description": "针对aspect属于多标签（labels不互斥），maturity为多类（离散进阶），采用multi-label和multi-class分类相结合的策略，提升模型适用性和分析精度。"
      },
      {
        "name": "详细定义标签体系并附录说明",
        "type": "writing-level",
        "purpose": "保证方法的可复现性和透明性",
        "location": "方法与附录部分",
        "description": "对所有模型标签进行详细定义，并在附录B中给出标签释义，便于他人理解和复现研究。"
      },
      {
        "name": "举例说明分类流程",
        "type": "writing-level",
        "purpose": "帮助读者直观理解方法应用过程",
        "location": "方法介绍结尾",
        "description": "通过给出实际的earnings call文本分类示例，展示模型如何对文本进行aspect和maturity分类，增强方法的可操作性和说服力。"
      },
      {
        "name": "强调无通用框架并突出研究创新性",
        "type": "writing-level",
        "purpose": "凸显本研究在领域内的创新和必要性",
        "location": "引言与方法部分",
        "description": "指出目前没有通用的公司绩效测量框架，尤其在数字战略领域，强调本研究方法的独特性和创新价值。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_37",
    "title": "Real-Valued Logics for Typological Universals: Framework and Application",
    "conference": "COLING",
    "domain": {
      "research_object": "探讨如何利用实值逻辑方法刻画语言类型学中的普遍规律。",
      "core_technique": "采用实值逻辑框架对语言类型学普遍性进行形式化建模与分析。",
      "application": "用于语言学类型学研究，辅助发现和验证语言普遍规律。",
      "domains": [
        "计算语言学",
        "形式语言学"
      ]
    },
    "ideal": {
      "core_idea": "用实值逻辑框架分析和验证语言类型学普遍规律",
      "tech_stack": [
        "实值逻辑",
        "树库分析",
        "类型学数据建模"
      ],
      "input_type": "多语言句法树库数据",
      "output_type": "类型学普遍规律的逻辑表达与验证结果"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍可比树库在多语言中的广泛应用，强调了其对发现自然语言语法系统规律和验证语言类型学理论假设的重要性。作者将研究定位于数据驱动的计算类型学，凸显了当前领域的研究热潮和实际需求。",
      "gap_pattern": "作者指出传统类型学研究多依赖理论假设，缺乏大规模实证数据支持。现有的计算类型学方法虽有进展，但对语法系统中未充分探索的属性间系统性关联研究不足，强调了数据驱动方法补充理论研究的必要性。",
      "method_story": "方法部分强调提出的新框架不仅用于简单的蕴涵和布尔变量分析，更为探索语言类型学空间提供了实证工具。作者明确框架的工具性和方法论价值，并提出需与理论议程结合，推动系统性关联的深入研究。",
      "experiments_story": "实验设计分为三步，先复现并重新评估经典类型学普遍性，分析不同真值和标准差的解释；再展示如何用框架测试新颖的类型学假设。实验流程清晰，突出方法的适用性和探索性，体现系统性实证检验思路。"
    },
    "tricks": [
      {
        "name": "引用和综述前人研究",
        "type": "writing-level",
        "purpose": "展示研究背景和现有方法，明确自己的创新点",
        "location": "论文开头第一段",
        "description": "通过引用大量前人研究（如Universal Dependencies、WALS、URIEL等）和相关文献，梳理领域发展脉络，突出本文方法与现有工作的关系和差异。"
      },
      {
        "name": "数据驱动与知识驱动方法对比",
        "type": "writing-level",
        "purpose": "突出方法创新，说明研究视角",
        "location": "论文第一段",
        "description": "对比基于treebank的数据驱动方法和基于知识库的传统方法，强调数据驱动方法能发现新的语言类型学规律。"
      },
      {
        "name": "明确实验目标和框架用途",
        "type": "writing-level",
        "purpose": "让读者清晰理解研究目标和贡献",
        "location": "论文第二段",
        "description": "直接陈述实验目标和框架最终用途，如‘框架是实证探索语言类型学空间的方法工具’。"
      },
      {
        "name": "分步法阐述研究流程",
        "type": "writing-level",
        "purpose": "结构清晰，便于读者理解复杂实验设计",
        "location": "论文第二段",
        "description": "将研究流程分为三步，分别介绍每一步的内容和作用，使方法逻辑清晰。"
      },
      {
        "name": "重评经典理论以验证框架",
        "type": "experiment-level",
        "purpose": "利用经典理论作为基准，检验新方法有效性",
        "location": "Sec. 4.1",
        "description": "以Greenberg的著名语言普遍性为实验对象，分析框架对已知结论的适用性和解释能力。"
      },
      {
        "name": "生成候选公式以发现新规律",
        "type": "method-level",
        "purpose": "系统探索未知的语言类型学普遍性",
        "location": "论文第二段",
        "description": "采用简单程序生成候选公式，将已知普遍性的逻辑结构与新属性组合，自动化挖掘潜在规律。"
      },
      {
        "name": "使用分层数据集验证泛化能力",
        "type": "experiment-level",
        "purpose": "检验研究结论的稳健性和可泛化性",
        "location": "Sec. 4.2",
        "description": "将treebank数据集分为估算集和保留集，验证发现的规律在不同数据集间的可迁移性。"
      },
      {
        "name": "引入连续变量和标准差分析",
        "type": "method-level",
        "purpose": "丰富变量表达力，超越传统布尔变量",
        "location": "Sec. 4.1",
        "description": "采用实值逻辑和标准差，分析语言属性的变异性，提升对语言类型学空间的刻画能力。"
      },
      {
        "name": "逻辑公式化表达语言普遍性",
        "type": "method-level",
        "purpose": "形式化表达和自动检验语言规律",
        "location": "论文第二段",
        "description": "用命题逻辑公式表达语言属性关系，使普遍性检测自动化、标准化。"
      },
      {
        "name": "强调方法的可拓展性和理论结合",
        "type": "writing-level",
        "purpose": "展现方法的未来潜力和研究价值",
        "location": "论文第二段",
        "description": "指出框架不仅可用于现有属性，还可扩展到尚未充分研究的语法系统属性，并与理论研究结合。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_38",
    "title": "Metrics also Disagree in the Low Scoring Range: Revisiting Summarization Evaluation Metrics",
    "conference": "COLING",
    "domain": {
      "research_object": "自动文本摘要评价指标在低分区间的一致性及其分歧分析。",
      "core_technique": "对主流摘要评价指标进行对比实验和一致性分析，揭示其局限性。",
      "application": "用于改进和选择更可靠的自动摘要评价方法，提高评估质量。",
      "domains": [
        "自然语言处理",
        "文本自动摘要"
      ]
    },
    "ideal": {
      "core_idea": "低分区间自动摘要评价指标之间也存在显著分歧",
      "tech_stack": [
        "自动评价指标分析",
        "相关性统计",
        "元评价方法"
      ],
      "input_type": "摘要系统输出及人工标注",
      "output_type": "评价指标一致性与相关性分析结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调自动评价指标在摘要评测中的重要性，引出对评价指标本身质量进行元评估的必要性。作者梳理了当前主流的两类元评估策略，并明确指出本文聚焦于无需人工标注的指标间相关性分析，提出了具体研究问题，逻辑清晰地引入研究主题。",
      "gap_pattern": "作者指出现有基于人工标注的元评估方法成本高、耗时长，批评其局限性，并以此为切入点，强调缺乏对无需人工标注的指标间相关性分析的系统性研究，明确展示了当前研究的空白和本文工作的创新点。",
      "method_story": "方法部分简明扼要地介绍了所选用的六种自动评价指标，突出它们在语义等价性度量上的不同机制，并说明了各自的技术原理和参数选择，为后续实验设计和结果分析奠定基础，展现了方法选择的合理性和科学性。",
      "experiments_story": "实验部分围绕六种评价指标展开，详细说明了各指标的计算方式和适用场景，强调了对系统生成摘要与参考摘要之间语义等价性的度量，实验设计紧扣研究问题，突出比较性和系统性，确保实验结果具有说服力和推广性。"
    },
    "tricks": [
      {
        "name": "明确研究问题",
        "type": "writing-level",
        "purpose": "聚焦论文目标，指导后续方法设计",
        "location": "引言和方法部分",
        "description": "通过提出两个具体的研究问题（RQ1和RQ2），明确论文的研究方向和目标，有助于结构化论文内容并引导实验设计。"
      },
      {
        "name": "复现和扩展前人实验",
        "type": "method-level",
        "purpose": "验证和补充已有结论，提升研究可信度",
        "location": "方法与实验部分",
        "description": "通过复现Peyrard (2019)的实验，并进一步分析评分区间对指标相关性的影响，既验证了前人的发现，也提出了新的见解。"
      },
      {
        "name": "分区间分析指标相关性",
        "type": "experiment-level",
        "purpose": "细致探究不同评分区间下指标表现差异",
        "location": "实验设计部分",
        "description": "将摘要评分区间划分为低、平均和高三个部分，分别分析指标相关性，揭示指标在不同区间的一致性与分歧。"
      },
      {
        "name": "引入评分区间宽度变量",
        "type": "method-level",
        "purpose": "发现影响指标相关性的关键因素",
        "location": "方法与结果分析部分",
        "description": "不仅关注评分区间本身，还分析区间宽度对指标相关性的影响，发现宽度而非区间位置才是关键影响因素。"
      },
      {
        "name": "多指标对比分析",
        "type": "experiment-level",
        "purpose": "全面评估不同自动化指标的表现",
        "location": "实验部分",
        "description": "选取六种主流自动化评价指标（BERTScore、MoverScore、JS divergence、ROUGE-1、ROUGE-2、ROUGE-L），对系统摘要与参考摘要进行对比分析，提升结论的全面性。"
      },
      {
        "name": "详细指标原理说明",
        "type": "writing-level",
        "purpose": "让读者理解实验方法和指标选择的合理性",
        "location": "方法介绍部分",
        "description": "对每个采用的自动化评价指标进行简要原理说明，包括其计算方式和使用的技术细节，增强论文的可复现性和透明度。"
      },
      {
        "name": "采用无人工标注的元评估方法",
        "type": "method-level",
        "purpose": "降低实验成本，提升实验可扩展性",
        "location": "研究方法部分",
        "description": "选择完全基于自动指标间相关性的评估方法，避免人工标注，节省时间和资源，同时保证实验的客观性。"
      },
      {
        "name": "参考文献支撑方法选择",
        "type": "writing-level",
        "purpose": "增强方法的科学性和权威性",
        "location": "方法介绍及相关工作部分",
        "description": "在阐述方法和指标选择时，引用相关领域权威文献，说明各方法的来历和应用场景，提升论文的学术说服力。"
      },
      {
        "name": "分析参考摘要属性对相关性的影响",
        "type": "method-level",
        "purpose": "探索除评分区间外的其他影响因素",
        "location": "方法与实验部分",
        "description": "除了评分区间宽度，还分析参考摘要的三个属性对指标相关性的影响，扩展了实验维度，丰富了结果解释。"
      },
      {
        "name": "统一指标变体选择",
        "type": "experiment-level",
        "purpose": "保证实验结果的可比性和一致性",
        "location": "实验设计部分",
        "description": "除MoverScore外，所有指标均采用recall变体，确保不同指标间结果具有可比性，避免因变体差异影响结论。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_39",
    "title": "A Systematic Analysis of Text Mining Features: Towards a Holistic Taxonomy",
    "conference": "COLING",
    "domain": {
      "research_object": "系统性分析文本挖掘中的特征，提出全面的特征分类体系。",
      "core_technique": "采用系统性文献分析与特征归纳方法，构建文本挖掘特征的分类框架。",
      "application": "为文本挖掘任务特征选择、算法设计及相关研究提供理论支持和参考。",
      "domains": [
        "自然语言处理",
        "数据挖掘"
      ]
    },
    "ideal": {
      "core_idea": "系统分析文本挖掘特征并提出全面分类法",
      "tech_stack": [
        "文本挖掘",
        "人工神经网络",
        "大数据分析"
      ],
      "input_type": "文本数据，如新闻、社交媒体内容等",
      "output_type": "文本特征分类体系或特征列表"
    },
    "skeleton": {
      "problem_framing": "论文通过列举文本挖掘在多个热门领域的应用（如垃圾邮件检测、体育预测、疫情预测等），强调其广泛关注度和实际价值，快速将读者引入研究主题，突出文本挖掘的现实意义和技术进步。",
      "gap_pattern": "作者在介绍深度学习和迁移学习（如BERT）取得的成功后，指出在某些具体应用场景下，传统机器学习模型可能更具优势，暗示现有研究过于偏重新技术，未充分探讨传统方法的潜力，形成研究空白。",
      "method_story": "方法部分通常会通过对比新旧技术，阐述为何选择特定模型，并详细说明所采用的算法、数据处理流程及参数设置，突出方法的合理性和创新点，回应前文提出的研究空白。",
      "experiments_story": "实验部分往往围绕验证方法有效性展开，设计对比实验，选取具有代表性的数据集和评价指标，系统呈现实验流程和结果，强调方法在实际应用中的表现，回应引言中的应用需求。"
    },
    "tricks": [
      {
        "name": "引用多领域应用案例",
        "type": "writing-level",
        "purpose": "展示研究领域的广泛应用和重要性",
        "location": "开头段落，介绍text mining应用时",
        "description": "通过列举多个具体的应用场景（如垃圾邮件检测、体育表现预测、疫情爆发预测、预测性警务、程序性知识抽取），增强研究的现实意义和说服力。"
      },
      {
        "name": "结合最新技术与传统方法对比",
        "type": "writing-level",
        "purpose": "突出研究的创新性和适用性",
        "location": "介绍ANN、BERT等新技术后，讨论传统机器学习模型的适用场景",
        "description": "对比现代深度学习方法与传统机器学习模型，指出在数据量小、需解释性强的场景下传统方法更优，体现技术选择的合理性和针对性。"
      },
      {
        "name": "强调数据量与模型选择的关系",
        "type": "method-level",
        "purpose": "指导模型选择的实际依据",
        "location": "讨论大数据驱动和小样本情境时",
        "description": "根据可用数据量大小，选择合适的机器学习方法：大数据适合深度学习，小样本场景推荐传统机器学习，并结合实际案例说明。"
      },
      {
        "name": "突出模型透明性与可解释性需求",
        "type": "method-level",
        "purpose": "强调实际应用中模型可解释性的重要性",
        "location": "分析传统模型优势时",
        "description": "指出在需要透明和可解释的实际应用（如人机决策支持、教育反馈、审计等）中，传统模型更易落地，强调方法选择需考虑实际需求。"
      },
      {
        "name": "引用丰富的文献支撑论点",
        "type": "writing-level",
        "purpose": "增强论文的学术权威性和说服力",
        "location": "全段各处引用相关文献",
        "description": "每提出一个观点或应用案例，都配以权威文献作为支撑，体现对前人工作的尊重和研究的系统性。"
      },
      {
        "name": "分层次介绍技术挑战",
        "type": "writing-level",
        "purpose": "清晰呈现研究难点，引出后续方法",
        "location": "段落结尾处，提出主挑战",
        "description": "先介绍应用场景，再聚焦到核心挑战（如文本预处理和特征提取），为后续方法论展开铺垫逻辑基础。"
      },
      {
        "name": "结合具体应用场景说明方法适用性",
        "type": "method-level",
        "purpose": "展示方法的实际价值和适用范围",
        "location": "举例说明传统模型在决策支持、写作反馈等场景",
        "description": "结合人类中心的决策支持、教育反馈等实例，说明方法选择与应用场景密切相关，增强研究的实际意义。"
      },
      {
        "name": "提出文本挖掘的核心技术难点",
        "type": "method-level",
        "purpose": "引出后续研究方法或创新点",
        "location": "段末提出主要挑战",
        "description": "明确指出文本预处理和特征提取是实现高性能信息抽取、数据分析和机器学习的关键难点，聚焦研究问题。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_3",
    "title": "An Analysis of Simple Data Augmentation for Named Entity Recognition",
    "conference": "COLING",
    "domain": {
      "research_object": "针对命名实体识别任务的数据增强方法进行分析与比较，提升模型性能。",
      "core_technique": "采用简单的数据增强策略，结合循环神经网络和Transformer模型进行实验评估。",
      "application": "用于提升生物医学和材料科学领域命名实体识别模型在小数据集上的表现。",
      "domains": [
        "自然语言处理",
        "生物医学信息学",
        "材料科学"
      ]
    },
    "ideal": {
      "core_idea": "探索并比较简单数据增强方法在命名实体识别中的效果",
      "tech_stack": [
        "数据增强",
        "命名实体识别",
        "深度学习"
      ],
      "input_type": "带标注的文本序列（如生物医药或材料科学领域）",
      "output_type": "每个词的实体类别标签序列"
    },
    "skeleton": {
      "problem_framing": "论文通过指出现代深度学习技术对大量标注数据的依赖切入问题，并强调在实际应用中，尤其是生物医学和材料科学等领域，标注数据难以获得，从而凸显研究的现实意义和紧迫性。",
      "gap_pattern": "作者批评现有方法在低资源场景下的局限，强调传统数据标注的高成本和专业性，提出当前领域缺乏有效应对小样本问题的解决方案，为后续提出新方法或改进方法铺垫理论空白。",
      "method_story": "方法部分采用先总述后细化的策略，先介绍主流的迁移学习和数据增强方法，再在实验部分详细说明所选模型和数据集，并在附录中补充技术细节，确保叙述的完整性和可复现性。",
      "experiments_story": "实验部分以实证分析为主线，明确说明所用数据集、模型架构及实验设置，并通过引用附录补充细节，突出实验的系统性和严谨性，同时为结果分析提供坚实基础。"
    },
    "tricks": [
      {
        "name": "引用相关文献支持观点",
        "type": "writing-level",
        "purpose": "增强论文论据的权威性和可信度",
        "location": "引言部分，介绍深度学习和低资源背景时",
        "description": "在阐述深度学习对大量标注数据依赖、领域数据稀缺等问题时，广泛引用相关领域的权威文献作为支持，展示研究背景的充分性。"
      },
      {
        "name": "对比多种现有方法",
        "type": "writing-level",
        "purpose": "突出当前研究在已有方法中的位置，凸显创新点",
        "location": "背景介绍和方法综述部分",
        "description": "系统梳理并简要介绍transfer learning、data augmentation等经典方法，并区分不同任务和领域的应用，明确本研究关注的技术路线。"
      },
      {
        "name": "实用领域数据集选取",
        "type": "experiment-level",
        "purpose": "确保实验结果具有现实意义和可推广性",
        "location": "实验设计部分",
        "description": "选用材料科学和生物医学领域的公开数据集（MaSciP和i2b2 2010），模拟真实应用场景，验证方法在低资源领域的有效性。"
      },
      {
        "name": "多模型对比实验",
        "type": "experiment-level",
        "purpose": "验证方法的通用性和鲁棒性",
        "location": "实验方法部分",
        "description": "采用两种主流序列标注模型（循环神经网络和Transformer）作为backbone，并结合条件随机场输出层，测试数据增强方法对不同模型的效果。"
      },
      {
        "name": "系统调参与网格搜索",
        "type": "method-level",
        "purpose": "获得最优实验结果，提高实验的公平性和可重复性",
        "location": "实验设置部分",
        "description": "对每种数据增强方法，系统调节生成样本数量和binomial分布的p值，采用网格搜索在开发集上寻找最佳超参数组合，确保结果的最优性和可比性。"
      },
      {
        "name": "合理控制变量",
        "type": "experiment-level",
        "purpose": "保证不同方法实验对比的公平性",
        "location": "实验设置部分",
        "description": "在应用所有数据增强方法时，统一调整生成样本数量，使每个原始训练样本生成的总实例数大致相同，排除因数据量不同带来的干扰。"
      },
      {
        "name": "模拟低资源场景",
        "type": "experiment-level",
        "purpose": "测试方法在真实低资源条件下的表现",
        "location": "实验设置部分",
        "description": "通过选取包含实体的前50、150、500条句子，构建不同规模的低资源训练集，真实反映目标应用场景的挑战。"
      },
      {
        "name": "方法自包含性说明",
        "type": "writing-level",
        "purpose": "方便读者理解和复现",
        "location": "方法介绍和附录部分",
        "description": "对采用的模型和方法在正文和附录中进行简要自我描述，并引用详细文献，确保论文内容自洽且便于查阅。"
      },
      {
        "name": "详细实验配置披露",
        "type": "writing-level",
        "purpose": "提升论文透明度和可复现性",
        "location": "附录A",
        "description": "将数据集的详细描述和实验配置放在附录，主文中保持简洁，兼顾信息完整性和可读性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_40",
    "title": "Neural Automated Essay Scoring Incorporating Handcrafted Features",
    "conference": "COLING",
    "domain": {
      "research_object": "自动化作文评分系统，结合神经网络与人工特征进行文本评价。",
      "core_technique": "融合神经网络模型与人工设计特征，提高作文评分的准确性。",
      "application": "用于教育领域的自动作文评分与写作能力评估。",
      "domains": [
        "自然语言处理",
        "教育技术"
      ]
    },
    "ideal": {
      "core_idea": "结合神经网络与人工特征实现自动作文评分",
      "tech_stack": [
        "神经网络",
        "手工特征提取",
        "自动评分模型"
      ],
      "input_type": "学生作文文本",
      "output_type": "作文分数或等级"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过强调作文测试在评估高阶能力（如逻辑思维、批判性推理和创造性思维）中的重要性，引出作文评分的现实需求。接着指出人工评分在效率和主观性上的局限性，自然过渡到自动化作文评分（AES）的研究意义。",
      "gap_pattern": "作者通过引用前人研究，指出人工评分不仅耗时费力，而且主观性强，影响评分准确性，明确了现有方法的不足。随后提出自动评分系统作为解决方案，进一步暗示现有AES方法仍有提升空间，为后文提出新方法埋下伏笔。",
      "method_story": "方法部分采用回顾式叙述，先简要介绍AES领域的传统方法，区分特征工程和神经网络两大类，并通过列举典型系统展示其实际应用。通过对比，突出新方法的创新点和改进之处，为实验部分做铺垫。",
      "experiments_story": "实验部分以实际数据集（ASAP）为基础，详细说明数据来源、样本构成及评价指标，突出实验的科学性和权威性。采用多模型对比和交叉验证，系统展示新方法的有效性，增强结果的说服力和可重复性。"
    },
    "tricks": [
      {
        "name": "文献综述开篇引入法",
        "type": "writing-level",
        "purpose": "引出研究主题，说明研究背景和意义",
        "location": "开头段落",
        "description": "以领域现状和主流观点为切入点，介绍作文评分测试的作用及其在评估高阶能力方面的重要性，并引用相关文献支持，营造学术氛围。"
      },
      {
        "name": "问题与挑战提出法",
        "type": "writing-level",
        "purpose": "明确研究动机，突出研究必要性",
        "location": "背景介绍后",
        "description": "指出人工评分的主观性和效率低下等局限，强调自动评分需求，形成研究的逻辑闭环。"
      },
      {
        "name": "方法分类综述法",
        "type": "writing-level",
        "purpose": "系统梳理研究方法，便于后续细致讨论",
        "location": "方法介绍部分",
        "description": "将自动作文评分方法分为feature-engineering和neural-network两大类，分别简要介绍其代表性方法及优缺点，为后续细节展开做铺垫。"
      },
      {
        "name": "对比优缺点法",
        "type": "writing-level",
        "purpose": "突出方法创新点或改进空间",
        "location": "方法分类描述中",
        "description": "对比特征工程方法的可解释性与工程量大、神经网络方法的自动特征提取能力，凸显新方法的优势或改进动机。"
      },
      {
        "name": "代表性方法举例法",
        "type": "writing-level",
        "purpose": "增强论述说服力，体现领域发展脉络",
        "location": "各方法介绍时",
        "description": "列举具体的AES系统（如PEG、IEA、e-rater、BETSY、IntelliMetric等），并简述其应用场景与技术路线。"
      },
      {
        "name": "引用真实应用案例法",
        "type": "writing-level",
        "purpose": "说明方法实际价值和影响力",
        "location": "方法介绍中",
        "description": "提及e-rater等系统已在TOEFL、GRE等真实考试中担任评分角色，增强方法的现实意义。"
      },
      {
        "name": "特征类型系统化归纳法",
        "type": "method-level",
        "purpose": "帮助读者理解特征工程方法的核心要素",
        "location": "特征工程方法介绍段",
        "description": "将特征类型分为简单（如字数、词数）和复杂（如可读性、语法错误等），并用表格归纳代表性特征。"
      },
      {
        "name": "多模型对比法",
        "type": "method-level",
        "purpose": "展示方法多样性和技术演进",
        "location": "方法介绍中",
        "description": "介绍不同的监督学习模型（回归、分类、排序等）在AES中的应用，展示领域方法的丰富性。"
      },
      {
        "name": "文献引用穿插法",
        "type": "writing-level",
        "purpose": "增强论据权威性，体现学术积累",
        "location": "各论述点后",
        "description": "每提出一个观点或介绍一个系统/方法后，及时引用相关文献，体现研究基础和广泛调研。"
      },
      {
        "name": "分段式结构布局法",
        "type": "writing-level",
        "purpose": "条理清晰，便于读者理解",
        "location": "全文结构",
        "description": "将内容分为背景、问题、方法分类、代表方法、应用案例、特征归纳等模块，层层递进，逻辑清晰。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_41",
    "title": "End to End Chinese Lexical Fusion Recognition with Sememe Knowledge",
    "conference": "COLING",
    "domain": {
      "research_object": "针对中文词汇融合现象进行自动识别，提升中文文本理解能力。",
      "core_technique": "采用端到端模型结合义原知识进行中文词汇融合识别。",
      "application": "可用于中文文本处理、信息抽取及自然语言理解等任务。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "利用义原知识实现端到端的中文词汇融合识别",
      "tech_stack": [
        "端到端神经网络",
        "义原知识融合",
        "中文词汇融合识别"
      ],
      "input_type": "中文文本序列",
      "output_type": "词汇融合识别结果（融合对及其关系）"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾核心指代在语言学和NLP领域的研究，逐步引入中文词汇融合这一新现象，将其定义为两词合并形成新词的指代关系，并强调其在下游任务中的OOV问题，突出研究的现实意义和理论价值。",
      "gap_pattern": "作者指出现有核心指代研究多聚焦于代词、省略等传统类型，而对中文词汇融合这一特殊现象关注不足，且该现象带来的OOV问题在现有方法中未被有效解决，明确提出研究空白和挑战。",
      "method_story": "方法部分采用分步叙述，先介绍整体端到端模型框架，再细化为提及检测与配对聚类两阶段，强调BIO标注和联合建模如何克服流水线方法的误差传播，最后简要描述模型结构以突出创新点。",
      "experiments_story": "实验部分以三元组识别为核心评价标准，系统说明评价指标和结果展示方式，并通过构建对比实验（伪图结构、单字义原）探究模型关键组件影响，展现实验设计的细致性和针对性。"
    },
    "tricks": [
      {
        "name": "引用前沿研究",
        "type": "writing-level",
        "purpose": "展示研究背景和相关工作，凸显研究的学术基础",
        "location": "引言部分，第一段",
        "description": "通过引用大量相关领域的经典和最新文献（如Gordon and Hendrick, 1998; Ng and Cardie, 2002; Lee et al., 2017等），说明所研究问题在学术界的重要性和已有成果。"
      },
      {
        "name": "明确定义新现象",
        "type": "writing-level",
        "purpose": "突出研究创新点，界定研究对象",
        "location": "第二段",
        "description": "提出并详细解释“Chinese lexical fusion”这一新现象，明确其与已有核心指代类别的区别，帮助读者理解研究内容。"
      },
      {
        "name": "举例说明复杂概念",
        "type": "writing-level",
        "purpose": "增强可理解性，具体化抽象理论",
        "location": "第二段及表格说明",
        "description": "通过表格和具体例子（如“受访”、“返杭”、“降息”），直观展示词汇融合现象及其核心指代关系，便于读者把握核心概念。"
      },
      {
        "name": "任务动机与应用场景结合",
        "type": "writing-level",
        "purpose": "强调研究意义和实际价值",
        "location": "第二段",
        "description": "指出词汇融合现象在实际NLP任务（如阅读理解、摘要、机器翻译）中造成的OOV问题，说明本研究对下游任务的帮助。"
      },
      {
        "name": "任务分解与步骤化说明",
        "type": "method-level",
        "purpose": "清晰展示方法流程，便于复现",
        "location": "第三段",
        "description": "将词汇融合识别任务分为“mention detection”和“pair-wise character-word clustering”两步，明确每步的目标和实现方式。"
      },
      {
        "name": "BIO标注方案应用",
        "type": "method-level",
        "purpose": "将识别子任务转化为标准序列标注问题，便于采用成熟方法",
        "location": "第三段",
        "description": "采用BIO标注体系将mention detection转化为序列标注任务，方便用现有模型（如CRF）进行处理。"
      },
      {
        "name": "端到端联合建模",
        "type": "method-level",
        "purpose": "减少误差传递，提高整体性能",
        "location": "第三段",
        "description": "使用端到端模型联合解决mention识别和核心指代识别，避免传统流水线方法中的误差累积问题。"
      },
      {
        "name": "多解码器结构设计",
        "type": "method-level",
        "purpose": "针对不同子任务采用专门解码器，提高细粒度识别效果",
        "location": "第三段",
        "description": "模型结构中分别采用CRF解码器用于mention识别，biaffine解码器用于核心指代识别，实现任务分工与协作。"
      },
      {
        "name": "引入外部知识增强",
        "type": "method-level",
        "purpose": "提升模型语义理解能力",
        "location": "第三段",
        "description": "在模型编码器中融合HowNet的义原知识，丰富语义信息，有助于更准确地识别词汇融合关系。"
      },
      {
        "name": "利用预训练模型",
        "type": "method-level",
        "purpose": "提升特征表达能力，利用最新技术",
        "location": "Encoder部分",
        "description": "采用BERT作为基础编码器，利用其强大的上下文建模能力，为后续任务提供高质量特征表示。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_42",
    "title": "Heterogeneous Graph Neural Networks to Predict What Happen Next",
    "conference": "COLING",
    "domain": {
      "research_object": "利用异构图神经网络对事件序列进行建模，预测后续事件的发展。",
      "core_technique": "采用异构图神经网络方法，融合不同类型节点和关系的信息进行推理。",
      "application": "可应用于事件预测、推荐系统、社交网络分析等需要预测未来行为的场景。",
      "domains": [
        "人工智能",
        "图神经网络"
      ]
    },
    "ideal": {
      "core_idea": "利用异构图神经网络预测事件链中的下一个事件",
      "tech_stack": [
        "异构图神经网络",
        "事件链建模",
        "自然语言处理"
      ],
      "input_type": "事件链结构化表示或文本描述",
      "output_type": "下一个可能发生的事件预测"
    },
    "skeleton": {
      "problem_framing": "论文通过引入事件链（script）这一结构化知识形式，强调其在理解自然语言语义和支持下游任务中的重要性。通过具体场景（如餐厅用餐、抓小偷）举例，直观展示事件链对机器推理能力的促进作用，增强问题现实意义。",
      "gap_pattern": "作者简要回顾现有事件表示方法，指出主要从三方面建模，但未能直接满足事件预测任务的需求。通过对比，隐含现有方法在推理和链式事件预测上的不足，为提出新方法埋下伏笔，突出研究空白。",
      "method_story": "方法部分以任务定义为切入点，明确提出事件预测问题。随后分层次介绍模型架构，将整体流程拆解为编码层、图层和预测层，逐步细化每一层的功能，逻辑清晰地引导读者理解方法设计思路。",
      "experiments_story": "实验部分按任务类型（一步、多步推理）组织，先介绍任务设定及相关数据集，再说明多步推理的三种事件链构建策略。通过分层次、递进式的实验设计，展示模型在不同推理场景下的表现，突出方法有效性。"
    },
    "tricks": [
      {
        "name": "引入研究背景和意义",
        "type": "writing-level",
        "purpose": "引导读者理解研究主题的重要性和应用场景",
        "location": "开头段落",
        "description": "通过介绍事件链（script）的定义和实际应用场景（如‘在餐厅用餐’、‘抓小偷’），强调事件链结构化知识对机器理解自然语言和推理能力的重要性，并指出其在问答、篇章理解、信息抽取等下游任务中的应用。"
      },
      {
        "name": "梳理现有方法并分类",
        "type": "writing-level",
        "purpose": "展示对领域研究现状的把握，为提出新方法做铺垫",
        "location": "第二段",
        "description": "将现有事件链建模方法分为intra-event、individual-event和event-segment三类，并列举相关文献，展示对领域内主流方法的了解和总结。"
      },
      {
        "name": "发现已有方法的不足",
        "type": "writing-level",
        "purpose": "突出自身工作的创新点和必要性",
        "location": "第二段后半部分",
        "description": "指出现有方法主要关注同质目标（如事件间关系），而忽略了异质目标（如词与事件之间的从属关系），强调这一点在事件链建模中的重要性。"
      },
      {
        "name": "明确提出研究问题",
        "type": "writing-level",
        "purpose": "让读者清楚地了解论文要解决的核心问题",
        "location": "第三段",
        "description": "用清晰的语言定义事件预测任务：给定不完整事件链及候选事件集合，选择正确的缺失事件。"
      },
      {
        "name": "模块化方法结构描述",
        "type": "method-level",
        "purpose": "增强方法的条理性和可复现性",
        "location": "方法介绍段落",
        "description": "将整体模型结构分为编码层、图层和预测层三部分，分别介绍每一层的输入、处理过程和输出，有助于读者理解整体流程。"
      },
      {
        "name": "引入异质图建模",
        "type": "method-level",
        "purpose": "提升模型对复杂关系的表达能力",
        "location": "Graph Layer描述部分",
        "description": "在图层中，将词和事件都作为节点，构建包含词-词、词-事件、事件-事件三类边的异质图，通过消息传递机制实现同质和异质节点的信息交互。"
      },
      {
        "name": "基于候选集的预测机制",
        "type": "method-level",
        "purpose": "提升模型在实际应用中的通用性",
        "location": "Prediction Layer描述部分",
        "description": "在预测层中，基于从图层获得的表示，对候选事件进行概率计算，选出最有可能的缺失事件，贴合实际任务需求。"
      },
      {
        "name": "对比基线模型设计",
        "type": "experiment-level",
        "purpose": "验证所提方法的有效性",
        "location": "最后一段",
        "description": "根据模型类型选取了多个最新相关工作作为基线（如Event-comp、Role-factor），便于后续实验对比和结果分析。"
      },
      {
        "name": "借助引用增强论据",
        "type": "writing-level",
        "purpose": "增强论文说服力和学术性",
        "location": "全文",
        "description": "在介绍背景、相关工作、方法细节时，大量引用已有文献，显示对领域的熟悉，并为观点和方法提供支撑。"
      },
      {
        "name": "结合图示辅助说明",
        "type": "writing-level",
        "purpose": "提升方法的可理解性",
        "location": "多处提到图1、图2",
        "description": "通过引用和描述图示（如Fig. 1中的事件链场景、Fig. 2的模型结构），帮助读者更直观地理解复杂概念和模型流程。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_43",
    "title": "Layer-wise Multi-view Learning for Neural Machine Translation",
    "conference": "COLING",
    "domain": {
      "research_object": "针对神经机器翻译模型的层级结构进行多视角学习方法的研究。",
      "core_technique": "提出层级多视角学习方法，融合不同层的表征以提升翻译性能。",
      "application": "用于提升神经机器翻译系统在多语言文本自动翻译中的准确性和鲁棒性。",
      "domains": [
        "自然语言处理",
        "机器翻译"
      ]
    },
    "ideal": {
      "core_idea": "多层多视角学习提升神经机器翻译效果",
      "tech_stack": [
        "多层表示",
        "多视角学习",
        "神经机器翻译"
      ],
      "input_type": "源语言句子文本",
      "output_type": "目标语言句子文本"
    },
    "skeleton": {
      "problem_framing": "论文通过简明回顾NMT主流架构（encoder-decoder）引入研究背景，指出当前模型在编码器顶层表示的依赖，并结合文献引用，突出该范式在实际应用中存在的潜在问题，明确了研究动机和改进空间。",
      "gap_pattern": "作者批评现有方法过度依赖顶层编码器表示，导致过拟合和未能有效利用底层语法语义信息，引用相关工作支持观点，强调这些不足在低资源场景下尤为突出，从而为新方法的提出奠定基础。",
      "method_story": "方法部分采用分步叙述，先简要介绍Transformer作为基础模型，再详细描述所提多视角学习（MV-Transformer）及其训练推理流程，最后通过对比现有多模型集成方法，突出自身创新点，并配以图示辅助理解。",
      "experiments_story": "实验部分系统对比MV-Transformer与三种主流多层融合方法，覆盖多项翻译任务，并细分不同归一化设置。通过量化BLEU分数提升，突出方法在各基线下的稳定优越性，最终以刷新SOTA结果收束，增强说服力。"
    },
    "tricks": [
      {
        "name": "问题引出法",
        "type": "writing-level",
        "purpose": "明确指出现有方法的不足，引出研究动机",
        "location": "开头段落",
        "description": "通过指出NMT模型过度依赖encoder顶层表示存在的两个问题（过拟合和无法充分利用底层信息），自然引出后续改进方法的必要性。"
      },
      {
        "name": "文献对比与归纳",
        "type": "writing-level",
        "purpose": "展示研究基础和创新点，定位本研究与前人工作的关系",
        "location": "相关工作介绍部分",
        "description": "系统性地梳理已有解决方案，将其分为两大类（特征融合、解码器层感知），并对不同方法的实现差异进行简要归纳。"
      },
      {
        "name": "分步介绍方法",
        "type": "writing-level",
        "purpose": "结构化地阐述方法，提升可读性",
        "location": "方法部分",
        "description": "采用分节说明（如§2.1、§2.2、§2.3），先介绍基础模型，再详细描述新方法，最后解释方法有效性。"
      },
      {
        "name": "图示辅助理解",
        "type": "writing-level",
        "purpose": "通过图形化方式帮助读者理解方法流程",
        "location": "方法部分（提及Figure 1）",
        "description": "用图示（如Figure 1）展示所提方法整体流程，增强读者对模型结构和创新点的直观理解。"
      },
      {
        "name": "多模型集成对比实验",
        "type": "experiment-level",
        "purpose": "验证所提方法的有效性，并与多种集成方法进行对比",
        "location": "实验部分",
        "description": "设计与现有多模型集成方法（Oneway-KD、Seq-KD、Ensemble）对比的实验，客观展示新方法的性能优势。"
      },
      {
        "name": "消融分析",
        "type": "experiment-level",
        "purpose": "分析各组成部分对整体性能的贡献",
        "location": "实验部分（对Oneway-KD等方法的分析）",
        "description": "通过去除/修改模型某些机制（如detach主模型梯度），观察性能变化，从而分析方法有效性来源。"
      },
      {
        "name": "多视角学习框架设计",
        "type": "method-level",
        "purpose": "提升模型对不同层次信息的利用能力",
        "location": "方法部分",
        "description": "提出MV-Transformer，将大模型和小模型作为主视角和辅助视角共同训练，实现多层信息互补。"
      },
      {
        "name": "任务实例化",
        "type": "method-level",
        "purpose": "增强方法的通用性和可复现性",
        "location": "方法部分（以Transformer为例）",
        "description": "以Transformer为具体实例，详细说明如何将多视角学习方法应用于主流NMT模型，便于他人复现。"
      },
      {
        "name": "指标和基线明确",
        "type": "experiment-level",
        "purpose": "确保实验结果的可比性和说服力",
        "location": "实验部分",
        "description": "明确采用IWSLT’14 De→En等公开数据集，设置合理的基线（如3层encoder的小模型），保证实验公正性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_44",
    "title": "Semi-supervised Domain Adaptation for Dependency Parsing via Improved Contextualized Word Representations",
    "conference": "COLING",
    "domain": {
      "research_object": "依存句法分析中的领域适应问题，提升跨领域解析性能。",
      "core_technique": "基于改进的上下文词表示，采用半监督领域适应方法优化解析模型。",
      "application": "用于不同领域文本的自动句法结构分析，如新闻、社交媒体等。",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "通过改进上下文词表示，实现依存句法分析的半监督领域自适应。",
      "tech_stack": [
        "半监督学习",
        "领域自适应",
        "上下文词表示（如BERT）"
      ],
      "input_type": "原始句子文本及部分有标签/无标签数据",
      "output_type": "依存句法树结构"
    },
    "skeleton": {
      "problem_framing": "论文通过强调依存句法分析在多项NLP任务中的重要作用引入研究主题，结合具体应用实例（如语义角色标注、自然语言生成、机器翻译）说明其广泛价值，并以形式化定义清晰界定研究对象，帮助读者快速理解研究背景和意义。",
      "gap_pattern": "作者通过回顾近年来神经网络方法在依存句法分析上的显著进步，隐含指出传统离散特征方法的不足，暗示当前主流方法虽有提升但仍有进一步优化空间，为后续提出改进方法埋下伏笔。",
      "method_story": "方法部分采用自上而下的叙述策略，先整体介绍所选用的BiAffine解析器作为强基线，再分模块详细说明输入层、编码器等关键组件，并通过公式和具体技术细节（如BERT增强）突出创新点，逻辑清晰、层层递进。",
      "experiments_story": "实验部分以数据集描述为起点，详细说明多领域数据来源和分布，随后介绍评测指标和训练流程，强调实验设计的科学性和可复现性，通过表格和迭代策略展现严谨的实验组织，便于结果对比和方法验证。"
    },
    "tricks": [
      {
        "name": "定义核心概念",
        "type": "writing-level",
        "purpose": "帮助读者理解论文研究对象",
        "location": "论文开头",
        "description": "对依存句法分析进行定义，并用数学符号描述依存树的结构，明确研究范围和对象。"
      },
      {
        "name": "引用相关工作",
        "type": "writing-level",
        "purpose": "展示领域发展和现有成果，凸显研究背景",
        "location": "第一段",
        "description": "通过引用多篇相关论文，说明依存句法分析在NLP中的重要性及神经网络方法的进展。"
      },
      {
        "name": "引入现实问题",
        "type": "writing-level",
        "purpose": "突出研究意义和实际挑战",
        "location": "第一段后半部分",
        "description": "提出领域自适应问题，强调在真实场景（如网络文本）中依存句法分析仍面临困难，增加研究的实际价值。"
      },
      {
        "name": "采用强基线模型",
        "type": "method-level",
        "purpose": "确保实验结果的可靠性和可比性",
        "location": "第二段开头",
        "description": "选择当前领域最先进的BiAffine parser作为基线，确保后续改进有明确对比对象。"
      },
      {
        "name": "模块化模型结构描述",
        "type": "writing-level",
        "purpose": "清晰展示模型架构，方便理解和复现",
        "location": "第二段",
        "description": "将模型结构分为输入层、BiLSTM编码器、MLP层、BiAffine层，分模块介绍每一部分的功能和作用。"
      },
      {
        "name": "混合嵌入特征",
        "type": "method-level",
        "purpose": "提升模型输入表达能力",
        "location": "输入层部分",
        "description": "将词向量（word2vec和可微调embedding）与POS标签embedding拼接，增强词语表示。"
      },
      {
        "name": "使用预训练语言模型",
        "type": "method-level",
        "purpose": "利用BERT提升模型性能",
        "location": "输入层部分",
        "description": "用BERT生成的词表示替换原有词嵌入，利用预训练模型的强表达能力提升效果。"
      },
      {
        "name": "双向编码获取上下文信息",
        "type": "method-level",
        "purpose": "捕捉句子中的上下文关系",
        "location": "BiLSTM编码器部分",
        "description": "采用三层双向LSTM，对输入序列进行前向和后向编码，并拼接隐藏状态，获得上下文丰富的表示。"
      },
      {
        "name": "简化公式表达",
        "type": "writing-level",
        "purpose": "提高论文可读性，聚焦关键流程",
        "location": "BiLSTM编码器部分",
        "description": "省略复杂计算细节，用简洁公式表示模块输入输出关系，突出主要思路。"
      },
      {
        "name": "分离功能模块的参数",
        "type": "method-level",
        "purpose": "便于模型扩展和调优",
        "location": "BiLSTM编码器公式",
        "description": "将BiLSTM编码器的参数单独表示（θBiLSTM），方便后续实验中调整和优化。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_45",
    "title": "Definition Frames: Using Definitions for Hybrid Concept Representations",
    "conference": "COLING",
    "domain": {
      "research_object": "利用词典定义构建混合型概念表示，提高词汇和概念的语义理解能力。",
      "core_technique": "结合定义信息与分布式表示，提出定义框架以生成更丰富的概念表示。",
      "application": "可用于自然语言处理任务，如词义消歧、知识图谱构建和语义检索等。",
      "domains": [
        "自然语言处理",
        "知识表示"
      ]
    },
    "ideal": {
      "core_idea": "结合定义信息构建混合的概念表示框架",
      "tech_stack": [
        "定义帧",
        "分布式表示",
        "本体知识融合"
      ],
      "input_type": "概念定义文本与本体结构",
      "output_type": "融合语义与分布式特征的概念表示"
    },
    "skeleton": {
      "problem_framing": "论文通过对比本体论与分布式表示在词汇语义中的应用，强调本体论的结构化优势及其难以适应新信息的局限，同时指出分布式方法虽自动化且表现优异，但缺乏可解释性，为后续方法提出需求和背景。",
      "gap_pattern": "作者批评现有分布式表示方法虽能编码大量信息，但缺乏显式语义解释，导致无法针对具体任务选择有用信息，凸显了语义解释与任务适应性之间的研究空白。",
      "method_story": "方法部分采用“框架分解+流程说明”策略，先整体介绍系统由Relation Retriever和DF Encoder两部分组成，再详细说明如何从WordNet定义中抽取Qualia结构关系，并将其编码为分布式表示，突出创新点与流程。",
      "experiments_story": "实验部分采用“标准任务+对比基线”策略，选用多个权威词相似度数据集，并区分词相似与词关联两类任务，明确评价指标和所用嵌入类型，保证实验设计的系统性和结果的可比性。"
    },
    "tricks": [
      {
        "name": "对比现有方法的优缺点",
        "type": "writing-level",
        "purpose": "突出研究动机和创新点",
        "location": "开头段落",
        "description": "通过比较本体方法和分布式表示的优缺点，强调现有方法在语义解释和扩展性上的不足，引出研究的必要性。"
      },
      {
        "name": "提出新概念/方法并命名",
        "type": "writing-level",
        "purpose": "明确展示创新贡献",
        "location": "引入Definition Frames部分",
        "description": "将新方法命名为Definition Frames (DF)，并简要介绍其核心思想和结构，便于后文展开和引用。"
      },
      {
        "name": "模块化框架设计",
        "type": "method-level",
        "purpose": "结构化展示方法流程，便于理解和复现",
        "location": "方法介绍部分",
        "description": "将整体方法分为Relation Retriever和DF Encoder两个模块，分别负责关系抽取和矩阵编码，提升逻辑清晰度。"
      },
      {
        "name": "利用权威资源自动抽取语义关系",
        "type": "method-level",
        "purpose": "提升语义信息的准确性和自动化程度",
        "location": "Relation Retriever介绍",
        "description": "采用WordNet词典定义，通过Relation Retriever模型自动抽取Qualia结构关系，确保语义关系的权威性和覆盖面。"
      },
      {
        "name": "理论基础结合实际应用",
        "type": "writing-level",
        "purpose": "增强方法的理论深度和可解释性",
        "location": "Qualia Structure部分",
        "description": "结合Qualia结构理论，将其具体化为isA、madeOf、usedFor等关系类别，并说明这些关系如何定义概念，有助于后续自动抽取。"
      },
      {
        "name": "人工标注验证关系覆盖性",
        "type": "experiment-level",
        "purpose": "验证方法设计的合理性和覆盖面",
        "location": "Qualia结构关系在定义中的验证",
        "description": "随机抽取并人工标注Wikipedia和WordNet定义，统计Qualia关系的覆盖情况，为自动抽取方法提供数据支持。"
      },
      {
        "name": "数据集自建与说明",
        "type": "experiment-level",
        "purpose": "补充领域缺失的数据资源",
        "location": "Training Data部分",
        "description": "指出领域缺乏现成的Qualia结构标注数据，采用自建标注集并说明采样和标注过程，保证实验的可复现性。"
      },
      {
        "name": "迁移学习/领域适应技术",
        "type": "method-level",
        "purpose": "解决数据稀缺问题，提升模型泛化能力",
        "location": "Training Data部分",
        "description": "利用ConceptNet进行预训练，实现领域适应，为后续在词典定义上的关系抽取提供先验知识。"
      },
      {
        "name": "矩阵化表示关系结构",
        "type": "method-level",
        "purpose": "便于下游任务调用和分析",
        "location": "Definition Frame Encoder部分",
        "description": "将抽取到的关系结构编码为矩阵，每一行对应一个语义关系，便于分布式表示和下游NLP任务应用。"
      },
      {
        "name": "补充细节和实验信息至附录",
        "type": "writing-level",
        "purpose": "提升论文主文的简洁性，便于查阅技术细节",
        "location": "多处提及Appendix A",
        "description": "将详细的定义标注和关系覆盖统计等内容放入附录，主文只突出结论，提升阅读流畅性和专业性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_46",
    "title": "Multitask Easy-First Dependency Parsing: Exploiting Complementarities of Different Dependency Representations",
    "conference": "COLING",
    "domain": {
      "research_object": "多任务依赖句法分析方法，结合不同依赖表示的互补性提升解析效果。",
      "core_technique": "采用Easy-First策略与多任务学习框架，融合多种依赖句法表示进行联合解析。",
      "application": "用于自然语言处理中的自动句法结构分析，提高文本理解与信息抽取能力。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "多任务易先依存句法分析，融合多种依存表示互补信息提升解析效果。",
      "tech_stack": [
        "多任务学习",
        "易先策略",
        "依存句法分析"
      ],
      "input_type": "阿拉伯语句子文本",
      "output_type": "多种依存关系结构"
    },
    "skeleton": {
      "problem_framing": "论文通过定义依存句法分析任务及其在下游应用中的重要性，强调了该领域的实际价值。引言部分不仅介绍了依存句法分析的基本概念，还指出了其在情感分析和信息抽取等任务中的应用，进而引出对阿拉伯语依存句法分析的关注。",
      "gap_pattern": "作者通过介绍阿拉伯语依存句法分析的两种主流形式体系，指出现有研究在表示方法和理论基础上的差异，隐含了当前方法在处理阿拉伯语特有语法现象时的局限性。这样设定为后续提出新方法或改进方案埋下伏笔。",
      "method_story": "方法部分采用先总述后细化的策略，先简要介绍单任务Easy-First解析算法及其核心思想，再引入多任务扩展，并说明其与已有工作的联系和创新点。叙述过程中强调算法的直观理解和操作流程，便于读者把握技术要点。",
      "experiments_story": "实验部分通过详细列举实验设置和参数配置，突出实验的系统性和可复现性。作者采用穷举式的组件组合设计，确保对比公平，并明确说明参数初始化和优化器设置，体现了严谨的实验组织思路。"
    },
    "tricks": [
      {
        "name": "任务与应用场景引入",
        "type": "writing-level",
        "purpose": "明确论文研究任务及其实际应用价值",
        "location": "论文开头",
        "description": "通过介绍依存句法分析任务及其在情感分析、信息抽取等下游任务中的重要作用，增强研究的现实意义和动机。"
      },
      {
        "name": "对比现有两种依存句法标注体系",
        "type": "writing-level",
        "purpose": "呈现研究对象的多样性，突出问题复杂性",
        "location": "相关工作部分",
        "description": "详细介绍阿拉伯语依存句法的两种主流标注体系（CATiB与UD），并分析其各自关注点和设计理念，为后续方法设计奠定基础。"
      },
      {
        "name": "提出联合学习（MTL）动机",
        "type": "writing-level",
        "purpose": "为方法创新提供理论依据",
        "location": "方法介绍前",
        "description": "指出以往工作分别处理两种标注体系，阐述多任务学习（MTL）可通过利用任务间结构或统计上的相似性，提升模型性能。"
      },
      {
        "name": "利用平行树库进行联合训练",
        "type": "method-level",
        "purpose": "实现多任务学习，充分利用数据资源",
        "location": "方法部分",
        "description": "提出在同一输入句子上同时学习CATiB和UD依存树，通过平行树库实现任务间的知识共享与迁移。"
      },
      {
        "name": "借鉴并改进已有算法结构",
        "type": "method-level",
        "purpose": "提升模型性能，增强创新性",
        "location": "方法部分",
        "description": "在单任务Easy-First（EF）算法基础上，结合Constant等人的多任务扩展思想，并针对树结构LSTM进行适配，推动模型进化。"
      },
      {
        "name": "自底向上、贪心式依存树构建策略",
        "type": "method-level",
        "purpose": "高效构建依存结构，简化推断流程",
        "location": "方法细节部分",
        "description": "采用贪心自底向上的树构建策略，每次合并相邻子树，通过减少候选子树数量降低计算复杂度。"
      },
      {
        "name": "递归LSTM编码子树结构",
        "type": "method-level",
        "purpose": "实现子树全局信息表达，提升表示能力",
        "location": "方法细节部分",
        "description": "每个子树根节点由两个方向的LSTM隐状态表示，递归编码所有修饰成分，确保整个子树得到有效表达。"
      },
      {
        "name": "分阶段表述模型组件",
        "type": "writing-level",
        "purpose": "提升论文可读性和逻辑性",
        "location": "方法部分",
        "description": "先简要介绍单任务模型各组件，再阐述多任务扩展，使读者易于理解两者的联系与区别。"
      },
      {
        "name": "引用前人工作并明确创新点",
        "type": "writing-level",
        "purpose": "突出论文贡献，体现学术积累",
        "location": "相关工作与方法部分",
        "description": "通过系统引用相关文献，说明所采用算法的来源及改进之处，帮助读者定位本研究的创新。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_47",
    "title": "Dynamic Curriculum Learning for Low-Resource Neural Machine Translation",
    "conference": "COLING",
    "domain": {
      "research_object": "针对低资源条件下的神经机器翻译模型进行动态课程学习方法的研究。",
      "core_technique": "提出动态课程学习机制，根据数据难度调整训练过程以提升翻译性能。",
      "application": "适用于低资源语言对的自动翻译系统，提高翻译质量和泛化能力。",
      "domains": [
        "自然语言处理",
        "机器翻译"
      ]
    },
    "ideal": {
      "core_idea": "通过动态课程学习提升低资源神经机器翻译性能",
      "tech_stack": [
        "神经机器翻译",
        "动态课程学习",
        "低资源学习"
      ],
      "input_type": "双语平行语料（低资源）",
      "output_type": "高质量翻译文本"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾NMT的最新进展，强调其在高资源场景下的成功，并指出其对大量数据的依赖，进而自然引出低资源场景下的挑战。引言中通过引用相关文献，展示了当前主流的应对策略，为后文聚焦低资源NMT设定背景。",
      "gap_pattern": "作者在介绍现有方法（如数据增强、迁移学习、预训练模型）后，批评这些方法都依赖于外部数据，指出鲜有工作关注如何仅利用双语文本提升低资源NMT效果，从而明确提出研究空白与创新点。",
      "method_story": "方法部分先引用前人提出的curriculum learning框架，详细介绍模型能力的数学定义及其调控方式，并分析其直观性和局限性，特别是在高低资源任务之间的差异，为提出新方法或改进提供理论依据。",
      "experiments_story": "实验部分通过表格对比不同curriculum learning方法的效果，先指出现有方法在低资源场景下表现不佳，再逐步分析动态能力度量的实验结果，结合定量指标和先前分析，层层递进地论证自身观点和方法有效性。"
    },
    "tricks": [
      {
        "name": "引用前沿研究以建立背景",
        "type": "writing-level",
        "purpose": "展示领域发展和研究现状",
        "location": "论文开头",
        "description": "通过引用多个关键文献（如Sutskever et al., 2014; Bahdanau et al., 2015; Vaswani et al., 2017），快速建立NMT的研究背景和主流进展，为后续问题引出做铺垫。"
      },
      {
        "name": "明确指出研究空白",
        "type": "writing-level",
        "purpose": "突出研究创新点和论文贡献",
        "location": "引言部分",
        "description": "在综述已有方法（如数据增强、迁移学习、预训练）后，强调这些方法依赖外部数据，指出利用双语数据提升低资源NMT的研究较少，突出本文工作的独特性。"
      },
      {
        "name": "系统性文献回顾",
        "type": "writing-level",
        "purpose": "为方法选择和创新提供理论依据",
        "location": "相关工作回顾部分",
        "description": "不仅列举现有方法，还讨论如curriculum learning、样本输入顺序等影响训练效果的研究，展示对领域方法论的全面理解。"
      },
      {
        "name": "引入理论支持实验设计",
        "type": "method-level",
        "purpose": "为方法选择提供理论基础",
        "location": "方法提出前",
        "description": "引用Arpit et al. (2017)和Bengio et al. (2009)等工作，说明神经网络倾向于先学习简单样本，理论上支持curriculum learning策略的合理性。"
      },
      {
        "name": "分析现有方法的局限性",
        "type": "method-level",
        "purpose": "为新方法提出提供合理动机",
        "location": "方法介绍前",
        "description": "分析现有curriculum learning中模型competence函数的直观性和非通用性，指出高低资源任务间的差异，为提出动态competence估计方法做铺垫。"
      },
      {
        "name": "提出动态模型competence估计方法",
        "type": "method-level",
        "purpose": "提升低资源NMT训练效果",
        "location": "方法部分",
        "description": "提出在每一阶段基于开发集性能动态估计模型competence，避免依赖训练过程的先验假设，使训练策略更加自适应和实际相关。"
      },
      {
        "name": "采用BLEU作为competence估计指标",
        "type": "experiment-level",
        "purpose": "提高competence估计的相关性和有效性",
        "location": "方法细节部分",
        "description": "比较开发集loss和句级BLEU，选择后者作为competence估计指标，并引用相关文献支持其优越性，增强方法的说服力。"
      },
      {
        "name": "预训练模型以确定curriculum长度",
        "type": "experiment-level",
        "purpose": "规范化训练进程，便于动态competence估计",
        "location": "方法实现部分",
        "description": "通过预训练一个基础NMT模型，并记录开发集上的最佳BLEU，定义curriculum长度，为后续动态competence计算提供参考标准。"
      },
      {
        "name": "公式化描述方法",
        "type": "method-level",
        "purpose": "增强方法的严谨性和可复现性",
        "location": "方法部分",
        "description": "对competence函数给出明确的数学表达式，并详细解释各参数含义，确保方法逻辑清晰、易于实现。"
      },
      {
        "name": "对比不同competence函数的学习曲线",
        "type": "experiment-level",
        "purpose": "验证新方法相较于传统方法的优势",
        "location": "实验结果分析部分（如Section 7.1）",
        "description": "通过展示不同competence函数下模型性能提升的速度，直观反映新方法在低资源场景下的优势。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_48",
    "title": "Creation of Corpus and analysis in Code-Mixed Kannada-English Twitter data for Emotion Prediction",
    "conference": "COLING",
    "domain": {
      "research_object": "基于Twitter的Kannada-English混合语料库进行情感预测分析。",
      "core_technique": "采用自然语言处理方法对代码混合社交媒体文本进行情感标注与预测。",
      "application": "提升社交媒体中多语言用户情感识别与分析能力。",
      "domains": [
        "自然语言处理",
        "情感分析"
      ]
    },
    "ideal": {
      "core_idea": "构建Kannada-English混合语料库并分析其情感预测方法",
      "tech_stack": [
        "语料库构建",
        "情感标注",
        "情感分类模型"
      ],
      "input_type": "Kannada-English混合推文文本数据",
      "output_type": "推文对应的情感类别标签"
    },
    "skeleton": {
      "problem_framing": "论文通过强调社交媒体中用户生成数据的情感识别和分析对于理解日常趋势和人类行为的重要性，引入了情感预测问题，并具体列举了需识别的情感类型，建立了研究的现实意义与应用场景。",
      "gap_pattern": "作者指出以往研究主要集中于单语文本，原因是单语数据规模大，进而批评现有工作忽视了多语言环境下的情感分析，特别是在印度这样多语言、多方言并存且广泛存在代码混用现象的背景下，现有方法存在明显不足。",
      "method_story": "方法部分简要介绍了所采用的情感预测模型，包括SVM和LSTM，表明作者采用了经典机器学习与深度学习方法对自建语料进行建模，突出方法的多样性和针对性。",
      "experiments_story": "实验部分说明了在自建语料上对SVM和LSTM模型进行了对比实验，体现了实验设计的系统性和科学性，旨在验证不同模型在多语言代码混用文本情感预测任务中的有效性。"
    },
    "tricks": [
      {
        "name": "背景引入",
        "type": "writing-level",
        "purpose": "阐明研究的重要性和应用场景",
        "location": "开头段落",
        "description": "通过介绍社交媒体用户生成内容中情感识别的重要性，引出研究主题，帮助读者理解研究的现实意义。"
      },
      {
        "name": "情感类别细化",
        "type": "writing-level",
        "purpose": "明确研究对象",
        "location": "第二句",
        "description": "详细列举了情感分类（如‘Happy’, ‘Sad’, ‘Angry’, ‘Fear’, ‘Surprise’, ‘Disgust’），为后续方法和实验设定清晰目标。"
      },
      {
        "name": "文献回顾",
        "type": "writing-level",
        "purpose": "展示前人研究基础，突出创新点",
        "location": "第三句",
        "description": "简要回顾相关领域已有工作，指出原始研究多关注单语文本，为后续研究多语种/混合语种文本埋下伏笔。"
      },
      {
        "name": "问题背景本土化",
        "type": "writing-level",
        "purpose": "突出研究的地域和语言特色",
        "location": "介绍印度语言环境部分",
        "description": "结合印度多语言、多方言的实际情况，强调研究对象的特殊性和挑战性，增强论文的现实针对性。"
      },
      {
        "name": "术语定义与区分",
        "type": "writing-level",
        "purpose": "为后续研究方法和分析奠定理论基础",
        "location": "关于code-mixing和code-switching的段落",
        "description": "详细区分代码混合（code-mixing）和代码转换（code-switching），并引用权威文献，保证术语使用的准确性。"
      },
      {
        "name": "资源稀缺性强调",
        "type": "writing-level",
        "purpose": "突出研究创新点和必要性",
        "location": "提出Kannada-English混合文本资源有限部分",
        "description": "说明当前相关语料资源的匮乏，强调自己工作的原创性和填补空白的意义。"
      },
      {
        "name": "语料库构建",
        "type": "method-level",
        "purpose": "为后续实验和模型训练提供基础数据",
        "location": "最后一段",
        "description": "针对目标语言对（Kannada-English）构建并注释混合语料库，解决数据资源不足问题。"
      },
      {
        "name": "多模型对比实验",
        "type": "experiment-level",
        "purpose": "验证方法有效性，比较不同模型性能",
        "location": "最后一句",
        "description": "在自建语料库上分别使用SVM和LSTM模型进行情感预测实验，展示不同算法在任务上的表现。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_49",
    "title": "Don’t Patronize Me! An Annotated Dataset with Patronizing and Condescending Language towards Vulnerable Communities",
    "conference": "COLING",
    "domain": {
      "research_object": "针对弱势群体的居高临下和施恩式语言的自动识别与数据标注。",
      "core_technique": "构建并标注包含施恩和居高临下语言的数据集，结合自然语言处理方法进行分析。",
      "application": "用于社交媒体、新闻评论等文本中识别和过滤不当语言，保护弱势群体权益。",
      "domains": [
        "自然语言处理",
        "社会计算"
      ]
    },
    "ideal": {
      "core_idea": "构建并标注媒体中针对弱势群体的居高临下语言数据集",
      "tech_stack": [
        "数据集构建",
        "文本标注",
        "语言分析"
      ],
      "input_type": "媒体文本数据",
      "output_type": "带有居高临下语言标注的数据集"
    },
    "skeleton": {
      "problem_framing": "论文通过定义PCL（居高临下和施恩式语言）及其对弱势群体的潜在危害，引出研究主题。作者强调媒体中PCL的普遍性及其对社会排斥和不平等的影响，从而凸显该问题的现实意义和紧迫性。",
      "gap_pattern": "作者指出，尽管PCL常常出于善意，但其潜在的歧视性和隐蔽性却被忽视。通过引用前人研究，强调媒体中对弱势群体的不公正待遇尚未被充分建模和研究，从而明确现有研究的不足。",
      "method_story": "方法部分采用基线法，系统介绍了用于PCL建模的不同机器学习方法。作者详细说明了输入特征（如段落嵌入、词袋模型）和具体实现细节，为后续实验提供了清晰的技术路径。",
      "experiments_story": "实验部分将任务分为二分类和多标签分类两种设置，分别对应PCL的有无及其具体类别。通过对比多种方法，旨在为后续研究提供基准，实验设计结构清晰、目的明确。"
    },
    "tricks": [
      {
        "name": "定义核心概念",
        "type": "writing-level",
        "purpose": "明确研究对象和范围",
        "location": "论文开头对PCL进行定义",
        "description": "在论文开头对Patronizing and Condescending Language (PCL)进行详细定义，阐明其在媒体中的表现及潜在影响，为后续研究奠定概念基础。"
      },
      {
        "name": "文献对比与差异突出",
        "type": "writing-level",
        "purpose": "突出研究创新点",
        "location": "介绍相关领域已有工作与本研究的区别",
        "description": "通过回顾offensive language、hate speech等相关NLP领域的研究，突出PCL的独特性和先前未被关注的空白，强调本研究的创新性。"
      },
      {
        "name": "任务分解与设置",
        "type": "method-level",
        "purpose": "清晰划分研究任务",
        "location": "方法部分对任务进行分类",
        "description": "将PCL的建模任务分为二分类（是否存在PCL）和多标签分类（PCL类别），便于针对不同目标设计和评估模型。"
      },
      {
        "name": "多方法对比实验",
        "type": "experiment-level",
        "purpose": "提供多种基线，增强实验说服力",
        "location": "方法与实验部分",
        "description": "采用SVM-WV、SVM-BoW、BiLSTM和BERT等多种模型方法进行实验，为后续研究提供丰富的基线和对比。"
      },
      {
        "name": "详细超参数说明",
        "type": "method-level",
        "purpose": "保证实验可复现性",
        "location": "每种模型方法后",
        "description": "对每种模型的关键超参数（如SVM的C、gamma、kernel，BiLSTM的units、dropout、epochs等）进行详细说明，方便他人复现和比较。"
      },
      {
        "name": "利用预训练词向量",
        "type": "method-level",
        "purpose": "提升模型表现和泛化能力",
        "location": "SVM-WV、BiLSTM方法说明中",
        "description": "采用Google News语料训练的Word2Vec词向量作为特征输入，增强模型对文本语义的理解。"
      },
      {
        "name": "早停机制",
        "type": "experiment-level",
        "purpose": "防止模型过拟合",
        "location": "BiLSTM方法描述中",
        "description": "在训练BiLSTM模型时采用early stopping机制，并设置patience参数，确保模型在最佳时刻停止训练，避免过拟合。"
      },
      {
        "name": "多任务设置",
        "type": "method-level",
        "purpose": "增强模型应用广度",
        "location": "任务分解部分",
        "description": "同时设置二分类和多标签分类任务，满足不同实际应用需求，展示方法的灵活性。"
      },
      {
        "name": "引用权威文献支持论述",
        "type": "writing-level",
        "purpose": "增强论述可信度",
        "location": "引言和相关工作部分",
        "description": "通过引用Ng (2007)、Zampieri et al. (2019)、Basile et al. (2019)、Mikolov et al. (2013)、Devlin et al. (2018)等权威文献，为观点和方法提供理论和技术支持。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_4",
    "title": "Logic-guided Semantic Representation Learning for Zero-Shot Relation Classification",
    "conference": "COLING",
    "domain": {
      "research_object": "面向零样本关系分类的语义表示学习方法，提升模型对未见关系的识别能力。",
      "core_technique": "结合逻辑推理与语义表示学习，通过逻辑引导提升关系分类的泛化能力。",
      "application": "用于自然语言处理任务中的关系抽取，特别适用于数据稀缺或新关系场景。",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "利用逻辑引导的语义表示实现零样本关系分类",
      "tech_stack": [
        "逻辑推理",
        "语义表示学习",
        "零样本学习"
      ],
      "input_type": "包含实体对及上下文的文本数据",
      "output_type": "实体对之间的关系类别（包括未见过的关系）"
    },
    "skeleton": {
      "problem_framing": "论文通过定义Relation Classification (RC)任务及其在信息抽取中的重要性，引入了RC在实际应用中的广泛需求，并强调其在知识库构建和问答等下游任务中的核心作用。通过举例和引用相关工作，增强了问题的现实意义和学术价值。",
      "gap_pattern": "作者批评了传统监督式RC方法在实际应用中的局限性，指出现实中存在大量细粒度关系，而标注数据稀缺，导致模型难以泛化到新关系类型。这种gap批评策略通过对比理想与现实，突出当前方法的不足和亟需解决的问题。",
      "method_story": "方法部分采用了递进式叙述，先提出针对上述gap的解决思路，随后引入基于知识图谱嵌入和语义空间构建的新方法。通过逻辑推演和理论支撑，展示方法如何应对标注稀缺和泛化难题，强调创新点和实际意义。",
      "experiments_story": "实验部分通过明确提出三个核心问题，结构化地组织实验目标，分别探讨KG嵌入、语义增强因素及逻辑知识对模型性能的影响。采用问题驱动的方式，突出实验设计的针对性和科学性，便于后续结果分析与讨论。"
    },
    "tricks": [
      {
        "name": "引入研究背景和实际需求",
        "type": "writing-level",
        "purpose": "突出任务的重要性和现实意义，吸引读者兴趣",
        "location": "开头段落",
        "description": "通过介绍Relation Classification任务在信息抽取中的重要性及其在知识库构建、问答等下游任务中的应用，强调该任务的现实需求和研究价值。"
      },
      {
        "name": "指出现有方法的局限性",
        "type": "writing-level",
        "purpose": "为提出新方法或新问题做铺垫，突出研究创新点",
        "location": "背景中部",
        "description": "明确指出传统有监督方法无法满足实际需求，尤其是在细粒度关系众多、标注数据有限的情况下，模型难以泛化到新关系。"
      },
      {
        "name": "举例说明问题",
        "type": "writing-level",
        "purpose": "具体化抽象问题，帮助读者理解研究动机",
        "location": "背景中部（例如Figure 1）",
        "description": "通过具体例子（如basin country为unseen relation）说明零样本关系分类的实际困难，使问题更具象、易于理解。"
      },
      {
        "name": "提出研究紧迫性",
        "type": "writing-level",
        "purpose": "强调研究工作的必要性和前沿性",
        "location": "背景结尾",
        "description": "使用‘urgent’等词汇，强调模型在零样本情景下提取关系的紧迫需求，增强论文的说服力。"
      },
      {
        "name": "回顾并对比相关工作",
        "type": "writing-level",
        "purpose": "展示对领域前沿的了解，为新方法提供理论基础",
        "location": "背景结尾",
        "description": "简要回顾以往零样本关系分类方法（如阅读理解、文本蕴含等），并指出这些方法的不足，如依赖人工描述信息。"
      },
      {
        "name": "借鉴跨领域方法",
        "type": "method-level",
        "purpose": "引入其他领域的先进思想，提升创新性",
        "location": "方法提出前",
        "description": "受计算机视觉领域零样本学习的启发，提出将输入样本特征空间映射到语义空间的思路，拓展了自然语言处理的解决方案。"
      },
      {
        "name": "提出具体研究问题",
        "type": "experiment-level",
        "purpose": "明确实验目标，指导后续实验设计",
        "location": "实验部分开头",
        "description": "清晰列出实验关注的三个核心问题：知识图谱嵌入与词嵌入的对比、强化语义表示的关键因素、逻辑知识对语义空间构建的作用。"
      },
      {
        "name": "提出零样本学习场景",
        "type": "method-level",
        "purpose": "扩展任务难度，体现方法的适用性和前瞻性",
        "location": "背景与方法衔接处",
        "description": "强调需要在零样本场景下进行关系分类，推动模型向更高泛化能力发展，适应实际开放环境。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_50",
    "title": "Improving Abstractive Dialogue Summarization with Graph Structures and Topic Words",
    "conference": "COLING",
    "domain": {
      "research_object": "对话摘要生成，特别是提升抽象式对话摘要的质量和效果。",
      "core_technique": "结合图结构和主题词，改进基于编码器-解码器框架的摘要生成方法。",
      "application": "自动生成对话内容摘要，应用于智能客服、会议纪要等场景。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "结合图结构和主题词提升对话抽象摘要质量",
      "tech_stack": [
        "图结构建模",
        "主题词提取",
        "编码-解码框架"
      ],
      "input_type": "多轮对话文本",
      "output_type": "抽象性对话摘要"
    },
    "skeleton": {
      "problem_framing": "论文通过强调文本信息爆炸性增长和文本摘要在NLP中的重要性引入研究问题，先区分抽取式与生成式方法，并指出生成式方法更接近人类摘要方式，进而引出神经网络在单说话者文档摘要中的进展，设定了研究背景和意义。",
      "gap_pattern": "文中通过回顾已有的抽取式和生成式方法，尤其是神经网络在单说话者文档上的应用，隐含指出对多说话者对话摘要的研究不足，暗示现有方法在对话场景下存在局限，形成研究空白和创新空间。",
      "method_story": "方法部分采用分步叙述策略，先整体介绍模型结构及其四个组成部分，再通过图示（Figure 1）提供直观理解，并详细列举对比基线模型，突出所提方法的创新点和对比基础，逻辑清晰，便于读者理解模型设计。",
      "experiments_story": "实验部分以标准数据集（SAMSum）和评价指标（ROUGE）为基础，系统展示模型与多种基线的对比结果，结合定量数据和现象分析（如Separator的作用），突出方法有效性，并通过与最优模型的对比，强调自身优势。"
    },
    "tricks": [
      {
        "name": "文献综述与分类",
        "type": "writing-level",
        "purpose": "为研究背景和方法分类提供理论基础",
        "location": "论文开头",
        "description": "通过引用大量相关文献，对文本摘要领域进行综述，并明确区分抽取式和生成式两类方法，帮助读者理解研究现状与方法差异。"
      },
      {
        "name": "问题背景对比",
        "type": "writing-level",
        "purpose": "突出研究对象的独特性和挑战",
        "location": "介绍对话文本与新闻文本的区别部分",
        "description": "通过详细描述对话文本与传统新闻文本的差异（如信息流动性、冗长、重复、话题漂移等），强调对话摘要任务的特殊挑战。"
      },
      {
        "name": "模型结构分模块介绍",
        "type": "method-level",
        "purpose": "清晰展示模型设计思路和各部分功能",
        "location": "模型介绍部分",
        "description": "将提出的模型分为四个部分（对话图构建、图编码器、序列上下文编码器、主题词引导解码器），逐步说明各模块作用，便于读者理解整体架构。"
      },
      {
        "name": "使用图结构建模对话",
        "type": "method-level",
        "purpose": "捕捉对话中的复杂关系和上下文信息",
        "location": "方法部分",
        "description": "通过构建对话图，将对话中的发言、话题等信息以节点和边的形式表示，利用图神经网络进行编码，增强模型对对话结构的理解能力。"
      },
      {
        "name": "多种基线模型对比实验",
        "type": "experiment-level",
        "purpose": "验证所提出方法的有效性和优势",
        "location": "实验部分",
        "description": "选取多种主流摘要模型（如Longest-3、Seq2Seq+Attention、Transformer、Pointer Generator等）作为对比基线，全面展示新方法在不同维度上的性能提升。"
      },
      {
        "name": "引用权威方法与最新进展",
        "type": "writing-level",
        "purpose": "增强论文可信度和学术影响力",
        "location": "相关工作与方法介绍部分",
        "description": "广泛引用领域内权威文献和最新方法（如Transformer、Pointer Generator、DynamicConv等），体现研究的前沿性和理论依据。"
      },
      {
        "name": "模型流程图展示",
        "type": "writing-level",
        "purpose": "增强模型结构的可视化和理解性",
        "location": "模型介绍部分（Figure 1）",
        "description": "通过模型流程图直观展示模型各部分及其关系，辅助文字说明，使读者快速把握模型整体框架。"
      },
      {
        "name": "针对性设计主题词引导解码器",
        "type": "method-level",
        "purpose": "提升摘要生成的相关性与凝练性",
        "location": "模型方法部分",
        "description": "引入主题词引导机制，在解码阶段利用话题信息指导摘要生成，提高生成内容的聚焦性和语义一致性。"
      },
      {
        "name": "强调对话摘要的实际应用场景",
        "type": "writing-level",
        "purpose": "突出研究价值和应用前景",
        "location": "研究背景部分",
        "description": "结合电话、邮件、社交网络等实际应用场景，说明对话摘要技术的广泛需求和应用意义，提升研究的现实相关性。"
      },
      {
        "name": "逐步介绍与比较模型创新点",
        "type": "writing-level",
        "purpose": "突出新方法的创新性",
        "location": "模型介绍与对比部分",
        "description": "通过对比现有模型和提出模型的结构与机制，逐步阐述新方法的创新点和针对性改进，增强论文说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_51",
    "title": "Learning to Decouple Relations: Few-Shot Relation Classification with Entity-Guided Attention and Confusion-Aware Training",
    "conference": "COLING",
    "domain": {
      "research_object": "针对少样本关系分类任务，提升模型在有限数据下的关系识别能力。",
      "core_technique": "采用实体引导注意力机制和混淆感知训练方法，提高关系分类准确性。",
      "application": "用于自然语言处理中的关系抽取、知识图谱构建等场景。",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "通过实体引导注意力和混淆感知训练提升小样本关系分类性能",
      "tech_stack": [
        "实体引导注意力机制",
        "混淆感知训练",
        "小样本学习"
      ],
      "input_type": "包含两个实体的句子及少量标注关系样本",
      "output_type": "实体对之间的关系类别"
    },
    "skeleton": {
      "problem_framing": "论文通过定义关系分类任务，并指出现有方法对人工标注数据的依赖，导致在样本不足时性能受限，进而引出‘小样本关系分类’这一关键挑战。随后引用计算机视觉领域的few-shot学习成功经验，为提出新方法做铺垫。",
      "gap_pattern": "作者批评现有方法过度依赖大量标注数据，难以处理样本稀缺的关系类型，明确指出领域内的不足和现实需求。通过引用相关文献，强调该问题的研究价值和紧迫性，形成研究空白。",
      "method_story": "方法部分采用递进式叙述，先介绍整体框架，再细化关键模块（如EGA和CAT），突出创新点。通过与已有方法对比，强调自身方法的独特性和改进点，逻辑清晰地引导读者理解技术路线。",
      "experiments_story": "实验部分结构分明，依次展示模型与主流方法的对比、关键模块的消融实验、可视化案例分析及对特定问题（关系混淆）的验证。通过多角度实证，系统论证方法有效性和适用性，增强说服力。"
    },
    "tricks": [
      {
        "name": "引入现实挑战",
        "type": "writing-level",
        "purpose": "突出研究意义，吸引读者关注",
        "location": "论文开头",
        "description": "通过指出现有方法在标注数据不足情况下的局限性，强调少样本关系分类的挑战性与实际价值。"
      },
      {
        "name": "借鉴跨领域方法",
        "type": "writing-level",
        "purpose": "展示研究的创新点和理论基础",
        "location": "相关工作介绍部分",
        "description": "说明受到计算机视觉领域few-shot learning方法的启发，并引用相关文献，突出方法的新颖性和合理性。"
      },
      {
        "name": "提出基准数据集",
        "type": "method-level",
        "purpose": "为后续实验和方法比较提供标准平台",
        "location": "方法背景介绍",
        "description": "介绍FewRel数据集作为少样本关系分类的标准基准，有助于保证实验的可复现性和对比性。"
      },
      {
        "name": "分析现有方法的不足",
        "type": "writing-level",
        "purpose": "为新方法的提出做铺垫",
        "location": "问题分析部分",
        "description": "指出已有few-shot关系分类模型在多关系、多实体对情况下的表现不佳，强调研究改进的必要性。"
      },
      {
        "name": "举例说明问题",
        "type": "writing-level",
        "purpose": "增强问题描述的直观性和说服力",
        "location": "问题分析部分（如表1说明）",
        "description": "通过具体数据集示例，展示多关系句子中模型混淆的现象，帮助读者直观理解问题。"
      },
      {
        "name": "系统性实验设计",
        "type": "experiment-level",
        "purpose": "全面评估方法效果",
        "location": "实验部分结构",
        "description": "将实验结果分为模型对比、消融实验、可视化分析和问题验证四大部分，系统展示模型性能和改进点。"
      },
      {
        "name": "消融实验",
        "type": "experiment-level",
        "purpose": "验证模型各组成部分的有效性",
        "location": "实验部分",
        "description": "通过移除模型关键组件（如EGA和CAT），分析其对整体性能的影响，证明各模块的贡献。"
      },
      {
        "name": "案例可视化分析",
        "type": "experiment-level",
        "purpose": "直观展示模型内部机制与效果",
        "location": "实验部分",
        "description": "通过展示模型在具体样本上的可视化结果，帮助理解模型对关系证据的识别能力。"
      },
      {
        "name": "针对性问题验证",
        "type": "experiment-level",
        "purpose": "展示模型对特定挑战（如关系混淆）的解决能力",
        "location": "实验部分",
        "description": "专门设计实验验证模型在关系混淆问题上的改进效果，突出模型针对性的优势。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_52",
    "title": "Multi-Word Lexical Simplification",
    "conference": "COLING",
    "domain": {
      "research_object": "针对多词表达的词汇简化方法，提升文本可读性和理解性。",
      "core_technique": "采用自然语言处理技术，自动替换复杂多词表达为更简单的等价表达。",
      "application": "辅助语言学习、阅读障碍者、自动文本简化和信息获取等场景。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "提出多词表达的词汇简化方法，提升文本易读性",
      "tech_stack": [
        "自然语言处理",
        "词汇替换算法",
        "语义保持模型"
      ],
      "input_type": "包含复杂词汇的自然语言文本",
      "output_type": "用更易懂多词表达替换后的简化文本"
    },
    "skeleton": {
      "problem_framing": "论文通过定义文本简化任务及其多样化应用场景，强调该任务对不同用户群体（如二语学习者、科学文本读者等）的重要性。引言以任务定义为起点，逐步引出文本简化的实际需求和挑战，建立研究背景。",
      "gap_pattern": "作者批评了以往仅关注单词替换的简化方法，指出这种方法过于简单，未能覆盖人类实际简化行为的复杂性。通过引用最新研究和数据集，强调现有方法在处理多词替换和句子级操作时的不足，明确研究空白。",
      "method_story": "方法部分以现有单词级无监督简化方法为基础，介绍了自身方法Plainifier的创新点。通过逐步说明候选生成、递归过程及模型训练，突出方法对多词替换复杂性的适应，并以章节分明的方式组织技术细节。",
      "experiments_story": "实验部分通过与人工众包结果对比，验证方法有效性。明确实验数据的选取与划分标准，突出方法无需训练数据但可调优的特点，体现实验设计的科学性和公正性，便于后续结果的量化评估。"
    },
    "tricks": [
      {
        "name": "引入任务背景与应用场景",
        "type": "writing-level",
        "purpose": "阐明研究的重要性与应用价值",
        "location": "论文开头",
        "description": "通过介绍文本简化任务的定义及其广泛应用场景（如二语学习者、普通读者、脑卒中患者等），增强论文的现实意义和吸引力。"
      },
      {
        "name": "阐述现有方法的局限性",
        "type": "writing-level",
        "purpose": "突出研究创新点和必要性",
        "location": "背景介绍后",
        "description": "指出单词替换方法过于简单，不能覆盖人类简化句子的多样操作，如替换、删除、添加和拆分，为提出新任务和方法做铺垫。"
      },
      {
        "name": "提出新任务MWLS",
        "type": "writing-level",
        "purpose": "展示研究创新点",
        "location": "方法介绍前",
        "description": "定义Multi-Word Lexical Simplification（MWLS）任务，强调其区别于传统LS，关注短语级片段替换以提升句子可理解性。"
      },
      {
        "name": "构建并公开新数据集",
        "type": "experiment-level",
        "purpose": "为任务研究提供数据基础",
        "location": "方法部分",
        "description": "通过众包收集1462句、7059条简化数据，保证研究的可复现性和数据丰富性。"
      },
      {
        "name": "扩展已有方法",
        "type": "method-level",
        "purpose": "提升模型适应新任务的能力",
        "location": "方法设计",
        "description": "在Qiang等人（2020）单词简化无监督方法基础上，扩展为可处理多词片段替换的Plainifier方法。"
      },
      {
        "name": "利用BERT生成候选片段",
        "type": "method-level",
        "purpose": "提升候选生成的多样性和上下文相关性",
        "location": "方法细节",
        "description": "采用特定训练的BERT模型，根据上下文递归生成多词候选片段，适应片段长度和结构变化。"
      },
      {
        "name": "多维度候选排序",
        "type": "method-level",
        "purpose": "保证简化片段的质量",
        "location": "方法细节",
        "description": "综合语言模型概率、简易度和语义相似性等指标，对生成的候选片段进行排序，确保输出兼顾简化与语义保持。"
      },
      {
        "name": "针对不同长度片段的比较方法",
        "type": "method-level",
        "purpose": "解决候选片段长度不一致带来的评价难题",
        "location": "方法细节",
        "description": "在候选排序阶段，设计机制比较不同长度的候选片段，保证评估的公平性和有效性。"
      },
      {
        "name": "严格的数据分割与调参",
        "type": "experiment-level",
        "purpose": "保证评估的客观性和泛化能力",
        "location": "实验设计",
        "description": "随机选取100句用于调参，剩余1177句用于评价，避免过拟合并确保结果的可靠性。"
      },
      {
        "name": "与人工结果对比评估",
        "type": "experiment-level",
        "purpose": "验证方法有效性",
        "location": "实验部分",
        "description": "将Plainifier输出与众包人工简化结果对比，采用多参考标准，提升评估的权威性和说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_53",
    "title": "Retrieving Inductive Bias of Attribute as Reference for Review Generation",
    "conference": "COLING",
    "domain": {
      "research_object": "基于属性归纳偏置的参考信息用于自动生成评论文本的方法与机制。",
      "core_technique": "利用属性归纳偏置作为参考，通过深度学习模型提升评论生成的相关性和多样性。",
      "application": "在电商、社交媒体等平台自动生成个性化产品或服务评论，提高用户体验。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "利用属性归纳偏置作为参考生成个性化产品评论",
      "tech_stack": [
        "归纳偏置建模",
        "属性表示学习",
        "文本生成"
      ],
      "input_type": "用户属性信息、产品属性信息",
      "output_type": "针对产品的个性化评论文本"
    },
    "skeleton": {
      "problem_framing": "论文通过引用权威文献，明确界定意见挖掘与情感分析的终极目标，即自动消化用户对产品的观点以辅助决策。作者先介绍现有用户评论的局限性，强调大多数产品并未被用户评论，突出问题的普遍性和现实需求。",
      "gap_pattern": "作者批评现有方法如基于方面的情感分析和推荐系统仅能提供表层输出，缺乏文本评论的表达力。通过对比现有解决方案与理想目标，作者有效揭示了自动生成评论任务的必要性，形成研究动机。",
      "method_story": "方法部分通过简要介绍现有基线模型（Attr2Seq和Cyclegen），强调它们的属性编码方式。随后提出自己的模型GEN，并突出其利用Coarse-和Fine-Grained REFLECT训练检索参考内容的创新点，形成递进式叙述。",
      "experiments_story": "实验部分先交代数据集来源及结构，详细说明每个属性的参考数量统计，增强实验透明度。随后介绍基线和自有模型的对比评估方式，突出实验设计的系统性和对比性，便于后续结果分析。"
    },
    "tricks": [
      {
        "name": "引入研究背景与动机",
        "type": "writing-level",
        "purpose": "阐述研究问题的重要性和现有方法的不足",
        "location": "论文开头",
        "description": "通过介绍意见挖掘和情感分析的终极目标，以及现有方法（如基于方面的情感分析和推荐系统）仅能提供表层输出，强调生成评论的必要性，为提出新方法作铺垫。"
      },
      {
        "name": "定义任务与挑战",
        "type": "writing-level",
        "purpose": "明确任务框架并突出核心难点",
        "location": "任务描述部分",
        "description": "将评论生成任务定义为属性到文本（A2T）问题，并指出从非语言属性学习丰富表示是关键挑战，为后续方法设计提供理论基础。"
      },
      {
        "name": "引用相关工作与方法分类",
        "type": "writing-level",
        "purpose": "展示方法发展历程，定位自身工作",
        "location": "相关工作介绍部分",
        "description": "通过引用模板生成、神经生成等方法，并对比前人工作，突出自身方法的创新点和改进空间。"
      },
      {
        "name": "使用公开数据集进行实验",
        "type": "experiment-level",
        "purpose": "保证实验的可复现性和公平性",
        "location": "实验设置部分",
        "description": "采用前人公开的Amazon书评数据集，便于与已有方法进行直接对比，并使实验结果具有说服力。"
      },
      {
        "name": "详细统计数据集属性",
        "type": "experiment-level",
        "purpose": "展示数据分布，支持实验设计合理性",
        "location": "数据集描述部分",
        "description": "统计用户、商品、评分的参考数量（最小、最大、平均），帮助理解数据稀疏性和多样性，为后续模型设计和结果分析提供依据。"
      },
      {
        "name": "多基线对比实验设计",
        "type": "experiment-level",
        "purpose": "全面评估新方法性能",
        "location": "模型与实验部分",
        "description": "与多个已有方法（如Attr2Seq、Cyclegen）进行对比，报告各自性能，突出新方法在特定指标上的优势。"
      },
      {
        "name": "提出新模型与命名规范",
        "type": "method-level",
        "purpose": "清晰区分不同方法，便于后续讨论",
        "location": "模型介绍部分",
        "description": "对新模型采用系统化命名（如GEN-C-F (RL)、RETRIEVE-C-F），并说明其具体实现细节和创新点，方便对比分析。"
      },
      {
        "name": "多维度自动评价指标设计",
        "type": "method-level",
        "purpose": "全面衡量生成评论的质量",
        "location": "评价指标部分",
        "description": "采用内容相似度（BLEU）和评分准确率（预训练分类器）两类指标，分别衡量文本生成质量和属性表达准确性。"
      },
      {
        "name": "实验结果表格展示",
        "type": "writing-level",
        "purpose": "直观呈现实验对比结果",
        "location": "结果分析部分",
        "description": "通过表格（如Table 1）汇总各方法在不同指标上的表现，使读者易于比较和理解实验结论。"
      },
      {
        "name": "分析检索与生成方法差异",
        "type": "method-level",
        "purpose": "揭示方法优劣，指导后续改进",
        "location": "结果讨论部分",
        "description": "对比检索式和生成式方法在内容相似度和准确率上的表现，分析原因，为未来研究方向提供参考。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_54",
    "title": "Detect All Abuse! Toward Universal Abusive Language Detection Models",
    "conference": "COLING",
    "domain": {
      "research_object": "面向多平台和多语言的普适性辱骂性语言检测模型的构建与评估。",
      "core_technique": "采用深度学习和自然语言处理方法实现跨域辱骂性语言自动识别。",
      "application": "社交媒体、论坛等在线平台的有害内容自动监测与过滤。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "提出通用模型以检测多种类型的网络辱骂语言。",
      "tech_stack": [
        "自然语言处理",
        "深度学习",
        "多任务学习"
      ],
      "input_type": "社交媒体文本或评论数据",
      "output_type": "文本是否包含辱骂语言的分类标签"
    },
    "skeleton": {
      "problem_framing": "论文通过引用权威文献，强调网络社区中辱骂性语言的社会危害，明确提出在线辱骂语言检测（ALD）的研究背景和现实需求，并区分了ALD与相关任务的异同，凸显其研究价值和复杂性。",
      "gap_pattern": "作者指出现有方法（如机器学习、人工审核、词典分析等）虽被广泛应用，但由于用户内容多样和分类难度大，尚无方法能完美解决ALD问题，从而揭示了当前研究的不足和挑战。",
      "method_story": "方法部分采用时间线叙述，梳理了ALD领域从早期基于规则和特征工程，到引入神经网络和深度学习的发展脉络，突出本研究方法在前人工作的基础上的创新和进步。",
      "experiments_story": "实验部分详细说明了数据集、模型配置和训练参数，展示了实验设计的全面性和严谨性，并通过对比不同模型与变体，体现了实验的系统性和对方法有效性的验证思路。"
    },
    "tricks": [
      {
        "name": "引用权威文献建立问题背景",
        "type": "writing-level",
        "purpose": "增强论文的可信度和研究的必要性",
        "location": "开头段落",
        "description": "通过引用多篇权威文献（如Nobata et al., 2016; Razavi et al., 2010等），明确指出在线社区辱骂性语言已成为重要社会问题，为后续研究铺垫背景。"
      },
      {
        "name": "定义研究范围与问题",
        "type": "writing-level",
        "purpose": "明确研究内容和目标，突出研究差异性",
        "location": "开头段落",
        "description": "详细阐述Abusive Language Detection（ALD）的范围，包括侮辱、粗俗、仇恨言论等，并指出现有方法的不足，提出泛化模型的研究问题。"
      },
      {
        "name": "梳理历史发展脉络",
        "type": "writing-level",
        "purpose": "展示领域技术演进，突出自身工作的阶段性意义",
        "location": "第二段",
        "description": "系统回顾从手工特征工程、规则方法到深度学习模型的发展历程，逐步递进，体现领域技术的演变。"
      },
      {
        "name": "对比不同子任务和领域的局限",
        "type": "writing-level",
        "purpose": "强调现有方法的不足，突出泛化需求",
        "location": "开头段落",
        "description": "指出现有ALD模型多聚焦于单一子任务或单一领域，难以迁移到其他社区或任务，突出泛化模型的研究价值。"
      },
      {
        "name": "提出核心研究问题",
        "type": "writing-level",
        "purpose": "明确论文创新点和研究目标",
        "location": "开头段落",
        "description": "以疑问句形式提出“最佳通用ALD模型是什么”，聚焦论文核心目标，引导后续研究。"
      },
      {
        "name": "引用综述性文献梳理现有分类体系",
        "type": "writing-level",
        "purpose": "借助前人工作建立理论基础",
        "location": "开头段落",
        "description": "引用Waseem et al. (2017)的综述性工作，介绍通用辱骂语言分类体系，为后续模型设计提供理论支撑。"
      },
      {
        "name": "多模型方法对比实验",
        "type": "experiment-level",
        "purpose": "验证不同模型在ALD任务上的性能",
        "location": "第二段",
        "description": "罗列并对比多种机器学习与深度学习模型（如SVM, Naive Bayes, CNN, LSTM, HybridCNN等）在不同数据集和任务上的应用与效果。"
      },
      {
        "name": "特征工程与模型结合",
        "type": "method-level",
        "purpose": "提升模型对复杂语言现象的检测能力",
        "location": "第二段",
        "description": "结合词汇、字符、语法等多种特征输入到神经网络模型中，增强模型表达能力，如Nobata et al. (2016)的做法。"
      },
      {
        "name": "用户行为建模",
        "type": "method-level",
        "purpose": "利用用户历史行为提升检测准确性",
        "location": "第二段",
        "description": "通过bi-LSTM或node2vec等方法，将用户历史行为特征融入ALD模型，生成更加丰富的用户表示。"
      },
      {
        "name": "引入最新深度学习框架",
        "type": "method-level",
        "purpose": "提升模型性能和泛化能力",
        "location": "第二段",
        "description": "采用如Bi-GRU、Transformer等最新深度学习架构，提升对复杂语义和上下文的建模能力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_55",
    "title": null,
    "conference": "COLING",
    "domain": {
      "research_object": "未提供论文标题和摘要，无法确定研究对象。",
      "core_technique": "未提供论文标题和摘要，无法确定核心技术。",
      "application": "未提供论文标题和摘要，无法确定应用场景。",
      "domains": []
    },
    "ideal": {
      "core_idea": "提出评估文本内容是否适合儿童阅读的新方法",
      "tech_stack": [
        "自然语言处理",
        "文本可读性分析",
        "儿童语言能力建模"
      ],
      "input_type": "儿童可接触的网络文本内容",
      "output_type": "文本内容对儿童阅读理解能力的适宜性评估结果"
    },
    "skeleton": {
      "problem_framing": "论文通过引用近年来儿童网络安全相关研究，强调该领域的关注度，并指出主流研究多聚焦于有害文本检测，巧妙地将话题引向儿童文本内容与其理解能力的匹配问题，突出研究的重要性与现实需求。",
      "gap_pattern": "作者采用对比批评策略，指出现有研究主要关注文本的有害性，忽视了文本内容是否适合儿童认知水平这一关键问题，从而明确提出当前领域的研究空白和待解决的科学难题。",
      "method_story": "方法部分以任务特性为切入点，将年龄预测建模为回归问题，并细致区分句子级和文本级，重点介绍核心模型（LSTM），结合预训练词嵌入，逐步阐释模型输入、处理流程及输出，逻辑清晰，层层递进。",
      "experiments_story": "实验部分先介绍主要评估指标（MAE），再补充分类评估以增强结果解释力，详细说明判定标准和误差计算方法，通过具体例子辅助理解，体现出实验设计的严谨性和结果解读的多维度性。"
    },
    "tricks": [
      {
        "name": "领域研究现状综述",
        "type": "writing-level",
        "purpose": "引入研究主题并阐明研究空白",
        "location": "论文开头",
        "description": "通过引用近年来相关文献，介绍儿童安全互联网的研究现状，并指出已有研究多关注有害文本，强调儿童可读性问题尚未解决，为后续工作奠定背景。"
      },
      {
        "name": "问题差异化定位",
        "type": "writing-level",
        "purpose": "突出本研究与已有工作的区别",
        "location": "引言部分",
        "description": "明确指出与前人研究关注点不同，本研究聚焦于文本内容与儿童阅读理解能力的适配性，而非有害内容识别。"
      },
      {
        "name": "相关工作对比总结",
        "type": "writing-level",
        "purpose": "展示方法发展脉络，定位自身创新点",
        "location": "相关工作综述段落",
        "description": "列举并简述前人采用的分类、回归、特征工程等方法，突出本研究采用的神经网络模型与前人手工特征或简化方法的区别。"
      },
      {
        "name": "任务建模为回归问题",
        "type": "method-level",
        "purpose": "更贴合年龄连续性特征，提升预测精度",
        "location": "方法介绍部分",
        "description": "根据年龄的连续和顺序特性，将年龄预测建模为回归任务而非分类任务，提高模型对年龄分布的刻画能力。"
      },
      {
        "name": "多粒度建模（句子与文本级）",
        "type": "method-level",
        "purpose": "丰富模型输入，探究不同层级效果",
        "location": "方法部分",
        "description": "分别在句子级和文本级进行年龄预测，分析不同粒度输入对模型表现的影响。"
      },
      {
        "name": "基于LSTM的序列建模",
        "type": "method-level",
        "purpose": "捕捉文本中的时序和上下文依赖关系",
        "location": "方法部分",
        "description": "采用LSTM模型处理输入文本序列，利用其长距离依赖建模能力，提升对文本年龄适配性的预测。"
      },
      {
        "name": "预训练词嵌入特征",
        "type": "method-level",
        "purpose": "利用丰富语义信息提升模型表现",
        "location": "模型输入部分",
        "description": "将输入单词映射为预训练词嵌入，通过投影层输入LSTM，增强模型对语义信息的捕捉能力。"
      },
      {
        "name": "输出策略多样化（直接与区间输出）",
        "type": "method-level",
        "purpose": "探索不同预测方式对结果的影响",
        "location": "方法部分",
        "description": "设计两种输出方式：直接预测均值年龄和预测年龄区间后人工取均值，比较不同策略下模型效果。"
      },
      {
        "name": "双向LSTM模型实验",
        "type": "experiment-level",
        "purpose": "增强模型对上下文信息的理解",
        "location": "方法与实验部分",
        "description": "实验采用双向LSTM结构，同时处理前向和后向序列，提升模型对输入文本的整体理解能力。"
      },
      {
        "name": "基线模型对比",
        "type": "experiment-level",
        "purpose": "验证方法有效性，提供性能参考",
        "location": "实验设计部分",
        "description": "设置两个基线模型，与提出的LSTM方法进行对比，客观评估所提模型的优势。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_56",
    "title": "Deconstruct to Reconstruct a Configurable Evaluation Metric for Open-Domain Dialogue Systems",
    "conference": "COLING",
    "domain": {
      "research_object": "开放域对话系统的评价指标，通过可配置方式提升评估的灵活性和准确性。",
      "core_technique": "将评价指标进行分解与重构，设计可配置的评估框架以适应不同需求。",
      "application": "用于开放域对话系统的自动化性能评估和比较，辅助系统优化。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "提出可配置的对话系统自动评价指标，通过分解重构实现灵活评估。",
      "tech_stack": [
        "评价指标分解",
        "自动化评估方法",
        "对话系统性能比较"
      ],
      "input_type": "对话系统生成的回复及参考回复",
      "output_type": "可配置的评价分数或指标"
    },
    "skeleton": {
      "problem_framing": "论文通过类比机器翻译领域的BLEU指标，强调对话系统自动评价的重要性，并指出其在系统性能比较和技术进步判定中的核心作用。引言以领域通用需求切入，突出自动评价的迫切性和实际意义。",
      "gap_pattern": "作者批评现有研究多依赖人工或众包评价，指出其耗时且成本高，难以满足实际需求。进一步指出已有自动评价方法多为词重叠类指标，未能充分覆盖对话响应的多维质量，形成研究空白。",
      "method_story": "方法部分采用“有效话语预测”模型，强调对话语句与句子的不同，结合语法不完整性等特性构建正负样本。通过具体规则生成训练数据，体现方法设计的针对性和创新性，逻辑清晰地铺陈模型训练流程。",
      "experiments_story": "实验部分详细介绍数据集选择与分割，确保训练和评价的科学性。通过多种生成和检索方法混合构建候选响应，保证评价指标能在优劣样本间充分验证，体现实验设计的全面性和严谨性。"
    },
    "tricks": [
      {
        "name": "借鉴相关领域评价指标",
        "type": "writing-level",
        "purpose": "为自己的研究方法提供合理性和对比基础",
        "location": "引言部分",
        "description": "通过类比机器翻译领域的BLEU等指标，说明对话系统也需要自动化评价指标，并指出相关领域已有的评价方式为本研究提供了参考。"
      },
      {
        "name": "指出现有方法的局限性",
        "type": "writing-level",
        "purpose": "突出自己方法的创新性和必要性",
        "location": "引言部分",
        "description": "明确指出基于词重叠的评价指标（如BLEU、METEOR等）与人工评价的相关性较低，强调对话生成任务的特殊性，从而引出学习型评价指标的必要性。"
      },
      {
        "name": "构建自动评价数据集",
        "type": "method-level",
        "purpose": "为训练自动化评价模型提供数据支撑",
        "location": "方法部分",
        "description": "通过人为构造有效和无效的utterance，结合正负样本生成规则，自动化构建用于模型训练的数据集，减少人工标注成本。"
      },
      {
        "name": "正负样本生成规则设计",
        "type": "method-level",
        "purpose": "提升模型对不同类型输入的区分能力",
        "location": "方法部分",
        "description": "正样本通过三种微扰（去标点、去停用词、不变），负样本通过三种方式（乱序、删词、重复）自动生成，确保训练数据多样性和代表性。"
      },
      {
        "name": "利用BERT进行上下文嵌入",
        "type": "method-level",
        "purpose": "提升评价模型对语义和上下文的理解能力",
        "location": "方法部分",
        "description": "采用BERT对每个词生成上下文相关的嵌入，再通过max-pooling聚合成utterance级别的表示，增强模型的表示能力。"
      },
      {
        "name": "多任务分指标建模",
        "type": "method-level",
        "purpose": "分别捕捉对话响应的不同评价维度",
        "location": "方法部分",
        "description": "分别针对utterance的可理解性（understandability）和合理性（sensibleness）训练不同的模型，针对性地优化不同评价维度。"
      },
      {
        "name": "软判别输出作为评分",
        "type": "method-level",
        "purpose": "获得连续的、可解释的评价分数",
        "location": "方法部分",
        "description": "通过softmax层输出预测概率，并将其作为最终的评价分数，便于后续量化比较。"
      },
      {
        "name": "引用大量相关工作对比和佐证",
        "type": "writing-level",
        "purpose": "增强论证的说服力和学术性",
        "location": "引言及相关工作部分",
        "description": "广泛引用机器翻译和对话系统领域的相关研究，展示方法的理论基础和与现有工作的联系、差异。"
      },
      {
        "name": "自动化vs人工评价对比",
        "type": "experiment-level",
        "purpose": "展现自动化评价的优势和必要性",
        "location": "引言部分",
        "description": "指出人工评价的高成本低效率，强调自动化评价指标在实际研究中的重要性和实用价值。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_57",
    "title": "An empirical analysis of existing systems and datasets toward general simple question answering",
    "conference": "COLING",
    "domain": {
      "research_object": "对现有的简单问答系统和相关数据集进行实证分析，评估其通用性和性能。",
      "core_technique": "采用实证分析方法，比较不同问答系统和数据集在处理简单问题上的表现。",
      "application": "提升自动问答系统在知识检索、智能客服等场景中的准确性和通用性。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "系统性分析现有简单问答系统与数据集，推动通用问答发展",
      "tech_stack": [
        "知识库",
        "自然语言处理",
        "实证分析"
      ],
      "input_type": "自然语言事实型问题",
      "output_type": "知识库中实体-属性的答案"
    },
    "skeleton": {
      "problem_framing": "论文通过强调简单事实问答在自然语言理解中的重要性进行问题引入，指出尽管任务看似简单，但其覆盖了大量真实用户查询，并且在更复杂语义解析中具有关键作用。引用相关文献强化任务的现实意义和研究价值。",
      "gap_pattern": "作者批评现有观点认为该任务已被标准机器学习技术“几乎解决”，通过引用近期文献（Petrochuk and Zettlemoyer, 2018等）指出该结论可能过于乐观，暗示现有方法在泛化和实际应用场景中仍存在不足，提出需要更深入的实证分析。",
      "method_story": "方法部分采用系统性比较策略，明确将不同模型应用于标准化数据集进行评估，并设计跨数据集实验，突出方法的广泛性和实用性。通过结构化分节说明方法流程，便于读者理解整体研究框架。",
      "experiments_story": "实验组织上，作者不仅在单一数据集上进行标准实验，还创新性地设计跨数据集训练与测试，模拟实际应用中的数据分布差异，增强实验的现实相关性。实验细节与数据来源透明，强调结果的可复现性和实用价值。"
    },
    "tricks": [
      {
        "name": "引用前人工作建立研究背景",
        "type": "writing-level",
        "purpose": "展示研究基础和领域现状",
        "location": "引言部分",
        "description": "通过引用多篇相关论文，说明简单事实型问答的重要性及其在语义解析等更复杂任务中的作用，强调该任务的现实意义和当前研究进展。"
      },
      {
        "name": "对比不同数据集和任务定义",
        "type": "writing-level",
        "purpose": "突出研究的创新点和广泛性",
        "location": "引言和方法部分",
        "description": "明确区分不同问答数据集（如SimpleQuestions, WebQuestions等），并讨论它们在数据分布和实际应用中的差异，为后续跨数据集实验做铺垫。"
      },
      {
        "name": "跨数据集鲁棒性测试",
        "type": "experiment-level",
        "purpose": "评估模型泛化能力",
        "location": "方法与实验部分",
        "description": "不仅在单一数据集上训练和测试，还将模型在一个数据集上训练，在另一个数据集上测试，以考察模型对分布变化的鲁棒性。"
      },
      {
        "name": "系统性比较多种现有方法",
        "type": "experiment-level",
        "purpose": "全面评估方法表现",
        "location": "实验部分",
        "description": "选择四个已有问答系统，在多个数据集和不同实验条件下进行统一评测，确保结论具有广泛适用性。"
      },
      {
        "name": "归一化数据集用于公平比较",
        "type": "method-level",
        "purpose": "消除数据集间的偏差影响",
        "location": "方法部分",
        "description": "对不同数据集进行归一化处理，使得各模型在相似输入条件下进行比较，避免数据集本身差异导致的结果偏差。"
      },
      {
        "name": "表格化展示核心实验结果",
        "type": "writing-level",
        "purpose": "清晰呈现实验对比",
        "location": "实验结果部分",
        "description": "使用表格（如Table 3）总结主要实验结果，并通过颜色或灰度区分不同实验设置，便于读者快速获取关键信息。"
      },
      {
        "name": "针对模型表现差异做深入分析",
        "type": "writing-level",
        "purpose": "揭示实验背后的原因",
        "location": "结果分析部分",
        "description": "不止报告准确率，还进一步分析不同数据集表现差异的原因，并在后续章节（如Section 4.2）详细探讨。"
      },
      {
        "name": "结合实际应用场景设置实验",
        "type": "experiment-level",
        "purpose": "提升研究的现实意义",
        "location": "实验设计部分",
        "description": "考虑实际应用中训练数据与真实用户查询分布不一致的问题，设计跨数据集实验以模拟真实环境下的模型表现。"
      },
      {
        "name": "补充实现和资源细节",
        "type": "writing-level",
        "purpose": "增加研究的可复现性",
        "location": "注释/脚注部分",
        "description": "在文中通过脚注补充实现细节（如分数加权方式）和开源代码链接，方便同行复现和进一步研究。"
      },
      {
        "name": "引用最新相关领域趋势",
        "type": "writing-level",
        "purpose": "与前沿研究接轨",
        "location": "引言和相关工作部分",
        "description": "提及近年来在语言理解任务中鲁棒性评估成为研究热点，将本研究与业界最新趋势相结合，增强论文的时效性和研究价值。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_58",
    "title": "Measuring Correlation-to-Causation Exaggeration in Press Releases",
    "conference": "COLING",
    "domain": {
      "research_object": "新闻稿中因果关系夸大现象的测量与分析",
      "core_technique": "采用文本分析和统计方法识别相关性被夸大为因果性的表达",
      "application": "用于提升科学传播准确性，减少公众误解",
      "domains": [
        "科学传播",
        "文本分析"
      ]
    },
    "ideal": {
      "core_idea": "量化新闻稿中将相关性夸大为因果性的现象",
      "tech_stack": [
        "文本分析",
        "统计方法",
        "自然语言处理"
      ],
      "input_type": "新闻稿文本",
      "output_type": "相关性到因果性夸大的测量结果"
    },
    "skeleton": {
      "problem_framing": "论文通过引用多项前沿研究，强调研究机构新闻稿在科学传播中造成误导信息的普遍性和严重性。作者将新闻稿的夸大行为与公众对科学信任的潜在危害直接关联，凸显该问题的现实紧迫性和社会影响力。",
      "gap_pattern": "作者指出，尽管新闻稿在科学传播中的影响力自20世纪80年代以来不断增强，但相关研究多集中于新闻稿内容本身，缺乏对其作为公关工具、对媒体和公众认知的系统性分析，揭示了现有研究的不足和待填补的空白。",
      "method_story": "方法部分通常通过阐述研究设计、数据来源和分析流程，强调其科学性和可重复性。作者可能采用定量分析新闻稿内容与媒体报道之间的关系，并说明如何控制变量以确保结果的有效性和客观性。",
      "experiments_story": "实验部分会详细描述实验设置、样本选择和操作流程，突出实验的逻辑严密性。作者可能通过对比实验组和对照组新闻稿的传播效果，来验证新闻稿夸大对信息误导的具体影响，并用数据支持结论。"
    },
    "tricks": [
      {
        "name": "文献综述引入背景",
        "type": "writing-level",
        "purpose": "为研究问题提供背景和理论基础，展示已有研究成果和不足",
        "location": "开头段落",
        "description": "通过引用多项以往研究，交代新闻稿是科学传播中错误信息的重要来源，强调该问题的研究价值。"
      },
      {
        "name": "引用权威数据和文献",
        "type": "writing-level",
        "purpose": "增强论点的说服力和权威性，支持论述",
        "location": "段落各处",
        "description": "在阐述新闻稿影响力、新闻机构依赖新闻稿、新闻稿质量对新闻报道质量的影响等方面，广泛引用相关权威文献和数据。"
      },
      {
        "name": "问题递进式写作结构",
        "type": "writing-level",
        "purpose": "逐步引导读者聚焦核心问题，理清逻辑关系",
        "location": "全文结构",
        "description": "先从新闻稿对科学传播的影响讲起，再过渡到新闻机构的依赖、新闻稿质量、健康领域的特殊问题，层层递进突出研究重点。"
      },
      {
        "name": "结合现实背景与趋势",
        "type": "writing-level",
        "purpose": "突出研究的现实意义和紧迫性",
        "location": "中间段落",
        "description": "结合1980年代以来竞争加剧、独立新闻业困境等现实背景，说明新闻稿在科学传播中的作用日益突出。"
      },
      {
        "name": "突出研究空白和问题严重性",
        "type": "writing-level",
        "purpose": "明确研究切入点，说明问题的迫切性",
        "location": "段落结尾",
        "description": "强调新闻稿夸大问题在健康研究领域尤为严重，为后文提出研究问题或假设做铺垫。"
      },
      {
        "name": "定性与定量研究结合",
        "type": "method-level",
        "purpose": "全面分析新闻稿对科学传播的影响",
        "location": "引用相关研究方法时",
        "description": "既引用了定量数据（如‘三分之一的新闻稿存在夸大’），也提及定性分析（如‘新闻稿质量影响新闻报道质量’），以增强论证的全面性。"
      },
      {
        "name": "对比分析法",
        "type": "method-level",
        "purpose": "通过对比不同新闻机构和新闻稿质量，分析变量间的关系",
        "location": "引用研究结果时",
        "description": "引用研究显示高质量新闻稿能提升新闻报道质量，暗示通过对比分析揭示新闻稿质量与新闻报道质量的相关性。"
      },
      {
        "name": "多源证据支持",
        "type": "method-level",
        "purpose": "通过多角度证据增强结论的可靠性",
        "location": "段落各处",
        "description": "综合使用多篇不同作者、不同年份的文献，交叉验证新闻稿对科学传播的影响，提高研究说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_59",
    "title": "Named Entity Recognition for Chinese biomedical patents",
    "conference": "COLING",
    "domain": {
      "research_object": "针对中文生物医学专利文本中的命名实体进行识别与抽取。",
      "core_technique": "利用命名实体识别（NER）技术，结合自然语言处理方法处理专利文本。",
      "application": "提升生物医学专利信息的自动化处理与知识抽取能力。",
      "domains": [
        "自然语言处理",
        "生物医学信息学"
      ]
    },
    "ideal": {
      "core_idea": "针对中文生物医学专利进行命名实体识别以促进知识发现",
      "tech_stack": [
        "命名实体识别",
        "生物医学自然语言处理",
        "专利文本处理"
      ],
      "input_type": "中文生物医学专利文本",
      "output_type": "生物医学实体及其类别标注"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍生物医学命名实体识别（NER）在知识发现和药物研发中的重要性，强调该领域的研究热度和实际应用价值。引言部分以任务目标和实际应用场景为切入点，快速建立研究意义和背景。",
      "gap_pattern": "作者在回顾已有英文Bio-NER数据集和任务的基础上，指出中文生物医学NER研究尝试较少，数据资源匮乏，明确提出当前研究领域存在的空白和挑战，从而为后续工作奠定合理性。",
      "method_story": "方法部分采用分步骤叙述，先总述整体流程，再细分为数据收集、标注、模型设计与训练等环节。通过对比三种不同的BERT微调方法，突出创新点和实验设计的多样性，逻辑清晰，便于理解。",
      "experiments_story": "实验部分首先关注数据质量，解释为何采用互F1而非Kappa指标，体现对领域特性的理解。随后说明训练测试集划分原则和数据集规模，为实验结果的可信度和局限性提供背景说明，结构严谨。"
    },
    "tricks": [
      {
        "name": "领域背景与问题陈述",
        "type": "writing-level",
        "purpose": "明确研究背景，突出研究问题和意义",
        "location": "开头段落",
        "description": "通过介绍生物医学命名实体识别（Bio-NER）的研究现状及其在知识发现和药物研发中的重要性，阐明了研究动机，并指出中文领域在数据集和实体类别定义等方面的不足，从而引出本文的研究重点。"
      },
      {
        "name": "相关工作与数据集梳理",
        "type": "writing-level",
        "purpose": "展示已有成果，突出自身工作的创新点和差异性",
        "location": "背景介绍部分",
        "description": "列举了英文Bio-NER的主流数据集和任务（如GENIA, JNLPBA, BC2GM），并分析了中文Bio-NER研究的局限性（例如数据类型、规模、实体类别预定义等），为后续研究工作提供铺垫。"
      },
      {
        "name": "多样本源数据集构建",
        "type": "method-level",
        "purpose": "提升模型泛化能力，覆盖更多实际应用场景",
        "location": "方法部分",
        "description": "不仅关注临床文本和科学出版物，还强调专利文本的重要性，扩展了数据来源，使模型能够适应更复杂的生物医学文本。"
      },
      {
        "name": "多策略模型训练方法设计",
        "type": "method-level",
        "purpose": "比较不同训练方法的效果，提升模型性能",
        "location": "方法部分",
        "description": "设计并实现了三种不同的训练策略，包括全监督微调、语言模型混合微调和部分BERT+CRF微调，分别针对不同的数据利用方式和模型结构进行优化。"
      },
      {
        "name": "预训练模型迁移",
        "type": "method-level",
        "purpose": "利用大规模通用语料提升下游任务表现",
        "location": "方法部分",
        "description": "采用在中文维基百科训练的BERT-base-Chinese作为基础模型，在领域数据上继续微调，使其更适合生物医学领域的命名实体识别任务。"
      },
      {
        "name": "数据集划分与子集构建",
        "type": "experiment-level",
        "purpose": "提升训练效率，便于实验对比和调参",
        "location": "方法部分",
        "description": "从大规模无标注数据中构建两个较小的子集（partBC和partHG），并进行训练集和测试集划分，以便于快速实验和评估。"
      },
      {
        "name": "复用与集成开源工具包",
        "type": "experiment-level",
        "purpose": "提高实验效率与可复现性",
        "location": "实验实现部分",
        "description": "集成使用FlairNLP、PyTorch版BERT和Huggingface实现，减少重复造轮子，保证实验的效率和结果的可复现性。"
      },
      {
        "name": "微调学习率选择",
        "type": "experiment-level",
        "purpose": "提升模型训练稳定性和效果",
        "location": "模型训练描述",
        "description": "在微调BERT及NER层时，选择较小的学习率（5*10^-5），以适应小规模标注数据，防止过拟合和模型退化。"
      },
      {
        "name": "任务流程结构化描述",
        "type": "writing-level",
        "purpose": "清晰展示研究流程，便于读者理解",
        "location": "方法部分开头",
        "description": "将数据收集与清洗、数据标注、模型与学习方法、评估、后分析等步骤结构化描述，提升论文的逻辑性和可读性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_5",
    "title": "Leveraging WordNet Paths for Neural Hypernym Prediction",
    "conference": "COLING",
    "domain": {
      "research_object": "利用WordNet路径信息提升神经网络对上位词关系的预测能力。",
      "core_technique": "结合WordNet知识库路径与神经网络模型进行超上位词关系建模与预测。",
      "application": "用于自动化文本分析、知识图谱构建及自然语言理解任务。",
      "domains": [
        "自然语言处理",
        "知识表示"
      ]
    },
    "ideal": {
      "core_idea": "利用WordNet路径信息提升神经网络对上位词关系的预测能力",
      "tech_stack": [
        "WordNet路径特征",
        "神经网络模型",
        "词嵌入"
      ],
      "input_type": "词对（待预测的词及其可能的上位词）",
      "output_type": "词对间的上位词关系预测结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调hypernymy（上位词关系）在词汇关系中的核心地位及其在WordNet等知识库中的组织作用，引出该关系在实际应用（如问答和阅读理解）中的重要性，并指出现有词嵌入方法在预测hypernymy方面面临挑战，设定研究背景和意义。",
      "gap_pattern": "作者通过引用近期文献，指出hypernymy预测比其他词汇关系更具挑战性，现有方法在准确性和泛化能力上存在不足，尤其是在与WordNet等权威分类体系对比时表现有限，从而明确提出当前研究的不足和改进空间。",
      "method_story": "方法部分采用“新旧对比”策略，先介绍两种新提出的路径生成模型（hypo2path和Path Encoder1），再对比四个基准模型。通过具体任务设定（如序列生成），详细说明模型创新点和技术实现，突出新方法的独特性和理论基础。",
      "experiments_story": "实验部分以评价指标为主线，先解释所用的硬性准确率（H@1）和软性相似度（WuP），并阐述这些指标在关系预测任务中的合理性和实用性。通过指标选择和解释，凸显实验设计的科学性和结果的可比性，为后续结果分析铺垫基础。"
    },
    "tricks": [
      {
        "name": "明确提出核心假设",
        "type": "writing-level",
        "purpose": "突出研究创新点和主线",
        "location": "引言与方法部分",
        "description": "在论文开头明确提出研究的主要假设（knowledge of taxonomy paths will be helpful for hypernymy prediction），为后续方法设计和实验提供理论依据。"
      },
      {
        "name": "聚焦单一关系进行评测",
        "type": "method-level",
        "purpose": "减少变量、突出模型针对性",
        "location": "方法介绍部分",
        "description": "只关注hypernymy关系的预测，而不是混合多种关系，避免不同关系间的性能掩盖，突出模型在目标任务上的表现。"
      },
      {
        "name": "利用完整路径而非单一标签",
        "type": "method-level",
        "purpose": "增强模型获取结构化知识的能力",
        "location": "方法介绍部分",
        "description": "提出利用WordNet中的完整taxonomy路径信息进行预测，而不是仅预测直接的hypernym，提高了模型对层级结构的理解。"
      },
      {
        "name": "序列生成任务建模",
        "type": "method-level",
        "purpose": "利用序列模型挖掘路径信息",
        "location": "方法介绍部分",
        "description": "将hypernym路径预测建模为序列生成任务（sequence generation），使用seq2seq模型生成从根节点到目标的完整路径。"
      },
      {
        "name": "引入标准的基线模型对比",
        "type": "experiment-level",
        "purpose": "确保实验结果的有效性和可比性",
        "location": "方法与实验部分",
        "description": "设计实验时，引入四个benchmark模型作为对比，确保新方法的效果提升有明确参考。"
      },
      {
        "name": "采用LSTM+Attention架构",
        "type": "method-level",
        "purpose": "提升长序列生成能力，防止遗忘",
        "location": "模型设计部分",
        "description": "在seq2seq模型中加入Luong-style attention机制，虽然只有一个源token，但attention有助于防止在长路径生成中遗忘输入信息。"
      },
      {
        "name": "量化Attention机制的增益",
        "type": "experiment-level",
        "purpose": "展示设计选择的实际效果",
        "location": "方法与结果部分",
        "description": "通过实验对比（attention提升noun类H@1约3分），量化说明引入attention机制对模型性能的具体提升。"
      },
      {
        "name": "详细举例说明任务",
        "type": "writing-level",
        "purpose": "帮助读者理解任务设定和模型输入输出",
        "location": "方法介绍部分",
        "description": "用具体实例（如flock.n.02路径生成）直观说明任务目标和模型的输入输出，降低理解门槛。"
      },
      {
        "name": "统一实验评测标准",
        "type": "experiment-level",
        "purpose": "保证结果的公平性与可比性",
        "location": "引言与实验部分",
        "description": "选择统一的评测数据集（如WordNet），并说明与相关工作评测标准的不同，保证实验结果的可比性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_60",
    "title": "Specializing Word Vectors by Spectral Decomposition on Heterogeneously Twisted Graphs",
    "conference": "COLING",
    "domain": {
      "research_object": "针对词向量在异构扭曲图上的专门化方法进行研究，提升词向量的表达能力。",
      "core_technique": "利用谱分解技术在异构扭曲图结构上优化和专门化词向量表示。",
      "application": "可用于自然语言处理任务，如语义理解、词义消歧和文本分析等。",
      "domains": [
        "自然语言处理",
        "图机器学习"
      ]
    },
    "ideal": {
      "core_idea": "通过异构扭曲图的谱分解优化词向量的语义特化",
      "tech_stack": [
        "谱分解",
        "异构图建模",
        "词向量优化"
      ],
      "input_type": "分布式词向量与词关系图",
      "output_type": "语义特化后的词向量"
    },
    "skeleton": {
      "problem_framing": "论文通过强调词嵌入在自然语言处理中的核心地位及其广泛应用，引出分布假设为主流方法基础，进而指出词向量在实际任务中的表现优异，为后续讨论奠定重要性和现实意义。",
      "gap_pattern": "作者批评现有分布式词向量未能区分语义相似性与相关性，导致词向量间的相似度无法准确反映词对间的具体语义关系，举例说明如反义词也可能被错误关联，突出理论与实际需求的差距。",
      "method_story": "方法部分采用形式化定义，先明确词汇、同义词和反义词集合及原始词向量的数学表示，随后引入相似度矩阵和词典信息，逐步构建包含词典传播信息的模型，逻辑严密、层层递进。",
      "experiments_story": "实验部分先概述评测任务及基本设置，明确采用的词嵌入方法和词典约束来源，随后介绍主要对比基线及额外尝试的方法，突出方法有效性验证的全面性和对比性，结构清晰有条理。"
    },
    "tricks": [
      {
        "name": "引入研究背景和现有问题",
        "type": "writing-level",
        "purpose": "明确研究领域和突出问题",
        "location": "论文开头",
        "description": "通过介绍词嵌入在NLP中的重要性及其广泛应用，随后指出分布式词向量混淆语义相似性与相关性的问题，为后续方法提出奠定基础。"
      },
      {
        "name": "引用并对比相关工作",
        "type": "writing-level",
        "purpose": "增强论证和权威性",
        "location": "现有方法讨论部分",
        "description": "通过引用Hill et al. (2015)、Yih et al. (2012)、Mrkšić et al. (2017)、Pham et al. (2015)等相关文献，阐述现有方法的不足和已有解决思路，为新方法的提出做铺垫。"
      },
      {
        "name": "数学符号和集合定义",
        "type": "method-level",
        "purpose": "规范方法流程，便于后续推导",
        "location": "方法部分开头",
        "description": "用集合符号明确定义词汇表V、同义词集合S、反义词集合A，以及词向量矩阵X和相似度矩阵W，为后续算法描述和公式推导提供清晰基础。"
      },
      {
        "name": "引入词典约束进行向量调整",
        "type": "method-level",
        "purpose": "提升词向量的语义区分能力",
        "location": "方法部分",
        "description": "通过引入同义词和反义词词典信息（S0和A0），结合原始词向量相似性，调整词向量使同义词更近、反义词更远，实现语义特化。"
      },
      {
        "name": "矩阵运算建模词典传播信息",
        "type": "method-level",
        "purpose": "捕捉间接语义关系",
        "location": "方法推导部分",
        "description": "通过定义词典传播（contagion）信息，并利用矩阵乘法T1 = T0T0，建模词汇间间接的同义和反义关系，增强语义信息的覆盖面。"
      },
      {
        "name": "分步提取同义与反义传播信息",
        "type": "method-level",
        "purpose": "细粒度区分不同语义关系",
        "location": "方法推导后半部分",
        "description": "根据传播矩阵T1的正负值分别提取同义传播信息S1和反义传播信息A1，实现对不同语义关系的精细建模。"
      },
      {
        "name": "多源信息融合优化相似度矩阵",
        "type": "method-level",
        "purpose": "综合提升词向量语义质量",
        "location": "方法结尾",
        "description": "将原始相似度矩阵W与词典直接信息（S0、A0）和传播信息（S1、A1）通过加权组合，得到词典注入后的优化相似度矩阵Ŵ，实现多源信息融合。"
      },
      {
        "name": "用具体例子说明理论缺陷",
        "type": "writing-level",
        "purpose": "增强可理解性和说服力",
        "location": "问题描述部分",
        "description": "通过举例说明反义词词向量可能距离很近，导致难以区分，直观展示分布式词向量的局限性。"
      },
      {
        "name": "结构化分步推导公式",
        "type": "method-level",
        "purpose": "提升方法逻辑清晰度",
        "location": "方法公式推导部分",
        "description": "方法描述采用分步递进、逐步推导公式的结构，便于读者理解每一步的数学意义和整体逻辑。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_61",
    "title": "KINNEWS and KIRNEWS: Benchmarking Cross-Lingual Text Classification for Kinyarwanda and Kirundi",
    "conference": "COLING",
    "domain": {
      "research_object": "针对Kinyarwanda和Kirundi两种语言的跨语言文本分类任务进行基准测试。",
      "core_technique": "采用跨语言文本分类方法，构建和评估多语言数据集与模型性能。",
      "application": "提升低资源语言的自动文本分类能力，支持多语言信息处理和智能应用。",
      "domains": [
        "自然语言处理",
        "跨语言学习"
      ]
    },
    "ideal": {
      "core_idea": "构建并评测Kinyarwanda和Kirundi跨语言文本分类基准数据集",
      "tech_stack": [
        "深度学习",
        "跨语言文本分类",
        "数据集构建"
      ],
      "input_type": "Kinyarwanda和Kirundi语言的新闻文本",
      "output_type": "文本分类标签及基准评测结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调近年来神经文本处理和大规模语料库推动文本分类质量提升，引入研究背景。作者将关注点聚焦于低资源语言，指出这些语言因缺乏标注数据而受限，巧妙地将技术进步与现实问题结合，突出研究的重要性。",
      "gap_pattern": "作者采用gap批评策略，指出尽管技术进步显著，但低资源语言因缺乏可用数据而被边缘化。通过引用文献和实际案例，强调现有方法在多语言环境下的局限性，为后续研究动机和贡献奠定基础。",
      "method_story": "方法部分采用逐步叙述策略，先说明数据预处理的重要性，再详细介绍实验设计，包括数据集划分、特征提取方式（如TFIDF）、模型选择等。通过具体操作流程，增强方法的透明度和可复现性。",
      "experiments_story": "实验部分以系统化组织为主，强调基准实验的多模型对比和数据集兼容性处理。通过明确的数据集调整和实验设置，突出实验的严谨性和针对性，为后续结果分析提供坚实基础。"
    },
    "tricks": [
      {
        "name": "背景与动机阐述",
        "type": "writing-level",
        "purpose": "说明研究的现实意义和学术价值，突出低资源语言的挑战与机遇",
        "location": "论文开头",
        "description": "通过介绍近年来神经文本处理和大规模语料库的进步，强调低资源语言在文本分类领域面临的数据匮乏问题，并结合非洲新闻机构语言多样化的新趋势，为后续研究设定背景和动机。"
      },
      {
        "name": "数据来源选择与说明",
        "type": "method-level",
        "purpose": "确保低资源语言数据的可靠性与可获取性",
        "location": "方法部分",
        "description": "明确选择在线新闻作为低资源语言（如Kinyarwanda和Kirundi）的数据来源，强调新闻报道的权威性和覆盖面，说明数据采集的合理性和实用性。"
      },
      {
        "name": "数据清洗与预处理",
        "type": "method-level",
        "purpose": "提高模型训练质量，减少噪声影响",
        "location": "实验部分",
        "description": "在所有实验中使用预处理后的数据集，去除原始数据中的噪声，保证后续实验的有效性和可复现性。"
      },
      {
        "name": "训练集与验证集的合理划分",
        "type": "experiment-level",
        "purpose": "确保模型评估的科学性和公平性",
        "location": "实验设置部分",
        "description": "采用9:1的比例划分训练集和验证集，保证有足够数据进行训练，同时留出部分数据用于模型性能评估。"
      },
      {
        "name": "类别兼容性处理",
        "type": "method-level",
        "purpose": "保证交叉测试的公平性和可比性",
        "location": "实验设置部分",
        "description": "在实验中将KINNEWS数据集中的旅游和时尚类别样本移除，使训练集与KIRNEWS测试集的类别分布一致，避免类别不匹配导致的误差。"
      },
      {
        "name": "特征工程—TFIDF特征构建",
        "type": "method-level",
        "purpose": "提升传统机器学习模型的文本表示能力",
        "location": "经典模型方法部分",
        "description": "对文本进行TFIDF处理，提取unigram特征，依据训练集和方法设定最大特征数，为后续经典机器学习模型（如MNB、LR、SVM）提供有效输入。"
      },
      {
        "name": "模型实现统一框架",
        "type": "experiment-level",
        "purpose": "保证实验的可复现性与结果对比的公平性",
        "location": "模型实现部分",
        "description": "所有经典机器学习模型均使用scikit-learn框架，并采用默认超参数，确保不同模型之间的实验条件一致。"
      },
      {
        "name": "预训练词向量迁移学习",
        "type": "method-level",
        "purpose": "模拟低资源场景下的实际应用，提升神经网络模型效果",
        "location": "神经网络模型方法部分",
        "description": "神经网络模型采用预训练词向量作为输入，在任务上进行微调，模拟仅有少量标注数据但可获得词嵌入的实际低资源场景。"
      },
      {
        "name": "多模型对比实验设计",
        "type": "experiment-level",
        "purpose": "系统评估不同方法在低资源文本分类上的表现",
        "location": "实验部分",
        "description": "在同一数据集上分别测试多种经典和神经网络模型，包括MNB、LR、SVM、Char-CNN等，形成全面对比，突出各类方法的优劣。"
      },
      {
        "name": "引用相关工具和文献",
        "type": "writing-level",
        "purpose": "增强论文的可追溯性与学术规范性",
        "location": "脚注与参考文献部分",
        "description": "在方法和数据处理描述中适当引用相关工具（如gensim、scikit-learn）和前人工作，提升论文的权威性和学术交流性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_62",
    "title": "A Human Evaluation of AMR-to-English Generation Systems",
    "conference": "COLING",
    "domain": {
      "research_object": "对AMR到英语生成系统进行人工评估，分析其生成质量和表现。",
      "core_technique": "采用人工评价方法对语义图到文本生成系统进行性能测量。",
      "application": "用于提升和验证自动语义到文本生成系统在实际应用中的有效性。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "对AMR到英文生成系统进行人工评价，分析其效果与不足。",
      "tech_stack": [
        "AMR语义表示",
        "自然语言生成",
        "人工评价方法"
      ],
      "input_type": "AMR语义图（有向无环图表示句子语义）",
      "output_type": "英文自然语言句子"
    },
    "skeleton": {
      "problem_framing": "论文通过定义AMR及其示例，明确介绍了AMR在句子意义表达中的作用，并指出其不涵盖形态和句法细节，强调AMR生成任务的挑战性，为后续研究动机奠定基础。",
      "gap_pattern": "作者批评了现有AMR生成系统主要依赖自动化评测指标（如BLEU），指出这些指标在自然语言生成任务中存在局限，强调缺乏细致的人类评估是当前研究的不足。",
      "method_story": "方法部分采用分段叙述，先整体介绍了人类评估设计，再细化为试点调查和正式评估，逐步验证方法的有效性，并通过对比不同系统，突出评估流程的科学性。",
      "experiments_story": "实验部分首先说明匿名投稿背景，随后详细描述人类评估流程，包括流畅性、充分性打分及错误类型归类，并与自动指标结果对比，突出人类评估带来的细致洞察和系统性误差分析。"
    },
    "tricks": [
      {
        "name": "定义关键术语与示例",
        "type": "writing-level",
        "purpose": "帮助读者快速理解研究对象",
        "location": "开头段落",
        "description": "在论文开头对AMR（Abstract Meaning Representation）进行定义，并通过具体例子展示其结构和表达能力，便于读者直观理解。"
      },
      {
        "name": "突出研究难点与挑战",
        "type": "writing-level",
        "purpose": "强调研究工作的必要性与创新点",
        "location": "背景介绍部分",
        "description": "指出AMR生成任务难以评估，因同一AMR可对应多种有效句子，自动评价指标存在局限，为后续提出人类评测方法做铺垫。"
      },
      {
        "name": "应用场景举例",
        "type": "writing-level",
        "purpose": "增强研究工作的实际意义",
        "location": "背景介绍部分",
        "description": "列举AMR生成在摘要生成、机器翻译等NLP任务中的应用，说明研究工作的广泛价值。"
      },
      {
        "name": "对比自动与人工评价方法",
        "type": "method-level",
        "purpose": "验证评价方法的有效性",
        "location": "方法描述部分",
        "description": "将自动评价指标（如BLEU）与人工评价（流畅性、充分性、错误类型分类）进行对比，分析各自优缺点，强调人工评价的必要性。"
      },
      {
        "name": "多维度人工评价设计",
        "type": "method-level",
        "purpose": "全面评估生成系统质量",
        "location": "实验方法部分",
        "description": "人工评价不仅收集流畅性和充分性分数，还对错误类型进行分类，获得更细致的系统表现分析。"
      },
      {
        "name": "分阶段实验流程",
        "type": "experiment-level",
        "purpose": "确保实验设计的科学性和可复现性",
        "location": "实验设计说明（§3.1-§3.3）",
        "description": "实验分为总体验证、先导实验（pilot survey）和对最新系统的评测，逐步完善和验证实验方法。"
      },
      {
        "name": "引用与批判已有工作",
        "type": "writing-level",
        "purpose": "展示对领域现状的了解，并说明本研究改进之处",
        "location": "相关工作与自动评价指标讨论部分",
        "description": "引用May and Priyadarshi (2017)等工作，指出BLEU等自动指标与人工评价结果不一致，强调本研究创新点。"
      },
      {
        "name": "错误分析",
        "type": "experiment-level",
        "purpose": "深入理解系统不足，指导后续改进",
        "location": "实验结果分析部分",
        "description": "对系统常见错误进行归类和分析，帮助识别性能瓶颈和改进方向。"
      },
      {
        "name": "结果对比分析",
        "type": "experiment-level",
        "purpose": "验证实验结论的可靠性",
        "location": "实验结果讨论部分",
        "description": "比较人工评价和自动指标在系统排序上的一致性与差异，分析自动指标的适用性和局限性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_63",
    "title": "Investigating Catastrophic Forgetting During Continual Training for Neural Machine Translation",
    "conference": "COLING",
    "domain": {
      "research_object": "神经机器翻译模型在持续训练过程中灾难性遗忘现象的研究",
      "core_technique": "分析和缓解神经机器翻译中灾难性遗忘的算法与方法",
      "application": "提升神经机器翻译系统在多任务或增量学习下的性能稳定性",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "分析NMT模型在持续训练中灾难性遗忘现象及其影响。",
      "tech_stack": [
        "神经机器翻译",
        "持续学习",
        "灾难性遗忘分析"
      ],
      "input_type": "NMT模型及不同领域训练数据",
      "output_type": "模型性能变化及遗忘现象评估结果"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾NMT模型的成功与局限，强调其在大规模数据下表现优异，但在特定领域小数据场景下存在挑战。通过引用相关文献，逐步引出实际应用中模型迁移与适应的需求，为后续研究动机埋下伏笔。",
      "gap_pattern": "作者指出现有NMT模型在特定领域小数据情况下表现不足，虽然常用的持续训练（微调）方法能提升领域内性能，但未能系统性解决灾难性遗忘等问题，暗示当前方法存在改进空间。",
      "method_story": "方法部分采用理论推导与文献借鉴相结合的方式，详细介绍基于泰勒展开的参数重要性评估准则。通过公式推导，明确阐释如何量化参数对损失函数的影响，为后续实验设计提供理论基础。",
      "experiments_story": "实验部分通过对比不同模块冻结与更新的策略，结合可视化结果（如柱状图），系统分析各模块对泛化与领域适应的影响。通过定量指标（BLEU）和现象解释，突出关键发现并与前述理论假设呼应。"
    },
    "tricks": [
      {
        "name": "引用前沿研究作为背景",
        "type": "writing-level",
        "purpose": "建立研究背景和权威性",
        "location": "论文开头",
        "description": "通过引用多个领域内权威和前沿的论文（如Kalchbrenner and Blunsom, 2013; Vaswani et al., 2017），展示NMT模型的研究进展和广泛应用，为后续问题引出做铺垫。"
      },
      {
        "name": "问题引入与实际应用场景结合",
        "type": "writing-level",
        "purpose": "突出研究的实际意义",
        "location": "背景介绍段",
        "description": "结合实际应用场景指出NMT模型在特定领域数据稀缺时的局限性，引出后续研究的必要性和实际价值。"
      },
      {
        "name": "方法命名与定义",
        "type": "writing-level",
        "purpose": "明确术语和方法，便于后续讨论",
        "location": "方法介绍段",
        "description": "对‘continual training’和‘fine-tuning’进行定义和说明，使读者明确后续讨论的对象。"
      },
      {
        "name": "问题现象描述与图示辅助",
        "type": "writing-level",
        "purpose": "直观展示问题和效果",
        "location": "catastrophic forgetting现象描述处",
        "description": "通过文字描述和引用图表（如Figure 1）直观展示in-domain与general-domain性能变化趋势，使问题更加具体和易于理解。"
      },
      {
        "name": "文献对比与现有方法总结",
        "type": "writing-level",
        "purpose": "展示领域已有解决方案，为创新做铺垫",
        "location": "catastrophic forgetting方法介绍处",
        "description": "简要列举已有方法（如Freitag and Al-Onaizan, 2016的模型集成），为后续提出新方法做铺垫。"
      },
      {
        "name": "基于泰勒展开的参数重要性评估",
        "type": "method-level",
        "purpose": "评估模型参数对损失的影响，指导参数选择或剪枝",
        "location": "方法部分",
        "description": "采用泰勒展开近似评估移除某参数对损失的影响，量化每个参数的重要性，为模型优化提供依据。"
      },
      {
        "name": "假设参数独立性以简化计算",
        "type": "method-level",
        "purpose": "降低计算复杂度，便于理论推导",
        "location": "参数重要性评估方法介绍处",
        "description": "假设模型各参数之间相互独立，简化损失变化的计算公式，使理论分析更可行。"
      },
      {
        "name": "利用ReLU激活性质简化推导",
        "type": "method-level",
        "purpose": "合理忽略高阶项，简化公式",
        "location": "泰勒展开推导末尾",
        "description": "利用ReLU激活函数的特性（损失一阶导趋于常数，二阶导趋于零），合理忽略泰勒展开中的高阶余项，最终得到简洁的参数重要性评价公式。"
      },
      {
        "name": "直观解释技术指标",
        "type": "writing-level",
        "purpose": "增强可理解性，便于非专业读者理解",
        "location": "参数重要性评价公式后",
        "description": "对最终的参数重要性评价公式进行直观解释（如“该准则不重视梯度平坦的参数”），帮助读者理解公式的实际意义。"
      },
      {
        "name": "分步推导公式并编号",
        "type": "writing-level",
        "purpose": "提升论述条理性和可追溯性",
        "location": "方法推导全过程",
        "description": "将复杂公式分步推导，逐步编号（如公式(2)-(6)），方便读者跟踪推导逻辑，增强论文结构清晰度。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_64",
    "title": "GenWiki: A Dataset of 1.3 Million Content-Sharing Text and Graphs for Unsupervised Graph-to-Text Generation",
    "conference": "COLING",
    "domain": {
      "research_object": "大规模包含文本与图结构内容共享的数据集，用于图到文本生成任务。",
      "core_technique": "无监督的图到文本生成方法，结合内容共享文本与图数据。",
      "application": "提升图结构信息自动生成文本的能力，应用于知识图谱、自动摘要等领域。",
      "domains": [
        "自然语言处理",
        "知识图谱"
      ]
    },
    "ideal": {
      "core_idea": "提出大规模无监督图到文本生成数据集GenWiki，促进模型训练。",
      "tech_stack": [
        "知识图谱",
        "无监督学习",
        "深度文本生成"
      ],
      "input_type": "知识图谱结构数据",
      "output_type": "与图谱内容对应的自然语言文本"
    },
    "skeleton": {
      "problem_framing": "论文通过具体实例（知识图谱文本生成）和数据需求，强调深度学习模型在文本生成任务中的数据饥渴问题。引言采用场景化描述，突出数据标注的高成本和复杂性，吸引读者关注实际挑战。",
      "gap_pattern": "作者批评现有数据集收集难度大，标注质量难以保证，并以WebNLG数据集多次修正为例，指出当前数据驱动方法面临的现实瓶颈，强调领域内尚未解决的关键问题。",
      "method_story": "方法部分通过历史回顾，先介绍传统基于规则和模板的方法及其对数据量的低依赖，再对比深度学习方法对大规模数据的需求，形成技术演进的叙事脉络，突出新方法的必要性。",
      "experiments_story": "实验部分采用标准自动评价指标（BLEU、Meteor、ROUGE-L、CIDEr），以量化模型生成文本与参考文本的相似度，体现实验设计的规范性和结果的客观性，增强方法说服力。"
    },
    "tricks": [
      {
        "name": "数据稀缺性问题的引入",
        "type": "writing-level",
        "purpose": "突出研究动机，说明现有方法的局限性",
        "location": "开头段落",
        "description": "通过描述深度学习文本生成模型对大规模标注数据的需求，引出数据收集、注释困难以及不同领域迁移困难等问题，为后文提出新方法或改进做铺垫。"
      },
      {
        "name": "具体案例说明问题",
        "type": "writing-level",
        "purpose": "增强论述说服力",
        "location": "Figure 1及其相关描述",
        "description": "通过引用具体的数据集（如WebNLG）和实例（如知识图谱三元组的不同表达），具体化数据注释和迁移的难点，使问题更直观易懂。"
      },
      {
        "name": "对比传统方法与深度学习方法",
        "type": "writing-level",
        "purpose": "突出深度学习方法的创新性及其对数据的高需求",
        "location": "第二段",
        "description": "系统梳理传统基于规则和模板的方法与现代深度学习方法在数据需求和模型复杂度上的差异，说明为何当前面临数据瓶颈。"
      },
      {
        "name": "引用和对比多个公开数据集",
        "type": "method-level",
        "purpose": "展示方法的适用性和通用性",
        "location": "第二段与表格引用处",
        "description": "通过列举WebNLG、WeatherGov、E2E等主流数据集的规模和特点，说明现有数据集的局限性，为后续实验设计和方法论提供依据。"
      },
      {
        "name": "强调数据质量控制难点",
        "type": "writing-level",
        "purpose": "说明数据集构建的复杂性和挑战",
        "location": "第一段中部",
        "description": "指出数据集注释不仅成本高，且质量把控难，举例WebNLG数据集多次修订，突出数据集构建的不易。"
      },
      {
        "name": "跨领域迁移难点举例",
        "type": "writing-level",
        "purpose": "突出模型泛化能力不足的问题",
        "location": "第一段后半部分",
        "description": "通过举例说明模型在不同领域（如人物介绍与植物介绍）之间迁移的失败，强调领域特定风格对生成模型的影响。"
      },
      {
        "name": "引用前沿无监督方法趋势",
        "type": "writing-level",
        "purpose": "展示领域最新发展，铺垫后续方法创新",
        "location": "结尾段落",
        "description": "提及无监督数据到文本生成方法的兴起，表明研究领域正尝试突破数据依赖，为后续介绍新方法埋下伏笔。"
      },
      {
        "name": "文献回顾与方法演化梳理",
        "type": "writing-level",
        "purpose": "建立研究背景，显示方法发展脉络",
        "location": "第二段",
        "description": "简要回顾从手工模板、概率模型到深度学习神经网络的发展历程，帮助读者理解研究方法的演进和当前面临的挑战。"
      },
      {
        "name": "数据集规模与模型参数量匹配分析",
        "type": "method-level",
        "purpose": "合理设计实验与数据需求",
        "location": "第二段中部",
        "description": "分析深度学习模型参数量大，需匹配大规模数据集，指导数据集选择和实验设计。"
      },
      {
        "name": "数据集版本与过滤说明",
        "type": "experiment-level",
        "purpose": "确保实验数据的有效性和可复现性",
        "location": "脚注与数据集描述处",
        "description": "说明数据集经过多次修订与过滤（如WebNLG数据集多次更新、样本数量过滤），保证实验数据的准确性和可靠性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_65",
    "title": "Dual Dynamic Memory Network for End-to-End Multi-turn Task-oriented Dialog Systems",
    "conference": "COLING",
    "domain": {
      "research_object": "面向多轮任务型对话系统的端到端建模方法，提升对话理解与管理能力。",
      "core_technique": "提出双动态记忆网络结构，增强对话历史和知识的联合建模与推理。",
      "application": "智能客服、虚拟助手等需要多轮任务型对话的自动交互系统。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "提出双动态记忆网络提升多轮任务型对话系统端到端性能",
      "tech_stack": [
        "动态记忆网络",
        "端到端学习",
        "多轮对话建模"
      ],
      "input_type": "用户多轮自然语言对话及相关任务信息",
      "output_type": "系统生成的任务型对话回复"
    },
    "skeleton": {
      "problem_framing": "论文通过具体应用场景（如天气查询、餐厅预订）引入任务型对话系统，将其与传统流水线方法对比，强调自然语言交互和自动扩展新领域的重要性。随后，聚焦端到端方法的研究热度，突出其相较传统方法的优势。",
      "gap_pattern": "作者通过对比传统流水线方法与端到端方法，指出前者依赖人工设计模块，难以扩展，而后者可自动适应新领域，暗示现有方法在灵活性和可扩展性上的不足，为提出新模型埋下伏笔。",
      "method_story": "方法部分采用形式化定义，清晰描述输入输出及任务目标，随后以模块化方式介绍模型架构，分为编码器、记忆管理器和解码器，逐步展开细节，并通过消融实验设计验证各模块贡献，逻辑严密。",
      "experiments_story": "实验部分紧扣前人工作，采用标准数据集和评价指标（BLEU与Entity F1），突出模型在任务完成能力上的提升。通过对比实验和自动评价，系统展示模型优越性，强调指标与实际任务相关性。"
    },
    "tricks": [
      {
        "name": "对比传统方法与新方法",
        "type": "writing-level",
        "purpose": "突出研究意义和创新点",
        "location": "论文开头",
        "description": "通过对比传统pipeline方法与end-to-end方法，强调后者自动扩展性和减少人工设计的优势，为提出新模型奠定背景基础。"
      },
      {
        "name": "引用相关工作",
        "type": "writing-level",
        "purpose": "展示研究基础与领域进展",
        "location": "相关工作介绍部分",
        "description": "广泛引用前人工作，说明领域发展脉络和现有方法的局限，突出本研究的定位和改进空间。"
      },
      {
        "name": "问题分析与局限性总结",
        "type": "writing-level",
        "purpose": "明确研究动机",
        "location": "模型提出前",
        "description": "详细分析当前模型的不足，如忽略推理过程和长时记忆追踪，明确指出需要解决的关键问题。"
      },
      {
        "name": "形式化任务定义",
        "type": "method-level",
        "purpose": "增强方法严谨性与可复现性",
        "location": "方法部分开头",
        "description": "用数学符号和集合定义对话任务的输入输出，包括对话历史、KB三元组和生成目标，便于后续详细描述模型结构。"
      },
      {
        "name": "模块化模型设计",
        "type": "method-level",
        "purpose": "提升模型结构清晰度与可扩展性",
        "location": "模型结构介绍",
        "description": "将模型分为对话编码器、对话记忆管理器、KB记忆管理器和解码器四个部分，分别阐述各模块功能，突出整体架构的逻辑性。"
      },
      {
        "name": "消融实验设计",
        "type": "experiment-level",
        "purpose": "验证各模块有效性",
        "location": "实验部分",
        "description": "通过逐步移除关键模块（如记忆更新、门控机制），分析性能变化，定量证明每个模块对整体性能的贡献。"
      },
      {
        "name": "细粒度门控机制分析",
        "type": "experiment-level",
        "purpose": "解释模型细节设计对性能的影响",
        "location": "消融实验部分",
        "description": "分别移除解码器中的g1和g2门控，比较对实体词复制和整体性能的影响，突出门控机制的设计合理性。"
      },
      {
        "name": "多数据集实验验证",
        "type": "experiment-level",
        "purpose": "提升结果的说服力和泛化性",
        "location": "实验结果分析",
        "description": "在不同领域的数据集（如In-Car Assistant和CamRest）上进行实验，展示方法在多场景下的有效性。"
      },
      {
        "name": "图示辅助说明",
        "type": "writing-level",
        "purpose": "增强模型结构的可理解性",
        "location": "模型结构介绍（提到Figure 1）",
        "description": "通过示意图展示模型各组件及其关系，帮助读者快速理解复杂结构。"
      },
      {
        "name": "逐步详细阐述模型",
        "type": "writing-level",
        "purpose": "提升方法描述的逻辑性与可读性",
        "location": "模型介绍部分",
        "description": "按照模型各模块顺序分步说明，避免一次性介绍全部细节，使读者易于跟随思路理解。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_66",
    "title": "Priorless Recurrent Networks Learn Curiously",
    "conference": "COLING",
    "domain": {
      "research_object": "无先验的循环神经网络在学习过程中表现出的探索性行为",
      "core_technique": "采用无需先验知识的循环神经网络结构进行自主学习",
      "application": "可用于强化学习、智能体自主探索等人工智能任务",
      "domains": [
        "人工智能",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "无需先验知识的循环网络可自主学习语言结构。",
      "tech_stack": [
        "循环神经网络",
        "无先验学习",
        "好奇心驱动机制"
      ],
      "input_type": "原始语言数据序列",
      "output_type": "语言结构或语法规则表示"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾语言学历史（如Pāṇini、Aristotle、Chomsky）引入语言可能性的问题，并将焦点转向神经语言模型能否学习“不可能”的语言结构，巧妙地将传统理论与现代技术结合，突出研究的创新性和重要性。",
      "gap_pattern": "作者批评现有研究主要关注模型在自然语言结构上的表现，尤其是Lakretz等对LSTM的分析只发现了有限的专门单元，并且这些方法对模型整体性能贡献有限，未能系统探究模型在非自然结构上的能力，明确指出研究空白。",
      "method_story": "方法部分通过对比Lakretz等的分析策略，强调其只关注单句和训练后模型的行为，而本文则转向在操控数据、引入非自然结构后，系统性地训练和测试模型，突出方法上的差异和创新点。",
      "experiments_story": "实验部分围绕不同结构变换对模型表现的影响展开，采用量化指标和统计检验（如t检验）分析结果，逐步比较各变换的效果，并解释背后的结构复杂性，逻辑清晰地展示模型在不同条件下的适应能力。"
    },
    "tricks": [
      {
        "name": "历史背景引入",
        "type": "writing-level",
        "purpose": "为研究主题提供历史和理论背景，突出研究的重要性和延续性",
        "location": "开头段落",
        "description": "通过引用古代和现代语言学家的工作（如Pānini、Aristotle、Chomsky），说明对语言结构可能性界限的长期关注，为后续研究铺垫理论基础。"
      },
      {
        "name": "经典案例举例",
        "type": "writing-level",
        "purpose": "用具体例子说明抽象概念，帮助读者理解研究问题",
        "location": "第二句",
        "description": "引用Chomsky的著名例句（colorless green ideas sleep furiously），对比语法正确与不正确的句子，直观展示研究关注的问题。"
      },
      {
        "name": "对比研究现状与创新点",
        "type": "writing-level",
        "purpose": "突出本研究与以往工作的区别，强调创新性",
        "location": "第三至五句",
        "description": "指出以往模型评估侧重于自然语言数据，而本研究关注模型在处理不自然（impossible）结构上的能力，明确研究的独特视角。"
      },
      {
        "name": "理论模型梳理",
        "type": "writing-level",
        "purpose": "为方法选择和实验设计提供理论依据",
        "location": "中间段落",
        "description": "简要介绍不同语法形式主义（如CFG、TAG、CCG），说明它们作为自然语言可能性空间的计算模型，便于后续与神经网络模型进行对比。"
      },
      {
        "name": "文献方法总结与局限分析",
        "type": "method-level",
        "purpose": "评估和借鉴前人方法，同时指出其不足，为新方法铺垫合理性",
        "location": "中间段落",
        "description": "总结Lakretz等人的方法（跟踪LSTM单位活动以分析数一致性），指出其只发现少量专用单元且贡献有限，并且主要关注单句分析。"
      },
      {
        "name": "方法创新：权重重要性比较",
        "type": "method-level",
        "purpose": "提出新的分析方法，解决前人方法的局限",
        "location": "后半段",
        "description": "采用比较权重重要性的方法来预测数一致性，关注网络哪些部分对处理整个句子上下文至关重要，区别于只分析激活活动的方法。"
      },
      {
        "name": "实验设计：自然与非自然句子对比",
        "type": "experiment-level",
        "purpose": "在实验中系统比较模型对自然与不自然结构的学习过程",
        "location": "多处强调",
        "description": "通过操纵训练和测试数据，使其包含不自然结构，专门对比模型在自然与非自然句子上的表现，验证模型区分可能与不可能结构的能力。"
      },
      {
        "name": "单一综合表示的构建",
        "type": "method-level",
        "purpose": "简化分析过程，便于总结模型处理句子的关键部分",
        "location": "后半段",
        "description": "利用权重分析，构建针对数一致性预测的单一表示，总结网络在处理整个句子时的关键部分，有助于解释模型决策过程。"
      },
      {
        "name": "利用反向传播分析网络",
        "type": "method-level",
        "purpose": "追踪模型内部机制，定位关键参数",
        "location": "最后一句",
        "description": "通过反向传播算法，定位对预测数一致性最重要的网络权重，实现对模型“决策依据”的可解释性分析。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_67",
    "title": "Catching Attention with Automatic Pull Quote Selection",
    "conference": "COLING",
    "domain": {
      "research_object": "自动选择文章中的吸引读者注意力的拉引语（Pull Quote）文本片段。",
      "core_technique": "构建新数据集并分析多种自动拉引语选择的基线方法。",
      "application": "提升新闻、杂志等文章的排版效果和读者参与度。",
      "domains": [
        "自然语言处理",
        "信息检索"
      ]
    },
    "ideal": {
      "core_idea": "自动选择吸引读者注意力的文章拉引语（Pull Quote）",
      "tech_stack": [
        "自然语言处理",
        "文本分析",
        "机器学习"
      ],
      "input_type": "新闻或文章文本",
      "output_type": "高吸引力的拉引语文本片段"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过明确提出PQ选择任务，将其与相关领域（如标题流行度预测、点击诱饵识别和摘要生成）进行类比，强调其在新闻文本处理中的重要性和实际应用价值，从而有效吸引读者关注该问题。",
      "gap_pattern": "作者通过指出现有方法在PQ选择任务上的不足，强调缺乏专门针对PQ选择的数据集和评价标准，批评了相关任务模型的泛化能力有限，突出本研究填补该领域空白的必要性。",
      "method_story": "方法部分采用分组叙述策略，系统介绍了四类PQ选择方法，并详细说明每类方法的技术细节和与相关任务的联系，逻辑清晰地展示了方法演进和创新点，便于读者理解整体技术路线。",
      "experiments_story": "实验部分首先介绍新数据集的构建和评价指标设计，随后明确实验目标和评价标准（AUC），通过数学公式和指标解释，突出实验的科学性和针对性，确保实验结果具有说服力和可复现性。"
    },
    "tricks": [
      {
        "name": "分组方法描述",
        "type": "writing-level",
        "purpose": "清晰展示不同方法类别",
        "location": "论文开头方法部分",
        "description": "将方法分为四组：手工特征、n-gram特征、SBERT嵌入+神经网络、跨任务模型，并在各节详细介绍，有助于结构化展示方法体系。"
      },
      {
        "name": "跨任务模型迁移",
        "type": "method-level",
        "purpose": "测试相关任务模型对PQ选择的适应性",
        "location": "方法部分，Section 3.4",
        "description": "使用headline popularity、clickbait identification、summarization等相关任务的模型，迁移到PQ选择任务，分析不同任务间的相似性和可迁移性。"
      },
      {
        "name": "特征多样性对比",
        "type": "experiment-level",
        "purpose": "比较不同特征对任务表现的影响",
        "location": "实验部分，Section 5.1-5.3",
        "description": "分别用手工特征、n-gram特征、SBERT嵌入+神经网络等方法进行实验，系统对比各类特征和模型的效果。"
      },
      {
        "name": "归一化概率输出",
        "type": "method-level",
        "purpose": "统一不同模型输出范围，便于比较",
        "location": "方法描述各模型输出部分",
        "description": "将各模型对句子的预测分数缩放到[0,1]区间，作为PQ概率，标准化后便于后续评估和比较。"
      },
      {
        "name": "创新评价指标AUCavg",
        "type": "method-level",
        "purpose": "更公平地评估PQ选择模型表现",
        "location": "评价指标部分",
        "description": "提出AUCavg指标，即对每篇文章分别计算AUC后再平均，防止“有趣”文章句子在全局AUC中被高估，保证各文章公平。"
      },
      {
        "name": "新数据集构建",
        "type": "method-level",
        "purpose": "支持新任务自动PQ选择的研究",
        "location": "方法部分",
        "description": "专门构建用于PQ选择的新数据集，确保实验的针对性和有效性。"
      },
      {
        "name": "明确任务目标设定",
        "type": "writing-level",
        "purpose": "让读者理解任务核心目标",
        "location": "评价指标与任务定义部分",
        "description": "明确说明PQ选择模型的目标是判断句子被专家选为PQ的概率，突出任务实用性和评估标准。"
      },
      {
        "name": "相关任务数据集复用",
        "type": "method-level",
        "purpose": "利用已有资源扩展实验范围",
        "location": "跨任务模型部分",
        "description": "复用headline popularity和clickbait identification等公开数据集，降低数据构建成本并提升方法泛化性。"
      },
      {
        "name": "多模型对比实验设计",
        "type": "experiment-level",
        "purpose": "系统分析不同模型优劣",
        "location": "实验结果部分",
        "description": "对四类方法分别进行实验并分析结果，形成系统的对比分析，突出各方法的贡献和适用场景。"
      },
      {
        "name": "逐节细化方法说明",
        "type": "writing-level",
        "purpose": "提高论文可读性和逻辑性",
        "location": "方法部分，按Section分节",
        "description": "每种方法单独分节详细描述，便于读者逐步理解每个方法的细节和创新点。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_68",
    "title": "A Deep Metric Learning Method for Biomedical Passage Retrieval",
    "conference": "COLING",
    "domain": {
      "research_object": "针对生物医学领域的文本段落检索问题，提升相关性匹配效果。",
      "core_technique": "采用深度度量学习方法，通过神经网络优化段落间的语义距离。",
      "application": "用于生物医学文献检索、问答系统和知识发现等场景。",
      "domains": [
        "人工智能",
        "生物医学信息学"
      ]
    },
    "ideal": {
      "core_idea": "利用深度度量学习提升生物医学文献片段检索效果",
      "tech_stack": [
        "深度学习",
        "度量学习",
        "自然语言处理"
      ],
      "input_type": "医学文献片段及查询",
      "output_type": "相关性排序后的文献片段"
    },
    "skeleton": {
      "problem_framing": "论文通过强调医学领域科学文献数量巨大，指出医生和研究人员在海量数据中手动查找相关信息面临巨大挑战，进而引出对高效信息检索方法的需求，将问题与实际应用紧密结合，增强研究的现实意义。",
      "gap_pattern": "作者批评现有人工查找方式效率低下，并指出传统检索方法难以应对文献激增，提出自动化检索技术（如passage retrieval）能够缓解这一问题，但仍需提升相关性与准确性，明确当前研究的不足和改进空间。",
      "method_story": "方法部分采用逐步讲解策略，先介绍模型输入（问题、正负片段），再说明相似度计算与矩阵表示，最后描述如何通过卷积神经网络提取交互模式并计算语义相关性，逻辑清晰，便于读者理解技术细节。",
      "experiments_story": "实验部分先简要说明评估模型所用的BioASQ生物医学挑战数据集，随后承诺将详细介绍数据集和实现细节，采用先总后分的组织方式，为后续实验结果和分析做好铺垫，突出实验设计的严谨性。"
    },
    "tricks": [
      {
        "name": "引入领域背景与挑战",
        "type": "writing-level",
        "purpose": "强调研究的重要性和现实挑战",
        "location": "开头段落",
        "description": "通过列举医学文献的海量增长和人工筛选的困难，突出自动化检索方法的必要性，为后续方法提出做铺垫。"
      },
      {
        "name": "类比迁移已有技术",
        "type": "writing-level",
        "purpose": "说明方法创新的逻辑来源",
        "location": "方法介绍前",
        "description": "将面部识别和图像处理中的metric learning方法类比迁移到文本检索任务，帮助读者理解方法的理论基础。"
      },
      {
        "name": "问题-答案对建模",
        "type": "method-level",
        "purpose": "精确建模检索任务的输入输出结构",
        "location": "模型架构描述",
        "description": "将输入分为问题、正答案片段和负答案片段三部分，便于模型学习区分相关与不相关的文本。"
      },
      {
        "name": "多通道相似性矩阵表示",
        "type": "method-level",
        "purpose": "丰富语义特征表达，增强模型能力",
        "location": "模型输入层说明",
        "description": "通过计算多个词级别的相似性度量，将结果表示为多通道矩阵输入到神经网络，提升语义捕捉能力。"
      },
      {
        "name": "Siamese卷积神经网络结构",
        "type": "method-level",
        "purpose": "捕捉问答对之间的内部语义交互模式",
        "location": "模型架构描述",
        "description": "采用Siamese结构并结合卷积网络，分别处理正负样本对，学习其内部交互模式以区分相关性。"
      },
      {
        "name": "距离度量与损失函数设计",
        "type": "method-level",
        "purpose": "实现正负样本区分的优化目标",
        "location": "模型训练部分",
        "description": "设计损失函数，使正样本距离趋近于0，负样本距离大于设定margin，实现有效的metric learning。"
      },
      {
        "name": "模型结构分块描述",
        "type": "writing-level",
        "purpose": "提升论文结构清晰度，便于读者理解",
        "location": "方法部分",
        "description": "将模型分为输入层和卷积层两大模块，分别进行详细说明，条理清晰，便于复现和理解。"
      },
      {
        "name": "公开源代码",
        "type": "experiment-level",
        "purpose": "提升研究复现性和学术影响力",
        "location": "方法实现说明",
        "description": "在Github上公开模型实现和源代码，方便其他研究者复现和扩展相关工作。"
      },
      {
        "name": "与前人工作的对比说明",
        "type": "writing-level",
        "purpose": "突出自身工作的创新点",
        "location": "方法提出前",
        "description": "指出相关领域中类似方法的不足或未深入探索之处，强调本工作在度量学习与文本检索结合上的新颖性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_69",
    "title": "Evaluating Unsupervised Representation Learning for Detecting Stances of Fake News",
    "conference": "COLING",
    "domain": {
      "research_object": "针对假新闻立场检测任务，研究无监督表示学习方法的有效性。",
      "core_technique": "采用无监督表示学习技术，对文本进行特征提取和建模以辅助立场识别。",
      "application": "用于社交媒体或新闻平台中自动识别和分析假新闻相关立场。",
      "domains": [
        "自然语言处理",
        "信息检索"
      ]
    },
    "ideal": {
      "core_idea": "利用无监督表征学习自动检测假新闻的立场倾向",
      "tech_stack": [
        "无监督学习",
        "表征学习",
        "假新闻检测"
      ],
      "input_type": "新闻文本或社交媒体内容",
      "output_type": "立场分类标签（如支持、反对、中立）"
    },
    "skeleton": {
      "problem_framing": "论文通过强调社交媒体兴起带来的信息传播速度加快，指出传统新闻审核机制被削弱，虚假新闻更易传播，突出了自动化检测虚假新闻的现实紧迫性。这种策略以社会现象为切入点，引发读者关注。",
      "gap_pattern": "作者批评了现有依赖人工识别虚假新闻的方式，指出其受限于人力资源且难以覆盖多样化内容和文体，明确提出自动化检测面临的挑战，从而为后续研究提供理论缺口。",
      "method_story": "方法部分采用技术演进叙述，先介绍表示学习对NLP模型的重要性，再具体说明BERT等模型在双向语境建模上的创新，强调其相较于以往方法的优势，为后续实验奠定理论基础。",
      "experiments_story": "实验部分以探索性实验为起点，明确实验目标为评估模型性能及超参数推荐的有效性。通过控制主要超参数，聚焦不同冻结技术的表现，逻辑清晰地为后续网格搜索和结论铺垫证据。"
    },
    "tricks": [
      {
        "name": "背景引入",
        "type": "writing-level",
        "purpose": "为研究主题设定背景和重要性",
        "location": "开头段落",
        "description": "通过描述社交媒体对新闻传播的影响，以及传统新闻与现代传播的对比，引出假新闻检测的重要性。"
      },
      {
        "name": "引用权威文献",
        "type": "writing-level",
        "purpose": "增强论述的可信度和学术性",
        "location": "文中多处（如Shu et al., 2017; Khan et al., 2019）",
        "description": "在论述现象和方法时，引用相关领域的权威论文，建立理论和方法的依据。"
      },
      {
        "name": "问题定义与任务转化",
        "type": "method-level",
        "purpose": "明确研究任务及其技术实现方式",
        "location": "第二段",
        "description": "将假新闻检测问题转化为stance detection任务（即判断新闻与标题的立场关系），便于采用现有NLP方法。"
      },
      {
        "name": "多模型对比实验设计",
        "type": "experiment-level",
        "purpose": "系统评估多种主流模型的表现",
        "location": "第三段",
        "description": "选择BERT, RoBERTa, DistilBERT, ALBERT, XLNet等近期主流预训练模型进行对比评估，展示方法的全面性。"
      },
      {
        "name": "模型原理简述",
        "type": "writing-level",
        "purpose": "帮助读者理解所用模型的核心机制",
        "location": "后续段落",
        "description": "简要介绍每个模型的创新点和训练方法，如BERT的双向编码、RoBERTa的更长预训练等。"
      },
      {
        "name": "技术演变脉络梳理",
        "type": "writing-level",
        "purpose": "展现领域技术发展的逻辑和进步",
        "location": "介绍各模型时",
        "description": "按照时间和技术发展顺序介绍BERT及其衍生模型，突出技术创新和改进点。"
      },
      {
        "name": "模型轻量化方法说明",
        "type": "method-level",
        "purpose": "解释模型参数精简的技术实现及意义",
        "location": "介绍DistilBERT与ALBERT时",
        "description": "阐述如何通过参数减少技术（如知识蒸馏、分解嵌入等）实现模型轻量化，适应资源受限场景。"
      },
      {
        "name": "预训练与微调策略说明",
        "type": "method-level",
        "purpose": "展示模型训练流程和应用方式",
        "location": "介绍BERT及相关模型时",
        "description": "说明模型先在大规模无标注语料上自监督预训练，再在特定任务上微调或特征抽取，突出迁移学习优势。"
      },
      {
        "name": "任务目标与方法关联",
        "type": "writing-level",
        "purpose": "将具体方法与研究目标紧密结合",
        "location": "各模型介绍与任务结合处",
        "description": "强调所选模型的特性如何服务于假新闻检测任务，如利用深度表征学习提升检测准确率。"
      },
      {
        "name": "对比分析训练目标",
        "type": "method-level",
        "purpose": "分析不同模型训练目标对性能的影响",
        "location": "介绍RoBERTa时",
        "description": "对比BERT的训练目标（如NSP任务）与RoBERTa的调整，讨论其对模型效果的影响和改进原因。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_6",
    "title": "Fine-tuning BERT for Low-Resource Natural Language Understanding via Active Learning",
    "conference": "COLING",
    "domain": {
      "research_object": "针对低资源自然语言理解任务，提升BERT模型的微调效果。",
      "core_technique": "结合主动学习方法对BERT模型进行微调，优化少量标注数据下的表现。",
      "application": "适用于低资源语言或数据稀缺场景下的自然语言理解任务。",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "通过主动学习优化BERT在低资源NLP任务上的微调效果",
      "tech_stack": [
        "BERT",
        "主动学习",
        "迁移学习"
      ],
      "input_type": "少量标注文本数据",
      "output_type": "提升的NLP任务模型性能"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾近年来预训练语言模型在NLP领域的广泛关注，结合相关文献，强调了模型在学习通用语言表示及迁移学习中的重要性，并以BERT为代表引出研究主题，设定了技术背景和研究动机。",
      "gap_pattern": "作者通过对现有方法（如BERT的简单分类架构）进行描述，指出其局限性，并提出采用更复杂的CNN架构以改进分类性能，暗示当前主流方法在模型表达能力或任务适应性方面存在不足。",
      "method_story": "方法部分先详细介绍了BERT原始分类流程，包括特征处理和输出层设计，随后对比提出自身改进方案，采用CNN结构对所有隐藏状态进行处理，突出创新点并与前人工作形成对照。",
      "experiments_story": "实验部分以BERT为基础模型，采用权威数据集GLUE进行多任务评测，并在实验设计上与前人工作做对比（如报告平均准确率而非最大值），强调结果的稳定性和可重复性，增强实验的说服力。"
    },
    "tricks": [
      {
        "name": "引用前沿研究和基准",
        "type": "writing-level",
        "purpose": "建立研究背景和权威性",
        "location": "开头段落",
        "description": "通过引用大量相关文献（如Dai and Le, 2015; Radford, 2018; Devlin et al., 2019等）介绍领域发展和主流方法，展示研究基础和前沿进展。"
      },
      {
        "name": "分阶段介绍方法",
        "type": "writing-level",
        "purpose": "清晰展示模型训练与应用流程",
        "location": "方法介绍部分",
        "description": "先详细介绍预训练（如BERT的训练目标和结构），再阐述如何迁移到下游任务，使读者容易理解整体流程。"
      },
      {
        "name": "对比现有方法与创新点",
        "type": "writing-level",
        "purpose": "突出自身方法的创新性",
        "location": "方法对比部分",
        "description": "先介绍BERT原生的分类结构，再明确指出本文采用更复杂的CNN架构，突出自己的改进点和创新。"
      },
      {
        "name": "采用特殊符号[CLS]进行分类",
        "type": "method-level",
        "purpose": "利用预训练模型的设计特点进行下游任务",
        "location": "分类模型细节描述",
        "description": "在文本开头插入特殊[CLS] token，利用其最后一层隐藏状态作为文本的整体表示，方便进行分类任务。"
      },
      {
        "name": "Dropout正则化",
        "type": "method-level",
        "purpose": "防止过拟合，提高模型泛化能力",
        "location": "分类器结构描述",
        "description": "在Transformer输出、CNN特征层和全连接层之间多次应用Dropout操作，增强模型鲁棒性。"
      },
      {
        "name": "CNN后接于Transformer输出",
        "type": "method-level",
        "purpose": "增强特征提取能力，提升分类性能",
        "location": "模型结构描述",
        "description": "将BERT最后一层所有隐藏状态组成矩阵，采用多种宽度的卷积核（3,4,5）提取局部特征，提升分类表现。"
      },
      {
        "name": "批归一化（Batch Normalization）",
        "type": "method-level",
        "purpose": "加速训练并提升稳定性",
        "location": "CNN特征处理流程",
        "description": "对CNN提取的特征图进行批归一化，有助于缓解内部协变量偏移，加快收敛速度。"
      },
      {
        "name": "全局最大池化（Global Max Pooling）",
        "type": "method-level",
        "purpose": "提取最显著特征，降低特征维度",
        "location": "CNN特征处理流程",
        "description": "对每个卷积特征图进行全局最大池化，保留最重要的信息，减少后续计算量。"
      },
      {
        "name": "冻结部分参数以减少可训练参数量",
        "type": "method-level",
        "purpose": "降低计算资源消耗，防止过拟合",
        "location": "模型优化部分",
        "description": "在微调阶段冻结部分参数，只训练部分层，减少需要调整的参数数量，提高训练效率。"
      },
      {
        "name": "单层全连接与Softmax输出分类",
        "type": "method-level",
        "purpose": "实现多类别分类任务",
        "location": "分类器结构描述",
        "description": "在特征提取后，使用全连接层输出C个类别的logits，并通过Softmax函数得到类别概率，实现文本分类。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_70",
    "title": "Liṅ: Unsupervised Extraction of Tasks from Textual Communication",
    "conference": "COLING",
    "domain": {
      "research_object": "从文本交流中无监督地自动提取任务信息，提高任务识别效率。",
      "core_technique": "采用无监督学习方法，结合自然语言处理技术实现任务抽取。",
      "application": "可用于企业沟通、协作平台等文本交流场景中的任务自动识别。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "无监督方法自动从文本交流中提取任务信息",
      "tech_stack": [
        "自然语言处理",
        "无监督学习",
        "文本分析"
      ],
      "input_type": "团队成员间的文本交流内容，如邮件、聊天记录",
      "output_type": "结构化的任务列表或任务描述"
    },
    "skeleton": {
      "problem_framing": "论文通过具体场景切入，引入团队协作中任务分配的实际需求，强调任务识别对高效协作的重要性。以自然语言处理（NLP）如何支持任务识别为核心问题，结合实际交流如邮件和聊天，明确提出研究目标。",
      "gap_pattern": "作者指出现有协作流程依赖于任务的明确表达，但缺乏自动化手段识别任务。通过定义任务为动词短语，并强调主谓识别的重要性，揭示了当前NLP在任务自动识别上的不足，形成研究切入点。",
      "method_story": "方法部分采用联合建模策略，将句法和语义信息结合，通过依存句法分析和VerbNet语义资源提取特征。作者详细说明任务识别依赖于执行者角色、时态等多维特征，突出方法的创新性和系统性。",
      "experiments_story": "实验部分通过两个真实数据集（邮件和聊天）进行评估，详细描述数据来源、标注流程及一致性检验，突出数据的代表性和标注的可靠性。通过多数据集验证方法的适用性和泛化能力，增强说服力。"
    },
    "tricks": [
      {
        "name": "明确定义核心概念",
        "type": "writing-level",
        "purpose": "确保读者理解研究对象和范围",
        "location": "定义task和main verb部分",
        "description": "在论文开头明确给出任务（task）的定义，即将任务界定为指定单一动作的动词短语，并解释主谓动词的作用，为后续方法和实验奠定基础。"
      },
      {
        "name": "举例说明难点和挑战",
        "type": "writing-level",
        "purpose": "帮助读者直观理解任务识别的复杂性",
        "location": "举例单一动词和多动词句子部分",
        "description": "通过简单和复杂句子的具体例子，分别展示主谓动词容易与难以识别的场景，突出问题的挑战性。"
      },
      {
        "name": "联合建模句法与语义信息",
        "type": "method-level",
        "purpose": "提升任务识别的准确性",
        "location": "提出Liṅ方法部分",
        "description": "方法设计时同时考虑句法（如依存句法树）和语义（如VerbNet词库）特征，通过联合建模提升模型对任务短语的识别能力。"
      },
      {
        "name": "利用角色、时态等多维特征",
        "type": "method-level",
        "purpose": "丰富任务判别的依据",
        "location": "任务识别特征描述部分",
        "description": "观察并利用任务执行者的角色、动词时态及其他句法语义特征，作为任务识别的辅助信息，增强方法的鲁棒性。"
      },
      {
        "name": "多数据集评估",
        "type": "experiment-level",
        "purpose": "验证方法的通用性和稳定性",
        "location": "实验数据集介绍部分",
        "description": "在不同类型数据集（邮件和聊天）上进行方法评估，展示方法在多场景下的有效性和适应性。"
      },
      {
        "name": "采用人工标注及一致性检验",
        "type": "experiment-level",
        "purpose": "保证数据集标注的质量和公正性",
        "location": "数据集标注及Cohen’s Kappa部分",
        "description": "由两名独立标注者对数据进行标注，并通过Cohen’s Kappa检验标注一致性，标注者通过讨论达成最终标签，提高数据可靠性。"
      },
      {
        "name": "公开数据集来源与统计信息",
        "type": "writing-level",
        "purpose": "提升实验的可复现性与透明度",
        "location": "数据集来源和统计部分",
        "description": "详细说明数据集的来源（如Enron语料库、公开对话数据集）及其统计信息（邮件数、句子数、任务数等），便于后续研究复现和对比。"
      },
      {
        "name": "细分任务领域并举例",
        "type": "writing-level",
        "purpose": "展示方法在具体实际场景的应用",
        "location": "聊天数据集领域说明部分",
        "description": "明确列举聊天数据集涉及的具体任务领域，如日程安排、天气查询、导航等，增强结果的实际意义和应用价值。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_71",
    "title": "RuSemShift: a dataset of historical lexical semantic changes in Russian",
    "conference": "COLING",
    "domain": {
      "research_object": "俄语词汇在历史时期中的语义变化及其数据集构建",
      "core_technique": "基于语料库的方法收集和分析词汇语义演变数据",
      "application": "用于语言学研究、自然语言处理中的语义变化建模与分析",
      "domains": [
        "计算语言学",
        "历史语言学"
      ]
    },
    "ideal": {
      "core_idea": "构建俄语词义历史变化数据集，助力语义演变研究",
      "tech_stack": [
        "语料库构建",
        "词义变化检测",
        "数据标注"
      ],
      "input_type": "俄语历史文本语料和词汇列表",
      "output_type": "标注有语义变化的俄语词汇数据集"
    },
    "skeleton": {
      "problem_framing": "论文通过强调语言作为不断变化的社会工具，引出词义随时间演变的重要性。作者将语义演变研究与社会变迁和实际应用相联系，突出其学术和现实意义，从而自然引出对语义变化检测的需求。",
      "gap_pattern": "作者指出，尽管已有大规模语料库，人工分析语义变化仍然耗时费力，暗示现有方法效率不足。这种gap批评策略通过强调实际操作中的困难，突出了自动化检测方法的必要性。",
      "method_story": "方法部分首先介绍了数据集的设计初衷，即为领域内研究者提供工具。随后，作者明确提出了任务设定（排序），并简要说明了所采用的两类主流词向量方法，逻辑清晰，突出方法的代表性和对比性。",
      "experiments_story": "实验部分以建立基线为目标，先用静态分布式词嵌入进行实验，再引入上下文嵌入方法。通过逐步展开，展示了不同方法在数据集上的表现，为后续研究提供对比和参考。"
    },
    "tricks": [
      {
        "name": "引言中阐述研究意义",
        "type": "writing-level",
        "purpose": "突出研究的重要性和应用价值",
        "location": "开头段落",
        "description": "通过强调语言和词汇语义变化对社会和语言学研究的重要性，说明追踪语义变化不仅有理论价值，也有实际应用价值，如社会语言学研究。"
      },
      {
        "name": "指出现有方法的局限性",
        "type": "writing-level",
        "purpose": "为新方法/数据集的提出做铺垫",
        "location": "引言中部",
        "description": "指出手工分析语义变化的高成本和现有词典资源的局限，说明需要自动化、计算化的方法。"
      },
      {
        "name": "结合前人工作",
        "type": "writing-level",
        "purpose": "建立研究的学术基础和背景",
        "location": "引言和相关工作部分",
        "description": "引用前人关于分布式语义和词嵌入的工作，说明本研究与已有研究的联系和区别，增强论文的学术连贯性。"
      },
      {
        "name": "提出新的数据集/资源",
        "type": "method-level",
        "purpose": "为相关领域研究者提供可复用资源",
        "location": "方法介绍部分",
        "description": "通过构建并发布RuSemShift语义变化测试集，为俄语语义变化检测提供标准数据资源，促进后续研究。"
      },
      {
        "name": "基线实验设定",
        "type": "experiment-level",
        "purpose": "为后续研究提供对比基准",
        "location": "实验部分",
        "description": "在新数据集上使用基本的语义变化检测方法进行实验，报告性能结果，设定后续研究的性能基线。"
      },
      {
        "name": "任务形式化为排序问题",
        "type": "method-level",
        "purpose": "明确任务目标，便于评估和复现",
        "location": "方法部分",
        "description": "将语义变化检测任务形式化为排序问题：系统需根据两个时期语料预测目标词的语义变化分数，使得排序尽量接近金标准。"
      },
      {
        "name": "多种嵌入方法对比",
        "type": "experiment-level",
        "purpose": "探索不同模型的表现，验证方法有效性",
        "location": "实验部分",
        "description": "分别使用静态分布式词嵌入（CBOW）和上下文相关嵌入（ELMo）进行实验，对比多种方法在任务上的效果。"
      },
      {
        "name": "关注多语言资源的缺乏",
        "type": "writing-level",
        "purpose": "突出研究创新点和填补空白",
        "location": "引言末尾",
        "description": "指出目前语义变化检测资源多集中于英语，其他语言（如俄语）缺乏标注数据，强调本研究的贡献。"
      },
      {
        "name": "引用最新相关资源",
        "type": "writing-level",
        "purpose": "展示研究的时效性和前沿性",
        "location": "引言和相关工作",
        "description": "引用最新发布的多语言语义变化测试集，展示本研究与领域最新进展的联系。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_72",
    "title": "The SADID Evaluation Datasets for Low-Resource Spoken Language Machine Translation of Arabic Dialects",
    "conference": "COLING",
    "domain": {
      "research_object": "面向低资源阿拉伯方言的口语机器翻译评估数据集",
      "core_technique": "构建和评估低资源语音到文本机器翻译数据集与方法",
      "application": "提升阿拉伯方言语音翻译系统的性能和评估能力",
      "domains": [
        "自然语言处理",
        "语音处理"
      ]
    },
    "ideal": {
      "core_idea": "构建阿拉伯方言低资源语音翻译评测数据集",
      "tech_stack": [
        "语音识别",
        "机器翻译",
        "数据集构建"
      ],
      "input_type": "阿拉伯方言语音数据",
      "output_type": "机器翻译评测数据集"
    },
    "skeleton": {
      "problem_framing": "论文通过对比高资源与低资源语言对的机器翻译进展，强调了高资源语言对的成功主要得益于数据和模型进步，而低资源语言对则因数据稀缺而发展缓慢。引言以领域现状切入，突出低资源场景的挑战性。",
      "gap_pattern": "作者指出现有方法如回译虽能缓解数据稀缺问题，但在目标语言缺乏大规模单语语料时并不适用，进一步强调了当前研究在低资源语言对上的局限性，明确提出了研究空白。",
      "method_story": "方法部分采用标准化、细致的实验设置描述，详细列举了模型结构、优化器、超参数等，突出实验的可复现性和严谨性，并通过引用权威工具和指标增强方法的信度。",
      "experiments_story": "实验部分强调数据质量控制流程，采用多轮人工评价和重译机制，确保数据集质量。通过具体评分标准和操作细节，展示了实验设计的严密性和对结果可靠性的高度重视。"
    },
    "tricks": [
      {
        "name": "引入研究背景与动机",
        "type": "writing-level",
        "purpose": "阐明研究的重要性和研究空白",
        "location": "开头段落",
        "description": "在论文开头介绍高资源与低资源语言对机器翻译领域的进展差异，强调低资源语言缺乏基准数据集的问题，从而突出本研究的必要性。"
      },
      {
        "name": "提出并发布基准数据集",
        "type": "method-level",
        "purpose": "为低资源语言对提供评价标准，推动领域发展",
        "location": "中间段落",
        "description": "针对阿拉伯方言缺乏公开基准数据集的问题，创建并发布多语言（英语、MSA、埃及、黎凡特）机器翻译基准数据集，便于模型评测和结果可复现。"
      },
      {
        "name": "详细描述模型实验设置",
        "type": "experiment-level",
        "purpose": "保证实验可复现性和公平性",
        "location": "模型实验部分",
        "description": "详细列举所用工具（fairseq）、模型架构（Transformer参数）、优化器（Adam及参数）、学习率、正则化方法（label smoothing, dropout），确保他人能够复现实验。"
      },
      {
        "name": "超参数调优",
        "type": "experiment-level",
        "purpose": "优化模型性能",
        "location": "模型实验部分",
        "description": "所有超参数通过开发集(dev set)进行调优，提升模型在目标任务上的性能。"
      },
      {
        "name": "多标准人工质量评估",
        "type": "method-level",
        "purpose": "确保数据集翻译质量",
        "location": "数据集构建部分",
        "description": "翻译后由两位母语者从‘意义保留’和‘自然度’两个标准对每条数据打分，低于阈值的句子需返工，确保数据集高质量。"
      },
      {
        "name": "多轮数据质量控制",
        "type": "method-level",
        "purpose": "进一步提升数据集质量",
        "location": "数据集构建部分",
        "description": "对低分句子进行返工，并在修正后再次评估，只有通过两位评审均达标的句子才被收录，保证数据集的可靠性。"
      },
      {
        "name": "采用标准化评价指标",
        "type": "experiment-level",
        "purpose": "结果可比性和权威性",
        "location": "实验结果报告部分",
        "description": "使用BLEU分数（multi-bleu.perl脚本）作为主要评价指标，确保结果与领域内其他研究具有可比性。"
      },
      {
        "name": "数据收集与翻译流程标准化",
        "type": "method-level",
        "purpose": "减少主观偏差，提升数据一致性",
        "location": "数据集构建部分",
        "description": "为译者提供明确的翻译指导，确保英语源句可翻译性，并规范整个数据制作流程，提高数据集的一致性和可用性。"
      },
      {
        "name": "强调数据集的多用性",
        "type": "writing-level",
        "purpose": "突出数据集的广泛适用性和贡献",
        "location": "数据集介绍部分",
        "description": "说明所构建的数据集覆盖英语、MSA、埃及、黎凡特四种语言，可用于多种机器翻译任务，提升数据集的价值和影响力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_73",
    "title": "Aspect-Category based Sentiment Analysis with Hierarchical Graph Convolutional Network",
    "conference": "COLING",
    "domain": {
      "research_object": "面向不同方面类别的文本情感分析，提升细粒度情感识别效果。",
      "core_technique": "采用分层图卷积网络模型，建模方面类别与情感之间的复杂关系。",
      "application": "用于产品评论、社交媒体等文本中自动识别多维度情感倾向。",
      "domains": [
        "自然语言处理",
        "情感分析"
      ]
    },
    "ideal": {
      "core_idea": "利用层次图卷积网络结合方面类别，实现无需标注的细粒度情感分析。",
      "tech_stack": [
        "Hierarchical Graph Convolutional Network",
        "Aspect-Category Modeling",
        "Sentiment Analysis"
      ],
      "input_type": "包含评论文本及方面类别信息的数据",
      "output_type": "各方面类别的情感极性标签"
    },
    "skeleton": {
      "problem_framing": "论文通过具体定义Aspect-Based Sentiment Classification (ABSC)任务，并结合实例（如图1中的food），直观展示了任务目标，帮助读者快速理解研究背景和实际意义。引用经典文献增强了论述的权威性和学术基础。",
      "gap_pattern": "作者指出现有ABSC方法依赖先验标注的aspect terms，限制了其在实际应用中的可用性。通过明确提出这一不足，强调了任务与现实需求之间的差距，为后续研究提供了合理动机。",
      "method_story": "方法部分未在片段中详细展开，但从整体结构看，作者采用顺承逻辑，先介绍任务和挑战，再引入联合抽取与分类的新方法，突出创新点与改进方向，形成连贯的研究叙事。",
      "experiments_story": "实验部分详细说明了数据集来源、评价指标和实验流程，包括数据划分、重复实验及结果统计方法，突出实验的科学性和结果的稳定性，增强了研究的可信度和可复现性。"
    },
    "tricks": [
      {
        "name": "指出现有方法的局限性",
        "type": "writing-level",
        "purpose": "突出研究意义，说明现有方法的不足，激发读者兴趣",
        "location": "第二段开头",
        "description": "在介绍任务（ABSC）后，立即指出其主要限制，即需要预先标注aspect term，这在实际应用中不可行，为后续提出新方法做铺垫。"
      },
      {
        "name": "引用权威文献和数据集",
        "type": "writing-level",
        "purpose": "增强论文可信度，表明方法和实验基于公认标准",
        "location": "全篇，尤其是数据集和相关工作介绍处",
        "description": "多次引用权威文献（如SemEval 2015/2016、BERT、AdamW等），说明实验和方法具有通用性和可比性。"
      },
      {
        "name": "联合建模任务设计",
        "type": "method-level",
        "purpose": "提升任务实用性，同时解决多个相关子任务",
        "location": "第二段中部",
        "description": "提出将aspect term抽取和情感分类联合建模（ATSA），避免单独标注aspect term的缺点。"
      },
      {
        "name": "关注隐式aspect问题",
        "type": "writing-level",
        "purpose": "发现并强调领域中被忽视但重要的问题，为创新点提供依据",
        "location": "第二段后半部分",
        "description": "指出现有ATSA方法忽略了隐式aspect，结合数据集统计（如25%的隐式aspect），强调该问题的重要性。"
      },
      {
        "name": "详细报告实验设置",
        "type": "experiment-level",
        "purpose": "确保实验可复现性，便于他人比较和复现",
        "location": "实验部分",
        "description": "详细列出训练集划分比例、优化器、学习率、batch size、最大句长、epoch数、dropout、hidden size、阈值等超参数设定。"
      },
      {
        "name": "多次运行取平均",
        "type": "experiment-level",
        "purpose": "减少偶然性，保证结果的统计稳定性",
        "location": "实验设置说明部分",
        "description": "将训练和评测过程重复10次，最终报告平均分数，提升结果的可靠性。"
      },
      {
        "name": "采用标准评价指标",
        "type": "experiment-level",
        "purpose": "便于与相关研究公平比较",
        "location": "实验评价部分",
        "description": "使用Precision、Recall和Micro-F1等标准指标对模型进行评估，使实验结果具有可比性。"
      },
      {
        "name": "任务和数据集详细定义",
        "type": "writing-level",
        "purpose": "确保任务描述清晰，便于读者理解和后续复现",
        "location": "任务和数据集介绍段落",
        "description": "清晰界定aspect category为E#A对，解释每一项的含义，并用表格总结数据集细节。"
      },
      {
        "name": "对比不同模型表现",
        "type": "experiment-level",
        "purpose": "突出新方法优势，揭示不同方法的适用范围",
        "location": "实验结果分析部分",
        "description": "通过表格展示不同系统在两个数据集上的表现，并对AddOneDimLSTM等模型在大类别数下的表现进行分析。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_74",
    "title": "SLICE: Supersense-based Lightweight Interpretable Contextual Embeddings",
    "conference": "COLING",
    "domain": {
      "research_object": "基于超义类别的轻量级可解释上下文嵌入模型，用于自然语言处理任务。",
      "core_technique": "结合超义标签与上下文信息，设计可解释且高效的词嵌入方法。",
      "application": "提升文本理解、信息抽取等NLP任务中的嵌入解释性与效率。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "利用Supersense标签构建轻量且可解释的上下文词嵌入模型",
      "tech_stack": [
        "Supersense标注",
        "词嵌入",
        "可解释性建模"
      ],
      "input_type": "文本序列（句子或段落）",
      "output_type": "带Supersense语义标签的词级上下文嵌入表示"
    },
    "skeleton": {
      "problem_framing": "论文通过强调词形与词义的关联是语言的基础，提出词义表示在计算语言学中的重要性，并将其与更高层次的NLP任务（如文本理解、信息抽取和自动摘要）紧密联系，突出词义处理的核心地位，从而引出研究主题。",
      "gap_pattern": "作者指出虽然已有大量人工和半自动构建的词义资源（如WordNet、BabelNet），但现有方法在词义编码和应用上仍存在不足，隐含批评当前资源的局限性，为提出新方法或改进现有方法奠定基础。",
      "method_story": "方法部分采用逐步叙述策略，先介绍以非歧义词为种子构建语料的总体思路，再细化为具体的三步操作，强调人工与自动结合、正负例构建和分类器训练，逻辑清晰，便于读者理解流程。",
      "experiments_story": "实验部分通过详细说明数据来源和类别划分，先介绍用于构建特征的数据，再说明实验对象（法语名词），并对类别进行合理归并，突出实验设计的系统性和分析的简化，为后续评估方法做铺垫。"
    },
    "tricks": [
      {
        "name": "文献综述与领域定位",
        "type": "writing-level",
        "purpose": "展示研究背景和相关工作，明确论文研究的问题及其意义",
        "location": "论文开头段落",
        "description": "通过引用大量相关文献（如Wordnet, Babelnet, SemCor, Eurosense等），介绍词义表示在计算语言学中的重要性，并将本研究定位于词汇语义领域，突出其在NLP高层任务中的核心作用。"
      },
      {
        "name": "问题分解与方法流程化描述",
        "type": "writing-level",
        "purpose": "提高论文结构清晰度，使方法逻辑易于理解和复现",
        "location": "方法部分",
        "description": "将方法分为多个步骤（如手动编制正例集、自动编制负例集、语料标注、分类器训练等），并用编号顺序详细阐述每一步骤，帮助读者把握整体流程。"
      },
      {
        "name": "种子词法（Seed Words Approach）",
        "type": "method-level",
        "purpose": "为每个超义类别提供高可信度的训练样本，实现无监督或弱监督学习",
        "location": "方法部分第一步",
        "description": "手动选取每个超义类别的典型词作为种子词，并在语料中标注其出现，确保训练数据的准确性和代表性。"
      },
      {
        "name": "自动负例采样",
        "type": "method-level",
        "purpose": "构建负例集，提升分类器的判别能力",
        "location": "方法部分第二步",
        "description": "自动从其他类别的种子词中随机抽取词作为当前类别的负例，降低人工标注负担，并保证负例的多样性。"
      },
      {
        "name": "伪标注语料构建（Pseudo-annotation）",
        "type": "method-level",
        "purpose": "在无人工细粒度标注的情况下，自动获得可用于训练的数据",
        "location": "方法部分第三步",
        "description": "利用种子词的分布，将语料中的相关词自动标注为对应类别或非类别，实现大规模语料的自动化处理。"
      },
      {
        "name": "多分类器并行训练",
        "type": "method-level",
        "purpose": "针对每个超义类别分别优化分类器，提升整体性能",
        "location": "方法部分第四步",
        "description": "为每个超义类别分别训练一个分类器，每个分类器专注于识别自身类别的上下文，提高分类的精度和可解释性。"
      },
      {
        "name": "上下文评分机制",
        "type": "method-level",
        "purpose": "量化上下文与类别的关联性，实现细粒度语义判别",
        "location": "方法部分第四步",
        "description": "分类器输出0到1之间的分数，表示上下文与某一类别的代表性强弱，为后续语义分析或应用提供连续型特征。"
      },
      {
        "name": "正负样本平衡设计",
        "type": "experiment-level",
        "purpose": "保证训练数据的均衡性，防止模型偏向某一类别",
        "location": "方法部分第二步、第三步",
        "description": "在构建正负样本时，确保每个超义类别的正负样本数量和来源合理分配，提高模型泛化能力。"
      },
      {
        "name": "引用经典理论与资源",
        "type": "writing-level",
        "purpose": "增强方法的理论基础与学术说服力",
        "location": "论文开头及方法部分",
        "description": "引用Harris分布式语义理论、Wordnet等经典资源，为新方法提供理论依据和数据支撑。"
      },
      {
        "name": "应用导向的动机阐述",
        "type": "writing-level",
        "purpose": "说明研究成果的实际价值和应用前景",
        "location": "论文开头段落",
        "description": "强调词义区分对文本理解、信息抽取、自动摘要等NLP下游任务的积极影响，突出方法的实用意义。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_75",
    "title": "Words are the Window to the Soul: Language-based User Representations for Fake News Detection",
    "conference": "COLING",
    "domain": {
      "research_object": "通过用户语言特征构建用户表示，用于识别虚假新闻。",
      "core_technique": "基于自然语言处理技术分析用户文本，生成用户特征表示。",
      "application": "社交媒体平台上的虚假新闻检测与用户行为分析。",
      "domains": [
        "自然语言处理",
        "信息安全"
      ]
    },
    "ideal": {
      "core_idea": "通过用户语言特征建模提升虚假新闻检测效果",
      "tech_stack": [
        "自然语言处理",
        "用户表示学习",
        "深度学习"
      ],
      "input_type": "新闻文本及用户历史语言数据",
      "output_type": "新闻真假分类结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调假新闻在社会中的广泛传播及其对重大事件的影响，引发读者对该问题的关注。作者引用权威文献，具体举例假新闻在选举、股市和疫情中的作用，突出其现实紧迫性和研究价值。",
      "gap_pattern": "作者指出，尽管已有大量NLP研究关注假新闻检测，早期方法仅依赖新闻文本本身，忽视了传播者生成内容的潜在信息价值。这一批评明确界定了现有研究的不足，为后续方法创新埋下伏笔。",
      "method_story": "方法部分采用模块化叙述，先整体介绍模型输入和输出，再细分为新闻和用户文本两大模块，突出二者既可独立使用也可并行。技术细节如CNN实现、数据获取流程等穿插其中，增强方法透明度。",
      "experiments_story": "实验设计强调对比性和系统性，分为仅用新闻、仅用用户信息及两者结合三大类，并细化用户信息来源。通过设置SVM基线，确保结果具备可比性，突出新方法的增量价值和适用场景。"
    },
    "tricks": [
      {
        "name": "文献回顾与问题引入",
        "type": "writing-level",
        "purpose": "明确问题背景与研究意义",
        "location": "开头段落",
        "description": "通过引用大量相关文献和重大事件，展示假新闻的社会影响和NLP领域对此问题的关注，为后续研究设定背景和意义。"
      },
      {
        "name": "相关工作分类梳理",
        "type": "writing-level",
        "purpose": "梳理前人工作，突出自身创新点",
        "location": "第二段",
        "description": "将已有研究分为仅使用文本内容的方法和结合社会上下文的方法，明确自身模型的定位和创新点。"
      },
      {
        "name": "多模块模型设计",
        "type": "method-level",
        "purpose": "综合利用新闻文本和用户生成文本以提升检测效果",
        "location": "模型介绍部分",
        "description": "设计了包含新闻模块和用户模块的双通道结构，分别处理新闻本身和用户生成内容，充分挖掘多源信息。"
      },
      {
        "name": "用户表征加权机制",
        "type": "method-level",
        "purpose": "动态调整新闻和用户信息对预测的贡献",
        "location": "模型介绍部分",
        "description": "采用门控系统对新闻向量和用户向量进行加权，控制二者对最终分类结果的影响，提高模型灵活性和解释性。"
      },
      {
        "name": "CNN用于文本特征提取",
        "type": "method-level",
        "purpose": "高效提取文本的局部特征",
        "location": "模型介绍部分",
        "description": "新闻和用户文本均采用卷积神经网络（CNN）编码，利用其在文本分类任务中的高效性和表现力。"
      },
      {
        "name": "特征向量拼接与线性分类器",
        "type": "method-level",
        "purpose": "融合多源信息并进行分类",
        "location": "模型介绍部分",
        "description": "将新闻和用户的加权向量拼接后，输入到一层线性分类器中，进行真假新闻的最终判别。"
      },
      {
        "name": "数据集获取与复现说明",
        "type": "experiment-level",
        "purpose": "确保实验的可复现性和数据完整性",
        "location": "模型介绍部分脚注",
        "description": "详细说明数据集的下载、新闻内容补全及用户信息抓取方法，包括代码和API的使用，保证实验可复现。"
      },
      {
        "name": "模型解释性关注",
        "type": "writing-level",
        "purpose": "强调模型可解释性和透明度",
        "location": "模型介绍结尾",
        "description": "提出结合CNN提取的语言特征进行模型解释性分析，顺应NLP领域对模型可解释性关注的趋势。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_76",
    "title": "Variation in Coreference Strategies across Genres and Production Media",
    "conference": "COLING",
    "domain": {
      "research_object": "不同体裁和媒介中指代消解策略的变化与差异",
      "core_technique": "对文本中的指代消解策略进行跨体裁和媒介的比较分析",
      "application": "提升自然语言处理系统在多样文本环境下的指代理解能力",
      "domains": [
        "计算语言学",
        "自然语言处理"
      ]
    },
    "ideal": {
      "core_idea": "分析不同体裁和媒介下指代策略的变化及其测量方法问题",
      "tech_stack": [
        "语料库分析",
        "指代链统计",
        "跨体裁比较"
      ],
      "input_type": "文本语料（不同体裁和媒介）",
      "output_type": "指代策略变化的定量与定性分析"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾已有关于指称表达策略在口语与书面语中的研究，指出该领域的研究结果尚无定论，部分结论甚至相互矛盾。作者以此为切入点，强调该问题的重要性和研究的必要性。",
      "gap_pattern": "作者批评现有研究主要存在两个不足：一是共指链属性的测量方式不透明，二是所用数据差异较大，导致研究难以比较。这种批评方式明确指出了领域内的研究空白和改进空间。",
      "method_story": "作者提出将通过细致的语料库对比分析来研究口语与书面语中的共指现象，并强调将明确公开具体的测量方法，以提升研究的透明度和可复现性。",
      "experiments_story": "实验部分聚焦于对比分析不同媒介（尤其是微博等微型博客）的数据，旨在通过实证数据揭示口语与书面语在共指表达上的异同，实验设计紧扣研究目标并结合新兴媒介。"
    },
    "tricks": [
      {
        "name": "明确研究目标",
        "type": "writing-level",
        "purpose": "突出研究的主旨和方向",
        "location": "Our primary goal here is to shed light on coreference with respect to the spoken/written distinction, by undertaking a careful comparative corpus analysis and explicitly stating our methods of measurement. The secondary goal is to explore how the medium microblog, specifically Twitter, relates to the spokenwritten spectrum for coreference strategies.",
        "description": "在论文开头明确陈述主要和次要研究目标，有助于读者理解研究的核心问题和研究范围。"
      },
      {
        "name": "批判性文献综述",
        "type": "writing-level",
        "purpose": "展示对前人工作的理解及研究空白",
        "location": "Research on strategies for producing referring expressions has often investigated the differences (if any) between spoken and written language, but as we will show in Section 2, results have been inconclusive. Sometimes, claims are simply contradictory, but the more important problem is that usually, the exact ways of measuring the properties of coreference chains are not being made transparent.",
        "description": "在引言部分批判性地回顾已有研究，指出已有结论的不一致和方法透明度不足，突出本研究的创新点和必要性。"
      },
      {
        "name": "方法透明化",
        "type": "method-level",
        "purpose": "提升研究的可重复性和科学性",
        "location": "by undertaking a careful comparative corpus analysis and explicitly stating our methods of measurement",
        "description": "明确指出将详细公开测量方法，强调方法透明性，便于他人复现和比较结果。"
      },
      {
        "name": "对比实验设计",
        "type": "experiment-level",
        "purpose": "突出不同数据集或条件下的差异",
        "location": "we used an out-of-the-box contemporary coreference resolver (Lee et al., 2018), set to coarse-to-fine inference, and obtained an F1 score of 72.6% on the standard OntoNotes test data (Pradhan et al., 2013), and in contrast a score of only 45.2% on the corpus of Twitter conversations.",
        "description": "通过在标准数据集和推特语料上对比实验结果，突出研究对象（如推特）在现有方法下的特殊性和挑战。"
      },
      {
        "name": "数据多样性与可比性讨论",
        "type": "writing-level",
        "purpose": "提醒读者注意数据差异对结果的影响",
        "location": "the data that has been used can vary considerably, and it is not always clear how studies can be compared.",
        "description": "强调不同研究使用的数据集差异及其对结果对比的影响，为后续方法选择和实验设计提供合理性。"
      },
      {
        "name": "引入新领域/新数据类型",
        "type": "writing-level",
        "purpose": "拓展研究领域，增加创新性",
        "location": "The secondary goal is to explore how the medium microblog, specifically Twitter, relates to the spokenwritten spectrum for coreference strategies.",
        "description": "将研究对象扩展到较少被关注的新领域（如推特），展现创新性和前沿性。"
      },
      {
        "name": "引用前沿工具与基线",
        "type": "method-level",
        "purpose": "确保实验具有代表性和可比性",
        "location": "we used an out-of-the-box contemporary coreference resolver (Lee et al., 2018), set to coarse-to-fine inference",
        "description": "选用当前先进的工具作为实验基线，便于与其他研究对比，并确保实验结果的有效性。"
      },
      {
        "name": "用具体实验指标量化对比",
        "type": "experiment-level",
        "purpose": "便于客观评价方法效果",
        "location": "obtained an F1 score of 72.6% on the standard OntoNotes test data (Pradhan et al., 2013), and in contrast a score of only 45.2% on the corpus of Twitter conversations.",
        "description": "使用F1分数等具体量化指标展示不同数据集上的性能差异，使得结果更具说服力和可比性。"
      },
      {
        "name": "提出领域特有问题",
        "type": "writing-level",
        "purpose": "为后续深入研究打基础",
        "location": "Aktaş et al. (2018) outlined peculiar anaphoric cases in Twitter conversations, such as exophoric references to non-linguistic",
        "description": "结合前人研究，指出推特语料中存在特有的指代现象，为后续深入分析和方法改进提供依据。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_77",
    "title": "Noise Isn’t Always Negative: Countering Exposure Bias in Sequence-to-Sequence Inflection Models",
    "conference": "COLING",
    "domain": {
      "research_object": "研究对象为序列到序列的形态变化模型在低资源环境下的泛化能力。",
      "core_technique": "核心技术是通过引入噪声和调整teacher forcing策略来缓解暴露偏差。",
      "application": "应用场景包括自然语言处理中的形态生成和其他序列到序列任务。",
      "domains": [
        "自然语言处理",
        "机器学习"
      ]
    },
    "ideal": {
      "core_idea": "通过引入噪声缓解序列到序列形态变化模型的曝光偏置，提高低资源条件下的泛化能力。",
      "tech_stack": [
        "序列到序列模型",
        "循环神经网络",
        "噪声注入"
      ],
      "input_type": "词干与形态句法描述对",
      "output_type": "词形变化后的单词"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾近年来形态变化任务的研究热潮及相关共享任务，强调形态变化学习的重要性和研究背景，并以具体示例（如run的分词）说明任务的输入输出形式，清晰界定研究对象。",
      "gap_pattern": "作者指出尽管现有方法多受神经机器翻译启发，但形态变化任务本身更直接，且现有共享任务揭示了该领域的诸多特殊性，暗示当前方法在应对这些特殊性上存在不足，为后续方法创新铺垫空间。",
      "method_story": "方法部分采用对比实验策略，明确提出将主流的teacher forcing与自定义的student forcing进行比较，并在三种经典神经模型上系统测试，突出创新点和方法选择的合理性。",
      "experiments_story": "实验部分详细说明实验流程、模型架构与参数设置，并通过开发实验初步分析两种策略的表现，结合评价指标解释结果，逐步引出调参实验，体现实验设计的层次性和针对性。"
    },
    "tricks": [
      {
        "name": "引用历年相关工作与任务以建立研究背景",
        "type": "writing-level",
        "purpose": "展示领域研究现状和本研究的相关性",
        "location": "论文开头",
        "description": "通过引用历年的共享任务和相关文献，快速向读者交代该领域的研究背景和当前关注点，为后续研究内容做铺垫。"
      },
      {
        "name": "明确任务定义并举例说明",
        "type": "writing-level",
        "purpose": "帮助读者快速理解研究任务和输入输出格式",
        "location": "方法介绍部分",
        "description": "在介绍形态变化任务时，详细说明输入（词干和形态语法描述符）和输出（变形词）之间的关系，并通过具体示例（如{run, V.PTCP;PRS}→running）直观展示任务内容。"
      },
      {
        "name": "分析任务本身的特点与现有方法的适用性",
        "type": "writing-level",
        "purpose": "突出任务与通用方法的异同，强调研究意义",
        "location": "任务分析部分",
        "description": "通过对比形态变化和神经机器翻译的异同，指出形态变化任务的特殊性（如大部分字符可直接拷贝，无需重排序），为采用特定机制（如copy mechanism和monotonic attention）提供理论依据。"
      },
      {
        "name": "引入copy mechanism和monotonic attention等专用机制",
        "type": "method-level",
        "purpose": "提升模型在特殊任务场景下的性能",
        "location": "方法相关工作介绍",
        "description": "针对形态变化任务的特性，采用copy mechanism和硬性单调注意力机制，利用输入输出的高度对应性，提升模型表现，尤其适用于数据稀缺场景。"
      },
      {
        "name": "对比teacher forcing与student forcing训练策略",
        "type": "experiment-level",
        "purpose": "探究不同训练策略对模型性能的影响",
        "location": "实验设计与结果分析",
        "description": "设计实验对比主流的teacher forcing和提出的student forcing策略，分析两者在模型训练和推理阶段的表现差异，揭示teacher forcing在学习早期的重要性。"
      },
      {
        "name": "多模型对比实验设计",
        "type": "experiment-level",
        "purpose": "验证方法的通用性与有效性",
        "location": "实验方法部分",
        "description": "在三种主流神经网络模型（Pointer-Generator, Hard Attention, Minimum Risk Training）上同时应用student forcing，确保实验结论具有普适性和说服力。"
      },
      {
        "name": "详细说明实验设置（模型结构、超参数、数据）",
        "type": "writing-level",
        "purpose": "保证实验可复现性和科学性",
        "location": "实验设置描述",
        "description": "系统介绍各模型结构、超参数选择和数据集规格，并解释评价指标选择理由，为实验设计的合理性和结果的可信度提供支撑。"
      },
      {
        "name": "采用多种评价指标（准确率与编辑距离）",
        "type": "experiment-level",
        "purpose": "全面评估模型性能",
        "location": "实验结果分析",
        "description": "不仅报告准确率，还关注编辑距离等细粒度指标，确保对模型性能的评估更加全面和细致。"
      },
      {
        "name": "根据实验结果动态调整训练策略",
        "type": "experiment-level",
        "purpose": "优化模型训练过程",
        "location": "实验结果讨论",
        "description": "根据实验发现，纯student forcing表现不稳定，teacher forcing在训练初期至关重要，因此尝试调整两者的权重以获得更优性能。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_78",
    "title": "Grammatical error detection in transcriptions of spoken English",
    "conference": "COLING",
    "domain": {
      "research_object": "针对英语口语转录文本中的语法错误进行检测与分析。",
      "core_technique": "采用自然语言处理与语法分析技术识别口语转录中的语法错误。",
      "application": "提升口语转录文本的语法准确性，辅助语言学习与自动评测。",
      "domains": [
        "自然语言处理",
        "教育技术"
      ]
    },
    "ideal": {
      "core_idea": "构建并标注英语口语转录语法错误数据集，推动口语语法错误检测研究",
      "tech_stack": [
        "语音转录",
        "语法错误标注",
        "自然语言处理"
      ],
      "input_type": "英语口语录音及其转录文本",
      "output_type": "转录文本中的语法错误检测与标注结果"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过介绍一个新的语音NLP资源切入，强调其在当前研究领域中的重要性。作者首先描述了CROWDED语料库的基本情况及其应用场景，突出了语音转录和错误标注在语言学习和评测中的价值。",
      "gap_pattern": "作者指出现有公开可用的语音语料库稀缺，尤其缺乏适合与学习者口语进行对比的母语者参考语料。这种批评策略通过明确领域内的资源短缺，凸显了新资源的必要性和创新性。",
      "method_story": "方法部分简明扼要地描述了实验流程，强调采用预训练词向量初始化输入，并用序列标注模型预测语法错误。作者还说明了超参数调整的原则，兼顾经验与计算成本，体现了方法设计的实用性和可复现性。",
      "experiments_story": "实验部分采用逐步推进策略，首先进行基础实验，不引入额外特征或辅助任务。随后通过手动调参探索模型表现，并与领域内最优方法进行对比，展示了实验设计的系统性和针对性。"
    },
    "tricks": [
      {
        "name": "创建并发布新语音NLP资源",
        "type": "writing-level",
        "purpose": "解决语音NLP公开资源稀缺问题，促进研究发展",
        "location": "引言和方法部分",
        "description": "通过众包方式收集并发布包含超过一千条转录和错误注释的CROWDED语料库，丰富了公开可用的语音NLP研究资源。"
      },
      {
        "name": "利用众包进行数据标注",
        "type": "method-level",
        "purpose": "高效获取大规模多样化的语音转录和错误注释数据",
        "location": "方法部分",
        "description": "通过分布式在线众包工人，先对现有转录进行纠错，再提升流利度，实现高效、低成本的数据标注。"
      },
      {
        "name": "多阶段数据标注流程设计",
        "type": "method-level",
        "purpose": "提升转录文本的准确性和流利性，便于后续任务研究",
        "location": "方法部分",
        "description": "标注流程分为先纠正转录错误，再编辑文本增强流畅度，确保数据既真实反映口语，又具备较高质量。"
      },
      {
        "name": "结合多种预训练词向量进行实验",
        "type": "experiment-level",
        "purpose": "比较不同预训练表示对模型性能的影响，提升模型效果",
        "location": "实验部分",
        "description": "尝试了fastText、Wikipedia2Vec、GloVe等多种预训练词向量作为输入，系统性评估其对语法错误检测的作用。"
      },
      {
        "name": "使用多种上下文词表示模型",
        "type": "experiment-level",
        "purpose": "探索上下文信息对任务性能的提升作用",
        "location": "实验部分",
        "description": "基于HuggingFace和Flair NLP，测试BERT、ELMo、GPT2、RoBERTa、Transformer-XL、XLNet等多种上下文词表示，丰富实验对比。"
      },
      {
        "name": "不引入额外特征或辅助任务的基线实验设计",
        "type": "experiment-level",
        "purpose": "确保实验结果的可解释性和可复现性，建立清晰基线",
        "location": "实验部分",
        "description": "实验初步阶段仅使用预训练词向量，直接训练序列标注器进行语法错误预测，未引入复杂特征或多任务学习。"
      },
      {
        "name": "人工直觉指导的超参数调优",
        "type": "experiment-level",
        "purpose": "在有限计算资源下高效探索超参数空间",
        "location": "实验部分",
        "description": "采用人工经验和直觉进行超参数手动调优，兼顾实验效率和覆盖可能的最优值，避免网格搜索带来的高昂计算成本。"
      },
      {
        "name": "对比实验设计与现有最佳方法",
        "type": "writing-level",
        "purpose": "突出自身方法的创新点，定位研究贡献",
        "location": "实验部分",
        "description": "明确对比当前GED领域的主流方法（如拼接上下文词表示与预训练表示），并基于多种预训练模型进行系统实验。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_79",
    "title": "Multi-grained Chinese Word Segmentation with Weakly Labeled Data",
    "conference": "COLING",
    "domain": {
      "research_object": "针对中文分词任务，研究多粒度分词方法，利用弱标注数据提升分词效果。",
      "core_technique": "采用多粒度建模结合弱监督学习，提升中文分词在不同粒度下的准确性。",
      "application": "可用于中文文本处理、自然语言理解、信息检索等相关应用场景。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "利用弱标注数据实现多粒度中文分词，提高分词灵活性与适应性。",
      "tech_stack": [
        "多粒度分词建模",
        "弱监督学习",
        "深度神经网络"
      ],
      "input_type": "未分词或弱标注的中文句子",
      "output_type": "多粒度分词结果（多个分词方案）"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾中文分词作为基础性任务的研究进展，引出当前主流方法（单粒度分词）存在的问题，即不同语料库的标注标准不一致，导致分词结果差异。通过具体例子（图1）直观展示现有方法的局限性，为后续提出多粒度分词任务埋下伏笔。",
      "gap_pattern": "作者批评现有研究主要采用单粒度分词，忽视了实际应用中多粒度分词的需求。此外，指出前人数据构建和标注流程存在缺陷，如缺乏严格的标注规范和较高的标注错误率，强调了高质量数据和科学标注流程的必要性。",
      "method_story": "方法部分采用对比叙述，先简述前人采用的转移式句法分析方法及其优劣，再说明本研究为何选择图结构句法分析器，并用两点理由（如性能和损失函数改进）论证方法选择的合理性，突出创新性和针对性改进。",
      "experiments_story": "实验部分首先介绍前人数据构建和标注流程的不足，结合自身调研发现的问题，强调数据质量对评测的重要性。随后详细说明本研究在数据标注和流程上的改进，突出科学性和严谨性，为实验可信度和后续分析奠定基础。"
    },
    "tricks": [
      {
        "name": "引用前人研究奠定背景",
        "type": "writing-level",
        "purpose": "展示领域进展和研究基础",
        "location": "论文开头",
        "description": "通过大量引用相关文献（如Zheng et al., 2013; Pei et al., 2014等），介绍中文分词的研究历史和进展，为后续工作提供理论背景。"
      },
      {
        "name": "对现有方法进行批判性分析",
        "type": "writing-level",
        "purpose": "突出现有方法的不足，提出研究动机",
        "location": "论文开头",
        "description": "指出大多数现有工作采用单粒度分词（SWS），并分析不同语料库标注指南导致的分词差异，强调中文复合词边界模糊给分词带来的挑战。"
      },
      {
        "name": "结合图示辅助说明",
        "type": "writing-level",
        "purpose": "提升读者对方法和问题的理解",
        "location": "分词方法介绍部分",
        "description": "通过引用和描述图1（左、右），对比单粒度分词与多粒度分词的结构，帮助读者直观理解任务区别。"
      },
      {
        "name": "任务转化为树结构建模",
        "type": "method-level",
        "purpose": "自然表达多粒度分词的层次关系",
        "location": "MWS任务介绍",
        "description": "将多粒度分词（MWS）建模为层次树结构，便于利用句法分析相关技术解决该任务。"
      },
      {
        "name": "方法对比与创新选择",
        "type": "method-level",
        "purpose": "明确方法创新点，突出贡献",
        "location": "方法部分",
        "description": "对比前人采用的transition-based parser（Gong et al., 2017），本工作选择graph-based parser（Stern et al., 2017），并用local span-wise loss替换global max-margin loss，说明选择原因和优势。"
      },
      {
        "name": "分析方法效率与性能权衡",
        "type": "experiment-level",
        "purpose": "说明方法选择的实际价值",
        "location": "方法选择理由",
        "description": "通过对比不同parser和loss的效率与性能，强调graph-based parser with local loss在保证性能的同时提升效率。"
      },
      {
        "name": "弱标注数据的自然融合",
        "type": "method-level",
        "purpose": "提升模型泛化能力和数据利用率",
        "location": "方法创新点",
        "description": "利用graph-based parser with local loss直接在span级别训练模型，使其天然支持弱标注数据，从而扩展训练数据来源。"
      },
      {
        "name": "模型结构分层展示",
        "type": "writing-level",
        "purpose": "清晰介绍模型架构",
        "location": "模型架构部分",
        "description": "将模型分为输入层、表示层等四大组件，并用图示（如Figure 2）辅助说明，便于读者理解整体流程。"
      },
      {
        "name": "结合具体应用场景解释标注差异",
        "type": "writing-level",
        "purpose": "增强方法的实际意义和适用性",
        "location": "分词标准分析部分",
        "description": "通过举例说明CTB偏细粒度、PPD偏粗粒度的原因，结合下游任务需求解释分词标准差异。"
      },
      {
        "name": "数据一致性问题的定量引用",
        "type": "writing-level",
        "purpose": "增强问题描述的说服力",
        "location": "问题分析部分",
        "description": "引用Sproat et al. (1987)的统计数据（共识率仅76%），用定量方式强调中文分词边界一致性问题。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_7",
    "title": "AutoMeTS: The Autocomplete for Medical Text Simplification",
    "conference": "COLING",
    "domain": {
      "research_object": "针对医学文本自动简化的自动补全系统",
      "core_technique": "结合自然语言处理与机器学习实现医学文本简化与补全",
      "application": "辅助医疗工作者或患者理解复杂医学文本",
      "domains": [
        "自然语言处理",
        "医学信息学"
      ]
    },
    "ideal": {
      "core_idea": "提出医疗文本简化的智能自动补全工具，辅助人工编辑。",
      "tech_stack": [
        "自然语言处理",
        "文本自动补全",
        "人机协作界面"
      ],
      "input_type": "医疗原始文本",
      "output_type": "简化后的医疗文本建议"
    },
    "skeleton": {
      "problem_framing": "论文通过强调文本简化的普适性目标引入问题，指出简化需兼顾内容保留，尤其在医疗等敏感领域。通过引用前人研究，展示自动化方法在关键信息保留上的不足，突出实际应用中的挑战和需求。",
      "gap_pattern": "作者批评现有研究过度依赖全自动简化方法，指出这些方法在医疗等领域可能导致重要信息丢失。通过具体数据（如30%关键信息遗漏），明确展示现有方法的局限性，为后续研究提供动力。",
      "method_story": "方法部分采用目标驱动的叙述，首先明确三大研究目标，然后将问题转化为语言建模任务，详细说明输入输出形式及评估方式。通过表格示例和预测机制，增强方法的可理解性和操作性。",
      "experiments_story": "实验部分以模型性能比较为主线，详细描述数据集划分、模型训练细节和参数设置。采用标准准确率等多维度指标进行评估，突出实验设计的严谨性和结果的客观性，便于后续分析和讨论。"
    },
    "tricks": [
      {
        "name": "明确研究动机与现实应用背景",
        "type": "writing-level",
        "purpose": "突出研究的实际意义和应用场景，增强论文说服力",
        "location": "引言开头",
        "description": "通过指出在医疗等领域全自动文本简化不适用，强调交互式简化工具的必要性，结合前人研究（如Shardlow et al., 2019的30%关键信息缺失），为后续研究铺垫合理性。"
      },
      {
        "name": "对比现有方法，突出创新点",
        "type": "writing-level",
        "purpose": "展示所提方法与现有工作的区别和改进，突出创新性",
        "location": "相关工作讨论段",
        "description": "对比全自动方法与交互式简化工具，说明本文工作与交互式机器翻译最为相似，凸显所提方法的新颖应用场景。"
      },
      {
        "name": "任务形式化与数学建模",
        "type": "method-level",
        "purpose": "将实际问题形式化，便于后续模型设计和评价",
        "location": "方法部分",
        "description": "将自动补全简化任务形式化为语言建模问题，明确输入（难句与已输入简化内容）和输出（下一个建议词），为后续模型实验提供统一框架。"
      },
      {
        "name": "多模型对比实验设计",
        "type": "experiment-level",
        "purpose": "系统评估不同模型性能，验证方法有效性",
        "location": "模型实验部分",
        "description": "选取四种基于Transformer的预训练语言模型（BERT、RoBERTa、XLNet、GPT-2），并分别设计有无上下文输入的实验版本，实现全面对比。"
      },
      {
        "name": "细粒度分解预测任务",
        "type": "method-level",
        "purpose": "提升评测细致度，便于分析模型表现",
        "location": "实验设计部分",
        "description": "将一个简化句子的预测任务分解为多个词级预测任务（n-1个），每次预测下一个词，便于量化模型逐步生成能力。"
      },
      {
        "name": "举例说明任务流程",
        "type": "writing-level",
        "purpose": "帮助读者理解任务定义和实验流程",
        "location": "方法说明及表格",
        "description": "通过具体例子（如表1、表2、表3），展示难句、简化句及预测任务分解过程，使抽象任务具体化。"
      },
      {
        "name": "多目标设定",
        "type": "writing-level",
        "purpose": "明确研究范围和评价维度，结构化论文内容",
        "location": "研究目标说明段",
        "description": "明确提出三个研究目标：考察上下文信息作用、探索PNLM新应用、评估新集成方法，增强研究条理性。"
      },
      {
        "name": "引证大量相关文献",
        "type": "writing-level",
        "purpose": "展示研究基础和学术积累，增强论文权威性",
        "location": "引言及相关工作部分",
        "description": "广泛引用前人工作（如Shardlow, Xu et al., Zhang and Lapata, Kloehn et al.等），显示对领域现状的把握。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_80",
    "title": "Dual-decoder Transformer for Joint Automatic Speech Recognition and Multilingual Speech Translation",
    "conference": "COLING",
    "domain": {
      "research_object": "联合自动语音识别与多语种语音翻译的模型方法",
      "core_technique": "采用双解码器Transformer结构，实现语音识别与翻译任务的协同处理",
      "application": "多语言语音输入的自动识别与实时翻译，如国际会议或跨语言交流",
      "domains": [
        "语音识别",
        "机器翻译"
      ]
    },
    "ideal": {
      "core_idea": "提出双解码器Transformer模型，联合实现语音识别和多语种语音翻译。",
      "tech_stack": [
        "Transformer",
        "双解码器架构",
        "端到端学习"
      ],
      "input_type": "语音音频（多语种）",
      "output_type": "源语言文本转录和目标语言文本翻译"
    },
    "skeleton": {
      "problem_framing": "论文通过对比cascade和end-to-end语音翻译系统，引入了当前研究背景与技术进展，强调了端到端模型在最新评测中的优越表现，从而自然引出对多语种语音翻译的需求与研究动机。",
      "gap_pattern": "作者批评了传统cascade方法的局限性，指出虽然早期工作已推动端到端语音翻译发展，但多语种场景下的系统性能与通用性仍存在不足，亟需进一步探索和改进。",
      "method_story": "方法部分采用逐步推演策略，先定义输入输出形式，再通过简化设定（单目标语言）说明模型结构与适用范围，最后强调方法的普适性，便于读者理解后续扩展。",
      "experiments_story": "实验部分尚未展开，但根据前文结构，预计将采用对比实验和多语种场景验证，围绕方法的有效性和通用性进行系统性组织，以支撑理论与方法创新。"
    },
    "tricks": [
      {
        "name": "对比两种系统架构",
        "type": "writing-level",
        "purpose": "突出研究背景和创新点",
        "location": "引言部分",
        "description": "对比了传统的级联自动语音到文本翻译系统（ASR+MT）与最新的端到端系统，强调端到端系统的进展和优势，为后续提出新方法做铺垫。"
      },
      {
        "name": "引用最新领域成果",
        "type": "writing-level",
        "purpose": "增强研究的时效性和权威性",
        "location": "引言与相关工作",
        "description": "引用了IWSLT 2020等最新会议的成果，说明端到端模型已经达到甚至超过级联模型，增强论文的可信度和前沿性。"
      },
      {
        "name": "问题动机强化",
        "type": "writing-level",
        "purpose": "明确研究方向和必要性",
        "location": "引言部分",
        "description": "通过强调多语种（one-to-many, many-to-many, many-to-one）语音翻译任务的需求，突出端到端模型天然适用，强化研究动机。"
      },
      {
        "name": "边界设计对比",
        "type": "method-level",
        "purpose": "展示现有方法的极端设计并提出改进空间",
        "location": "方法论讨论",
        "description": "指出级联方法和端到端方法分别是松散和完全忽略ASR子任务的两个极端，提出未来需要更紧密耦合ASR和MT，激发创新设计。"
      },
      {
        "name": "任务简化与泛化",
        "type": "writing-level",
        "purpose": "便于读者理解模型设计",
        "location": "模型介绍部分",
        "description": "将多语种输出任务简化为单语种输出进行阐述，实际方法可扩展到多语种情况，降低表述复杂性，便于读者理解。"
      },
      {
        "name": "符号与公式定义",
        "type": "method-level",
        "purpose": "提升表达精确性和可复现性",
        "location": "模型方法部分",
        "description": "明确定义输入、输出序列符号及其上下文（如y<t, y>t），为后续公式推导和模型描述打下基础，保证表达的严谨性。"
      },
      {
        "name": "联合自回归建模",
        "type": "method-level",
        "purpose": "提升模型预测能力",
        "location": "模型方法部分",
        "description": "提出联合自回归建模（joint autoregressive modeling），同时预测转录和翻译，提升模型的上下文理解和输出一致性。"
      },
      {
        "name": "双解码器设计",
        "type": "method-level",
        "purpose": "解决联合任务中的词汇和任务干扰问题",
        "location": "模型方法部分",
        "description": "针对联合ASR和ST任务，设计双解码器分别处理转录和翻译，避免单一解码器导致词汇表过大和任务干扰，提高模型性能。"
      },
      {
        "name": "理论与实际结合",
        "type": "writing-level",
        "purpose": "增强方法的通用性和适用性",
        "location": "模型设计说明",
        "description": "虽然用单一目标语言阐述模型，但所有方法和结果都适用于多语种场景，理论与实际结合，提升模型的通用性。"
      },
      {
        "name": "形式化概率建模",
        "type": "method-level",
        "purpose": "确保模型描述的数学严谨性",
        "location": "模型方法部分",
        "description": "用概率公式形式化模型预测过程（如p(y, z | x)），为后续模型训练和推导提供数学基础。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_81",
    "title": "Subword Representations and Pre-trained Language Model for Thai Part-of-Speech Tagging in Universal Part of Speech Scheme",
    "conference": "COLING",
    "domain": {
      "research_object": "针对泰语文本的词性标注，特别是使用通用词性标注体系。",
      "core_technique": "利用子词表示（字符、音节、BPE）和预训练语言模型进行词性标注。",
      "application": "提升泰语自然语言处理任务中的词性标注准确性，支持多语言应用。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "结合子词表示和预训练语言模型提升泰语通用词性标注性能",
      "tech_stack": [
        "子词表示",
        "预训练语言模型",
        "神经网络"
      ],
      "input_type": "泰语文本序列",
      "output_type": "通用词性标签序列"
    },
    "skeleton": {
      "problem_framing": "论文通过强调词性标注在NLP中的重要性，并指出其在高资源语言中的成熟应用，引入了泰语作为低资源语言的研究对象。通过具体举例，展示了泰语词汇结构的特殊性，为后续研究奠定基础。",
      "gap_pattern": "作者批评现有研究主要集中于英语和中文等高资源语言，泰语相关工作较少，且由于泰语缺乏屈折形态，传统方法难以直接应用，突出当前方法在泰语上的局限性和挑战。",
      "method_story": "方法部分采用对比展示策略，列举不同的子词切分方式（字符、音节、BPE），并结合具体例子说明这些方法如何应对泰语词汇结构的复杂性。通过引用相关工作和提出假设，逻辑递进地引出所用特征与模型。",
      "experiments_story": "实验部分以验证假设为核心，围绕不同子词表示作为特征，组织CRF和BiLSTM-CRF模型的对比实验。通过具体实验设计，展示方法有效性，紧扣前文提出的挑战与假设，形成完整的研究闭环。"
    },
    "tricks": [
      {
        "name": "提出研究空白",
        "type": "writing-level",
        "purpose": "突出研究意义和创新点",
        "location": "引言部分",
        "description": "在高资源语言（如英语和中文）POS标注已广泛研究的背景下，指出泰语POS标注的研究不足，从而突出本研究的必要性和创新性。"
      },
      {
        "name": "利用语言特性分析挑战",
        "type": "writing-level",
        "purpose": "阐明研究难点",
        "location": "引言部分",
        "description": "分析泰语为孤立语，缺乏屈折形态，从而导致POS标注难以借助形态信息，明确问题的特殊性。"
      },
      {
        "name": "假设驱动方法设计",
        "type": "method-level",
        "purpose": "理论指导实验方案",
        "location": "方法部分",
        "description": "基于泰语词语可分割为音节和子词的特性，提出将音节和子词作为特征能够提升POS标注性能，并据此设计实验。"
      },
      {
        "name": "结合最新预训练模型",
        "type": "method-level",
        "purpose": "提升模型泛化能力和适应性",
        "location": "相关工作与方法部分",
        "description": "采用ELMo和BERT等预训练模型，通过wordpiece表示解决OOV问题，并捕捉词内复合结构，提升泰语POS标注效果。"
      },
      {
        "name": "多粒度子词特征融合",
        "type": "method-level",
        "purpose": "丰富输入特征，提升模型表现",
        "location": "方法部分",
        "description": "将字符、音节、BPE等不同粒度的子词特征作为输入，通过多种方式（如三元组、单元组）进行特征融合，增强模型对词汇细节的感知。"
      },
      {
        "name": "对比不同子词分割方式",
        "type": "experiment-level",
        "purpose": "验证各特征方法的有效性",
        "location": "实验设计部分",
        "description": "对比wordpiece、音节分割、BPE等子词分割方法，分析各自对POS标注性能的影响，科学验证假设。"
      },
      {
        "name": "特征工程与模型结合",
        "type": "method-level",
        "purpose": "提升传统模型性能",
        "location": "方法部分",
        "description": "在CRF模型中，将子词表示作为离散特征（如字符三元组、音节单元组）加入，提高模型对泰语特殊结构的适应能力。"
      },
      {
        "name": "端到端嵌入表示学习",
        "type": "method-level",
        "purpose": "自动提取有效特征",
        "location": "方法部分",
        "description": "在BiLSTM-CRF模型中，通过BiLSTM对字符、音节、BPE嵌入进行序列建模，自动学习词的深层表示。"
      },
      {
        "name": "案例分析辅助说明",
        "type": "writing-level",
        "purpose": "增强方法可理解性",
        "location": "方法部分与表格说明",
        "description": "通过具体泰语复合词的分割示例（如表2），直观展示不同子词分割方法，帮助读者理解方法设计依据。"
      },
      {
        "name": "引用前沿相关工作",
        "type": "writing-level",
        "purpose": "增强论文权威性与学术联系",
        "location": "引言与方法部分",
        "description": "系统引用Bohnet et al., Akbik et al., Peters et al., Devlin et al.等最新工作，说明方法选择的学术依据和前沿性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_82",
    "title": "Modality Enriched Neural Network for Metaphor Detection",
    "conference": "COLING",
    "domain": {
      "research_object": "该论文研究多模态神经网络在隐喻检测任务中的表现与方法。",
      "core_technique": "采用融合多种模态信息的神经网络模型，以提升隐喻识别的准确性。",
      "application": "可应用于自然语言处理中的文本理解、情感分析及自动内容生成等场景。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "融合多模态信息的神经网络提升隐喻检测准确率",
      "tech_stack": [
        "神经网络",
        "多模态融合",
        "隐喻识别"
      ],
      "input_type": "文本及其他模态数据（如图像、语音）",
      "output_type": "文本中隐喻的检测结果"
    },
    "skeleton": {
      "problem_framing": "论文通过强调隐喻在日常语言中的普遍性和无意识性，引出其在认知和交流中的核心作用。引用Lakoff等权威理论，将隐喻定位为理解世界和结构化经验的基本机制，从而凸显研究隐喻的重要性和现实意义。",
      "gap_pattern": "作者通过回顾隐喻相关理论和现有方法，暗示传统方法在处理复杂隐喻识别时的局限性，尤其是在语义迁移和多模态信息整合方面未能充分捕捉隐喻本质，进而为提出新模型奠定理论和实际需求基础。",
      "method_story": "方法部分采用逐步递进的叙述策略，先介绍模型整体架构与关键技术（如LSTM、注意力机制），再详细说明各模块功能及其在隐喻识别中的作用。通过公式和流程图，增强方法的透明度和可复现性，突出创新点。",
      "experiments_story": "实验部分通过明确的数据集划分和基线设定，突出模型评估的科学性。先对比传统方法和各子模型，逐步展示新模型的性能提升，最终用量化指标（如F1提升）突出方法有效性，形成递进式论证结构。"
    },
    "tricks": [
      {
        "name": "引言中定义与背景引入",
        "type": "writing-level",
        "purpose": "为研究设定理论基础，帮助读者理解研究对象的重要性和背景",
        "location": "论文开头关于隐喻的定义和Lakoff的理论引用",
        "description": "通过引用权威文献（如Lakoff等人）介绍隐喻的认知机制和语言属性，为后续研究方法和实验设计提供理论依据。"
      },
      {
        "name": "明确提出研究问题和创新点",
        "type": "writing-level",
        "purpose": "突出本研究与已有工作的区别和创新，吸引读者注意",
        "location": "提出‘我们提出一种语言学增强的深度学习模型’及对已有工作的延续和改进",
        "description": "在介绍相关研究基础上，明确指出本研究在已有工作的基础上进行了哪些拓展（如引入modality norms），强调研究的创新性。"
      },
      {
        "name": "采用标准公开数据集",
        "type": "experiment-level",
        "purpose": "保证实验结果的可比性和可复现性",
        "location": "说明使用VUA corpus及其共享任务数据集",
        "description": "详细说明数据集来源及其在领域中的权威性，使得实验结果具有说服力和可与其他方法直接比较。"
      },
      {
        "name": "特征融合输入表示",
        "type": "method-level",
        "purpose": "增强模型输入的表达能力，提升模型性能",
        "location": "描述用glove嵌入和modality向量作为输入，进行拼接",
        "description": "将词嵌入和语言学特征（modality向量）进行拼接，作为模型输入，使得模型能同时利用分布式语义信息和语言学知识。"
      },
      {
        "name": "引入注意力机制",
        "type": "method-level",
        "purpose": "自动聚焦于输入序列中与任务最相关的信息，提高模型表现",
        "location": "详细描述attention机制如何计算权重并与LSTM输出结合",
        "description": "在BiLSTM的基础上加入attention机制，对每个词的隐藏状态分配权重，生成加权句子表示以提升分类性能。"
      },
      {
        "name": "损失函数正则化",
        "type": "method-level",
        "purpose": "防止模型过拟合，提高泛化能力",
        "location": "损失函数部分包含L2正则项",
        "description": "在交叉熵损失函数中加入L2正则化项，对参数进行约束，减少模型在训练集上的过拟合。"
      },
      {
        "name": "模型结构图示说明",
        "type": "writing-level",
        "purpose": "帮助读者直观理解模型架构",
        "location": "提及Figure 1展示模型结构",
        "description": "通过图示展示模型各部分（如输入、拼接、LSTM、注意力、线性层等）及其关系，增强论文的可读性和表达力。"
      },
      {
        "name": "详细步骤化方法描述",
        "type": "writing-level",
        "purpose": "让方法流程清晰易懂，便于复现",
        "location": "逐步描述从输入到输出的处理流程",
        "description": "系统性地描述每一步数据处理和模型计算（如输入拼接、LSTM处理、注意力加权、线性层、softmax输出），确保方法可操作性和复现性。"
      },
      {
        "name": "与前人工作的对比与延续",
        "type": "writing-level",
        "purpose": "展示研究的连续性和改进点",
        "location": "说明基于WAN et al., 2020工作的延续和改进",
        "description": "在方法介绍中明确指出本研究对前人工作的继承与拓展，体现学术研究的传承与创新。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_83",
    "title": "Constructing A Multi-hop QA Dataset for Comprehensive Evaluation of Reasoning Steps",
    "conference": "COLING",
    "domain": {
      "research_object": "多跳问答数据集的构建与推理步骤的全面评估方法。",
      "core_technique": "利用多跳推理和数据集设计，评估模型在复杂推理任务中的表现。",
      "application": "用于自然语言处理模型的推理能力测试与评估。",
      "domains": [
        "自然语言处理",
        "人工智能"
      ]
    },
    "ideal": {
      "core_idea": "构建多跳问答数据集以全面评估模型推理能力",
      "tech_stack": [
        "数据集构建",
        "多跳推理",
        "机器阅读理解"
      ],
      "input_type": "文本材料与问题",
      "output_type": "多跳推理问答数据集"
    },
    "skeleton": {
      "problem_framing": "论文在引言部分通过定义机器阅读理解（MRC）的目标，并引用主流模型在SQuAD数据集上的优异表现，强调该领域的研究进展。接着，作者指出当前模型虽在指标上超越人类，但并不代表真正理解文本，为后续问题展开奠定基础。",
      "gap_pattern": "作者通过引用前人工作，指出现有模型存在理解不精确、容易被对抗样本欺骗，以及数据集包含大量简单实例等问题，批判现有方法的局限性，强调需要更深入的文本理解能力，从而提出研究空白。",
      "method_story": "在方法部分，作者以现有基线模型为基础，描述了对模型结构的改进，特别是新增证据生成模块，并说明复用了双向注意力等技术。方法叙述以任务分解和技术细节为主，突出创新点和与前作的联系。",
      "experiments_story": "实验部分详细说明了模型修改及证据生成流程，结合具体技术步骤和评价指标，展示了实验设计的严谨性。通过表格呈现结果，并对任务难度和模型表现进行分析，突出实验的针对性和有效性。"
    },
    "tricks": [
      {
        "name": "引用前人工作和数据集",
        "type": "writing-level",
        "purpose": "建立背景和相关性",
        "location": "论文开头",
        "description": "通过引用前人研究和数据集（如SQuAD、ComplexWebQuestions等），展示领域发展现状及存在的问题，为后续研究动机和方法奠定基础。"
      },
      {
        "name": "分析现有模型的局限性",
        "type": "writing-level",
        "purpose": "突出研究意义",
        "location": "背景介绍部分",
        "description": "指出当前模型虽然在标准数据集上表现优异，但并不代表真正理解文本，强调对模型推理和理解能力的进一步研究需求。"
      },
      {
        "name": "采用对比实验设计",
        "type": "experiment-level",
        "purpose": "验证新方法有效性",
        "location": "方法与实验部分",
        "description": "通过对比基线模型和改进模型的性能，评估新方法（如证据生成模块）在多跳推理任务中的表现。"
      },
      {
        "name": "模块化模型设计",
        "type": "method-level",
        "purpose": "提升模型功能与可扩展性",
        "location": "方法部分",
        "description": "在基线模型中新增证据生成模块，并采用不同的技术（如bi-attention）进行多任务处理，提高模型推理能力。"
      },
      {
        "name": "多任务学习框架",
        "type": "method-level",
        "purpose": "同时解决多个相关任务",
        "location": "模型设计部分",
        "description": "模型同时进行句子级支持事实预测和证据生成任务，提升模型对复杂问题的处理能力。"
      },
      {
        "name": "细粒度错误分析",
        "type": "experiment-level",
        "purpose": "发现模型不足与改进方向",
        "location": "实验结果分析部分",
        "description": "对模型在证据生成任务中的错误进行分析，发现模型能部分正确预测，但难以完全准确，说明任务难度并提出改进建议。"
      },
      {
        "name": "采用多种评价指标",
        "type": "method-level",
        "purpose": "全面评估模型性能",
        "location": "实验结果部分",
        "description": "使用不同评价指标（如EM分数、二分类准确率等）分别评估支持事实预测和证据生成任务，保证评估的全面性和细致性。"
      },
      {
        "name": "任务难度分级分析",
        "type": "experiment-level",
        "purpose": "深入理解模型表现",
        "location": "实验结果部分",
        "description": "对不同类型问题进行性能分类分析，探讨各类问题对模型推理能力的挑战，揭示模型在复杂任务上的瓶颈。"
      },
      {
        "name": "引入结构化证据表示",
        "type": "method-level",
        "purpose": "提升解释性与推理能力",
        "location": "方法部分",
        "description": "将证据信息表示为三元组（主语、关系、宾语），便于模型进行结构化推理和结果解释。"
      },
      {
        "name": "强调任务创新性",
        "type": "writing-level",
        "purpose": "突出贡献",
        "location": "讨论与结论部分",
        "description": "强调将证据生成任务加入数据集，有助于测试模型的推理和推断能力，提升数据集和任务的研究价值。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_84",
    "title": "Automatic Distractor Generation for Multiple Choice Questions in Standard Tests",
    "conference": "COLING",
    "domain": {
      "research_object": "自动生成标准测试多项选择题的干扰项，提高题目质量和评估效果。",
      "core_technique": "利用自然语言处理和生成模型自动构建合理的干扰项选项。",
      "application": "用于教育考试系统、在线学习平台的自动化题库建设与评估。",
      "domains": [
        "自然语言处理",
        "教育技术"
      ]
    },
    "ideal": {
      "core_idea": "自动生成标准测试多项选择题的干扰项",
      "tech_stack": [
        "自然语言处理",
        "机器学习",
        "文本生成"
      ],
      "input_type": "标准测试题目及正确答案文本",
      "output_type": "高质量多项选择题干扰项列表"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍标准化考试（如TOEFL和SAT）在评估学习者知识水平中的重要作用，引出选择合适题型（尤其是多项选择题MCQ）的问题。通过强调MCQ的广泛应用和优势，自然引出对其组成部分（如干扰项）的关注，明确研究背景和实际意义。",
      "gap_pattern": "文中隐含地指出，尽管MCQ被广泛采用，但如何生成高质量的干扰项仍是一个关键挑战。通过对现有测试流程的描述，突出当前干扰项生成方法的不足，暗示需要更有效的自动化方法来提升考试题目的质量和区分度。",
      "method_story": "方法部分采用“技术栈+可扩展性”策略，先明确使用GloVe词向量和Bi-LSTM编码器，并说明模块间参数共享，突出方法的通用性和可替换性。通过具体参数设置和模型结构，展示方法的科学性和灵活性，便于后续复现和扩展。",
      "experiments_story": "实验部分采用“多维评价+人工标注”策略，详细说明评价指标（流畅性、连贯性、迷惑性）及其来源，强调评价的客观性和权威性。通过描述样本选择、对比模型和评审人员资质，增强实验的公正性和说服力，突出结果的可靠性。"
    },
    "tricks": [
      {
        "name": "引用权威来源支持论点",
        "type": "writing-level",
        "purpose": "增强论述的可信度和权威性",
        "location": "第一段，提及(Ch and Saha, 2018)",
        "description": "在介绍标准化考试及MCQ优势时，引用了权威文献来支撑相关观点，使论述更具说服力。"
      },
      {
        "name": "详细描述研究对象",
        "type": "writing-level",
        "purpose": "让读者清楚理解研究对象的结构和特性",
        "location": "第一段，介绍MCQ结构",
        "description": "对MCQ的结构（stem、候选答案、distractors）进行详细拆解，便于后续方法展开。"
      },
      {
        "name": "强调研究难点和意义",
        "type": "writing-level",
        "purpose": "突出研究问题的重要性和挑战性，引起读者兴趣",
        "location": "第一段，关于distractor设计的讨论",
        "description": "指出高质量distractor设计的困难，并说明其对测试区分度和有效性的影响，凸显研究价值。"
      },
      {
        "name": "提出判定标准",
        "type": "writing-level",
        "purpose": "为后续方法设计提供评价标准",
        "location": "第一段，good distractor的标准",
        "description": "明确提出distractor应具备语法正确、语义一致且具有迷惑性等标准，为后续方法评价提供依据。"
      },
      {
        "name": "模块化设计方法",
        "type": "method-level",
        "purpose": "提升模型的可扩展性和灵活性",
        "location": "第二段，Bi-LSTM编码器描述",
        "description": "将Bi-LSTM编码器设计为可替换的模块，便于用Transformer、BERT等其他模型替换，增强方法通用性。"
      },
      {
        "name": "共享参数机制",
        "type": "method-level",
        "purpose": "减少模型参数量，提高效率",
        "location": "第二段，Bi-LSTM参数共享",
        "description": "在编码模块和两个reforming模块之间共享Bi-LSTM参数，提升训练效率，降低过拟合风险。"
      },
      {
        "name": "合理设置输入长度上限",
        "type": "experiment-level",
        "purpose": "控制计算资源消耗，保证模型覆盖主流数据",
        "location": "第二段，最大长度设置",
        "description": "根据95百分位数设置passage、question、answer、distractor的最大长度，兼顾效率与数据覆盖率。"
      },
      {
        "name": "使用预训练词向量",
        "type": "method-level",
        "purpose": "利用外部知识提升模型表现",
        "location": "第二段，GloVe.840B.300d",
        "description": "采用GloVe预训练词向量初始化词嵌入，提升模型对语义的理解能力。"
      },
      {
        "name": "采用主流优化器和正则化手段",
        "type": "experiment-level",
        "purpose": "提升模型训练效果，防止过拟合",
        "location": "第二段，NAG优化器和dropout",
        "description": "使用Nesterov Accelerated Gradient优化器，设置合理学习率，并采用dropout防止过拟合。"
      },
      {
        "name": "多基线模型对比实验",
        "type": "experiment-level",
        "purpose": "全面验证新方法的有效性",
        "location": "第二段，基线模型介绍",
        "description": "选取多种序列到序列基础模型及其变体作为对比基线，提升实验说服力。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_85",
    "title": "ContraCAT: Contrastive Coreference Analytical Templates for Machine Translation",
    "conference": "COLING",
    "domain": {
      "research_object": "针对机器翻译中的指代消解问题，提出分析模板以提升翻译质量。",
      "core_technique": "采用对比学习方法与指代消解分析模板，增强模型对指代关系的理解。",
      "application": "用于提升机器翻译系统在处理指代关系时的准确性和一致性。",
      "domains": [
        "自然语言处理",
        "机器翻译"
      ]
    },
    "ideal": {
      "core_idea": "通过对比模板提升机器翻译中的指代消解准确性",
      "tech_stack": [
        "对比学习",
        "指代消解分析",
        "模板方法"
      ],
      "input_type": "包含需翻译文本及指代信息的语料",
      "output_type": "指代消解优化后的目标语言翻译文本"
    },
    "skeleton": {
      "problem_framing": "论文通过具体实例（英语it到德语的翻译）展示机器翻译任务的复杂性，强调需要多层次语言知识。引用前人工作，突出指代消解在上下文感知模型中的重要性，并提出核心问题：Transformer模型是否真正学会了该任务。",
      "gap_pattern": "作者指出虽然已有方法和模型在指代翻译上取得进展，但Transformer是否真正理解和解决了指代消解问题仍存疑。通过质疑现有模型的能力，明确研究空白，强调进一步分析的必要性。",
      "method_story": "方法部分采用对比和扩展策略，先以句级Transformer为基线，再通过拼接上下文句子增强模型能力。详细描述数据处理和实验设置，突出方法的创新点和与前人工作的联系，确保可复现性。",
      "experiments_story": "实验设计围绕对模型表现的系统性攻击，分析不同类型干扰对分数的影响。通过具体案例（如引入新实体、同义词替换等）揭示模型弱点，并用数据和图表支持分析，强调实验结果的解释性和洞察力。"
    },
    "tricks": [
      {
        "name": "引用前人工作以建立研究背景",
        "type": "writing-level",
        "purpose": "展示研究的背景和相关性，说明问题的重要性",
        "location": "引言段（如提及Hardmeier and Federico, 2010; Miculicich Werlen and Popescu-Belis, 2017; Müller et al., 2018）",
        "description": "通过引用前人的研究，说明pronoun translation在NMT中的挑战和已有的评测方法，为本研究提供理论基础。"
      },
      {
        "name": "提出研究问题并设立假设",
        "type": "writing-level",
        "purpose": "明确研究目标，引导读者关注核心问题",
        "location": "引言段（如：'the question remains: Are transformers...?'）",
        "description": "在介绍背景后，直接提出当前transformer模型是否真正学会了指代消解任务，还是仅仅利用了简单启发式规则，明确研究关注点。"
      },
      {
        "name": "对比实验（基线与改进模型）",
        "type": "experiment-level",
        "purpose": "评估上下文信息对模型性能的影响",
        "location": "方法部分（如：'We use Transformer for all experiments and train a sentence-level model as a baseline.'）",
        "description": "设置句子级Transformer作为基线模型，再通过添加上下文信息的模型与之比较，分析上下文对表现的提升。"
      },
      {
        "name": "引入对抗性攻击（adversarial attacks）",
        "type": "method-level",
        "purpose": "测试模型的鲁棒性，揭示模型潜在缺陷",
        "location": "方法部分（如：'making small adversarial changes in the contextual sentences.'）",
        "description": "通过对输入文本做细微但有针对性的修改，检验模型对pronoun coreference的处理是否依赖于脆弱的启发式规则。"
      },
      {
        "name": "使用对比数据集（ContraPro扩展）",
        "type": "experiment-level",
        "purpose": "系统化评测模型对指代消解的能力",
        "location": "方法部分（如：'we extend ContraPro...a contrastive challenge set'）",
        "description": "在已有的ContraPro数据集基础上，通过对抗性修改扩展测试集，便于自动化且细粒度地评估模型表现。"
      },
      {
        "name": "上下文拼接输入法（concatenation of sentences）",
        "type": "method-level",
        "purpose": "将上下文信息纳入模型输入，提升模型对跨句指代的处理能力",
        "location": "方法部分（如：'incorporate contextual information...by concatenating consecutive sentences.'）",
        "description": "通过在源端和目标端分别拼接前一句和当前句，并用特殊分隔符<SEP>区分，使模型能够获取更多上下文信息。"
      },
      {
        "name": "消融实验（移除重叠文档）",
        "type": "experiment-level",
        "purpose": "避免数据泄漏，确保评测的公正性",
        "location": "方法部分（如：'We remove documents overlapping with ContraPro.'）",
        "description": "训练集与测试集去重，防止模型在训练时见过测试数据，保证评测结果的有效性。"
      },
      {
        "name": "错误案例分析",
        "type": "experiment-level",
        "purpose": "深入理解模型错误原因，发现潜在问题",
        "location": "结果分析部分（如：'We analyze examples that are scored incorrectly.'）",
        "description": "对模型预测错误的样本进行详细分析，区分不同类型的对抗攻击对模型的影响，揭示模型脆弱点。"
      },
      {
        "name": "同义词替换实验",
        "type": "experiment-level",
        "purpose": "检验模型对词汇变化的敏感性",
        "location": "结果分析部分（如：'Our synonym replacement also leads to a 17% drop in scores.'）",
        "description": "通过替换输入中的同义词，测试模型对轻微语义变动的鲁棒性，发现其对同义表达的适应能力有限。"
      },
      {
        "name": "定量与直观分析结合",
        "type": "writing-level",
        "purpose": "增强论证的说服力，便于读者理解结果",
        "location": "结果分析部分（如：'These straightforward modifications drop the ContraPro scores by over 10%'）",
        "description": "通过量化分数变化（如10%、17%下降）和举具体实例（如it/that替换）相结合，说明模型对对抗性攻击的脆弱。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_86",
    "title": "Using Eye-tracking Data to Predict the Readability of Brazilian Portuguese Sentences in Single-task, Multi-task and Sequential Transfer Learning Approaches",
    "conference": "COLING",
    "domain": {
      "research_object": "利用眼动追踪数据预测巴西葡萄牙语句子的可读性",
      "core_technique": "单任务、多任务和序列迁移学习方法结合眼动追踪数据分析",
      "application": "辅助巴西葡萄牙语文本的可读性评估与优化",
      "domains": [
        "自然语言处理",
        "认知科学"
      ]
    },
    "ideal": {
      "core_idea": "利用眼动追踪数据预测葡萄牙语句子的可读性，比较多种学习方法。",
      "tech_stack": [
        "眼动追踪数据分析",
        "单任务学习",
        "多任务学习",
        "顺序迁移学习"
      ],
      "input_type": "葡萄牙语句子及对应眼动追踪数据",
      "output_type": "可读性预测评分或标签"
    },
    "skeleton": {
      "problem_framing": "论文通过引用权威定义（Dubay, 2007）对文本可读性进行界定，并追溯其自动化分析的历史起源，强调可读性在教育领域的实际应用，逐步引入复杂度评估的传统方法，为后续研究奠定背景基础。",
      "gap_pattern": "作者指出传统可读性评估依赖于表层词句指标，暗示其局限性，未能充分考虑更深层的语言特征与读者实际阅读过程，为引入新的评估方法和特征选择创造理论空白。",
      "method_story": "方法部分采用递进式叙述，首先验证现有语言特征对眼动数据的预测能力，随后以此为基础筛选特征，并系统比较单任务、多任务及顺序迁移学习方法，强调模型评估的严谨性和技术实现细节。",
      "experiments_story": "实验部分通过10折交叉验证确保结果的可靠性，统一采用Adam优化器，并明确使用Keras和Scikit-Learn工具，突出实验流程的标准化和可复现性，为结果分析提供坚实基础。"
    },
    "tricks": [
      {
        "name": "引用权威定义",
        "type": "writing-level",
        "purpose": "增强论文的理论基础和权威性",
        "location": "开头段落",
        "description": "通过引用Dubay (2007)等权威学者对文本可读性的定义，为研究奠定理论基础，显示对前人研究的继承和尊重。"
      },
      {
        "name": "梳理领域发展脉络",
        "type": "writing-level",
        "purpose": "展示研究背景和领域演变",
        "location": "第二句至第三句",
        "description": "通过回顾可读性自动化的起源及其发展历程，帮助读者了解该领域的历史演变和现有研究基础。"
      },
      {
        "name": "引入多学科视角",
        "type": "writing-level",
        "purpose": "突出研究的广泛性和多样性",
        "location": "中段",
        "description": "强调可读性分析已成为多学科研究领域，覆盖了文本简化、文本摘要等相关任务，凸显研究的应用广度。"
      },
      {
        "name": "强调技术进步",
        "type": "writing-level",
        "purpose": "说明研究创新点和技术背景",
        "location": "介绍NLP和机器学习方法时",
        "description": "指出随着NLP和机器学习的发展，可读性分析采用了新的计算方法，体现研究与技术前沿的结合。"
      },
      {
        "name": "分层次分析对象",
        "type": "method-level",
        "purpose": "细化研究粒度，提高分析精度",
        "location": "介绍句子和文档层面",
        "description": "不仅在文档层面分析可读性，还关注句子层面的复杂性，反映出对分析对象的分层次处理。"
      },
      {
        "name": "特征与指标的验证性分析",
        "type": "experiment-level",
        "purpose": "确保特征选择的科学性",
        "location": "模型开发流程描述",
        "description": "先验证当前语言特征能否预测眼动追踪指标，再以此为基础选择特征，保证特征选择的合理性和有效性。"
      },
      {
        "name": "多模型对比实验",
        "type": "experiment-level",
        "purpose": "评估不同模型的性能",
        "location": "模型开发流程描述",
        "description": "对比了单任务、多任务和顺序迁移学习三种方法，全面评估不同机器学习策略的优劣。"
      },
      {
        "name": "交叉验证",
        "type": "experiment-level",
        "purpose": "提升结果的可靠性和泛化能力",
        "location": "模型评估方法",
        "description": "采用10折交叉验证评估模型性能，确保实验结果的稳健性和代表性。"
      },
      {
        "name": "详细工具和参数说明",
        "type": "method-level",
        "purpose": "保证实验可复现性",
        "location": "方法描述结尾",
        "description": "明确说明使用了Adam优化器、Keras和Scikit-Learn包，以及Python语言，便于他人复现实验流程。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_8",
    "title": "Incorporating Inner-word and Out-word Features for Mongolian Mor- phological Segmentation",
    "conference": "COLING",
    "domain": {
      "research_object": "蒙古语形态切分方法，关注词内部和上下文特征的利用。",
      "core_technique": "结合内词特征与外部上下文特征的神经网络模型，采用LSTM结构实现端到端切分。",
      "application": "用于蒙古语相关的自然语言处理任务的预处理，如分词和语法分析。",
      "domains": [
        "自然语言处理",
        "计算语言学"
      ]
    },
    "ideal": {
      "core_idea": "结合词内和词外特征提升蒙古语形态切分效果",
      "tech_stack": [
        "LSTM",
        "端到端分割方法",
        "特征融合"
      ],
      "input_type": "蒙古语单词或文本序列",
      "output_type": "分割后的蒙古语词素序列"
    },
    "skeleton": {
      "problem_framing": "论文通过介绍蒙古语的形态复杂性及其词缀结构，强调形态切分对自然语言处理任务的重要性。引用相关文献，展示该问题在命名实体识别、信息检索、机器翻译等领域的应用价值，从而引出对蒙古语形态切分的研究需求。",
      "gap_pattern": "文中通过列举蒙古语拥有约六万形态素及其衍生词数量巨大，隐含当前方法在处理复杂形态变化时的不足。并通过对比已有方法，暗示现有模型在准确率和泛化能力等方面存在提升空间，强调研究意义。",
      "method_story": "方法部分采用结构化叙述，先整体介绍模型架构及其主要组件，然后分节详细说明每一部分。通过与主流方法（如BiLa*和True and pseudo mapping model）对比，突出所提SAN模型的创新点和改进之处。",
      "experiments_story": "实验部分以定量评价为主，明确采用Precision、Recall和F1-score等标准指标，并详细说明评价方式和模型参数设置。通过与已有方法对比，展示新模型的性能优势，保证实验的可复现性和科学性。"
    },
    "tricks": [
      {
        "name": "背景介绍与任务动机",
        "type": "writing-level",
        "purpose": "为研究任务提供背景和必要性，突出任务的重要性",
        "location": "开头部分",
        "description": "通过介绍蒙古语的形态结构特点、词法分析的难点及其在NLP任务中的应用，强调形态切分对下游任务的促进作用和缓解OOV问题的意义。"
      },
      {
        "name": "相关工作对比说明",
        "type": "writing-level",
        "purpose": "展示研究与已有方法的联系并突出创新点",
        "location": "模型介绍前",
        "description": "简要介绍并引用当前主流的蒙古语形态切分方法（如BiLa*和True and pseudo mapping model），为后续实验对比和创新点说明做铺垫。"
      },
      {
        "name": "任务定义与标准化",
        "type": "method-level",
        "purpose": "明确实验任务和评价单位，保证研究的可复现性",
        "location": "定量评估部分",
        "description": "将蒙古语形态切分任务标准化为将词切分为词素（morpheme）单元，并在后续评价中以词素为单位，便于量化评估。"
      },
      {
        "name": "采用标准评价指标",
        "type": "experiment-level",
        "purpose": "保证实验结果的可比性和科学性",
        "location": "定量评估部分",
        "description": "采用Precision、Recall和F1-score作为分割系统的评价指标，并给出明确的定义和计算公式，确保与相关文献的一致性。"
      },
      {
        "name": "对比实验设计",
        "type": "experiment-level",
        "purpose": "验证新方法的有效性和优越性",
        "location": "方法与实验部分",
        "description": "与已有方法（如BiLa*和True and pseudo mapping model）进行对比实验，采用相同实现和参数设置，确保对比的公平性和客观性。"
      },
      {
        "name": "模型结构分层描述",
        "type": "method-level",
        "purpose": "清晰展示模型创新点和结构组成",
        "location": "模型介绍部分",
        "description": "将提出的SAN-based模型分为inner-word encoder、out-word encoders和doubly attentive decoder三大模块，并分别详细介绍，突出模型设计的层次性和创新性。"
      },
      {
        "name": "数据稀疏与OOV问题强调",
        "type": "writing-level",
        "purpose": "突出研究意义，吸引读者关注",
        "location": "背景介绍部分",
        "description": "特别指出蒙古语词素数量巨大，词形变化导致的数据稀疏和OOV（未登录词）问题，为形态切分研究提供现实驱动力。"
      },
      {
        "name": "实例展示与可解释性增强",
        "type": "writing-level",
        "purpose": "通过实例帮助读者理解任务",
        "location": "背景介绍后，表格展示",
        "description": "通过表格展示蒙古语形态切分的具体例子，使任务定义更加具体、直观，提升论文的可理解性。"
      }
    ]
  },
  {
    "paper_id": "COLING_2020_9",
    "title": "Visual-Textual Alignment for Graph Inference in Visual Dialog",
    "conference": "COLING",
    "domain": {
      "research_object": "视觉对话中的视觉与文本信息对齐及图推理方法",
      "core_technique": "结合视觉-文本对齐机制与图推理模型提升对话理解能力",
      "application": "用于多模态对话系统中的信息理解与交互优化",
      "domains": [
        "人工智能",
        "计算机视觉"
      ]
    },
    "ideal": {
      "core_idea": "通过视觉-文本对齐提升视觉对话中的图推理能力",
      "tech_stack": [
        "跨模态对齐",
        "图神经网络",
        "视觉对话建模"
      ],
      "input_type": "图像与多轮文本对话",
      "output_type": "对话回复或推理结果"
    },
    "skeleton": {
      "problem_framing": "论文通过回顾跨模态语义理解在自然语言处理和计算机视觉中的重要任务（如图像描述和视觉问答），强调视觉与语言协同的挑战，并以文献引用的方式展示该领域的研究进展，逐步引出视觉对话任务的提出。",
      "gap_pattern": "作者批评现有任务仅支持单轮视觉与语言的共指，缺乏与人类持续交互的能力，明确指出传统方法在多轮对话和上下文理解方面的不足，从而为视觉对话任务的必要性和创新性奠定基础。",
      "method_story": "方法部分采用递进式叙述，先形式化定义视觉对话任务及输入输出结构，随后分章节介绍语言特征、图像特征、核心模块（VTA和VGAT），通过分步细化逐层展开模型设计思路，逻辑清晰。",
      "experiments_story": "实验部分先介绍所用数据集的版本及特点，详细说明训练、验证、测试集的规模和差异，随后描述评价流程和标准，突出模型在真实多轮对话场景下的表现，整体结构由数据到评估逐步展开，便于理解方法有效性。"
    },
    "tricks": [
      {
        "name": "引用前人工作以建立背景",
        "type": "writing-level",
        "purpose": "通过引用相关文献，阐明研究领域的发展和现有挑战，增强论文的学术基础和说服力。",
        "location": "开头段落",
        "description": "在介绍领域时，引用了多篇相关工作，如图像描述、视觉问答等，展示了跨模态语义理解的研究进展，并指出现有任务的不足。"
      },
      {
        "name": "问题定义的形式化表达",
        "type": "method-level",
        "purpose": "明确任务输入输出，便于后续方法描述和实验复现。",
        "location": "方法部分开头",
        "description": "以数学符号形式详细定义视觉对话任务，包括输入的图片、问题、历史对话，以及候选答案的排序任务。"
      },
      {
        "name": "数据集详细说明",
        "type": "experiment-level",
        "purpose": "让读者清楚实验所用数据集的规模、来源及分割方式，保证实验的可复现性和可信度。",
        "location": "方法与实验部分",
        "description": "对VisDial v1.0数据集进行了详细介绍，包括图片来源、对话数量、训练/验证/测试集划分，以及测试集对话长度的特殊性。"
      },
      {
        "name": "任务挑战分析与动机阐述",
        "type": "writing-level",
        "purpose": "突出任务的关键难点，引出后续方法设计的合理性和必要性。",
        "location": "引言与相关工作分析",
        "description": "通过引用人工分析结果，指出约20%的问题需要历史对话信息，强调如何有效利用文本与视觉信息是视觉对话任务的核心挑战。"
      },
      {
        "name": "模块化方法结构说明",
        "type": "method-level",
        "purpose": "清晰划分模型结构，便于读者理解各部分作用和创新点。",
        "location": "方法部分结构安排",
        "description": "在方法部分，提前告知将分别介绍语言特征、图像特征、VTA模块和VGAT模块，形成模块化描述。"
      },
      {
        "name": "与已有方法对比分析",
        "type": "writing-level",
        "purpose": "通过对比，突出新方法的创新点和改进之处。",
        "location": "相关工作描述",
        "description": "简要介绍了RvA和DAN等已有方法如何处理对话历史，为后续方法创新做铺垫。"
      },
      {
        "name": "标准化评价指标说明",
        "type": "experiment-level",
        "purpose": "确保实验结果具有通用性和可比性。",
        "location": "实验设置部分",
        "description": "详细说明了模型在每轮对话的评估方式，采用标准检索指标如mean rank等，保证结果可以与前人工作直接比较。"
      },
      {
        "name": "任务流程分步描述",
        "type": "method-level",
        "purpose": "帮助读者系统理解模型处理流程。",
        "location": "方法定义部分",
        "description": "明确分步描述了输入（图片、问题、历史）、处理过程（模型排序候选答案）、输出（返回排序列表）等环节。"
      }
    ]
  }
]