[
  {
    "review_id": "79120777ee4ef25b",
    "paper_id": "COLING_2020_3",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "The paper presents the application of relatively simple data augmentation techniques to a NER task, evaluated on two different datasets.\nThe paper is clearly written and the results are interesting, although not specially exciting. In particular, the experiments with RNNs show much lower performance than those with the transformer model (and hence, the improvements are also smaller, as the baseline is also higher).\nSome details should be given, for example: - \"(LwTR): For each token, we use a binomial distribution to randomly decide whether it should be replaced\"   Does this mean to replace a token with 50% probability? Or any other proportion? Why ths number? Have this been tested on a small subset of the data to adjust it conveniently?\nMinor corrections: these augmentation do not rely ---> these augmentations do not rely previous studies mainly investigative the effectiveness ---> previous studies mainly investigate the effectiveness RoBERTa (Liu et al., 2019), which have captured various knowledge. --- > I think that the sentence is not correct (but I am not totally sure). Please revise.",
    "overall_score": "2",
    "confidence": "3"
  }
]