[
  {
    "review_id": "37f5cdda9053e0c5",
    "paper_id": "COLING_2020_77",
    "reviewer": null,
    "paper_summary": "",
    "strengths": "",
    "weaknesses": "",
    "comments": "From a general point of view, the paper describes the effect of the teacher-forcing technique employed in training a recurrent neural network model on a sequence-to-sequence task. The teacher-forcing technique (i.e. the use of the gold-pattern to be used as input at time t) increases the exposure bias of the model (indeed the training condition is different with respect to the test condition, where the output prediction at time (t-1) is used as input at time t, hereinafter the \"student-forcing\" technique), making the model less prone to correctly predict unseen sequences. Low-resource settings perform better with the \"student-forcing\" technique, while high-resource settings benefit of the \"teacher-forcing\" technique.\nThe authors argues that the teacher-forcing technique may cause the overfitting on the training data, due to an increase of the exposure bias especially in low-resource settings. The authors tested such hypothesis on a morphological inflection task, modelled as sequence-to-sequence task at character level and employing a mixture of the two forcing methods during training.\nThe paper is clear and interesting, my main concern being the fact that the choice between the teacher and the student forcing technique remains open and highly dependant on the specific task and the size of the training data.",
    "overall_score": "4",
    "confidence": "5"
  }
]