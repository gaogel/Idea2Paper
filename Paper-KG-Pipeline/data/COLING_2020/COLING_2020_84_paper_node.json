{
  "paper_id": "COLING_2020_84",
  "title": "Automatic Distractor Generation for Multiple Choice Questions in Standard Tests",
  "conference": "COLING",
  "domain": {
    "research_object": "自动生成标准测试多项选择题的干扰项，提高题目质量和评估效果。",
    "core_technique": "利用自然语言处理和生成模型自动构建合理的干扰项选项。",
    "application": "用于教育考试系统、在线学习平台的自动化题库建设与评估。",
    "domains": [
      "自然语言处理",
      "教育技术"
    ]
  },
  "ideal": {
    "core_idea": "自动生成标准测试多项选择题的干扰项",
    "tech_stack": [
      "自然语言处理",
      "机器学习",
      "文本生成"
    ],
    "input_type": "标准测试题目及正确答案文本",
    "output_type": "高质量多项选择题干扰项列表"
  },
  "skeleton": {
    "problem_framing": "论文通过介绍标准化考试（如TOEFL和SAT）在评估学习者知识水平中的重要作用，引出选择合适题型（尤其是多项选择题MCQ）的问题。通过强调MCQ的广泛应用和优势，自然引出对其组成部分（如干扰项）的关注，明确研究背景和实际意义。",
    "gap_pattern": "文中隐含地指出，尽管MCQ被广泛采用，但如何生成高质量的干扰项仍是一个关键挑战。通过对现有测试流程的描述，突出当前干扰项生成方法的不足，暗示需要更有效的自动化方法来提升考试题目的质量和区分度。",
    "method_story": "方法部分采用“技术栈+可扩展性”策略，先明确使用GloVe词向量和Bi-LSTM编码器，并说明模块间参数共享，突出方法的通用性和可替换性。通过具体参数设置和模型结构，展示方法的科学性和灵活性，便于后续复现和扩展。",
    "experiments_story": "实验部分采用“多维评价+人工标注”策略，详细说明评价指标（流畅性、连贯性、迷惑性）及其来源，强调评价的客观性和权威性。通过描述样本选择、对比模型和评审人员资质，增强实验的公正性和说服力，突出结果的可靠性。"
  },
  "tricks": [
    {
      "name": "引用权威来源支持论点",
      "type": "writing-level",
      "purpose": "增强论述的可信度和权威性",
      "location": "第一段，提及(Ch and Saha, 2018)",
      "description": "在介绍标准化考试及MCQ优势时，引用了权威文献来支撑相关观点，使论述更具说服力。"
    },
    {
      "name": "详细描述研究对象",
      "type": "writing-level",
      "purpose": "让读者清楚理解研究对象的结构和特性",
      "location": "第一段，介绍MCQ结构",
      "description": "对MCQ的结构（stem、候选答案、distractors）进行详细拆解，便于后续方法展开。"
    },
    {
      "name": "强调研究难点和意义",
      "type": "writing-level",
      "purpose": "突出研究问题的重要性和挑战性，引起读者兴趣",
      "location": "第一段，关于distractor设计的讨论",
      "description": "指出高质量distractor设计的困难，并说明其对测试区分度和有效性的影响，凸显研究价值。"
    },
    {
      "name": "提出判定标准",
      "type": "writing-level",
      "purpose": "为后续方法设计提供评价标准",
      "location": "第一段，good distractor的标准",
      "description": "明确提出distractor应具备语法正确、语义一致且具有迷惑性等标准，为后续方法评价提供依据。"
    },
    {
      "name": "模块化设计方法",
      "type": "method-level",
      "purpose": "提升模型的可扩展性和灵活性",
      "location": "第二段，Bi-LSTM编码器描述",
      "description": "将Bi-LSTM编码器设计为可替换的模块，便于用Transformer、BERT等其他模型替换，增强方法通用性。"
    },
    {
      "name": "共享参数机制",
      "type": "method-level",
      "purpose": "减少模型参数量，提高效率",
      "location": "第二段，Bi-LSTM参数共享",
      "description": "在编码模块和两个reforming模块之间共享Bi-LSTM参数，提升训练效率，降低过拟合风险。"
    },
    {
      "name": "合理设置输入长度上限",
      "type": "experiment-level",
      "purpose": "控制计算资源消耗，保证模型覆盖主流数据",
      "location": "第二段，最大长度设置",
      "description": "根据95百分位数设置passage、question、answer、distractor的最大长度，兼顾效率与数据覆盖率。"
    },
    {
      "name": "使用预训练词向量",
      "type": "method-level",
      "purpose": "利用外部知识提升模型表现",
      "location": "第二段，GloVe.840B.300d",
      "description": "采用GloVe预训练词向量初始化词嵌入，提升模型对语义的理解能力。"
    },
    {
      "name": "采用主流优化器和正则化手段",
      "type": "experiment-level",
      "purpose": "提升模型训练效果，防止过拟合",
      "location": "第二段，NAG优化器和dropout",
      "description": "使用Nesterov Accelerated Gradient优化器，设置合理学习率，并采用dropout防止过拟合。"
    },
    {
      "name": "多基线模型对比实验",
      "type": "experiment-level",
      "purpose": "全面验证新方法的有效性",
      "location": "第二段，基线模型介绍",
      "description": "选取多种序列到序列基础模型及其变体作为对比基线，提升实验说服力。"
    }
  ]
}