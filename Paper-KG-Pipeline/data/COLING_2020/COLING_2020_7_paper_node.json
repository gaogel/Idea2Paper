{
  "paper_id": "COLING_2020_7",
  "title": "AutoMeTS: The Autocomplete for Medical Text Simplification",
  "conference": "COLING",
  "domain": {
    "research_object": "针对医学文本自动简化的自动补全系统",
    "core_technique": "结合自然语言处理与机器学习实现医学文本简化与补全",
    "application": "辅助医疗工作者或患者理解复杂医学文本",
    "domains": [
      "自然语言处理",
      "医学信息学"
    ]
  },
  "ideal": {
    "core_idea": "提出医疗文本简化的智能自动补全工具，辅助人工编辑。",
    "tech_stack": [
      "自然语言处理",
      "文本自动补全",
      "人机协作界面"
    ],
    "input_type": "医疗原始文本",
    "output_type": "简化后的医疗文本建议"
  },
  "skeleton": {
    "problem_framing": "论文通过强调文本简化的普适性目标引入问题，指出简化需兼顾内容保留，尤其在医疗等敏感领域。通过引用前人研究，展示自动化方法在关键信息保留上的不足，突出实际应用中的挑战和需求。",
    "gap_pattern": "作者批评现有研究过度依赖全自动简化方法，指出这些方法在医疗等领域可能导致重要信息丢失。通过具体数据（如30%关键信息遗漏），明确展示现有方法的局限性，为后续研究提供动力。",
    "method_story": "方法部分采用目标驱动的叙述，首先明确三大研究目标，然后将问题转化为语言建模任务，详细说明输入输出形式及评估方式。通过表格示例和预测机制，增强方法的可理解性和操作性。",
    "experiments_story": "实验部分以模型性能比较为主线，详细描述数据集划分、模型训练细节和参数设置。采用标准准确率等多维度指标进行评估，突出实验设计的严谨性和结果的客观性，便于后续分析和讨论。"
  },
  "tricks": [
    {
      "name": "明确研究动机与现实应用背景",
      "type": "writing-level",
      "purpose": "突出研究的实际意义和应用场景，增强论文说服力",
      "location": "引言开头",
      "description": "通过指出在医疗等领域全自动文本简化不适用，强调交互式简化工具的必要性，结合前人研究（如Shardlow et al., 2019的30%关键信息缺失），为后续研究铺垫合理性。"
    },
    {
      "name": "对比现有方法，突出创新点",
      "type": "writing-level",
      "purpose": "展示所提方法与现有工作的区别和改进，突出创新性",
      "location": "相关工作讨论段",
      "description": "对比全自动方法与交互式简化工具，说明本文工作与交互式机器翻译最为相似，凸显所提方法的新颖应用场景。"
    },
    {
      "name": "任务形式化与数学建模",
      "type": "method-level",
      "purpose": "将实际问题形式化，便于后续模型设计和评价",
      "location": "方法部分",
      "description": "将自动补全简化任务形式化为语言建模问题，明确输入（难句与已输入简化内容）和输出（下一个建议词），为后续模型实验提供统一框架。"
    },
    {
      "name": "多模型对比实验设计",
      "type": "experiment-level",
      "purpose": "系统评估不同模型性能，验证方法有效性",
      "location": "模型实验部分",
      "description": "选取四种基于Transformer的预训练语言模型（BERT、RoBERTa、XLNet、GPT-2），并分别设计有无上下文输入的实验版本，实现全面对比。"
    },
    {
      "name": "细粒度分解预测任务",
      "type": "method-level",
      "purpose": "提升评测细致度，便于分析模型表现",
      "location": "实验设计部分",
      "description": "将一个简化句子的预测任务分解为多个词级预测任务（n-1个），每次预测下一个词，便于量化模型逐步生成能力。"
    },
    {
      "name": "举例说明任务流程",
      "type": "writing-level",
      "purpose": "帮助读者理解任务定义和实验流程",
      "location": "方法说明及表格",
      "description": "通过具体例子（如表1、表2、表3），展示难句、简化句及预测任务分解过程，使抽象任务具体化。"
    },
    {
      "name": "多目标设定",
      "type": "writing-level",
      "purpose": "明确研究范围和评价维度，结构化论文内容",
      "location": "研究目标说明段",
      "description": "明确提出三个研究目标：考察上下文信息作用、探索PNLM新应用、评估新集成方法，增强研究条理性。"
    },
    {
      "name": "引证大量相关文献",
      "type": "writing-level",
      "purpose": "展示研究基础和学术积累，增强论文权威性",
      "location": "引言及相关工作部分",
      "description": "广泛引用前人工作（如Shardlow, Xu et al., Zhang and Lapata, Kloehn et al.等），显示对领域现状的把握。"
    }
  ]
}