[
  {
    "review_id": "52ea8e6e91e0a5b3",
    "paper_id": "ARR_2022_287",
    "reviewer": null,
    "paper_summary": "The paper presents a novel dataset for the task of stereotype detection. The authors also propose a multi-task model that uses neighbor tasks such as hate speech detection and offensive language detection to improve the classification on stereotypes. They further introduce a reinforcement learning agent that can identify the most informative examples in multi-task learning setup. An ablation study analyzes the importance of different factors in the classification process. ",
    "strengths": "- detecting stereotypes and biases in the pre-trained language model is an important problem in contemporary NLP - the proposed dataset appears to be of better quality than existing resources and contain real-world examples rather than artificially constructed ones - using multi-task approach is justified in the presented situation - various experiments and ablation study give a good overview of the advantages of the model ",
    "weaknesses": "- the writing of the paper can be improved in some sections (Introduction/Related work) to accommodate readers that are not experts on the task - missing details on corpus creation (instructions, agreement) ",
    "comments": "- the paragraph from l90 to l116 is very unclear. It is explained in later paragraphs, but on first reading it is somewhat confusing - l121 - ``consists'' -> ``consists of'' or ``contains'' - can you include more details on the selection criteria for candidate examples from reddit (section 3.1). E.g.: what are the topics, what are the stereotype targets, what kind of filtering do you apply?\n- can you include agreement statistics for the corpus in section 3.1 or 3.2?\n- while the contribution of the reinforcement agent is clear, it would be good to include a different baseline for \"selecting relevant examples\", in order to justify the use of RL in that setup over a simpler selection method ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "b2900de8ed206555",
    "paper_id": "ARR_2022_287",
    "reviewer": "Alessandro Suglia",
    "paper_summary": "This paper proposes presents a multi-task learning approach to improve low-resource stereotype recognition performance. The authors first critically analyse the state of the art in stereotype detection. Based on the resulting insights, they propose a new 4-way classification setup that is more suitable for the task and that guarantees a more systematic analysis of language phenomena in real-world data. Due to the limits of previously defined datasets, they propose a data collection to derive a crowd-sourced dataset based on Reddit content. Additionally, they use the same annotation protocol to analyse previous datasets as well. However, stereotype detection is a task with very few accurate data points. Therefore, they rely on the intuition that other related offensive language datasets could be used to boost performance. This is mostly because offensive language phrases are typically relying on specific stereotypes. In their evaluation, they use 6 offensive language datasets in a multi-task learning regime. This multi-task learning regime can be further enhanced with a policy that decides which data points to consider for training based on the classification performance. The policy is trained via an actor-critic reinforcement learning algorithm to optimise the F1 measure of the classification task. The authors tried this approach with several large-scale language models showing substantial performance improvement over the corresponding baselines. ",
    "strengths": "1. The authors completed an analysis of the literature which they use to define a data collection procedure based on a novel annotation scheme for stereotype detection; 2. The authors propose to combine several offensive language detection to boost performance in the stereotype classification setup; 3. The authors describe how to use a state of the art RL technique to combine multiple tasks together; 4. The paper clearly describes the problem that the authors are trying to solve and provide a very good evaluation to support their approach. ",
    "weaknesses": "1. The multi-task learning approach defined in Section 4.1 is not described in detail. There are several ways of performing multi-task learning and the authors should be a little bit more precise in the description of their model. For a more systematic description of MTL approaches for Deep learning models, please refer to https://arxiv.org/abs/1706.05098. \n2. Multi-task learning generally struggles when tasks of different complexities are combined together (e.g., see GradNorm for a possible solution: https://arxiv.org/abs/1711.02257). On the other hand, the authors assume that multi-task learning is going to work without putting much effort into studying how each task affects the others. \n3. The authors perform an ablation where the model is trained using each neighbour dataset together with the reference dataset. However, to show the power of using multiple related tasks at the same time, it would be beneficial to see the effect on the overall performance, of different combinations of datasets. ",
    "comments": "Regarding the issue 1) and 2), I believe the authors should better describe their MTL approach and properly localise it in the literature. Additionally, the authors should provide more details about the training regime and what is the effect of combining different tasks at once. In this sense, weakness 3) can be useful to solve all the others. In particular, I would suggest the authors take their `bert-base` classifier, and train using MTL with different dataset combinations. For instance, assuming that their reference task is S and the related tasks are T_1, T_2, ..., T_6, I would evaluate the following combinations: 1. T_1 + S 2. T_1 + T_2 + S 3. (...) \n4. T_1 + T_2 + ... + T6 + S (this is the version with all the datasets that is currently implemented in the evaluation) In this sense, Table 4 goes in this direction. However, I believe the evaluation should focus on the performance of the stereotype detection task only because is the reference task for this paper. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "3214e7021970e65e",
    "paper_id": "ARR_2022_287",
    "reviewer": null,
    "paper_summary": "This paper presented a fine-grained stereotype detection set and proposed a reinforcement-learning based multi-task framework for stereotype detection. Different from previous datasets that focus more on the explicit stereotype, the constructed dataset considers explicit, implicit and non-stereotypes. Experimental results show that the proposed framework significantly improves the base model on different datasets. ",
    "strengths": "1. This paper presented a fine-grained evaluation set for stereotype detection, which aims to alleviate the conceptual issue of various stereotypes.\n2. The proposed reinforcement-learning based multi-task framework shows superior performance over the base model. ",
    "weaknesses": "1. The authors presented a fine-grained evaluation set in this paper. However, the anti-stereotype that appears in previous datasets is missing in the constructed dataset. In addition, details of annotations are missing in this paper. Since stereotype detection is quite challenging, it would be important to discuss how to guarantee the annotation quality and whether annotators can reach an agreement on collected corpus.\n2. Missing related baselines. Only PLMs are considered in this paper and other task-related baselines are missing.\n3. Missing in-depth analysis on experimental results. For example, why the improvements of models are limited on offense detection dataset and are significant on coarse stereotype set? ",
    "comments": "1. More discussions about dataset construction should be provided, e.g., the time range of data collection, preprocessing strategies and quality control.\n2. All \"table\" and \"figure\" in the context should be capitalized. ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]