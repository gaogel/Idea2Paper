[
  {
    "review_id": "7ee102243dbf8de1",
    "paper_id": "ARR_2022_190",
    "reviewer": null,
    "paper_summary": "This paper investigates the causes of an Event Detection model’s skewed performance and presents trigger saliency attribution to explicitly assess the underlying pattern of events. The authors also develop a new training mechanism based on trigger saliency attribution, which uses saliency as evidence to enhance learning. Experimental results achieve promising performance on two benchmarks. ",
    "strengths": "- The paper investigates the causes of an Event Detection model’s skewed performance.\n- A technically sound method to improve Event Detection by presents trigger saliency attribution that can explicitly quantify an event’s contextual pattern.\n- Experiments on ACE-2005 and MAVEN benchmarks verify its effectiveness. ",
    "weaknesses": "- Authors aim to improve previous methods via trigger saliency attribution and grouping event types with similar patterns together. But one question is how to measure the correctness of the divided group, not only from the perspective of intuitions but experimental evidence.\n- As a recent trend is pre-training Transformer on large-scale corpora and larger models also show greater capabilities for context representative, I am wondering if the larger model performs poorly on context-dependent types.\n- Case visualization contains only two examples of each instance and consists of mere conjectures about the reason behind their model’s performance and errors. ",
    "comments": "As mentioned by weaknesses above. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]