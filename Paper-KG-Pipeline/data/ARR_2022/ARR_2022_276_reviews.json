[
  {
    "review_id": "d6fb6367ef701083",
    "paper_id": "ARR_2022_276",
    "reviewer": null,
    "paper_summary": "This paper presents two extensions for improving non-autoregressive machine translation (NAT) with lexical constraints, with a focus on low frequency words. The authors take as base model an approach very similar to that of Xu & Carpuat 2021 and expand it with a) \"constrained training\", where the system already sees lexicon constraints at training time and b) \"alignment prompting\", where alignment information is included into the model. The motivation for this last method is to inform the model as to what source word(s) correspond to the constraint, so that the context can be better generated. Experimental results shows that the method is able to improve the generation quality (measured in BLEU), specially for out-of-domain tasks, while retaining the efficiency advantages of NAT systems. ",
    "strengths": "- The paper is clearly written and well-motivated. Section 3.3 gives a clear indication of shortcomings of current models, and Section 6.1 revisits the issue and analyzes how the model addresses it.\n- The approach is general enough that it can be applied to different models.\n- Table 5 shows good improvements for out-of-domain test sets.\n- The approach is (mostly) clearly described and the authors plan to release the code. ",
    "weaknesses": "- The evaluation of the paper could be made stronger by using some of the standard datasets for terminology translation (e.g. wmt21 shared task) and evaluation metrics (Alam et al. 2021).\n- The description of the alignment embedding seems a bit under-specified. Am I understanding it correctly that the constraints in the target sentence get an additional index that gets embedded (similar in concept to positional embeddings)? Are unaligned words in the constraints marked in a special manner? Are these embeddings recomputed in every refinement step of the LevT? ",
    "comments": "- Line 232: The are surely sentences where not every bucket is represented, right? Would it be then more correct to say that you have **approximately** 6x the data? Or am I misunderstanding something?\n- Line 248: This explanation, while plausible, could be relatively easy to check just by looking at the words themselves. Have you done that? Have you tried filtering those words out (e.g. using stopword lists or similar) as they are unlikely to appear as constraints in real life situations?\n- Line 263: It would be better to use l_i.\n- Subsubsection starting at 324: Would it make sense to use the lexicon information directly if available (which it is for some test conditions) and resort to automatic tools only if necessary? Related to this, have you measured how sensitive the method is against alignment errors? This is also specially relevant for out-of-domain settings, where the alignment model is also operating in out-of-domain conditions.\n- Table 4: Please also include bold numbers for the baselines of previous work. Specifically for WMT17-WIKT the best result in terms of BLEU is actually in the baselines. ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work."
  },
  {
    "review_id": "c00ac5b1456ef83c",
    "paper_id": "ARR_2022_276",
    "reviewer": null,
    "paper_summary": "This paper proposed improvements to the Levenshtein transformer for lexically constraint translation task. The proposed improvements through alignment constraints during training and or inference ",
    "strengths": "- Clear writing and captivating content; the motivating study section is a nice approach to architecture and experimental design and the analysis section is a great read - The experiments/analyses are well-taught out to validate stated hypothesis and comparative studies with different ablations are applied to support analyses - Based on Ding et al. 2021 analysis of low-freq words, the hunch of injecting alignments knowledge outside of the AT / NAT model is a good one ",
    "weaknesses": "- Nothing much, a very well-written and thought out papers and experiments; although it's incremental improvements to the LevT, it's an extensive study with solid empirical evidence for the conjectures stated in the paper.\n- [Possibly out of scope] The question still remains why can't a NAT learn the alignment mapping with its cross attention to different token positions? It's possibly out of scope of the paper but a good food for thought. ",
    "comments": "- I might have missed it but the results section stated \"When translating without constraints, however, adding ACT does not bring consistent improvements as hard and soft constraints do, which could be attributed to the discrepancy between training and inference.\"; does that mean all the +ACT results only have alignments constraints and prompting during training and no alignments prompting at inference? Actually, it'll be kind of tough to do alignment prompting at inference anyways because should the prompting at every iteration or the first iteration of the decoder?  - Would the code and experiments be open sourced like Susanto et al?  - Maybe I'm reading too much into Table 4 results, the improvements clearly comes from the constraint training, esp. the soft constraint setup. Thinking out loud, is GIZA++ or any external aligner necessary for the alignment? Can some mechanism/layer be proposed to replace that alignment from GIZA?\n- Section 6.3 is honest limitation but the improved from 94.25 -> 96.90 is also quite a feat since it's inching at a strong baseline.  - Figure 2 also shows where the BLEU is lost in the 10-30% bin, would it be possible to identify all terms in that bin and list them in the appendix with the (source, term) -> LevT vs LevT + ACT outputs? A few possible reason that the model is finding it hard to learn that 10-30% bin, (i) term is mapped to too many multiple targets in training data or mapped to targets that's not in the constraint list of terms in a skewed manner, (ii) the translated outputs though not in the reference are valid translations though not the preferred one ",
    "overall_score": "5 = Top-Notch: This is one of the best papers I read recently, of great interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "0f8103add9d5c982",
    "paper_id": "ARR_2022_276",
    "reviewer": null,
    "paper_summary": "This work proposes to improve lexically constrained non-autoregressive translation by incorporating constraints during training and utilizing the source-side alignment during training and inference. The main motivation is that even for rare constraints, the context is not necessarily rare, and aligning source-side context can be beneficial for the model's performance. The results on En-De in-domain and out-of-domain data, as well as a comparison with other constrained models show that the proposed model a) improves the quality b) does not increase latency ",
    "strengths": "- Paper contains an extensive comparison with previous works on lexically constrained NAT, as well as with AR Transformer model - ACT shows improvements on domain-specific datasets and on a constrained portion of in-domain data - Incorporated constraints do not result in latency increase ",
    "weaknesses": "- No comparison across languages (only De target language) - While testing on the full En-De test set, the improvements are minor ",
    "comments": "*Typos:* - Table 1: htten --> hatten - line 155: An --> a - line 166: For NATs --> seems redundant, an NAT --> a - Figure 1: I am confused by frequency buckets. Does the x-axis represent the **inverse** frequency of constraint? Otherwise, I am genuinely confused. And while sampling self-constrains, do you sample from the word buckets based on the sentence itself or do you consider ALL possible words (from all sentences) in the bucket?  *Additional questions:* - During training you sample 0-3 reference tokens as constraints, since the BPE is used, does it mean that it might be the case that only part of the word is considered as a constraint? Or do you handle such a situation in some way?\nThanks! ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]