[
  {
    "review_id": "883cec982be6ead1",
    "paper_id": "ARR_2022_283",
    "reviewer": null,
    "paper_summary": "The paper addresses the problem of privacy for document embeddings. The authors define a strong sentence-level privacy for documents and propose deepcandidate, an unsupervised embedding technique to generate sentence-private document embeddings. Experiments on sentiment analysis and text classification were conducted to show the usefulness and effectiveness of the proposed method. ",
    "strengths": "- The paper is theoretically sound. There are a lot of mathematical notations in the paper but the authors defined them clearly, explained in detail, also showed the some necessary derivations (in Appendix) to help the readers to understand.\n- Experimental results show SentDP performs much better on stronger privacy guarantee, empirically proved the previous theoretical statements.\n- The authors proposed a novel approach from a strong privacy definition for document embeddings, which is significant different from the existing works. ",
    "weaknesses": "- It would be nice to show more experimental results of the proposed method from more aspects such as an ablation study or parameter analysis.\n- There is still a clear gap between the private embeddings and non-private ones. For some baseline approaches the embedding performances are basically random guessing. The paper failed to explain this tradeoff and potential solutions. ",
    "comments": "- One question: x' is sampled within certain distance from x in the embedding space, does that mean they are semantically/syntactically similar? If so, how much high-level concepts from the documents can be hided? ",
    "overall_score": "3.5 ",
    "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work."
  },
  {
    "review_id": "3b7abb0934c42ac0",
    "paper_id": "ARR_2022_283",
    "reviewer": null,
    "paper_summary": "This paper introduces an approach to produce privacy-preserving document embeddings with the property that every single sentence of the document could be replaced by some other random one while obtaining a similar embedding for the document. The paper is way out of my area of expertise, and thus this review must remain an educated guess. \nThe proposed method replaces sentence embeddings from the private document for embeddings obtained from a set of public documents. The method uses embeddings that are close to the original ones by picking those with high \"Tukey Depth\" with respect to the set of candidate embeddings. Finally, the embeddings are spread apart by passing them through a network trained with an unsupervised clustering signal, and, if understand correctly, averaged together. ",
    "strengths": "1. The method seems to be well grounded in a theoretical framework. \n2. The paper is very clear, and even though I lack the relevant background I could follow it (with quite some effort, which is also quite natural) 3. The empirical results seem good (but I am not familiar with the state of the art in this area) ",
    "weaknesses": "1. As an outsider, I wonder whether some natural baselines could have been explored. For instance, given that the method uses sentence embeddings after a clustering transformation, I wonder what would happen if cluster centroids were directly used instead. Similarly, I wonder what's the need for computing the Tucker Depth, and not just using the closest vector in terms of cosine similarity. ",
    "comments": "L404: It might be worth recalling the reader that k is the number of sentences at this point, given that this fact was introduced much earlier on and not used until then. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "1 = Not my area, or paper is very hard to understand. My evaluation is just an educated guess."
  }
]