[
  {
    "review_id": "e965dd1f90d06352",
    "paper_id": "ARR_2022_58",
    "reviewer": null,
    "paper_summary": "This paper targets a source of ambiguity in user interactions with task-oriented dialog systems: when a user asks for an action (e.g. booking) to be taken with regards to, or asks a question about an ambiguous/underspecified entity. This paper proposes that existing datasets are unable to properly model this ambiguity, and thus provide an extended version of the popular MultiWOZ and SGD task-oriented dialog datasets containing disambiguation questions and responses. The authors create disambiguation annotations by applying templates from a limited-domain dataset and paraphrase a subset. The authors test a baseline GPT2-based model on named entity recognition when trained with the original data compared to different ways to use their augmented datasets, showing that training with augmented data improves named entity recognition/disambiguation on their test split. ",
    "strengths": "1. The authors identify an important challenge with existing popular benchmark datasets/tasks for task-oriented dialog and propose a way to solve this challenge via data augmentation 2. Different addressing/reference methods are tested, which mirror common modes of user interaction (e.g. typos, positional referencing, typos or multiple selections). The analysis of each form of augmentation is of particular interest and should be put in the main paper body rather than put in a table in the supplementary section. \n3. There is an interesting discussion on how to best use the augmented data - whether to augment the target dataset and a pre-training dataset, to perform joint augmentation, as compared to using the non-augmented data. They show that pre-fine-tuning with augmented data can lead to improvements with a lower training budget compared to full augmentation. ",
    "weaknesses": "1. It would be more relevant and important to remark on how much the degree of ambiguity (number of possible options) varies across dataset examples and whether that was sampled uniformly, by difficulty, or otherwise during data augmentation. It would also be helpful to include whether this degree of ambiguity is reflected in real-world dialog systems as opposed to benchmark WoZ-collected datasets like MultiWOZ and SGD --- essentially, the problem seems to be intuitive, but the paper lacks some context on how widespread the issue actually is. \n2. The results only support the assertions that \"augmentation helps resolve ambiguity\" and \"augmentation brings no harm\" for the specific model used; however, the JGA numbers in Table 3 are a fair degree below state of the art for the original data (~60 for MultiWOZ, ~80-90 for SGD) which raises questions about whether the augmented data and disambiguation task are applicable to state of the art modeling techniques for task oriented dialog. It would have been important to either experiment with additional models or at least include baseline numbers for state of the art models applied to each dataset (and augmented dataset). \n3. The named entity recognition accuracy metric seems to be weak compared to the proposed scale of the problem. If ambiguity is supposed to cause issues in task-oriented dialog models it would be important to measure end-to-end metrics like success rate, inform rate, as well as preference tracking and dialog policy learning (all metrics used in the base MultiWOZ/SGD settings) to demonstrate whether the proposed database result disambiguation task helps in the downstream dialog task and the end goal of the system. There are no data/experiments generalizing this to usage in end-to-end systems. Similarly, the assertion of \"augmentation brings no harm\" is not supported for general end-to-end task oriented dialog. ",
    "comments": "Comments incorporated into strengths/weaknesses above ",
    "overall_score": "2.5 ",
    "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work."
  },
  {
    "review_id": "8f644ad52cbea4b4",
    "paper_id": "ARR_2022_58",
    "reviewer": null,
    "paper_summary": "This paper addresses and focuses on disambiguation resolution on task-oriented dialog systems. The authors augment the seminal databases (MultiWOZ and SGD) with synthetic disambiguation turns, and use it as a new dataset to make their dialog system understand the user's answer and do follow up clarification questions. ",
    "strengths": "Overall this paper is complete and very well written. The ablation studies are convincing, and the results are promising. Furthermore the analysis presented in the paper is concise and complete as well. This paper has a potential to inspire other dialog researchers to work on enhancing universal dialog skills. ",
    "weaknesses": "It might be difficult for readers to understand the explanation in Sec 3.1. and 3.2., rephrasing the paragraph along with its pseudo-code can add clarity. ",
    "comments": "It would be really helpful for the dialog community if authors open their experiment script, especially their script to do automatic augmentation (Sec. 3.2.) ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]