[
  {
    "review_id": "4a1c1a54db4c8630",
    "paper_id": "ARR_2022_196",
    "reviewer": null,
    "paper_summary": "This paper empirically studied CLIP models as few-shot learners for two vision-language understanding tasks: VQA and Visual entailment. In the VQA task, the paper proposed a two-step method to mitigate the gap between natural language description and question answering. In addition, the paper used only a very small set of parameters in CLIP models during fine-tuning, including bias and normalization terms. ",
    "strengths": "It studied how to transfer CLIP zero-shot capabilities into VLU tasks and confirms CLIP models can be good few-shot learners.\nThe paper proposed a two-step prompt generation method to apply CLIP on VQA.\nThe paper identified only a small number of parameters are enough to fine-tune the CLIP few-shot learner. ",
    "weaknesses": "The way of using T5 for template generation is unclear, and lack of evaluation of the template generation quality.\nIn model fine-tuning experiments, it is unclear about the learning rates and epochs for different parameter settings, which could largely affect the results. ",
    "comments": "See the weakness. ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "7c0a758d59caeaed",
    "paper_id": "ARR_2022_196",
    "reviewer": null,
    "paper_summary": "The authors of this paper propose an empirical study for the zero-shot capabilities of CLIP models and demonstrate that CLIP models have strong few-shot capabilities. The authors propose the TAP-C method for evaluating VQA and demonstrate zero-shot cross-modal transfer capabilities on the visual entailment. ",
    "strengths": "1. The paper conducts rich experiments and presents several interesting insights, which have a certain value to the community. \n2. The paper is well-written and easy to follow. \n3. The proposed two-step prompt generation method is interesting for studying the zero-shot performance. ",
    "weaknesses": "1. There should be more VLU tasks to prove the argument of the paper, e.g., NLVR. ",
    "comments": "1. It is best to use vector graphics in the paper. ",
    "overall_score": "3.5 ",
    "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work."
  }
]