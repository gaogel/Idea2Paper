{
  "paper_id": "ARR_2022_182",
  "title": "MetaWeighting: Learning to Weight Tasks in Multi-Task Text Classification",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，主要关注多任务文本分类问题。",
    "core_technique": "多任务学习中的任务加权方法，利用元学习（Meta-Learning）框架来自动学习各任务的权重分配。",
    "application": "多任务文本分类，可应用于新闻分类、情感分析、意图识别等自然语言处理任务。",
    "domains": [
      "自然语言处理",
      "多任务学习",
      "元学习"
    ]
  },
  "ideal": {
    "core_idea": "提出了一种基于双层优化的任务加权方法MetaWeighting，以提升多任务文本分类的泛化性能。",
    "tech_stack": [
      "多任务学习",
      "任务加权",
      "双层优化（bi-level optimization）",
      "元学习（learning-to-learn）"
    ],
    "input_type": "多任务文本分类问题的数据集（如评论情感分析、新闻主题分类）",
    "output_type": "各任务的最优加权模型及其在测试集上的分类性能"
  },
  "skeleton": {
    "problem_framing": "论文从学术gap出发引出问题。首先介绍多任务学习（MTL）在文本分类等领域的成功应用，强调其优于单任务学习的性能。随后指出多任务学习中常见的任务竞争和任务不平衡现象，强调如果不能合理平衡任务，会导致某些任务主导训练过程，损害其他任务的性能。接着，提出当前主流的解决方法是任务加权，但现有方法仅基于训练损失或梯度，忽略了训练损失与泛化损失之间的差距。通过实验现象（训练损失与测试损失模式不一致）进一步强化这一学术gap，最终引出本文提出的新方法以优化泛化性能。",
    "gap_pattern": "论文批评现有方法时，采用了“现有方法忽视了X”的逻辑。具体地，指出现有任务加权方法仅基于训练损失或梯度计算权重，忽略了训练损失与泛化损失之间的差距。此外，针对Pareto优化类方法，批评其目标函数仅涉及训练损失，只能获得关于训练损失的Pareto解，也同样忽视了泛化损失。通过举例和引用相关工作，强调这一忽视会导致多任务学习性能下降，进一步突出本文方法的必要性。",
    "method_story": "方法部分采用了先整体后局部的叙述策略。首先从多任务学习的整体问题设定入手，定义任务空间、训练样本分布、参数共享等基础概念。随后引入本文的核心创新——基于双层优化的任务加权方法MetaWeighting，强调其目标是直接优化泛化性能。方法介绍过程中，先阐述整体思路，再逐步细化到权重计算方式和学习流程，体现由抽象到具体的递进结构。",
    "experiments_story": "实验部分采用主实验+多数据集验证的叙述策略。首先在情感分析任务上验证MetaWeighting的性能，通过与多种主流方法进行对比，展示分类准确率的提升。实验细节包括模型结构（TextCNN/BERT）、参数设置、数据集来源等。随后在新闻主题分类任务上进一步验证方法的有效性。实验结果以表格和可视化方式呈现，突出方法在不同任务和数据集上的优势。整体上，实验设计注重方法的广泛适用性和性能对比，未涉及消融或可视化分析，但强调了多任务和多基线的全面验证。"
  },
  "tricks": [
    {
      "name": "引用权威文献建立背景",
      "type": "writing-level",
      "purpose": "增强说服力和学术权威性，表明所研究问题是被广泛关注的",
      "location": "introduction",
      "description": "通过引用Caruana (1993), Baxter (2000)等经典文献，说明多任务学习（MTL）的重要性和广泛应用"
    },
    {
      "name": "问题现象举例",
      "type": "writing-level",
      "purpose": "帮助读者理解任务失衡的问题严重性和现实性",
      "location": "introduction",
      "description": "通过描述任务失衡现象及其对性能的影响，引出研究动机"
    },
    {
      "name": "实验现象先行",
      "type": "writing-level",
      "purpose": "用实验数据提前佐证问题存在，增强问题描述的说服力",
      "location": "introduction",
      "description": "在引言中提前引用实验结果（如Figure 1），展示训练损失与泛化损失的差异"
    },
    {
      "name": "现有方法局限性对比",
      "type": "writing-level",
      "purpose": "突出新方法的创新点和必要性",
      "location": "introduction",
      "description": "指出现有任务加权方法只关注训练损失或梯度，忽略了泛化损失与训练损失的gap"
    },
    {
      "name": "方法命名与包装",
      "type": "method-level",
      "purpose": "提升方法辨识度和记忆点，便于推广",
      "location": "introduction / method",
      "description": "将新方法命名为MetaWeighting，并强调其learning-to-learn和bi-level optimization特性"
    },
    {
      "name": "理论与实验双重验证",
      "type": "writing-level",
      "purpose": "增强方法有效性的说服力和科学性",
      "location": "introduction / experiments",
      "description": "在引言和实验部分均强调理论分析和实验验证并重"
    },
    {
      "name": "多数据集、多任务实验",
      "type": "experiment-level",
      "purpose": "证明方法的通用性和稳健性",
      "location": "experiments",
      "description": "在情感分析和主题分类两个经典任务上进行实验，覆盖多种数据集"
    },
    {
      "name": "与多种SOTA方法系统对比",
      "type": "experiment-level",
      "purpose": "突出新方法的性能优势",
      "location": "experiments",
      "description": "与Single Task Learning、Uniform Scaling、AdvMTL、MGDA等多种主流方法进行系统性对比"
    },
    {
      "name": "可视化实验结果",
      "type": "experiment-level",
      "purpose": "提升结果的直观性和可解释性",
      "location": "experiments",
      "description": "通过图表（如Figure 2, Figure 3）展示不同方法在各任务上的准确率分布"
    },
    {
      "name": "平均性能与单任务性能并重",
      "type": "experiment-level",
      "purpose": "全面展示方法优势，避免只关注单一指标",
      "location": "experiments",
      "description": "既报告各子任务的性能，也报告平均性能，突出方法整体优越性"
    },
    {
      "name": "详细实验设置说明",
      "type": "experiment-level",
      "purpose": "增强实验的可复现性和科学性",
      "location": "experiments",
      "description": "详细描述模型结构、参数设置、预训练模型来源等实验细节"
    },
    {
      "name": "逻辑递进式叙事结构",
      "type": "writing-level",
      "purpose": "帮助读者顺畅理解研究动机、方法提出、实验验证的全过程",
      "location": "introduction / method / experiments",
      "description": "先引出问题，再分析现有方法不足，提出新方法，最后用实验验证，形成完整闭环"
    }
  ]
}