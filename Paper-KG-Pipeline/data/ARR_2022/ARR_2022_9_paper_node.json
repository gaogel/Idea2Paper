{
  "paper_id": "ARR_2022_9",
  "title": "Measuring Fairness of Text Classifiers via Prediction Sensitivity",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，主要关注文本分类器的公平性问题。",
    "core_technique": "公平性评估方法，基于预测敏感性分析，可能结合了现有的文本分类技术（如深度学习模型）来衡量和改进模型的公平性。",
    "application": "文本分类相关的实际场景，如舆情分析、垃圾邮件检测、内容审核、招聘筛选等需要保证算法公平性的应用。",
    "domains": [
      "自然语言处理",
      "人工智能伦理与公平性"
    ]
  },
  "ideal": {
    "core_idea": "提出基于模型输入特征敏感性的累积预测敏感性指标，统一衡量和关联群体公平性、个体公平性及人类公平性感知。",
    "tech_stack": [
      "累积预测敏感性（Accumulated Prediction Sensitivity）",
      "特征归因（Feature Attribution）",
      "保护属性分类器（Protected Status Model）",
      "统计公平性指标（Statistical Parity）",
      "个体公平性指标（Individual Fairness）"
    ],
    "input_type": "包含保护属性（如性别、年龄等）和文本特征的数据集，适用于分类模型",
    "output_type": "模型预测对输入特征的敏感性度量值及其与公平性相关的评估结果"
  },
  "skeleton": {
    "problem_framing": "论文从学术gap出发引出问题，强调当前机器学习语言处理模型中存在的社会偏见，并指出算法公平性已被提出但有多种量化定义。引言首先介绍了个体公平和群体公平的主流定义，随后指出现有研究往往只关注其中一两个维度，未能全面衡量模型的公平性。作者提出以模型对输入特征敏感性为基础的新公平度量，并强调该方法与人类公平感知的关联，体现出对现有公平度量与人类认知之间差距的关注。",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出多数研究只关注个体或群体公平的某一方面，缺乏对两者统一度量的探索；现有敏感性度量仅针对单一特征且权重均匀，未能捕捉不同特征对模型输出的非均匀影响；此外，部分方法未能与人类公平认知进行对齐验证。批评语句多以“although...”, “often consider only...”, “do not contain...”, “majority of these bias metrics are automatically computed...”等方式展开。",
    "method_story": "方法部分采用‘先整体后局部’和‘分模块介绍’的叙述策略。首先介绍了累积预测敏感性指标的总体思想及其与现有敏感性度量的关系，然后针对无显式保护属性的场景，提出并详细介绍了保护属性状态模型（PSM）的训练与应用流程。方法描述从原理、公式推导到具体实现（如如何计算敏感性、如何训练PSM），并穿插具体数据集和模型架构细节，逐步递进，最后补充了指标的理论性质和权重选择方法。",
    "experiments_story": "实验部分采用‘主实验+多数据集验证’的策略。首先设计主实验，通过众包标注收集人类对模型公平性的感知，验证所提指标与人类感知的相关性。实验内容包括数据集介绍、标注流程、样例展示以及公平性判定标准。实验覆盖了两个不同领域的数据集（Bias in Bios和Jigsaw Toxicity），并在每个数据集上分别训练和评估模型，确保方法的通用性和有效性。实验还详细说明了标注流程、样本选择和公平性判定标准，突出方法与人类认知的对齐。"
  },
  "tricks": [
    {
      "name": "多维度公平性定义梳理",
      "type": "writing-level",
      "purpose": "帮助读者理解公平性问题的复杂性和多样性，为新方法的提出做铺垫",
      "location": "introduction",
      "description": "作者详细介绍了个体公平和群体公平的定义，并引用了相关文献，强调现有研究多局限于某一维度，突出问题背景。"
    },
    {
      "name": "理论联系与扩展",
      "type": "method-level",
      "purpose": "增强方法的说服力和学术深度，证明新指标与主流公平性度量的关系",
      "location": "introduction / method",
      "description": "作者提出累积预测敏感性指标，并建立其与统计公平性和个体公平性之间的理论联系，显示方法的基础和合理性。"
    },
    {
      "name": "人类感知公平性的实证关联",
      "type": "experiment-level",
      "purpose": "提升方法的实际意义和社会价值，增强说服力",
      "location": "introduction / experiments",
      "description": "作者强调新指标与人类公平性感知之间的相关性，并通过众包标注实验进行验证。"
    },
    {
      "name": "对现有敏感性指标的泛化",
      "type": "method-level",
      "purpose": "突出方法的新颖性和改进点，展示创新性",
      "location": "introduction / method",
      "description": "作者将已有的预测敏感性指标扩展为累积预测敏感性，并允许对输入特征赋予非均匀权重，提升灵活性和表达力。"
    },
    {
      "name": "无显式保护属性场景的适应性设计",
      "type": "method-level",
      "purpose": "显示方法的广泛适用性和实际可操作性",
      "location": "method",
      "description": "通过训练保护属性状态模型（PSM），实现对无显式保护属性场景的敏感性度量，增强方法的普适性。"
    },
    {
      "name": "具体示例辅助理解",
      "type": "writing-level",
      "purpose": "提升可解释性，让读者直观理解公平性判定标准和方法应用",
      "location": "experiments",
      "description": "通过展示具体的偏见/无偏见样本，帮助读者理解人工标注的标准和模型预测的公平性判定。"
    },
    {
      "name": "多指标相关性分析",
      "type": "experiment-level",
      "purpose": "证明方法的有效性和完备性，提升结论的可靠性",
      "location": "experiments",
      "description": "采用互信息和双序列相关等多种统计指标，系统分析人工标注与模型敏感性指标之间的关联。"
    },
    {
      "name": "与基线方法的对比",
      "type": "experiment-level",
      "purpose": "突出新方法的优势，增强说服力",
      "location": "experiments",
      "description": "通过与已有敏感性指标的相关性对比，展示新方法在与人类公平性感知关联上的提升。"
    },
    {
      "name": "实验设计的细致描述与合理性保障",
      "type": "experiment-level",
      "purpose": "增强实验的可信度和可复现性，体现完备性",
      "location": "experiments",
      "description": "详细说明众包标注流程、样本选择、标注者筛选和报酬设置，并报告标注一致性指标，确保实验结果可靠。"
    },
    {
      "name": "逻辑递进式叙事结构",
      "type": "writing-level",
      "purpose": "帮助读者顺畅理解问题提出、方法设计和实验验证的全过程",
      "location": "introduction / method / experiments",
      "description": "全文从问题背景出发，逐步引入新方法，再通过理论和实证分析验证，形成完整闭环。"
    }
  ]
}