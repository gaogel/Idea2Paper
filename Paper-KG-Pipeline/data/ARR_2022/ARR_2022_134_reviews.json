[
  {
    "review_id": "a870e0cbe442bebd",
    "paper_id": "ARR_2022_134",
    "reviewer": null,
    "paper_summary": "The paper deals with an important practical problem of models using unreliable lexical cues to make predictions. E.g. a token like “Spielberg” may correlate with a “positive” label in a specific movie reviews dataset, but in itself the token is not a “genuine” indication of a positive review and relying on it may hurt a model's ability to generalize to new datasets or domains.\nThe authors present a method to identify tokens indicative of spurious correlations by: (i) identifying tokens that significantly affect model predictions (e.g. by looking at assigned attention, aggregated over a corpus); (ii) filter these tokens through cross-dataset analysis: removing tokens which are significant across multiple dataset (and thus unlikely to represent spurious correlations); and (iii) further filter the tokens through perturbation analysis: remove tokens which if replaced by their synonyms cause the classifier to change the predicted score significantly.\nThe authors discuss different methods to make models more robust based on the identified tokens. ",
    "strengths": "The paper is clear and well written and the research seems very sound: 1. The authors evaluate their methods on multiple text classification datasets 2. They evaluate intrinsically by showing that the tokens identified as spurious correlations correlate with human judgements, and also extrinsically by showing that models that mask the identified tokens generalize better to new datasets/domains. \n3. They discuss the different steps of their method, clearly detailing how each is applied and how it affects the accuracy of the predictions. \n4. Effort is made to make the method as widely applicable as possible. e.g. the first step of identifying important tokens uses attention scores as a driving mechanism. However, to accommodate for models which do not use attention,  alternative methods to obtain important tokens are discussed and an experiment is conducted to measure their impact. ",
    "weaknesses": "Not a lot to say here as I think the researchers have done a thorough job. \n1. Personally, I’m somewhat skeptical that identifying tokens which are significant in aggregate across a corpus is a promising method to predict how a complex model will behave when these tokens are in a specific context (this is also pointed out by the authors as a limitation in their conclusions). In that sense, the impact of this research would be greater if the benefits shown when generalizing to new domains were higher (table 5). As is, the method seems like a non-trivial amount of work, to yield models which may be slightly more robust – a tradeoff which may suit some but not all.  2. I did not see an indication that code and data will be released for this paper and I would encourage the authors to add these. This is not only important to allow easy reproduction of the results, but also to allow readers to easily apply the method to their models, etc.\nStill, I think this is a very good paper and I don’t see any significant methodological issues. ",
    "comments": "NA ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]