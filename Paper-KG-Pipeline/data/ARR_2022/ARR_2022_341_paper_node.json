{
  "paper_id": "ARR_2022_341",
  "title": "Entity-based Neural Local Coherence Modeling",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，主要关注文本的局部连贯性建模，分析实体在文本中的分布和关系。",
    "core_technique": "基于神经网络的方法，结合实体信息进行局部连贯性建模，可能涉及序列建模网络如LSTM或其他深度学习结构。",
    "application": "自动文摘、文本生成、机器翻译等需要判断或提升文本连贯性的自然语言处理任务。",
    "domains": [
      "自然语言处理",
      "文本生成"
    ]
  },
  "ideal": {
    "core_idea": "提出一种基于实体聚焦的神经文本连贯性模型，将语言学理论与预训练语言模型结合以提升连贯性建模。",
    "tech_stack": [
      "实体表示",
      "预训练语言模型",
      "神经网络",
      "Centering理论",
      "句子编码",
      "前馈神经网络"
    ],
    "input_type": "需要评估连贯性的文本或文档",
    "output_type": "文本连贯性评分或标签"
  },
  "skeleton": {
    "problem_framing": "论文通过从学术gap出发引出问题，首先介绍了语篇连贯性的重要性及其在文本处理系统中的应用价值，随后指出当前神经网络模型虽然在局部连贯性建模上取得了进展，但其底层机制（即模型如何计算连贯性）并不清晰，尤其是与传统基于实体的方法相比，神经模型可能依赖于偶然或无意义的词语连接，导致从语言学角度来看并不合理。作者强调了这一理论与实际之间的断层，并提出需要更具语言学合理性的神经连贯性模型。",
    "gap_pattern": "论文批评现有方法时，采用了‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体来说，指出神经实体网格模型存在稀疏性问题，难以捕捉有意义的实体转移，且模型特征不可解释，无法判断模型关注的实体。此外，现有神经模型虽然在人工任务（如shuffle test）上表现优异，但在实际下游任务中不一定优于非神经模型，说明评估方式存在局限。作者用对比和引用前人工作的方式，系统性地揭示了现有方法的不足。",
    "method_story": "方法部分采用了‘先整体后局部’和‘分模块介绍’的策略。首先给出模型整体架构的流程图，随后依次介绍实体表示、句子编码、局部连贯性建模、上下文向量融合等关键模块，最后说明如何通过前馈网络输出最终评分。方法描述中还穿插了与现有方法的对比，确保读者理解创新点和改进之处。",
    "experiments_story": "实验部分主要采用主实验+对比实验的策略。以shuffle test为主要评测方法，并与近期的神经连贯性模型进行公平对比（统一使用预训练模型XLNet）。实验设计强调与前人工作的可比性，验证新方法在标准任务上的有效性。实验部分未详细展开消融或多数据集验证，主要聚焦于主流评测任务和模型性能对比。"
  },
  "tricks": [
    {
      "name": "引用权威文献建立背景",
      "type": "writing-level",
      "purpose": "通过引用大量相关领域权威文献，增强研究背景的权威性和可信度，让读者信服问题的重要性和研究的必要性。",
      "location": "introduction",
      "description": "作者在引言中引用了多篇核心文献，系统梳理了神经网络和传统模型在篇章连贯性建模上的发展脉络。"
    },
    {
      "name": "指出现有方法的局限性",
      "type": "writing-level",
      "purpose": "通过批判现有神经模型的缺陷，引出自身工作的创新点和必要性，增强说服力。",
      "location": "introduction",
      "description": "明确指出现有神经模型虽然效果好，但从语言学角度存在‘错误的理由’达成高性能的问题。"
    },
    {
      "name": "理论与实证双重支撑创新点",
      "type": "method-level",
      "purpose": "通过结合语言学理论和最新实证研究，突出方法的新颖性和理论合理性。",
      "location": "introduction",
      "description": "将Centering理论与最新实证研究结合，强调以实体为基础的建模更具语言学解释力和实证支撑。"
    },
    {
      "name": "方法流程分步清晰展示",
      "type": "writing-level",
      "purpose": "帮助读者快速理解模型结构和创新点，提升可解释性。",
      "location": "method",
      "description": "在方法部分用‘首先...接着...最后...’的结构分步介绍模型各组成部分。"
    },
    {
      "name": "与现有方法详细对比",
      "type": "method-level",
      "purpose": "通过详细介绍对比对象，突出自身方法的优势和创新点，增强对比性和说服力。",
      "location": "method",
      "description": "详细介绍了Mesgar and Strube (2018)和Moon et al. (2019)等对比模型，并说明如何公平对比。"
    },
    {
      "name": "公平性对比设置",
      "type": "experiment-level",
      "purpose": "通过控制变量（如统一预训练模型），确保实验结果的公平性和可靠性，增强结论的完备性。",
      "location": "method",
      "description": "在对比实验中统一采用XLNet，保证不同方法间的可比性。"
    },
    {
      "name": "采用标准评测方法",
      "type": "experiment-level",
      "purpose": "通过使用领域公认的shuffle test等标准评测方法，证明实验设计的充分性和结果的可靠性。",
      "location": "experiments",
      "description": "采用Barzilay and Lapata (2008)提出的shuffle test作为评测手段。"
    },
    {
      "name": "问题-方法-实验-结论的线性叙事结构",
      "type": "writing-level",
      "purpose": "通过线性递进的叙事结构，帮助读者顺畅理解研究动机、方法设计及其实证效果。",
      "location": "introduction, method, experiments",
      "description": "先提出问题和现有方法不足，再介绍新方法，最后通过实验验证，形成完整闭环。"
    },
    {
      "name": "强调方法的可解释性",
      "type": "method-level",
      "purpose": "突出自身方法在可解释性上的优势，提升方法的学术价值和应用潜力。",
      "location": "introduction, method",
      "description": "通过约束模型关注名词短语和专有名词，获得显式的focus表示，提升模型可解释性。"
    }
  ]
}