[
  {
    "review_id": "3d3b2e1f9dc0097f",
    "paper_id": "ARR_2022_342",
    "reviewer": "Prashanth Vijayaraghavan",
    "paper_summary": "The paper focuses on exploring the role of context in determining the humans’ (annotators) perception of hate or counter-hate in social media comments. Further, the authors also investigate if the context helps improve the models that detect hate speech or counter hate. The authors aggregate a corpus of 6,846 text pairs containing — (a) the context referred as “parent” and the comment to be classified referred to as “target”, and (b) annotations indicating whether each target is hate/counter-hate/neutral. Experiments demonstrate the benefits of incorporating context and training context-aware neural models towards better detection of hate speech in text. ",
    "strengths": "The paper is written well. \nThe paper introduces an annotated dataset which could be useful for future research. \nThe authors perform a detailed analysis of the collected data and the results as well. ",
    "weaknesses": "1. The importance of context is well known and well-established in several prior work related to hate speech. While the paper cites works such as Gao and Huang, 2017 and Vidgen, et al., it just mentions that they don’t identify the role of context in annotation or modeling. The former definitely considers its role for modeling and the latter incorporates it in the annotation phase. Though this work performs analysis of corpus and model to study the role of the context, the claim of being the first work to establish the importance of context may be a little stretched. \n2. Table 2 includes several work but drops out Vidgen et al, 2021, which might be really similar to the dataset presented in this work though the size varies significantly here. So, why is this dataset not used as a potential benchmark for evaluation (for investigating the role of context in detection of hate) as well? \n3. Though MACE can be used to assess the competent annotators and eliminate redundant annotators, it could be challenging to use when it involves most ambiguous content. \n4.  Some of the analysis and results discussed  (for eg. section 6) might be specific to the tested Roberta model. More experiments using different architectures are needed to determine if the findings and errors that arise are consistent across different models and different settings. ",
    "comments": "Claim of being the first one to recognize the importance of context might be too stretched. \nMore experiments with multiple runs with different random seeds for the dataset split will help report the mean score and the standard deviation. This will help us understand the sensitivity of the model to the data split or order of training etc. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "262843a4c9c8009e",
    "paper_id": "ARR_2022_342",
    "reviewer": null,
    "paper_summary": "This paper provides a new dataset of about 6900 English comments (Parent-Target pairs) collected from Reddit annotated according to already existing definitions of hate speech and counter hate. In addition to describing the corpus creation, the authors conduct preliminary experiments which show that taking into consideration the Parent comment improves the model's performance, highlighting the importance of considering the conversational context. ",
    "strengths": "The paper is reasonably strong. The general framing of the task is conducted well. \nThe error analysis is very interesting as it highlights how prevalent each kind of mistake are, which is useful for future research and would allow one to prioritize which kind of misclassification to focus on next. ",
    "weaknesses": "Regarding the dataset construction: the approach is generally sound, but the purposive (i.e., keyword-search oriented) method regarding representative keywords potentially provides a heavy bias. Reflection on how to mitigate this bias, or discussion of machine learning/other unsupervised approaches to reasonably expanding this list, would be welcomed. ",
    "comments": "Could the authors please comment more on their decision of including only one comment for context? ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "3b51e3d3b5c133b4",
    "paper_id": "ARR_2022_342",
    "reviewer": null,
    "paper_summary": "This paper presents an English Reddit corpus which consists of Parent/Target comments to explore whether the conversational context is important to identify a message as Hate, Counter, or Neutral considering both human judgments and system predictions. Authors conduct an extensive analysis based on the annotation by humans as wells as the automatic system's decision. Moreover, an error analysis of the best systems is presented. ",
    "strengths": "S1: The paper is well-written and structured. The authors define clearly the contributions, motivation, and experiments conducted.  S2: Novelty of the work lies in the creation of a Reddit corpus to explore whether the conversational context affects identifying a comment as hate speech, counter, or neutral.  S3: Extensive experiment results are conducted. Both, the main results, as well as ablation results, are strong.\nS4: The experiments in the paper confirm the hypothesis of the authors about the utility of using the conversational context to identify hate speech or counter-narratives. The author shows it affects both human judgments and system prediction. ",
    "weaknesses": "W1: In the process of collecting the Redding messages, a pair (parent, target) is considered, but a better justification of this decision is needed to explain why authors have not considered more response messages.\nW2: In the process of annotation analysis, five annotators label each message. An explanation of this number is necessary.  W3: The analysis of the results is complete but didactic examples while explaining each case would help to interpret the discussion of the authors.  W4: An analysis of the difficulty of the annotators in identifying each class is not presented. Would be important to see in which cases the annotators do not agree and why.\nW5: I believe that the annotation guide may be too short for annotators who are not familiar with this type of task. Have examples been provided to the annotators? ",
    "comments": "- The word \"context\" in the title of the paper could be more specified. I suggest the authors replace it with \"Conversational context\", otherwise could be confused by the context of the sentence.  - What is the annotator agreement between the five annotators before employing MACE's method? Would be helpful to see this analysis in order to observe the difficulty of the task.  - How the authors have resolved the possible doubts of the annotators while the annotating process in MTurk?  - Please, mention the language you focus on to retrieve the Reddit posts.  - Please, move Table 1 to page 2.  - The link of the code is not available but the authors in a footnote affirm \"Code and data available at anonymous_GitHub_link\" - A dot is missing after the \"Label distribution and linguistic insights\" paragraph title.\n- In paragraph 481, please show didactic examples where the \"Parent\" helps to identify the class of the \"Target\".  - Please, explain what do you mean by \"Intricate text\" in Table 8. ",
    "overall_score": "3.5 ",
    "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work."
  }
]