[
  {
    "review_id": "fd2caf0a98ac82aa",
    "paper_id": "ARR_2022_20",
    "reviewer": null,
    "paper_summary": "This paper aims to find the best strategy to select training examples for few-shot transfer. They evaluated 5 data selection methods (data cross-entropy, predictive entropy, gradient embedding, loss embedding) on 3 tasks (POS tagging, NER, NLI) from 20 languages (categorized into 3 groups) . Their final results showed embedding based data selection methods consistently outperforms other strategies. ",
    "strengths": "Comprehensive empirical studies. Experiments seems to be very solid. Paper is clearly written. ",
    "weaknesses": "Although the experiments are very comprehensive, this paper lacks technical novelty. The optimal data selection strategy also seems to offer limited improvement over random data selection. ",
    "comments": "Can you provide more insights about why loss embedding based data selection is better for sequential labeling task while gradient embedding is better for classification task? Why embedding based methods are better than other selection methods?\nFor method selection, details should be included in the main paper rather than appendix (2.1 and 2.2 all refer to Appendix B). ",
    "overall_score": "3 = Good: This paper makes a reasonable contribution, and might be of interest for some (broad or narrow) sub-communities, possibly with minor revisions.",
    "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work."
  }
]