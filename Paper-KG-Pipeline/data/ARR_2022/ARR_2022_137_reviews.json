[
  {
    "review_id": "6de4c24feda039f6",
    "paper_id": "ARR_2022_137",
    "reviewer": null,
    "paper_summary": "The paper describes a transformer that has a block (a component that's enhanced by residual connection). replaced (or enhanced) by ordinary differential equation. The claims are that this method while adding a (reasonably small) computational cost overhead. ",
    "strengths": "Definitely a novel work. Reasonably well described, extensive evaluation. ",
    "weaknesses": "Evaluation is done on very old WMT datasets. It's difficult to claim that those results are state of the art, because those datasets are small by today's standard. Most improvements of MT architectures are shown to not hold out when evaluated rigorously on a wide array of datasets and one of the problems is the dataset size: https://arxiv.org/abs/2102.11972 Nevertheless, the main contribution of this paper is a novel transformer architecture and the evaluation results can be taken as a sanity check. ",
    "comments": "Please include a more recent big datasets for evaluation. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "2 =  Willing to defend my evaluation, but it is fairly likely that I missed some details, didn't understand some central points, or can't be sure about the novelty of the work."
  }
]