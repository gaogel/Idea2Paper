[
  {
    "review_id": "90e04379fb077ffb",
    "paper_id": "ARR_2022_36",
    "reviewer": null,
    "paper_summary": "This paper proposes a new task XBRL tagging, which aims to annotate financial documents into the XBRL format. The target entities are mainly numbers, and the model needs to assign different types to these numbers. The size of type set is large, 139. This paper also proposes their own models on this task SEC-BERT-SHAPE. What they do is fine-tuning BERT on financial documents, and replace the fragment of numbers into a special token. They report SOTA performance on this task. ",
    "strengths": "- A new task that could be useful in the financial domain.\n- A dataset for the new task.\n- A model with SOTA performance.\n- Compared with different baseline models. The setting of the experiments is good.\n- The replacing of number fragments is interesting and could be useful for other related tasks. ",
    "weaknesses": "- It is unclear why SEC-BERT is better than FIN-BERT. The only difference seems to be the financial documents that BERT is pre-trained on. The paper fails to analyze why the different choice of documents leads to a large difference in performance.\n- The technical novelty of SEC-BERT is limited, but it is fine to me since the model is not the only contribution in this paper. ",
    "comments": "Why FIN-BERT is much worse than SEC-BERT?\nWhat about the other XBRL tags that are not in the 139 tags? If this task is for real applications, the other tags are also necessary, right? ",
    "overall_score": "3.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]