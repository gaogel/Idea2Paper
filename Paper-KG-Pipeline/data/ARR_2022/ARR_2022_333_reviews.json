[
  {
    "review_id": "99d64669158590f9",
    "paper_id": "ARR_2022_333",
    "reviewer": null,
    "paper_summary": "This paper introduces the first Thai Nested NER dataset, with a large size (largest non-English dataset) and high inter agreement. Along with introducing how they annotate the dataset, they also train three English SOTA models on the dataset to set a baseline performance for future works. ",
    "strengths": "- The dataset could be very useful for future works. It's large with high quality.  - Experiments are good. Different models have been evaluated. ",
    "weaknesses": "- The writing is really poor. Many places are very confusing. The figures are not clearly separated from the text, and it is confusing that where I should look at. Many sentences use the past tense, while other sentences use the present tense. The only reason that I would like this paper to be accepted is because of the dataset. The writing itself is far from a solid paper, and I suggest authors go over the writing again.\n- This dataset is the first Thai N-NER dataset, and N-NER in Thai is a new task for the community, so it could be very insightful to know what specific challenges are in Thai, and what errors the models make. The paper provides an error analysis, but not deep enough. It would be insightful if the authors could list error patterns at a finer granularity. ",
    "comments": "It is also unclear to me that why syllable segmentation could be useful for the annotation. Many of the readers do not know Thai, so I think more explanation is necessary.\nFor the writing part, for example, Section 3 is mixed with the past tense and present tense. Figure 2 is hidden in the text. I suggest the authors put all the tables and figures at the top of the pages. ",
    "overall_score": "3 = Good: This paper is of interest to the *ACL audience and could be published, but might not be appropriate for a top-tier publication venue. It would likely be a strong paper in a suitable workshop.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "e4459891946c3b9d",
    "paper_id": "ARR_2022_333",
    "reviewer": null,
    "paper_summary": "The paper is about the creation of a large dataset for Thai nested named entity recognition. The dataset is characterized by manually curated class and span annotations, and by the use of a very large class set, 104 classes. \nIn addition, some experiments about using known methods and a new innovative task approach for NNER task are described and analysed. ",
    "strengths": "The paper introduces a new dataset which could be used by others to make different experiments. \nThe paper introduces three different baselines for comparing the experiments with new state of the art models. An error analysis is also included. ",
    "weaknesses": "The paper covers too many topics and some of them are not clear enough. \nThe paper describes the creation of the dataset, the characteristics of Thai that impact the task, the processing problems, the guidelines and human annotation procedures, evaluation and quality control of the manual annotation, five different experiments offered as baseline and 3 experiments with state of the art models, and error analysis. ( Note that there are four pages of appendices). However, some of the topics are not totally covered. For instance, for the description of Thai characteristics, and associated challenges. It is not clear to me the problem of segmentation and it is not clear what are the human annotators doing after the syllable segmentation. An example would help to see the problem in this context. ",
    "comments": "Line 302, right column. \" to trained the model\" => to train the model ",
    "overall_score": "3.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "879b13234d6d0137",
    "paper_id": "ARR_2022_333",
    "reviewer": "Tunga Gungor",
    "paper_summary": "The paper proposes a new nested named entity recognition dataset for the Thai language. It is formed of 8 layers with 10 coarse-grained classes and 104 fine-grained classes. The dataset is formed of about 5K documents collected from two domains, news articles and restaurant reviews. The data was annotated using an annotation guideline and the annotation steps were explained. The dataset was evaluated using SOTA models. ",
    "strengths": "A nested NER dataset with a wide coverage was compiled for the Thai language. It is the first such dataset for the language. It may be useful for nested NER studies for that language and also for low-resource languages as a comparison. Quality of the annotations was checked. ",
    "weaknesses": "There some parts left unclear during the compilation process. Please see below. \nAlso the dataset submitted as supplementary material to the paper seems to be a small part of the whole dataset. ",
    "comments": "My comments are as follows: - How did you decide the number of classes (10 for coarse-grained and 104 for fine-grained) and how did you decide these classes?\n- It will be useful explaining briefly the currently available NER datasets for the Thai language in the related works section.\n- It was stated in Section 3.1 that the data was annotated on a syllable-basis in order to avoid the automatic word segmentation problems. But, in the rest of the paper, all the explanations were given on a word-basis. Section 3.5 indicates that words were segmented using an automatic tokenizer. Also, the example in Table 2 was annotated on a word-basis. This point should be clarified.\n- Another related issue is, if the dataset was annotated on a syllable basis, how useful will be such an annotation for NLP tasks? For instance, relation extraction, where we usually extract the NEs and the find relations between them. By using syllable annotations, how can we find word NEs? Using a segmenter or tokenizer?\n- How is the annotation on Thai NER datasets, on a syllable-basis or word-basis, and why?\n- It is stated that the dataset includes 4,894 documents. In NER datasets, it is better to state the size of the dataset with the number of sentences. How many sentences does the dataset include?\n- Were these 4,894 documents selected randomly? ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]