[
  {
    "review_id": "0eca541313bb789a",
    "paper_id": "ARR_2022_147",
    "reviewer": null,
    "paper_summary": "This work proposes a pipeline for combining existing general knowledge resources with domain specific knowledge extracted from the web via constructed query templates and evaluates the contributions of the domain specific knowledge in two training approaches: a) selecting relevant sentences and b) generated relevant sentences in the context of counseling dialogue applications. ",
    "strengths": "+A well written paper with clear organization, goals, and results +Clear task definition +Reasonable choices for different aspects of the process and justification for each of the pipeline elements.  +Good understanding of models, resources and prior work.\n+A pipeline that can inspire others to replicate and improve. ",
    "weaknesses": "-The chosen evaluation metrics are neither appropriate nor insightful for the task. However, I understand that the authors made the best they could to provide some evaluation based on standard and community accepted metrics and that there are no standard metrics for the task. It is still unsatisfying that a well thought out pipeline has not been convincingly evaluated.\n-The human evaluation helps somewhat but is very limited because it lacks comparisons with other methods.\n-Use of existing resources -- lack of scientific novelty ",
    "comments": "I would strongly advise the authors to provide a discussion/comparison with respect to: https://aclanthology.org/2020.sigdial-1.2.pdf Consider improving the work with a more sophisticated human evaluation on the actual dialogue task. Can you recruit volunteer patients? ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "5f9df67495c17db9",
    "paper_id": "ARR_2022_147",
    "reviewer": null,
    "paper_summary": "The paper studies methods for incorporating knowledge in generating reflective listening responses in psychological counseling conversations. The contribution is trifold: a) the authors proposed a counseling knowledge dataset as well as the pipeline to automatically collect it. b) the authors proposed two methods for incorporating knowledge: a retrieval setup based on embedding similarity; a generation setup that completes knowledge triplets with COMET. c) an analysis of the effects of different types of knowledge on generation quality. ",
    "strengths": "- The task proposed is novel. Using generative models for producing reflective listening responses in counseling conversations is a task that is being actively tackled in the psychological counseling domain, and the authors are being innovative in proposing to incorporate common sense and domain knowledge to further improve the quality of generated utterances.\n- The analysis of the importance of different types of commonsense knowledge to the task is interesting. ",
    "weaknesses": "- The core contribution of the work is unclear: this work is a collection of work the authors done around reflective listening: a dataset and the pipeline to collect it; two methods for incorporating knowledge; a series of vastly different experiments. The authors are advised to limit the scope to one of the contributions and elaborate on just that.\n- Each individual contribution is limited in significance:     - The dataset itself is not carefully curated and the highlight instead is the automation of dataset creation process from Google search, which is also a complex collection of several trivial steps itself and is prone to propagated errors. \n    - The two methods proposed are mostly based on pre-existing libraries along with a series of engineering techniques (e.g., turning triplets into sentences using templates, masking out part of the input, combining K-BERT with BART, etc.). No novel architecture tailored to the studied task is being proposed. \n    - The evaluation metrics are not well-motivated thus it is not entirely clear how well do they reflect the usefulness of the proposed techniques. The human evaluation was performed by just 2 annotations with their professional background unspecified. \n    - Again, additional experiments in Section 4.5 is an overly detailed piece of information and is not super relevant to rest of the writing. ",
    "comments": "See weaknesses ",
    "overall_score": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "7729b516d59a80fd",
    "paper_id": "ARR_2022_147",
    "reviewer": null,
    "paper_summary": "The authors present an approach for knowledge enhanced counseling reflection generation. It uses dialogue context as well as commonsense and domain knowledge for generating responses in counseling conversations. Two methods for knowledge integration are proposed: a retrieval-based method and a generative method. Experimental results show that both methods for knowledge incorporation improve the system's performance.\nCONTRIBUTIONS: (1) The authors propose a pipeline that collects domain knowledge (medical) through web mining and apply it to build up a counseling knowledge base. \n(2) The authors use the domain knowledge they collected along with commonsense knowledge bases for the task of reflection generation. \n(3) The authors analyze different types of commonsense and domain knowledge, as well as their effect on the generation task. ",
    "strengths": "- Overall, the paper is clear in its objectives and methodology followed. The work is well structured, easy to read and follow.\n- The authors show empirical success of their approach.\n- The overall story is convincing. The proposed approach is tested with reasonable models and appropriate experiments. The experimental results are promising, demonstrating the effectiveness of the proposed method. Thus, the paper makes valuable contributions to the field.\n- The approach is well motivated and addresses a problem that is relevant to the community. ",
    "weaknesses": "- Lack of illustrative examples regarding the model outputs.\n- Some details regarding the knowledge collection process have been omitted (see \"Questions\" below). ",
    "comments": "QUESTIONS: - Fig. 2: Why did you discard the \"anatomy\" category?\n- l. 221: How many query templates did you specify in total?\n- l. 227: What's the size of the set of knowledge candidates?\n- l. 550: Did you calculate the agreement between the annotators? Were the annotators authors of the paper?\nMINOR: - Try to better align the figures with the text.\n- fix punctuation: l. 336, l. 433, l. 445, l. 534 - Table 2: The highlighting of the numbers does not correspond to the caption (\"highest scores are in bold, second highest scores in italic\") ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]