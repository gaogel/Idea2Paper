[
  {
    "review_id": "363d19b7089db8a3",
    "paper_id": "ARR_2022_268",
    "reviewer": null,
    "paper_summary": "This work methods for role-based dialogue summarization. They argue that information for other role’s utterances and summaries can improve the informativeness and quality of dialogue summaries. They propose two enhancements which could be applied to existing methods: a cross attention mechanism to to acquire other role’s information supported by a attention divergence loss to match the attention distribution between different roles. And a decoder self-attention-based interaction mechanism to share other role’s summary information. On two role-based dialogue summarization datasets, the authors perform automatic and human evaluation to show improvements over base architectures. ",
    "strengths": "The paper is clearly written and easy to understand. The two mechanisms proposed are individually motivated with ablated model variations showing advantage of both. Extensive experiments are performed to show the advantage of the proposed models. ",
    "weaknesses": "•\tIt is not clear why does the user decoder at time step t uses only the information till time step t from the agent decoder and why not use the information from all the time steps?\n•\tThe motivation of applying the attention divergence loss to force attention similarity is still not clear to me. What happens if att^a_u is made equal to att^u_u . I couldn’t find any model ablation which justifies this loss as well.  •\tThe human evaluation is not clearly able to identify if the model improvements actually help as the results are close and not consistent across models (although reasoning has been provided). ",
    "comments": "Paper is well written and organized. Additional experiments to justify the the attention divergence loss can help the paper. More examples in case studies can better help in understanding the contributions. ",
    "overall_score": "3.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "1590e6fc469f7d05",
    "paper_id": "ARR_2022_268",
    "reviewer": "Xiachong Feng",
    "paper_summary": "This paper proposes an interaction-based model for role-oriented dialogue summarization. This sub-task of dialogue summarization is important for dialogues in specific domains. The idea is interesting, especially the *Attention Divergence Loss*, which guides the inter-attention by means of intra-attention. Experiments are conducted on two datasets: CSDS and the Medical dataset proposed by Song. Actually, the medical dataset is not very suitable for this task, the authors also mention this consideration. The choice of BertAbs as the backbone model also makes sense. However, I am also curious about the performance of using other pre-trained LM for Chinese, like *T5-PEGASUS-Chinese*. The experiments are extensive, both automatic and human evaluations are conducted. ",
    "strengths": "1. interesting idea: Attention Divergence Loss. \n2. extensive experiments and various evaluation metrics, also perform the t-test. \n3. codes will be released. ",
    "weaknesses": "1. Choose BERTAbs as the backbone model rather than fully pre-trained seq2seq LM. \n2. The experimental results on MC are not very significant, Song et al., 2020 achieve better results on agent summary in terms of ROUGE-1 and ROUGE-L. 3. For *Agent Summary Completeness Analysis*, some details are missing, how to judge agent summaries need to be integrated? ",
    "comments": "The line number on page 4 is missing. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]