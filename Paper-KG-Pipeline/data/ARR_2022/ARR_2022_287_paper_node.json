{
  "paper_id": "ARR_2022_287",
  "title": "Reinforcement Guided Multi-Task Learning Framework for Low-Resource Stereotype Detection",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究文本数据，聚焦于低资源环境下的刻板印象检测问题。",
    "core_technique": "论文采用了强化学习引导的多任务学习框架，结合多任务学习和强化学习技术以提升刻板印象检测的效果。",
    "application": "论文成果可应用于自动化文本审核、社交媒体内容分析、偏见检测与消除等实际场景。",
    "domains": [
      "自然语言处理",
      "人工智能伦理"
    ]
  },
  "ideal": {
    "core_idea": "通过多任务学习和强化学习选择相关数据，提升低资源环境下的刻板印象检测性能。",
    "tech_stack": [
      "多任务学习",
      "强化学习",
      "预训练语言模型"
    ],
    "input_type": "带有刻板印象及相关攻击性语言标签的文本数据",
    "output_type": "对文本中刻板印象及攻击性语言的检测与分类结果"
  },
  "skeleton": {
    "problem_framing": "论文首先从实际应用痛点出发，指出大规模预训练语言模型（PLMs）在实际NLP应用中广泛使用，但由于无监督训练于海量网络数据，模型输出中不可避免地渗入有害语言和偏见，这些偏见又会通过下游应用进一步扩散到社会中。作者通过具体的有害文本示例（如侮辱、刻板印象等）强化问题的现实紧迫性，并进一步指出刻板印象检测的独特挑战和社会危害，由此引出对刻板印象检测的研究需求。",
    "gap_pattern": "论文批评现有工作的策略主要有两点：一是指出现有关于冒犯性语言检测的研究较多，但专注于英文刻板印象检测的工作稀缺，原因包括刻板印象的隐蔽性和对社会知识的依赖；二是批评现有数据集多为众包构建的诊断性数据，缺乏对自然文本的覆盖，导致模型泛化能力有限。作者采用‘现有方法忽视了X’（如忽视刻板印象的隐蔽性和社会知识需求）、‘现有方法在Y场景下失效’（如诊断性数据集不适用于自然场景）等句式和逻辑。",
    "method_story": "方法部分采用‘先整体后局部’和‘从简单到复杂’的叙述策略。首先，作者提出利用多任务学习（MTL）框架，将刻板印象检测与相关的冒犯性语言检测任务联合建模，整体介绍模型结构。随后，提出关键观察：邻近任务数据对目标任务的贡献不均，进而引出基于强化学习的数据选择机制（RL-MTL），详细描述该机制如何动态选择最有助于目标任务的数据。最后，介绍具体的分类器实现和任务设置。",
    "experiments_story": "实验部分采用‘多阶段+多数据集验证’的策略。首先在六个数据集上进行三阶段实验：一是各任务的PLM微调基线，二是多任务学习模型，三是强化学习引导的多任务学习模型。每阶段均在多个主流PLM上验证，系统比较不同模型和设置下的表现，突出方法的有效性。此外，实验覆盖了主任务（刻板印象检测）和相关任务（如仇恨言论、冒犯性语言、厌女检测），并在细粒度和粗粒度数据集上进行零样本测试，体现方法的泛化能力。"
  },
  "tricks": [
    {
      "name": "现实危害引入",
      "type": "writing-level",
      "purpose": "强调研究问题的重要性和现实影响，增强说服力",
      "location": "introduction",
      "description": "通过描述PLMs在现实应用中传播有害语言和偏见，强调问题的社会危害性和紧迫性，引发读者关注。"
    },
    {
      "name": "具体案例举例",
      "type": "writing-level",
      "purpose": "帮助读者直观理解问题类型，提升可解释性和共鸣",
      "location": "introduction",
      "description": "列举多个具体的有害文本实例（S1-S4），展示不同类型的stereotype和offensive language。"
    },
    {
      "name": "文献递进梳理",
      "type": "writing-level",
      "purpose": "展示研究基础，表明本工作在前人工作的基础上推进，增强说服力和学术积累感",
      "location": "introduction",
      "description": "梳理从Peters et al. (2018)到Vaswani et al. (2017)及后续工作的进展，说明本研究的理论和技术背景。"
    },
    {
      "name": "问题细分与定义",
      "type": "writing-level",
      "purpose": "明确问题边界，提升可解释性和科学性",
      "location": "introduction",
      "description": "区分stereotype与其他offensive language的不同，引用权威定义，帮助读者理解研究对象的特殊性。"
    },
    {
      "name": "两阶段解决方案框架",
      "type": "writing-level",
      "purpose": "系统化问题解决思路，展示研究的全面性和创新性",
      "location": "introduction",
      "description": "提出诊断/去噪PLM偏见和输出端有害文本识别的双重策略，明确本工作的定位和创新点。"
    },
    {
      "name": "任务稀缺性强调",
      "type": "writing-level",
      "purpose": "突出研究难点和创新空间，增强新颖性",
      "location": "method",
      "description": "指出高质量stereotype检测数据稀缺，强调本工作在低资源场景下的意义。"
    },
    {
      "name": "邻近任务迁移利用",
      "type": "method-level",
      "purpose": "展示方法创新性，通过迁移学习提升目标任务表现",
      "location": "method",
      "description": "提出利用与目标任务相关的邻近任务数据（如hate speech、abuse detection）进行多任务学习。"
    },
    {
      "name": "强化学习数据选择机制",
      "type": "method-level",
      "purpose": "提升方法有效性和新颖性，细化多任务学习的数据利用",
      "location": "method",
      "description": "设计强化学习代理从邻近任务数据中选择与目标任务最相关的样本，优化模型学习。"
    },
    {
      "name": "模型结构分层描述",
      "type": "method-level",
      "purpose": "提升可解释性，帮助读者理解模型架构",
      "location": "method",
      "description": "详细描述模型的表示层、共享参数和任务特定分类头，明确各部分功能。"
    },
    {
      "name": "多阶段实验设计",
      "type": "experiment-level",
      "purpose": "展示实验的系统性和完备性，逐步验证方法有效性",
      "location": "experiments",
      "description": "将实验分为单任务微调、多任务学习、强化学习多任务三阶段，层层递进验证改进效果。"
    },
    {
      "name": "多模型对比验证",
      "type": "experiment-level",
      "purpose": "增强结论的说服力和普适性",
      "location": "experiments",
      "description": "在四种主流PLM上分别进行实验，展示方法对不同模型的适用性和提升幅度。"
    },
    {
      "name": "多任务多数据集评测",
      "type": "experiment-level",
      "purpose": "证明方法的广泛适用性和实验结果的充分性",
      "location": "experiments",
      "description": "在六个数据集、多个相关任务上进行评测，涵盖不同类型的offensive language。"
    },
    {
      "name": "分阶段量化对比",
      "type": "experiment-level",
      "purpose": "清晰展示方法改进幅度，增强对比性和说服力",
      "location": "experiments",
      "description": "分别报告baseline、MTL、RL-MTL三类模型的F1分数，突出每一步的性能提升。"
    },
    {
      "name": "零样本评估设置",
      "type": "experiment-level",
      "purpose": "验证模型泛化能力，提升实验说服力",
      "location": "experiments",
      "description": "在Fine-Grained Stereotype Detection任务上采用zero-shot设置，仅用于评测，展示模型迁移能力。"
    },
    {
      "name": "逻辑递进式叙事结构",
      "type": "writing-level",
      "purpose": "提升论文整体可读性和逻辑性",
      "location": "introduction / method / experiments",
      "description": "从问题引入、现象分析，到方法提出、实验验证，层层递进，环环相扣，逻辑清晰。"
    }
  ]
}