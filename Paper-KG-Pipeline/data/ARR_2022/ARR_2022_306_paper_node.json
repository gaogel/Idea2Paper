{
  "paper_id": "ARR_2022_306",
  "title": "In-BoXBART: Get Instructions into Biomedical Multi-task Learning",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究生物医学领域的文本数据，关注多任务学习中的指令理解与执行问题。",
    "core_technique": "论文基于BART模型架构，提出了In-BoXBART方法，将指令学习（instruction learning）与多任务学习结合，属于Transformer系列模型的改进与应用。",
    "application": "成果可应用于生物医学文本的问答、信息抽取、文本生成等自然语言处理相关任务，提升生物医学领域的多任务处理能力。",
    "domains": [
      "自然语言处理",
      "生物医学信息学",
      "多任务学习"
    ]
  },
  "ideal": {
    "core_idea": "首次提出基于指令的统一模型，实现多种生物医学NLP任务的高效泛化。",
    "tech_stack": [
      "指令学习",
      "多任务学习",
      "BART模型微调",
      "meta-dataset构建"
    ],
    "input_type": "带有任务指令和输入实例的文本数据",
    "output_type": "针对各生物医学NLP任务的文本输出结果"
  },
  "skeleton": {
    "problem_framing": "论文首先从实际应用痛点出发，指出任务特定模型虽然在通用和生物医学NLP中取得了SOTA性能，但其计算资源消耗大、训练耗时，难以适应实际需求。接着，作者引入学术gap，指出虽然通用NLP领域已有多任务泛化的尝试，但生物医学NLP领域尚未系统研究多任务泛化方法。最后，结合应用需求，强调需要一个能够高效泛化到多种任务的统一模型。",
    "gap_pattern": "论文批评现有方法时，采用了'现有方法在实际应用中存在局限'和'某领域尚未系统研究'的逻辑。具体句式包括：'task-specific models have limitations to real-world applications because this approach is computationally expensive and time-consuming'，以及'However, approaches to achieve generalization across various biomedical NLP tasks have not been systematically studied.' 通过对比通用NLP和生物医学NLP的研究现状，突出当前方法的不足和研究空白。",
    "method_story": "方法部分采用了先整体后细节的叙述顺序。首先总体介绍了提出的基于指令的多任务模型In-BoXBART及其与两类基线的对比思路。随后，详细描述了数据处理流程，包括指令与输入实例的拼接、训练数据的构建、模型微调流程。最后，补充说明了具体实现细节（如输入长度限制、样本筛选、采样策略等），逐步细化每个关键环节。",
    "experiments_story": "实验部分采用了主实验+消融分析的策略。首先，统一使用BART (base)模型对比主方法与两类基线（单任务、多任务无指令），并详细说明实验设置。其次，设计了多种实验以分析不同因素的影响，包括：不同采样策略（欠采样、均值采样、过采样）对模型的影响、few-shot学习场景下的表现、实例筛选和指令示例选择对结果的作用。所有实验均在统一的数据集和评价指标（Rouge-L）下进行，保证了结果的可比性和系统性。"
  },
  "tricks": [
    {
      "name": "问题驱动式引入",
      "type": "writing-level",
      "purpose": "突出实际问题，激发读者兴趣并强调工作的必要性",
      "location": "introduction",
      "description": "通过指出现有任务特定模型在计算资源和时间上的高昂成本，强调需要更高效的通用模型，明确提出研究动机。"
    },
    {
      "name": "领域现状梳理与定位",
      "type": "writing-level",
      "purpose": "展示作者对领域的全面了解，凸显工作在现有研究中的位置",
      "location": "introduction",
      "description": "系统回顾了通用NLP和生物医学NLP领域的主流方法及其局限，指出通用化在生物医学NLP尚未被系统研究，从而为本工作定位创新空间。"
    },
    {
      "name": "创新点明确陈述",
      "type": "writing-level",
      "purpose": "突出工作的创新性，吸引读者关注",
      "location": "introduction",
      "description": "明确提出首次将instructional prompt方法应用于生物医学NLP多任务泛化，并构建了32项任务的统一数据集和模型。"
    },
    {
      "name": "可视化方法概览",
      "type": "writing-level",
      "purpose": "帮助读者快速理解方法整体框架",
      "location": "introduction",
      "description": "通过引用Figure 1，简要展示了多任务模型的整体架构，降低理解门槛。"
    },
    {
      "name": "对比实验设计",
      "type": "experiment-level",
      "purpose": "增强说服力，通过与现有方法直接比较，突出自身优势",
      "location": "introduction / experiments",
      "description": "设计了与单任务模型和无指令多任务模型的对比实验，并报告了显著的性能提升。"
    },
    {
      "name": "方法流程分步阐述",
      "type": "method-level",
      "purpose": "提升可解释性，使读者清晰理解模型实现细节",
      "location": "method",
      "description": "详细描述了如何将指令与输入实例结合、编码、训练BART模型等具体步骤。"
    },
    {
      "name": "实验细节透明化",
      "type": "experiment-level",
      "purpose": "提升完备性和复现性，让读者相信实验结果可靠",
      "location": "experiments",
      "description": "详细说明了模型参数、硬件环境、训练轮数、数据预处理和实例筛选等关键实验细节。"
    },
    {
      "name": "数据处理策略说明",
      "type": "experiment-level",
      "purpose": "增强实验的科学性和公平性，避免数据偏差影响结论",
      "location": "experiments",
      "description": "针对输入长度限制、样本不平衡等问题，说明了数据筛选和采样方法，保证实验公平。"
    },
    {
      "name": "多维度实验分析",
      "type": "experiment-level",
      "purpose": "证明方法的完备性和适用性，增强结论的说服力",
      "location": "experiments",
      "description": "不仅报告主结果，还分析了采样策略、few-shot学习等不同设置下的模型表现。"
    },
    {
      "name": "统一评价指标设定",
      "type": "experiment-level",
      "purpose": "保证不同任务间结果可比性，增强结论的可靠性",
      "location": "experiments",
      "description": "将所有任务统一转化为文本生成问题，采用Rouge-L作为评价指标，便于横向比较。"
    },
    {
      "name": "逻辑递进式叙事结构",
      "type": "writing-level",
      "purpose": "提升论文整体可读性和逻辑性，帮助读者顺畅理解研究流程",
      "location": "introduction / method / experiments",
      "description": "从问题引入、现状梳理、方法提出、实验设计到结果分析，层层递进、环环相扣。"
    },
    {
      "name": "实验结果量化展示",
      "type": "experiment-level",
      "purpose": "增强说服力，通过具体数据支撑结论",
      "location": "experiments",
      "description": "用具体的Rouge-L分数量化不同模型的性能差异，突出方法优势。"
    },
    {
      "name": "公平性对比设计",
      "type": "experiment-level",
      "purpose": "确保对比结果可信，避免因数据处理差异导致偏见",
      "location": "experiments",
      "description": "在所有模型训练和评测时统一去除超长实例，保证对比公平。"
    }
  ]
}