[
  {
    "review_id": "cf042f2488f47016",
    "paper_id": "ARR_2022_9",
    "reviewer": null,
    "paper_summary": "Below is a copy from the previous review: >In this paper the authors proposed a new fairness metric, accumulated prediction sensitivity. The authors formulate the metric and establish its properties in relationship with group fairness and individual fairness. Interestingly, the authors measure the correlation of the proposed metric with a human judgment of fairness. Since the proposed metric requires a choice of the way of computing two hyperparameter vectors, the authors experiment with different choices and show that this choice matters quite a lot. ",
    "strengths": "Below is a copy from the previous review: > - Important direction of research > - Relatively good correlation with human judgment > - The authors evaluated several choices of the metric > - Intuitive formulation of the metric > - Clearly written and easy to follow paper ",
    "weaknesses": "Below is a copy from the previous review: > - Need of choice of the two hyperparameters vectors w and v > - This choice, as evident from the authors experiments, is very important > - Process of obtaining v can be quite involved > - The proposed metric works only or gradient-based models > - Although the formulation is intuitive, the metric values themselves can be hard to interpret. ",
    "comments": "The authors addressed most of the reviewers' comments made for the previous submission. This is an important direction of research and I believe in the current state the paper can be accepted for publication. ",
    "overall_score": "4 = Strong: This paper is of significant interest (for broad or narrow sub-communities), and warrants acceptance in a top-tier *ACL venue if space allows.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "cd54453bcc2a3839",
    "paper_id": "ARR_2022_9",
    "reviewer": null,
    "paper_summary": "This paper proposed a new machine learning model fairness metric based on the prediction sensitivity. The paper also showed its theoretical connection to group fairness and individual fairness. ",
    "strengths": "- The paper proposed a new fairness metric accumulated prediction sensitivity to measure the model prediction change with respect to the change of the protected features.\n- The paper showed theoretical relations between accumulated prediction sensitivity and group/individual fairness.\n- The evaluation is conducted on multiple datasets. The author explained the reason to only compare with CF baseline. ",
    "weaknesses": "It seems that the main focus in the experiment is \"gender-ness\" of words (e.g., he, she, etc.) based on the description and qualitative examples. How about many other cases? For example: - Same words with different senses in different sentences: \" book an Italian trip for me\" vs \"i want an Italian trip book\" - Different verbs/prepositions: \"she takes the flight to new york city\" vs \"she works in the flight to new york city\" ",
    "comments": "Please see the above reviews. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]