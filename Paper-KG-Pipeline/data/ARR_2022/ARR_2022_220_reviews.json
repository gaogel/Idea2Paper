[
  {
    "review_id": "c2a349441a32e604",
    "paper_id": "ARR_2022_220",
    "reviewer": null,
    "paper_summary": "This submission proposed a model for offensive span detection (OSD). Specifically, the authors train GPT-2 in a dual-training setting with reinforcing learning to generate synthetic training data for OSD. ",
    "strengths": "- Good writing and well organized - Interesting topic of offensive span detection ",
    "weaknesses": "- Limited novelty: simple application via utilizing GPT-2 to generate data of a specific domain - Insufficient evaluation:    - only one dataset is used   - lack of detailed dataset statistics   - the comparison is not persuasive ",
    "comments": "Although OSD is an interesting topic, the submission should address the following issues before it can be published: - Only one dataset is used for evaluation, is there anything more?\n- Is it possible to add more evaluations about the synthetic data itself? In the current paper, the comparison is between the whole pipeline and other baselines. Not sure how much performance is made by the data itself, or the training mode itself?\n- Is it possible to generalize the application? For example, from the OSD to general opinion and aspect detection?  - The method needs the manual labels as the start (the BIO labels mentioned in the experiments), is it possible to add more statistics about this label set?\n- The definitions of usefulness and diversity seem quite intuitive. Any motivations to justify this definition, or is there any alternative form of definition? ",
    "overall_score": "2 = Borderline: This paper has some merit, but also significant flaws. It does not warrant publication at top-tier venues, but might still be a good pick for workshops.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]