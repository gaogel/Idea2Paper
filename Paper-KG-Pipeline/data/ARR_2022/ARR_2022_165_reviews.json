[
  {
    "review_id": "5a2c468d42a1d327",
    "paper_id": "ARR_2022_165",
    "reviewer": null,
    "paper_summary": "This paper proposes a “plug and play” method for controlled text generation using language models, i.e., it does not require finetuning of the language model used for generation. Their algorithm uses MCTS, where the policy balances sequence likelihood with the score from a discriminator that determines the presence of certain textual attributes. This balance encourages generation to meet certain constraints while maintaining quality. They provide empirical evidence of the effectiveness of the algorithm. ",
    "strengths": "The paper offers an intuitive extension of MCTS for controlled generation that doesn’t require fine-tuning of a language model. The method has the potential to be widely applicable. The experiments are very comprehensive, exploring multiple baselines, datasets, and parameter settings. ",
    "weaknesses": "- The MCTS algorithm itself in the context of text generation is not explained very well, which makes it hard to understand the proposed algorithm - The need for a discriminator for any possible constraint can be quite limiting to the applicability of the algorithm - There lacks a formal runtime analysis. Speed during decoding is often quite important and it's unclear what the extent of the computational drawbacks of this algorithm are - There have been a number of recent works also using MCTS for language generation. I am not very familiar with these works so it is hard for me to tell how novel this paper is in context ",
    "comments": "- I don’t quite see where p(x|c) fits into equation 1. Is it just s_i? This could be made more clear - In terms of plug and play controlled generation methods that do not require fine-tuning of an LM, a citation is missing for Pascual et. al. 2021. Schick et. al 2021 also use a discriminator at each time step to control generation for certain attributes - Line 467: the standard definition of perplexity used in language modeling divides by the number of tokens, and so is not dependent on length - Line 228: token -> tokens ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "5385e108c4289cb3",
    "paper_id": "ARR_2022_165",
    "reviewer": "Nan Jiang",
    "paper_summary": "The authors propose to use Monte Carlo Tree Search to generate sentences that satisfy the constraints. The authors conduct rigorous experiment analysis to show the advantage of the method ",
    "strengths": "The paper is well written and easy to follow. The figures present the idea clearly. There are various experiments to support the proposed method. ",
    "weaknesses": "What specific problem that previous approaches cannot solve but this paper can resolve? Or in terms of what aspect, discriminator-guided decoding can do better (not just score)? For example, every constraint is modeled as one discriminator, will it mean the model is better modularized? ",
    "comments": "- could you give a detailed example of what \"constraint\" is used in this paper? It is not clear how multiple discriminators can enforce constraints simultaneously.\n- MCTS is mainly used in RL since the state transition and reward function are probability distributions. It is unclear why you need MCTS to do a search, why not just depth-first search, best-first search, A* search, or any heuristic search? Could you highlight the necessary steps that can achieve discriminator-guided decoding?\n- Do you assume you can naturally have every constraint as well as the corresponding discriminator?\n- you can put all the HTTPS links as footnotes.\n- Line 513 \"Go of RAM\" ->  \"GB of RAM\" ",
    "overall_score": "3.5 ",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  }
]