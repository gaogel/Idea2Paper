[
  {
    "review_id": "a12d4e4c3013ba70",
    "paper_id": "ARR_2022_286",
    "reviewer": null,
    "paper_summary": "This paper presents an algorithm to detect if unargmaxable classes occur given a certain model. \nOn top of that, the authors find that although theoretically possible, the \"stolen probability problem (SPP)\" rarely occurs in reality.\nTo expand a bit, the authors start by revisiting the SPP, which sometimes goes by the name of softmax bottleneck in literature. \nIn its essence, the problem arises from the hidden dimension being smaller than the output vocabulary size. \nThe problem basically states that the model can not output arbitrary distribution over the vocabulary.\nMoving on, the authors propose an approximate algorithm that pre-filters candidates, and then an exact algorithm is applied to decide if a certain class is unargmaxable.\nWith the tools ready, the authors then examine various LMs and MT models for the SPP. \nUnsurprisingly, most of the models do not suffer from the problems and those who do, only fail to argmax some \"corner case\" subwords. ",
    "strengths": "The authors provided a nice geometrical intuition for the SPP. \nAlthough the problem is known before, I think the authors did a good job in presenting their take on the problem.\nThe authors propose an algorithm to find the unargmaxable classes which is a combination of an approximate filtering and exact search.\nThe authors examined a large quantity of LM and MT models and only found a limited number of models suffering from SPP. \nAdditionally, for those models, they show that the problem is not severe as the classes are \"corner case\" subwords.\nThe paper is easy-to-follow.\nThe final comment in the future work section about the connection between the difficulty of model training and the difficulty of finding the unargmaxable classes is definitely interesting. ",
    "weaknesses": "While there exist many papers discussing the softmax bottleneck or the stolen probability problem, similar to what the authors found, I personally have not found enough evidence in my work that the problem is really severe. \nAfter all, there are intrinsic uncertainties in the empirical distributions of the training data, and it is quite natural for us to use a smaller  hidden dimension size than the vocabulary size, because after all, we call them \"word embeddings\" for a reason. \nI guess what I mean to say here is that the problem is of limited interest to me (which says nothing about a broader audience) because the results agree very well with my expectations. \nThis is definitely not against the authors because they did a good job in showing this via their algorithm and the concrete experiments. ",
    "comments": "I feel like the authors could mention and expand on the implications when beam search is used. \nBecause in reality, especially that many MT models are considered in the paper, greedy search is seldomly used. \nIn other words, \"even if greedy search is used, SPP is not a big deal, let alone that in reality we use beam search\", something like that.\nCompared to the main text, I am personally more interested in the point brought up at L595. \nWhat implications are there for the training of our models? \nHow does the gradient search algorithm decide on where to put the word vectors and hidden state vector? \nIs there anything we, i.e. the trainers of the NNs, can do to make it easier for the NNs?\nSmall issues: - L006, as later written in the main text, \"thousands\" is not accurate here. Maybe add \"on the subword level\"?\n- L010, be predicted - L034, personally, I think \"expressiveness\" is more commonly used, this happens elsewhere in the paper as well.\n- L082, autoencoder - L104, greater than or equal to ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]