[
  {
    "review_id": "41157292909defe5",
    "paper_id": "ARR_2022_294",
    "reviewer": null,
    "paper_summary": "This paper presents and empirically confirms the \"prompt waywardness hypothesis\" in the context of continuous prompt tuning. The hypothesis is that for any arbitrary text there exists a continuous prompt whose discrete projection is said arbitrary text *and* whose resulting performance is almost as good as the best possible continuous prompt. Therefore, the paper suggests, it is difficult to evaluate continuous prompts in a discrete space because there always exist good continuous prompts that map to random or misleading discrete text.\nA little more formally, the hypothesis is that for any downstream task and arbitrary text $p_d$ of length L, there exists some continuous prompt $\\tilde{p}_c$ of length L such that $\\tilde{p}_c$ results in a test loss close to that of the best continuous prompt $p^*_c$ of length L, and yet $\\tilde{p}_c$ projects to $p_d$ (when projected into discrete space).\nThe authors empirically confirm this hypothesis by showing that for five downstream classification tasks they are able to find continuous prompts which project to certain arbitrary sentences (at least very closely, as evaluated by F1) but whose resulting accuracy is almost as good as that of the optimal prompt (as evaluated by the difference in test accuracy). These experiments use the GPT-2-large model (except when model size is ablated), and projection is defined as follows: continuous prompts are projected to discrete space by finding the token with the nearest-neighbor embedding (where token embeddings are taken to be GPT-2's embedding matrix). Finally, the paper discusses implications of the prompt waywardness hypothesis, the main implication being that continuous prompts may never be interpretable by being projected to discrete language. ",
    "strengths": "1. The paper is clearly written and easy to follow. \n2. The experimental results are thorough and convincing; the paper provides a strong analysis section evaluating the effects of hyperparameters, model size, and prompt length. \n3. The paper discusses implications of the hypothesis: the difficulty of interpreting discrete prompts and the untrustworthiness of discrete projections of continuous prompts. \n4. The conclusion that encouraging continuous prompts to project to semantically accurate instructions (Appendix B) provides interesting insight into the function of continuous prompts. ",
    "weaknesses": "The implications discussed in the paper apply *if* one were to try to project continuous prompts to discrete space using GPT-2's (or any other) embedding matrix, but, as far as I am aware, no one has attempted to interpret continuous prompts in this way. The paper could be strengthened by more explicitly discussing *why* we should be concerned with this particular method of prompt interpretation: 1. Do the authors think we should be especially concerned about nearest-neighbor, embedding matrix projections because that's how language model outputs and word2vec are calculated? This seems to be the case, but could be made more explicit. It's not clear why the use of an embedding matrix at the output layer of language models implies this would be a popular way of discretizing continuous prompts. \n2. Is it because the particular discrete projection studied is the simplest that the authors believe it might be used in the future? \n3. Do the authors think their hypothesis generalizes to other methods of discretely interpreting prompts? If so, that could also be made more explicit. ",
    "comments": "1. Space permitting, it may be beneficial to move the finding of Appendix B to the main paper as I found this interesting. \n2. Line 246 is difficult to parse. Possibly split this into two sentences. ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  },
  {
    "review_id": "270a173af727771a",
    "paper_id": "ARR_2022_294",
    "reviewer": "Linqi Song",
    "paper_summary": "This paper proposed a Waywardness Hypothesis for the connection between continuous prompt and discrete prompt and use experiments to justify this connection. The author concluded that a soft prompt could complete a desired task while projecting to any given task-related/unrelated target text, at a small cost of accuracy.  Five classification tasks have been considered to verify the authors’ hypothesis. Experiments with large models and long prompts are also conducted to analyze the “waywardness” of the prompt method. The authors also discussed several social and research implications of waywardness. ",
    "strengths": "1. The idea to establish a connection between the continuous prompt and the discrete prompt is interesting. The hypothesis is justified by a few experiments and the proposed methods are well motivated. The writing is clear and the description of the waywardness is easy to follow. \n2. The proof method is simple and the design of the experiment and the objective are clear. All the experiments are easy to re-implement. \n3. Comprehensive extensive analysis: The paper offers the further analysis of different aspects, including model size, prompt length etc.. ",
    "weaknesses": "1. It seems that the hypothesis needs to consider a compact space for continuous prompts in order to build an approximate mapping to the discrete prompt space, as there is only a finite number of discrete prompts. Any point in an unbounded space seems hard to be mapped with a certain accuracy into a discrete space with a finite number of points. \n  2. The authors design an objective to build up a trade-off between the task accuracy and the prompt F1. According to the experimental results, it is possible to achieve ≥ 94% prompt F1 when projecting the soft prompt to task-unrelated instructions with under 2% drop in accuracy. The authors want to use these results to prove that there is little correspondence between continuous prompts and their interpretation. However, methods based on soft prompt were designed with these factors in mind when it was first introduced. The soft prompt has nothing to do with the natural language that humans are accustomed to and can exist in any form. The soft prompt is only a sequence of ‘abstract pseudo tokens’ that can be understood by machines to assist the training of language models.\n3. The authors find that project to “true” target prompts is no more effective at solving the tasks. This is not a new discovery either. OPTIPROMPT(Zhong et al. 2021) proposed a method that initializes virtual tokens based on discovered discrete prompts, then fine-tunes the embeddings to increase task accuracy. The resulting accuracy greatly surpasses the that based on so-called “true” discrete prompts, this previous result already shows that the so-called “true” target prompt is not effective compared with the soft prompts.\nIn a summary, the authors have done a lot of exploration and experimentation, as well as using experiments to prove many of their conjectures, yet many of these conjectures can be directly summarized by previous work. ",
    "comments": "1. It seems that the hypothesis needs to consider a compact space for continuous prompts in order to build an approximate mapping to the discrete prompt space, as there is only a finite number of discrete prompts. Any point in an unbounded space seems hard to be mapped with a certain accuracy into a discrete space with a finite number of points. \n  2. The authors design an objective to build up a trade-off between the task accuracy and the prompt F1. According to the experimental results, it is possible to achieve ≥ 94% prompt F1 when projecting the soft prompt to task-unrelated instructions with under 2% drop in accuracy. The authors want to use these results to prove that there is little correspondence between continuous prompts and their interpretation. However, methods based on soft prompt were designed with these factors in mind when it was first introduced. The soft prompt has nothing to do with the natural language that humans are accustomed to and can exist in any form. The soft prompt is only a sequence of ‘abstract pseudo tokens’ that can be understood by machines to assist the training of language models.\n3. The authors find that project to “true” target prompts is no more effective at solving the tasks. This is not a new discovery either. OPTIPROMPT(Zhong et al. 2021) proposed a method that initializes virtual tokens based on discovered discrete prompts, then fine-tunes the embeddings to increase task accuracy. The resulting accuracy greatly surpasses the that based on so-called “true” discrete prompts, this previous result already shows that the so-called “true” target prompt is not effective compared with the soft prompts.\nIn a summary, the authors have done a lot of exploration and experimentation, as well as using experiments to prove many of their conjectures, yet many of these conjectures can be directly summarized by previous work. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]