{
  "paper_id": "ARR_2022_313",
  "title": "Prompt-based Data Augmentation for Low-Resource NLU Tasks",
  "conference": "ARR",
  "domain": {
    "research_object": "文本数据，聚焦于自然语言理解（NLU）任务中的低资源场景。",
    "core_technique": "基于提示（prompt-based）的数据增强方法，可能结合了预训练语言模型（如Transformer架构）进行数据生成或扩充。",
    "application": "自然语言理解相关的实际应用场景，如意图识别、文本分类、问答系统等，尤其是在训练数据稀缺的情况下。",
    "domains": [
      "自然语言处理",
      "数据增强",
      "低资源学习"
    ]
  },
  "ideal": {
    "core_idea": "提出基于软提示（soft prompts）的数据增强方法PromDA，用于低资源NLU任务中生成高质量合成数据。",
    "tech_stack": [
      "Prompt Tuning",
      "Pre-trained Language Models (PLMs)",
      "Soft Prompts",
      "Data Augmentation"
    ],
    "input_type": "小规模标注文本数据，用于自然语言理解任务（如句子分类和序列标注）",
    "output_type": "高质量的合成训练样本，用于提升NLU模型性能"
  },
  "skeleton": {
    "problem_framing": "论文从实际痛点出发引出问题。首先指出深度神经网络需要大量高质量标注数据，而在许多场景下标注数据获取十分困难，尤其是在低资源自然语言理解（NLU）任务中。通过强调数据稀缺带来的挑战，明确了研究的现实意义和紧迫性，进而引出低资源NLU任务下数据扩增的需求。",
    "gap_pattern": "论文系统性地批评了现有方法，采用了‘现有方法在X场景下存在Y问题’的逻辑。具体包括：1）自训练方法依赖难以获得的领域内未标注数据；2）从通用语料中抽取领域数据并不容易；3）基于启发式规则的数据扩增可能导致语法和语义错误；4）直接微调预训练语言模型在小样本下容易过拟合，生成的数据缺乏多样性。通过逐条指出现有方法的局限性，突出自身工作的创新点和必要性。",
    "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先提出整体方案PromDA的核心思想，即冻结预训练模型，仅微调软提示（soft prompts），避免过拟合并提升生成数据的多样性。随后进一步强调软提示初始化对极低资源场景的重要性，并提出相应的初始化策略。整体上，方法介绍从总体框架到关键细节，层层递进。",
    "experiments_story": "实验部分采用‘主实验+消融+对比+多数据集验证+分析’的多层次叙述策略。具体包括：1）主实验：在句子分类和序列标注两个任务上，多个数据集和不同shot数下全面对比PromDA与各类基线方法；2）消融实验：分析PromDA各组成部分对性能的影响；3）与无标注数据方法对比，验证PromDA在无需额外未标注数据情况下的有效性；4）多样性分析和案例分析，进一步说明生成数据的质量和实际效果。整体结构严密，覆盖方法有效性、鲁棒性和实用性。"
  },
  "tricks": [
    {
      "name": "问题背景与挑战铺垫",
      "type": "writing-level",
      "purpose": "让读者充分理解低资源NLU任务的难点和现有方法的不足，激发对新方法的兴趣",
      "location": "introduction",
      "description": "通过详细罗列低资源NLU面临的数据匮乏、标注难、现有数据增强方法的局限等问题，为提出新方法做铺垫。"
    },
    {
      "name": "引用前沿工作对比现有方法",
      "type": "writing-level",
      "purpose": "展示作者对领域前沿的了解，并突出当前方法的不足",
      "location": "introduction",
      "description": "系统性地引用并简述多种已有方法（如自训练、规则增强、PLM微调等），指出它们的局限性，为提出新方法提供合理性。"
    },
    {
      "name": "创新点明确提出",
      "type": "method-level",
      "purpose": "突出方法的新颖性和独特贡献",
      "location": "introduction",
      "description": "明确提出Prompt-based Data Augmentation (PromDA)的核心思想，并强调仅微调soft prompts而非整个模型以避免过拟合。"
    },
    {
      "name": "理论动机与方法匹配",
      "type": "method-level",
      "purpose": "增强方法的说服力，让读者相信设计选择是合理的",
      "location": "introduction",
      "description": "结合低资源场景下的过拟合问题，阐释prompt tuning为何适合该任务，并以文献支持其有效性。"
    },
    {
      "name": "方法细节前置与可解释性强调",
      "type": "method-level",
      "purpose": "帮助读者理解方法原理和实现细节",
      "location": "introduction",
      "description": "在引言中提前解释soft prompt的概念、参数冻结等关键技术细节，降低理解门槛。"
    },
    {
      "name": "多任务/多数据集实验设计",
      "type": "experiment-level",
      "purpose": "证明方法的通用性和实验结果的充分性",
      "location": "experiments",
      "description": "在句子分类和序列标注两类任务、多个公开数据集上进行实验，覆盖不同shot数，增强实验的广泛性和说服力。"
    },
    {
      "name": "系统性对比多种基线",
      "type": "experiment-level",
      "purpose": "突出新方法的性能优势",
      "location": "experiments",
      "description": "与规则增强、自训练、PLM微调等多种主流方法系统对比，涵盖不同类型的增强方法，突出PromDA的优越性。"
    },
    {
      "name": "消融实验与细致分析",
      "type": "experiment-level",
      "purpose": "验证方法各组成部分的有效性，增强结论的可靠性",
      "location": "experiments",
      "description": "通过消融实验、性能提升分析、统计显著性检验等手段，细致剖析PromDA的贡献来源。"
    },
    {
      "name": "可视化与分组实验结果展示",
      "type": "experiment-level",
      "purpose": "提升实验结果的可读性和直观性",
      "location": "experiments",
      "description": "用表格和曲线分别展示不同shot数下的性能变化，使改进效果一目了然。"
    },
    {
      "name": "结论与动机呼应",
      "type": "writing-level",
      "purpose": "形成完整闭环，增强论文的整体逻辑性",
      "location": "experiments / discussion",
      "description": "在实验结果和讨论中反复强调PromDA如何解决引言中提出的过拟合和泛化问题，形成首尾呼应。"
    },
    {
      "name": "统计显著性检验",
      "type": "experiment-level",
      "purpose": "增强实验结论的科学性和可信度",
      "location": "experiments",
      "description": "采用配对t检验验证PromDA相较于基线的提升具有统计学意义。"
    }
  ]
}