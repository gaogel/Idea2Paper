{
  "paper_id": "ARR_2022_273",
  "title": "Generated Knowledge Prompting for Commonsense Reasoning",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究的是文本数据，聚焦于常识推理任务中的知识生成与提示方法。",
    "core_technique": "论文采用并改进了基于预训练语言模型（如Transformer架构）的知识生成与提示技术，通过生成式方法提升模型的常识推理能力。",
    "application": "论文成果可应用于对话系统、问答系统、智能助理等需要常识推理的自然语言理解场景。",
    "domains": [
      "自然语言处理",
      "常识推理",
      "人工智能"
    ]
  },
  "ideal": {
    "core_idea": "提出了一种无需结构化知识库，通过生成式知识提示提升大模型常识推理能力的方法。",
    "tech_stack": [
      "生成式知识提示（Generated Knowledge Prompting）",
      "大规模预训练语言模型",
      "few-shot学习",
      "自然语言知识生成"
    ],
    "input_type": "常识推理相关的自然语言问题或任务输入",
    "output_type": "包含生成知识提示的增强型模型推理结果"
  },
  "skeleton": {
    "problem_framing": "论文从学术gap出发引出问题，开篇即指出外部知识在常识推理中的作用尚无定论，并对比了两类主流观点：一类认为高质量外部知识有助于提升任务表现，另一类认为随着预训练模型规模增大，外部知识的增益逐渐减弱。作者进一步指出，即使外部知识有效，现有知识集的覆盖性和灵活性也存在挑战，并强调现有集成方法通常需要任务定制的监督，难以快速适配新任务。通过这些论述，论文明确了当前研究的核心痛点和未解之处。",
    "gap_pattern": "论文批评现有方法主要采用了‘现有方法在Y场景下失效’和‘现有方法忽视了X’的逻辑。具体表现为：批评现有知识集覆盖有限，难以适配多样任务；批评现有方法依赖高质量知识库和定制化监督，适应性差；指出部分方法仅对特定数据集有效，缺乏通用性。句式上频繁使用‘然而’‘但’‘即使’等转折词，强调现有方法的局限性和现实挑战。",
    "method_story": "方法部分采用‘先整体后局部’的叙述策略。首先整体介绍了Generated Knowledge Prompting的核心思想和流程（即从语言模型生成知识并作为输入提示），突出方法的灵活性和对现有模型的无缝适配。随后与模板法、检索法等现有方案进行对比，展示自身优势。最后通过具体实验结果支持方法有效性，逐步细化对比和分析，逻辑清晰、层层递进。",
    "experiments_story": "实验部分采用‘多数据集验证+多角度评测’的策略。首先在多个常识推理数据集（NumerSense、CommonsenseQA、CommonsenseQA 2.0、QASC）上进行主实验，验证方法的普适性和有效性。其次，设置了不同知识生成基线（随机句、上下文句、模板生成、检索生成）进行消融对比。最后，补充了人工评测，从语法性、相关性、事实性、帮助性四个维度对生成知识进行细致分析，提升实验的说服力和解释性。"
  },
  "tricks": [
    {
      "name": "对立观点设定",
      "type": "writing-level",
      "purpose": "增强说服力，通过展示领域内的争议引发读者兴趣并突出研究意义",
      "location": "introduction",
      "description": "作者首先列举了外部知识有助于常识推理的观点，又指出大模型可能弱化外部知识作用的现象，制造悬念，引出自己的研究问题。"
    },
    {
      "name": "引用权威工作",
      "type": "writing-level",
      "purpose": "增强说服力，通过引用领域内权威文献证明问题的重要性和方法的合理性",
      "location": "introduction",
      "description": "作者广泛引用了相关领域的代表性文献，说明外部知识整合是被广泛关注且尚未解决的问题。"
    },
    {
      "name": "方法创新点突出",
      "type": "method-level",
      "purpose": "展示新颖性，强调所提方法区别于现有方法",
      "location": "introduction / method",
      "description": "作者明确指出其方法无需结构化知识库和联合微调，提出了Generated Knowledge Prompting的关键思想，并与现有模板化和检索式方法做对比。"
    },
    {
      "name": "多任务覆盖",
      "type": "experiment-level",
      "purpose": "增强完备性，通过在多个主流数据集上实验，证明方法的通用性和有效性",
      "location": "introduction / experiments",
      "description": "作者在四个不同类型的常识推理数据集上进行实验，覆盖数值、一般和科学常识，显示方法的广泛适用性。"
    },
    {
      "name": "与主流方法直接对比",
      "type": "experiment-level",
      "purpose": "增强对比性，通过与模板生成、检索式等主流方法的系统性对比，突出自身优势",
      "location": "method / experiments",
      "description": "作者在实验中系统比较了自身方法、模板生成、自检索和检索式方法的效果，量化性能差异。"
    },
    {
      "name": "消融实验设计",
      "type": "experiment-level",
      "purpose": "增强完备性，通过消融不同知识生成方式，证明自身方法的有效性",
      "location": "method",
      "description": "作者设计了随机句子、上下文句子、模板生成等多种基线，显示只有自身方法能持续带来显著提升。"
    },
    {
      "name": "人类主观评测",
      "type": "experiment-level",
      "purpose": "增强说服力和可解释性，通过人工标注分析知识质量和作用，补充自动评测的不足",
      "location": "experiments",
      "description": "作者邀请NLP专家对生成知识的语法性、相关性、事实性和有用性进行标注，并分析其与模型表现的关系。"
    },
    {
      "name": "错误分析",
      "type": "experiment-level",
      "purpose": "增强可解释性和完备性，通过分析有害知识的成因，指导未来改进",
      "location": "experiments",
      "description": "作者分析了误导模型预测的知识多为非事实性，指出提升事实性是未来改进方向。"
    },
    {
      "name": "逻辑递进式叙事",
      "type": "writing-level",
      "purpose": "优化叙事结构，帮助读者顺畅理解问题提出、方法创新、实验验证到结论的全过程",
      "location": "introduction / method / experiments",
      "description": "作者先引出领域争议，提出问题，再介绍方法创新，最后通过多角度实验和分析呼应前文，形成闭环。"
    },
    {
      "name": "具体案例举例",
      "type": "writing-level",
      "purpose": "增强可解释性，通过具体例子帮助读者理解方法的实际操作和优越性",
      "location": "introduction / method",
      "description": "作者通过表格和案例对比展示生成知识与模板化、检索式知识的区别和优势。"
    },
    {
      "name": "多维度评测指标",
      "type": "experiment-level",
      "purpose": "增强完备性和可解释性，从多个维度系统性评估生成知识的质量与作用",
      "location": "experiments",
      "description": "作者设计了语法性、相关性、事实性、有用性等多维度主观评测指标，细致刻画知识质量。"
    }
  ]
}