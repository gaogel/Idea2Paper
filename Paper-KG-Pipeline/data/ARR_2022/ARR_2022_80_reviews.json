[
  {
    "review_id": "bb5a8e3b3e4a450f",
    "paper_id": "ARR_2022_80",
    "reviewer": null,
    "paper_summary": "This is a revision of a previously submitted article. The article discusses scoring essays holistically and scoring their single traits. \nThe article clearly contains revisions, based on my suggestions and I can also see some of the revisions, requested by the other reviewers. ",
    "strengths": "- Scoring the essay both as a whole and according to its different aspects (depending on the essay type) is a very useful contribution both for the research community and for the end-users.\n- The method and the results are interesting.\n- The authors are sharing their code and data.\n- The article is written in a very clear way.\n- The authors have addressed my suggestions and also the transformer baseline comparison pointed out by the Area Chair and one of the other reviewers ",
    "weaknesses": "I cannot see any ",
    "comments": "None ",
    "overall_score": "4 = This paper represents solid work, and is of significant interest for the (broad or narrow) sub-communities that might build on it.",
    "confidence": "3 =  Pretty sure, but there's a chance I missed something. Although I have a good feel for this area in general, I did not carefully check the paper's details, e.g., the math or experimental design."
  },
  {
    "review_id": "41ef404cc5f20855",
    "paper_id": "ARR_2022_80",
    "reviewer": "Sourav Ghosh",
    "paper_summary": "The paper discusses a multi-task learning (MTL) approach for scoring an essay text, both holistically, as well as in terms of different traits, such as content, organization, style, prompt adherence, etc. In this work, the authors treat scoring the essay traits as auxiliary tasks and scoring the essay holistically as the primary task. The architecture of the STL stack is based on the work by Dong et al. (2017). The output of individual essay traits (scores) are concatenated with the essay representation for the primary task and passed through a dense layer to predict the overall score for the essay. For the experiments, the authors use the ASAP AEG dataset, consisting of 8 essay sets, and quadratic weighted Kappa (QWK) as the evaluation metric. Along with the MTL system, where the holistic scoring is the primary task, the work evaluates alternative configurations (MTL*), where one of the essay traits is treated as the primary task and the other traits, along with the holistic scoring, are treated as auxiliary tasks. The paper also explores the speedup in overall training time and the associated cost in terms of loss in scoring the essay traits. By performing an ablation study to analyze the most important trait, this work also observes that content is the most significant trait for three of the essay sets, while prompt adherence and word choice are the most significant for the two essay sets, where they are scored.\nOverall, this is a well-written paper that explores whether training signals from the essay trait scoring tasks can be used to score a model holistically. This work can be a good example of the application of MTL in settings, where the primary task is intuitively influenced by the auxiliary tasks, but the weightage of the individual tasks in this aggregation is not definitive or well-established.\n-- The above review is based on my understanding of the previous and current submissions. Strengths, weaknesses, and scores are based on the author responses and current revised draft. ",
    "strengths": "- The paper performs a detailed analysis of whether the task of scoring an essay holistically can be better informed using the training signals from auxiliary tasks like scoring traits of the essay.\n- The work performs an ablation study to identify the most important traits that affect the holistic scoring in the MTL setting that lead to interesting observations.\n- The paper builds on top of existing research and reuses a popular dataset and the configuration of related work that can be useful for a comparative study.\n- The work can be a good example of the application of MTL in settings, where the primary task is intuitively influenced by the auxiliary tasks, but the weightage of the individual tasks in this aggregation is not definitive or well-established. ",
    "weaknesses": "The points shared in this section in my review for the previous submission have been clarified in the author responses and/or incorporated in the revised draft. Further comments follow: - Regarding the regression experiments that the authors discuss in their response, these results can perhaps be mentioned for readers' reference if space permits. The fact that MTL is more helpful than a regression w.r.t QWK metric, in a setting where the holistic score is intuitively dependent on the scores of the parts, can be a useful observation for future studies. ",
    "comments": "Suggestions in the previous submission have been addressed. ",
    "overall_score": "3.5 ",
    "confidence": "5 = Positive that my evaluation is correct. I read the paper very carefully and am familiar with related work."
  },
  {
    "review_id": "007b93f0c37668d8",
    "paper_id": "ARR_2022_80",
    "reviewer": null,
    "paper_summary": "This paper presentes a multi task learning approach for automatic grading of English essays, by considering a holistic score as well as scores on individual essay traits. The authors proposed an LSTM based model and compared single task and multi task settings to show that Multi-task learning based system gives better performance, and is also much faster than the single task setup. They also present a comparison with a BERT model, and report a series of ablation tests to understand the relationship between traits and holistic scores. ",
    "strengths": "In Automatic Essay Scoring research, it is more common to develop models for a holistic scoring, although in general, there is an agreement that a score may have many dimensions (e.g., content, spelling/grammar, organization etc). This paper is among the few papers in the direction of modeling multiple dimensions of essay scoring.\nThey performed ablation tests in the multi task learning setup, to understand what traits are useful for each set of essays - I think this is an interesting experiment I did not see before in this task's context.\nThey use a popular dataset which is publicly available and uploaded their code along with the paper. ",
    "weaknesses": "-  The paper does not seem to have any comparison with previous work on this topic at all. They directly do different experiments using their own architecture. Simple baselines (e.g., document length) that are commonly used for this problem can be used as a comparison point, in a STL setup, where the predicted variable can be different (holistic score, individual trait scores), keeping the text representation constant.\n- The paper misses a discussion on the limitations of the current approach. For example, the authors commented in the response pdf to one of the reviewers that performance difference across traits is due to topical variation. The modeling process does not have any specific component to account for such topical variations resulting in different scores. It could be a potential limitation. I am not saying a paper is bad because it has a limitation. I think acknowledging limitations gives a more holistic perspective for the reader about the approach. ",
    "comments": "I reviewed the previous version of this paper, and most of the minor comments I mentioned have been addressed in this version.  One other comment:  - How are the trait  scores obtained for the prompts that did not have them in the original dataset? The authors claim they took from another source, but understanding how they are created is relevant for this paper.  - I think having a few points of comparison to your approach will give a better perspective for us as readers. Comparison between LSTM and BERT is good, but not enough, as  this topic still has a dominant approach of combining some linguistic features with neural models, for modeling overall score. For individual traits too, predicting the trait score instead of individual score, keeping rest of the set up same, may give you a quick comparison point, and make the paper more complete. ",
    "overall_score": "3.5 ",
    "confidence": "4 = Quite sure. I tried to check the important points carefully. It's unlikely, though conceivable, that I missed something that should affect my ratings."
  }
]