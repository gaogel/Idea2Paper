{
  "paper_id": "ARR_2022_202",
  "title": "Improving Event Representation via Simultaneous Weakly Supervised Contrastive Learning and Clustering",
  "conference": "ARR",
  "domain": {
    "research_object": "该论文主要研究文本数据中的事件表示问题，关注如何更好地对文本中的事件进行表征。",
    "core_technique": "论文采用了弱监督对比学习与聚类方法，并将二者结合以提升事件表示的质量，属于深度学习与表示学习范畴。",
    "application": "论文成果可应用于事件抽取、信息检索、知识图谱构建、文本理解等自然语言处理相关场景。",
    "domains": [
      "自然语言处理",
      "表示学习",
      "事件抽取"
    ]
  },
  "ideal": {
    "core_idea": "提出了一种结合弱监督对比学习和原型聚类的方法，以更有效地利用事件共现信息学习事件表示。",
    "tech_stack": [
      "弱监督对比学习",
      "原型聚类",
      "掩码语言模型（MLM）",
      "事件共现关系建模"
    ],
    "input_type": "包含多个事件及其共现关系的文本数据",
    "output_type": "高质量的事件分布式表示向量"
  },
  "skeleton": {
    "problem_framing": "论文从学术gap出发引出问题。开篇先介绍事件分布式表示在多种任务中的重要性和挑战，强调获得有效事件表示需要捕捉事件间的多种关系。随后指出早期方法主要利用事件共现关系，但这种方式过于粗糙，难以满足对事件的深层理解需求，进而引出对更细粒度知识建模的需求。整体上，通过回顾现有方法的不足，逐步聚焦到自身关注的研究问题。",
    "gap_pattern": "论文批评现有方法主要采用‘现有方法忽视了X’和‘现有方法在Y场景下失效’的逻辑。具体表现为：指出早期方法仅利用事件共现关系，缺乏对细粒度知识的建模，难以捕捉事件间的复杂语义关系；而现有细粒度知识方法类型有限，难以覆盖所有事件知识，且人工标注成本高、难以扩展到大规模数据。此外，现有基于margin loss的对比学习方法只能处理单一正负样本，难以区分不同语义的事件。整体批评逻辑为：现有方法要么粗糙，要么覆盖有限、成本高，要么在语义区分上存在不足。",
    "method_story": "方法部分采用‘先整体后局部，分模块介绍’的策略。首先整体介绍方法框架和目标，明确提出方法包含两大部分：弱监督对比学习和基于原型的聚类。随后分别详细介绍这两部分的技术细节，最后补充引入辅助的MLM损失。整体上，先给出总览，再分模块详细展开，逻辑清晰、层次分明。",
    "experiments_story": "实验部分采用‘主实验+多任务验证’的策略。首先按照领域常规，采用两类事件相似性任务和一个迁移任务对所提方法进行分析和评估。通过多任务、多角度验证方法的有效性，体现其实用性和泛化能力。"
  },
  "tricks": [
    {
      "name": "引用权威工作",
      "type": "writing-level",
      "purpose": "增强说服力，通过引用大量相关文献证明问题的重要性和方法的有效性",
      "location": "introduction",
      "description": "作者在引言中广泛引用了领域内的权威工作，展示该领域已有的成果和不足，强化自身工作的合理性和必要性"
    },
    {
      "name": "问题递进与不足强调",
      "type": "writing-level",
      "purpose": "突出新方法的必要性，通过层层递进地指出现有方法的局限性",
      "location": "introduction",
      "description": "作者先介绍已有方法的进展，再逐步指出它们的不足，如粗粒度、知识类型有限、人工标注成本高等，为提出新方法做铺垫"
    },
    {
      "name": "图示辅助理解",
      "type": "writing-level",
      "purpose": "提升可解释性，通过图示帮助读者直观理解事件关系和方法框架",
      "location": "introduction / method",
      "description": "作者在引言和方法部分分别用图1和图2展示事件关系和方法整体框架，降低理解门槛"
    },
    {
      "name": "方法分模块介绍",
      "type": "writing-level",
      "purpose": "增强可解释性和结构清晰度，将复杂方法拆分为易于理解的模块",
      "location": "method",
      "description": "作者将方法分为弱监督对比学习和原型聚类两部分，分别介绍各自的技术细节和目标"
    },
    {
      "name": "联合损失函数设计",
      "type": "method-level",
      "purpose": "突出新颖性，通过创新的损失函数组合展示方法的独特性",
      "location": "method",
      "description": "作者提出包含对比学习、聚类和MLM三项的联合损失函数，强调方法的综合性和创新性"
    },
    {
      "name": "对比现有方法的局限",
      "type": "writing-level",
      "purpose": "增强对比性，通过具体分析现有方法的缺陷来突出自身工作的优势",
      "location": "introduction",
      "description": "作者详细分析了基于co-occurrence的对比学习方法的两个主要局限，为自身方法的改进做铺垫"
    },
    {
      "name": "任务多样性实验设计",
      "type": "experiment-level",
      "purpose": "增强完备性，通过多任务实验验证方法的广泛适用性和有效性",
      "location": "experiments",
      "description": "作者在实验部分采用事件相似性和迁移任务两类实验，展示方法在不同场景下的表现"
    },
    {
      "name": "遵循领域通用实验标准",
      "type": "experiment-level",
      "purpose": "提升说服力和可靠性，通过采用领域内通用的实验流程和基准",
      "location": "experiments",
      "description": "作者明确说明实验设计参考了主流工作，保证结果的可比性和可信度"
    },
    {
      "name": "逻辑递进式叙事结构",
      "type": "writing-level",
      "purpose": "提升整体可读性和说服力，通过清晰的逻辑流引导读者理解问题和方法",
      "location": "introduction / method / experiments",
      "description": "作者先介绍问题和挑战，再提出方法，最后用实验验证，形成完整的论证闭环"
    },
    {
      "name": "强调隐性知识利用",
      "type": "method-level",
      "purpose": "突出新颖性，强调方法对隐性事件知识的挖掘能力",
      "location": "introduction / method",
      "description": "作者指出co-occurrence关系包含隐性知识，并提出方法能更好地挖掘这些信息，体现创新点"
    }
  ]
}